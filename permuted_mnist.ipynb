{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cf/x33nxtlj1rzbqn7mh62k2v9c0000gn/T/ipykernel_244/3382429931.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(train_dataset.data)\n",
      "/var/folders/cf/x33nxtlj1rzbqn7mh62k2v9c0000gn/T/ipykernel_244/3382429931.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(train_dataset.targets)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "data = torch.tensor(train_dataset.data)\n",
    "targets = torch.tensor(train_dataset.targets)\n",
    "\n",
    "perm = torch.randperm(28*28)\n",
    "data_permuted = data.view(-1, 28*28)[:, perm].view(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = data_permuted[0], targets[0]\n",
    "\n",
    "if len(img.shape) > 2 and img.shape[0] == 1:\n",
    "    img = img.squeeze(0)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f'Label: {label}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cf/x33nxtlj1rzbqn7mh62k2v9c0000gn/T/ipykernel_244/3177233283.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(train_dataset.data)\n",
      "/var/folders/cf/x33nxtlj1rzbqn7mh62k2v9c0000gn/T/ipykernel_244/3177233283.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(train_dataset.targets)\n"
     ]
    }
   ],
   "source": [
    "permuted_datasets = []\n",
    "for i in range(2):\n",
    "  data = torch.tensor(train_dataset.data)\n",
    "  targets = torch.tensor(train_dataset.targets)\n",
    "\n",
    "  perm = torch.randperm(28*28)\n",
    "  \n",
    "  data_permuted = data.view(-1, 28*28)[:, perm].view(-1, 28, 28)\n",
    "  permuted_datasets.append((data_permuted, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[240,   0,   0,  ...,   0,   0,   0],\n",
      "         [136,  46,   0,  ...,   0,   0, 253],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 246,  85,  ...,   0,   0,   0],\n",
      "         [252,   0,   0,  ...,   0,   0, 253],\n",
      "         [238,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 165,   0,  ...,   0,  38,   0],\n",
      "         [ 54,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[241, 207,   0,  ...,   0,   0,  46],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 234, 177,  ..., 159, 248,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 241],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  26,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   6,   0,  ...,   0,   0,   0],\n",
      "         [252,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 127,   0,  ...,   0,  22,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 97,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 198],\n",
      "         [ 89,   0,   0,  ...,   0, 244,   0],\n",
      "         ...,\n",
      "         [  0, 252,   0,  ...,   0, 233,   0],\n",
      "         [  0, 177,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[249,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  35,   0],\n",
      "         ...,\n",
      "         [156,   0, 253,  ...,   0,   0,   0],\n",
      "         [ 16,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  7,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 85,   0,   0,  ...,   0, 159,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  38,   0,   0],\n",
      "         [  0,   0,   0,  ...,  25,   0,   0],\n",
      "         [ 75, 114,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[169,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  96,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 120,   0,  ...,   0,   0, 198],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [ 54,   0,   0,  ...,  26,   0,   0],\n",
      "         [  6,   0,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  9,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 28,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0,   5,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  16,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 128,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 66,   0,   0,  ...,   0,   0, 187],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 229,   0, 180],\n",
      "         [  0,   0,   0,  ..., 162,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [ 94,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 253, 255],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,  64,   0,  ..., 253,   0,  56]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  57,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 252,  ...,  71, 252,   0],\n",
      "         [  0,  85,   0,  ...,   0,  79,   0],\n",
      "         [  0, 225,   0,  ..., 253,   0, 122]],\n",
      "\n",
      "        [[ 81,   0,   0,  ...,   0, 120,   0],\n",
      "         [150,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 232],\n",
      "         [  0,   0,   0,  ...,   0, 183,   0],\n",
      "         [243,   0,   0,  ...,   0,  96, 210]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ..., 108,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 253, 213],\n",
      "         [157,   0,   0,  ...,   0,   0,   0],\n",
      "         [254,   0,   0,  ...,  52,   0,  26]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 216,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 124,  ..., 186, 143,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 31, 255,   0,  ...,  62,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  38,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 172,   0],\n",
      "         [ 73,   0,   0,  ...,   0,  92,   0],\n",
      "         [254,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[ 16, 190, 170,  ...,   0, 205, 226],\n",
      "         [  1, 148, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [132,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  93, 166],\n",
      "         [253,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,  84,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0, 252,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  96,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 253,  12,   0],\n",
      "         [  0,   0,   0,  ...,   0,  84,   0],\n",
      "         [252,   0,   0,  ...,   0, 190,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [178,   0,   0,  ...,   0, 254,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 220,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  67],\n",
      "         [254,   0,   0,  ...,   0,  47, 254]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  6, 147,   0,  ...,   0, 253, 240],\n",
      "         [  2,   0, 218,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,  27,   0],\n",
      "         ...,\n",
      "         [253,   0,   0,  ...,   0,  31,   0],\n",
      "         [  0,   0,   0,  ...,   0, 223, 121],\n",
      "         [173,   0,   0,  ...,   0,   0,  39]],\n",
      "\n",
      "        [[253, 111,   0,  ...,   0, 246,   0],\n",
      "         [  0,  22,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  18, 101,   0],\n",
      "         [  0,   0,   9,  ...,   0,   0,   0],\n",
      "         [146,   0,   0,  ...,   0, 241,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 254,  26],\n",
      "         [254,   0,  67,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 218,   0],\n",
      "         ...,\n",
      "         [134,   0,   0,  ...,   0,   4,   0],\n",
      "         [  0,   0,   0,  ...,   0, 254,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,  94],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 207,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 154,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 195,   0, 252],\n",
      "         [  0,   0,   0,  ...,   0, 208,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 173,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  25,   0,  ...,   0, 252,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 207],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 150,  ...,   0, 254,   0],\n",
      "         ...,\n",
      "         [  0, 163,   0,  ...,   0,  57,   0],\n",
      "         [153, 169,   0,  ...,   0,   0,   0],\n",
      "         [  0, 177,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  67,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 137,   0, 190],\n",
      "         [  0,   0,   0,  ...,   0, 199,   0],\n",
      "         [  0, 194,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 28,   0,   0,  ...,   0, 163,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 147,   0,  ...,   0, 143,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  92,   0],\n",
      "         [  0,  46,   0,  ...,   0, 248,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  76, 217,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   2,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 172,   0,  ..., 175,   0, 226],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 219,  14, 253],\n",
      "         [253,  43,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[252,   0,   0,  ...,   0,   0,   0],\n",
      "         [195,   0,   0,  ...,   0, 148,  50],\n",
      "         [  0,   0, 253,  ..., 252,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  48, 252],\n",
      "         [253, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 255, 252]],\n",
      "\n",
      "        [[177, 116,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 169,   0,   0],\n",
      "         [  0,   0,   0,  ..., 163, 254,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,  19,   0,  ...,   0,  69,  39],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 115,   0,  ...,   0,   0, 240],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 240, 253],\n",
      "         [ 52,   0,   0,  ...,  67,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[110,  32,   0,  ...,  63,   0,   0],\n",
      "         [137,   8,   0,  ...,   0, 232,   0],\n",
      "         [  0,   0, 236,  ..., 210,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 222],\n",
      "         [ 62,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  42]],\n",
      "\n",
      "        [[  0, 196,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 240],\n",
      "         [  0,   0, 131,  ...,   0,   0,  26],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 243],\n",
      "         [  0,  14,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 231,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0, 154, 253],\n",
      "         [  0,   0,   1,  ...,   0,   0, 253],\n",
      "         [  0,   0, 229,  ..., 154,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 186,  ...,   0,  94,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 252, 253],\n",
      "         [165, 148,   0,  ...,   0,   0,   0],\n",
      "         [  0, 249,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 252,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 178,  ...,   0,   0, 243],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,  91,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   5,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   2,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 192,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0, 254,  ...,   0,   0,  52]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 143, 128],\n",
      "         [  0, 232,   0,  ...,   0,   0,  31],\n",
      "         [  0, 196,  66,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 218,  ...,   0,   0,   0],\n",
      "         [  0,   0, 143,  ...,   0,   0,   0],\n",
      "         [  0,   0, 194,  ...,   0,   0,  62]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 217,   0],\n",
      "         [177,   0, 254,  ...,   0,   0, 254],\n",
      "         [  0, 153,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 11,   0, 181,  ...,   0,   0,   0],\n",
      "         [  0,   0, 172,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[135,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 82,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0, 221,  93,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253, 178],\n",
      "         [ 28,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 148],\n",
      "         [253,  12,   0,  ...,   0, 253,   0],\n",
      "         [225,  85,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 159,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [153,   0,   0,  ...,   0, 216, 163],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [121,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [131,  31, 157,  ..., 121,   0,   0],\n",
      "         [  0,   0, 242,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 128,   0],\n",
      "         [  0,   0,   0,  ...,   0,  84, 252],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 232],\n",
      "         [  0, 101,   0,  ...,   0,   0,   0],\n",
      "         [128, 211, 217,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[197,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 203,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 27,   4,  73,  ...,   0, 239, 199],\n",
      "         [254,  60,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  90,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 241,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [241,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0, 148],\n",
      "         [  0, 160,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0, 179,   0,  ..., 252, 165,   0],\n",
      "         [  0,   0, 252,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 57,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 254,  ...,   0, 237,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  14,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 243,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  39,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [248,   0,  39,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 148,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 236,   0,  ..., 131,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  22],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  92,   0,  ...,   0, 177,   0],\n",
      "         [  0,   0, 218,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 244,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 232,   0],\n",
      "         [  0,  63,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,  36,  ...,   0, 253,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [ 70,   0,   0,  ...,   0,   1,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 212,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[114,   0,   0,  ..., 243, 252,   0],\n",
      "         [ 63,   0,  54,  ...,   0,   0,   0],\n",
      "         [  0,   0, 255,  ...,   0, 238,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,  56,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  40,  ...,   0,   0, 159],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 28,   0,   0,  ...,   0,   0,   0],\n",
      "         [177,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 121]],\n",
      "\n",
      "        [[ 17,   0,   0,  ...,   0,  42,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,  11,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 194],\n",
      "         [  0,   0,   0,  ...,   0,   0, 106]],\n",
      "\n",
      "        [[ 67,   0,   0,  ..., 253,   0,   0],\n",
      "         [192,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  25,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 193,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0, 242,   0],\n",
      "         [  0, 154,  11,  ...,  66, 253,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0, 136],\n",
      "         [  0,   0,   0,  ...,   0, 148,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 225,   6,   0],\n",
      "         [  0, 252,  37,  ..., 252, 223,   0],\n",
      "         ...,\n",
      "         [  0, 165,   0,  ...,   0,   0, 252],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [153,   0,   0,  ...,   0, 180,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [163, 169,  81,  ...,   0,   0,   0],\n",
      "         [  0, 254,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [ 60, 253, 253,  ...,   0, 108,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 128,   0,   0],\n",
      "         [  0, 143,   0,  ..., 252,  84,   0],\n",
      "         ...,\n",
      "         [  0,  87,   0,  ...,   0,   0, 252],\n",
      "         [  0,   0,   0,  ...,   0,  22,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         [  0, 217,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [254,   0,   0,  ...,   0,   0, 105]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 64,   0,   0,  ...,   0,   0, 253],\n",
      "         [166,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ..., 135,   0,   0]],\n",
      "\n",
      "        [[ 25,   0,  57,  ...,   0,   0,   0],\n",
      "         [225,   0,   0,  ...,   0,   0, 252],\n",
      "         [  0,   0, 223,  ..., 252, 131,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 195,  ...,   0,   0,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[177,   0,   0,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 159, 254],\n",
      "         [ 67,   0,   0,  ...,  16, 254,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  56,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 173],\n",
      "         [121,   0,   0,  ...,   0, 159,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[147,   0,   0,  ...,   0,   0,   0],\n",
      "         [255,   0,   0,  ...,   0,   0, 146],\n",
      "         [  0,   0, 216,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 192],\n",
      "         [222,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 213,   0,  ..., 154,   0,   0],\n",
      "         [  0,   0,   6,  ...,  94,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [164,   0,  10,  ...,   0,   0,   0],\n",
      "         [243,   0,   0,  ..., 197, 254,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ..., 225,   0,   0],\n",
      "         [  0,   0,   0,  ..., 241,   0,   0],\n",
      "         [ 11,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 35,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 107,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 233,   0,   0],\n",
      "         [  0,  12,   0,  ..., 252,   0, 243],\n",
      "         [ 37,  57,  85,  ...,   0,   0, 246],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  51,   0,   0]],\n",
      "\n",
      "        [[252,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 231,  ...,   0,   0,  56],\n",
      "         [  0,   0,   0,  ...,   0,   0, 207],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 250,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ..., 241,   0,   0],\n",
      "         [  0,   0,   0,  ...,  39,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 205, 184,   0]],\n",
      "\n",
      "        [[252,   0,   0,  ...,  66,   0,   0],\n",
      "         [  0, 187,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  28,  ...,   0,   0,   6],\n",
      "         ...,\n",
      "         [  5,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,  48,   0,   0],\n",
      "         [  0,   0, 105,  ..., 218,   0, 253],\n",
      "         [  0,   0,  66,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 225,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0, 195,   0],\n",
      "         [ 39,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0, 253,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 80,   0,   0,  ...,  18,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[114,   0,   0,  ...,   0, 233,   0],\n",
      "         [  0,   0,   0,  ...,   0, 255,   7],\n",
      "         [  0,   0, 252,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  28,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  40, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [163,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 28,   0,   0,  ...,   0,  27,   0],\n",
      "         [  0,   0, 121,  ...,   0,   0,  39],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 161,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 17,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 11,   0,   0,  ..., 252, 253,   0],\n",
      "         [  0,   0,  42,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 192,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 67,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 86,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 116,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  90,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,  18],\n",
      "         [253,   0,  93,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   1, 253, 154],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [166,   0,   0,  ..., 253,  18,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [252,   0,  84,  ...,   0,   0,   0],\n",
      "         [ 85, 112, 243,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 238, 239,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 178, 238,   0]],\n",
      "\n",
      "        [[  0,   0, 163,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  56],\n",
      "         [  0, 253,  56,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 67,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 223,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 157,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 253, 157,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [121,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 124,   0],\n",
      "         [138,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 28, 226,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  11, 199,   0],\n",
      "         [  0,   8,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [167,   0, 254,  ...,   0,   0, 254],\n",
      "         [ 66,   0, 253,  ...,   0,  73,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  25,  48,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,  25,  ...,   0,   0,   0],\n",
      "         [  0, 154,   0,  ...,   0,   0,   0],\n",
      "         [ 80,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [253,   0, 253,  ..., 170, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [195, 252,   0,  ...,   0,   0,   0],\n",
      "         [145,   0,   0,  ..., 249,   0,   0],\n",
      "         ...,\n",
      "         [253,   0,  10,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 241,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 120,   0,  ...,   0, 234,   0],\n",
      "         [254,   0,   0,  ..., 119,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [ 98,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 52,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 237,  ...,   0,   0,   0],\n",
      "         [  0, 143,   0,  ...,   0,   0,   0],\n",
      "         [  0,  16,   0,  ..., 196,   0,   0],\n",
      "         ...,\n",
      "         [ 62,   0,   0,  ...,   0, 127,   0],\n",
      "         [  0,   0,   0,  ...,   0, 194,   0],\n",
      "         [  0,   0,   0,  ...,   0,  27,   0]],\n",
      "\n",
      "        [[  0,   0,  52,  ...,   0,   0,   0],\n",
      "         [ 10, 217,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 153,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0,  46,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[225,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,  93],\n",
      "         [  0,   0, 253,  ...,   0,   0, 182],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [119,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,  82,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,  84],\n",
      "         [112,   0, 239,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 246,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 148, 146],\n",
      "         [252,   0, 253,  ...,   0, 225,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,  57],\n",
      "         ...,\n",
      "         [ 94,   0, 207,  ...,   0,   0, 198],\n",
      "         [179,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 153,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[147,   0,   0,  ...,  60,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253, 223],\n",
      "         [  0,   0, 157,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 97,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0, 131,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 222,   0],\n",
      "         [226,   0, 199,  ...,   0,   0,  12],\n",
      "         ...,\n",
      "         [  0,   0,   6,  ...,  42,   0,   0],\n",
      "         [180,   0,   0,  ...,   0, 232, 169],\n",
      "         [143,   8,   0,  ...,   0, 252, 252]],\n",
      "\n",
      "        [[  2,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 243, 254],\n",
      "         [  0,   0,  48,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 180],\n",
      "         [146,   0,   0,  ...,   0,   0,  19],\n",
      "         [172,   0,  27,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,  45,  64,  ...,   0,   0,   0],\n",
      "         [253, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ..., 253,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   9,  ...,   0, 160,   0]],\n",
      "\n",
      "        [[148,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 57,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 96,   0,   0,  ..., 252,   0,   0],\n",
      "         ...,\n",
      "         [  0, 131,   0,  ...,   0, 168,   0],\n",
      "         [ 85,   0,   0,  ...,   0,   0, 223],\n",
      "         [ 47,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 143,   0,  ...,   0,   0, 245],\n",
      "         [120,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 243,   0,  ...,   0,  98,   0],\n",
      "         ...,\n",
      "         [  0, 254,   0,  ..., 254, 125,   0],\n",
      "         [  0, 255,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  14,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,  72, 146,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 27, 254,   0,  ..., 253,   0,   0],\n",
      "         ...,\n",
      "         [  0, 159,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 206,  ...,   0, 148,   0]],\n",
      "\n",
      "        [[232,  27,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  31,   0,  ..., 246,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 128,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 216],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 232,   0,  ...,   0,  59,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [218, 254,   0,  ..., 242, 130,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 126, 122,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   6],\n",
      "         [  0,   0,   0,  ...,   0,  63,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,  16,   0,  ...,   0,   2, 219],\n",
      "         [  0, 253,   0,  ..., 253, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,  11],\n",
      "         [  0,   0, 253,  ..., 253,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 252],\n",
      "         [  0,   0,   0,  ..., 252, 252,   0],\n",
      "         [ 86,   0, 196,  ...,   0,   0, 252],\n",
      "         ...,\n",
      "         [ 47,  71,   0,  ...,   0,   0, 190],\n",
      "         [  0,   0,  25,  ...,  54,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,  49,   0,   0],\n",
      "         [  0, 234,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 153,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,  23,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   6,   0,  ...,   0,   0,   5],\n",
      "         [242, 253,   0,  ..., 108, 164,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 147],\n",
      "         [  0,   0, 252,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[  0, 253,   0,  ..., 170,   0,   0],\n",
      "         [110, 127,   0,  ..., 216,  43,   0],\n",
      "         [ 14,   0, 242,  ...,   0,   0, 124],\n",
      "         ...,\n",
      "         [  0, 186,   0,  ...,   0,   0, 208],\n",
      "         [  0, 150,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  16,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 190,   0, 175],\n",
      "         [121, 252,   0,  ...,  38,  97,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,  97],\n",
      "         [  0,   0, 229,  ...,   0, 164,   0],\n",
      "         [ 18,   0,   0,  ...,   0,   0, 213]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [154,   0, 190,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 154,  ...,   0, 253,   0],\n",
      "         [  0, 253, 130,  ...,  18,   0,   0],\n",
      "         [  0, 241,   0,  ...,   0,   2,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ...,   7,   0,   0],\n",
      "         [228,   0,  84,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 252,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,  48,   0,   0],\n",
      "         [  0, 252, 252,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 254, 150,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [153,   0,   0,  ...,   0, 169,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  39,   0,   0],\n",
      "         [  0,   0, 147,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 253,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  39,  36,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 111,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 143,  ...,  18, 169,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 130, 164,   0],\n",
      "         ...,\n",
      "         [  0,   0, 217,  ...,  77, 219,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 218,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[ 23,   0,   0,  ...,  56,   0,   0],\n",
      "         [  0,   0,  49,  ...,   0,   0, 225],\n",
      "         [ 55,   0,  36,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 198,  ...,   0,  81,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,  46,   0,   0]],\n",
      "\n",
      "        [[252,   0,   0,  ..., 122,   0,   0],\n",
      "         [ 57,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 198, 196,  ...,   0, 130,   0],\n",
      "         [  0,   0,   0,  ..., 239,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  38]],\n",
      "\n",
      "        [[  0, 255,   0,  ..., 210,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 159,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  62],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,  26,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 147],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,  20,  ...,   0, 201,   0],\n",
      "         [  0,   0,  69,  ..., 157,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  26]],\n",
      "\n",
      "        [[252,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 199,   0,   0],\n",
      "         [  0,  55,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[165,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   2],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,  48,   0,   0],\n",
      "         [ 21,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0, 229,   0],\n",
      "         [  0, 253,   9,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  18,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  64,   0],\n",
      "         [  0, 253,   0,  ...,   0, 249,   0],\n",
      "         [  0, 253, 135,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 148,   0,  ...,   0,   0,   0],\n",
      "         [  0,  10,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 159,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 254,   0,  ...,   0, 137, 163],\n",
      "         [  0,   0,   0,  ...,   0,   0, 150]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 206,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [208,   0, 253,  ...,   0, 146,   0],\n",
      "         [  0, 173,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 232,   0,  ...,   0,  66,   0],\n",
      "         [ 28,   0,   0,  ...,  42,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 69,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 146,   0,  ...,   0, 124,   0],\n",
      "         [  0,   0,   0,  ...,   0,  27,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 154,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [101,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 197,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0, 219],\n",
      "         [  0,  55,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 247,   0,   0],\n",
      "         [  0,   0, 175,  ..., 154,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 252],\n",
      "         [  0,   0,  75,  ..., 253,   0,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 21,   0,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0, 252,  ..., 252,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  67,   0],\n",
      "         [  0, 237,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   5],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  22,   0,   0],\n",
      "         [  0,   0,   0,  ..., 117,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 129,   0,   0],\n",
      "         [138,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  16,   0,   0],\n",
      "         [  0,   0, 210,  ..., 143,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 175],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [167,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 236],\n",
      "         [  0,   0,   0,  ..., 225,   0,   0],\n",
      "         [  0,   0,   0,  ..., 217,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 172,  45,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [154,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ..., 252,   0,   0],\n",
      "         [223,  63,   0,  ..., 253,   0,   0],\n",
      "         ...,\n",
      "         [  0, 121, 168,  ...,   0, 252,   0],\n",
      "         [228,  50,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 225, 252,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 67,   0, 143,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 177,   0],\n",
      "         ...,\n",
      "         [  0,   0, 125,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 207,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 251,  72,  ...,   0,   0,   0],\n",
      "         [  0, 177,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  27,  ..., 247,   0,   0],\n",
      "         [216, 253,   0,  ..., 236,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 241,   0],\n",
      "         [  0, 190,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 128, 190,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0,  22, 232,  ...,   0,   0,   0],\n",
      "         [  6, 192,   0,  ..., 131,   0,   0],\n",
      "         ...,\n",
      "         [ 23,   0, 122,  ...,   0, 254,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 164],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  35,  ..., 154, 182, 253],\n",
      "         ...,\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0, 247,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0, 175]],\n",
      "\n",
      "        [[  0, 186,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  96,   0,   0],\n",
      "         [  0,   0,   0,  ..., 228, 253,  54],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 252,  ...,   0,   0, 178],\n",
      "         [  0,   0,   0,  ...,   0,  71, 252]],\n",
      "\n",
      "        [[153,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 159,  ...,   0, 253,   0],\n",
      "         [  0, 153,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [126,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  27,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0, 216,   0],\n",
      "         ...,\n",
      "         [  0,   0, 157,  ...,   0,   0,   0],\n",
      "         [  0,   0, 117,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 216,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   5,  ...,   0, 222,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  16,  ...,   0,   0, 252],\n",
      "         [252,   0,   0,  ...,   0, 186, 210]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 218,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 254,   0],\n",
      "         ...,\n",
      "         [  0,   0,  73,  ...,   0,   0,   0],\n",
      "         [  0,   0, 225,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   1],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 166,  ...,   0,   0,  25],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,  18,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ..., 186,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [225, 253,   0,  ...,   0,   0,   0],\n",
      "         [ 85,   0,   0,  ...,   0,  28,   0]],\n",
      "\n",
      "        [[  0, 198,   0,  ...,   0,   0, 178],\n",
      "         [  0, 163,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,  67,  ...,   0,   0, 241],\n",
      "         [  0,   0,   0,  ..., 120,   0,   0],\n",
      "         [  0,   0, 153,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   2],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253, 121,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 161,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  42,   0],\n",
      "         [  0,   0,   0,  ..., 169,   0,   0],\n",
      "         [  0,   0,   0,  ..., 216,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 237],\n",
      "         [128, 236,   0,  ...,   0,   0,   0],\n",
      "         [ 28,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 180,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ..., 219,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,  52],\n",
      "         [254, 131,   0,  ...,   0,   0,   0],\n",
      "         [ 66,   0,   0,  ...,   0,  90,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 80,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 244,  ...,   0,   0,   2],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253, 253,  ...,   0,   0, 132]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 253, 252, 243],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [145,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 252,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 252],\n",
      "         [  0,   0, 252,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  16,  56],\n",
      "         [  0,   0,   0,  ...,   0,   0,  91],\n",
      "         [  0, 126,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 198,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 177],\n",
      "         [  0,  28, 254,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 98,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 147,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 254, 173,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 128,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 191],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 129,   0,  63],\n",
      "         [  0,   0,   0,  ...,   0,   0, 110],\n",
      "         [  0, 252, 146,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  94, 253],\n",
      "         [  0,   0,  76,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 180, 244,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  60,   0,  ...,   0,   0, 134]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[ 64,   0, 172,  ...,   0,   0,   0],\n",
      "         [190,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0, 219,  ...,  78,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0, 160,   0]],\n",
      "\n",
      "        [[225,   0, 252,  ...,   0,   0,   0],\n",
      "         [ 19,   0, 165,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  56,   0,  21],\n",
      "         ...,\n",
      "         [230, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 220,   0,   0],\n",
      "         [  0,   0, 169,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 255,   0,   0],\n",
      "         ...,\n",
      "         [177,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  14,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0, 251,  ...,   0,   0,   0],\n",
      "         [253,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  74,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  22, 164,   0],\n",
      "         [  0,   0,   0,  ...,   0, 148,   0]],\n",
      "\n",
      "        [[255,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 21,   0,  87,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [252, 222,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  43,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,  22,  ...,   0,   0,   0],\n",
      "         [ 41,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 243,   0,  ..., 230,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  97,   0],\n",
      "         [  0,   0,   0,  ...,   0,  63,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0, 253,  ...,   0,   0,  46],\n",
      "         [  0,   0,   0,  ...,   0,  81,   0],\n",
      "         [  0,   0, 198,  ...,  55, 247,   0],\n",
      "         ...,\n",
      "         [  0,  16,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   1,   0],\n",
      "         [250,  93,   2,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[  0,   0,  10,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 252,  ...,   0, 252,   0],\n",
      "         ...,\n",
      "         [  0,   0,  12,  ...,   0,   0,   0],\n",
      "         [  0,  85,  71,  ...,   0,   0,   0],\n",
      "         [162,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 150, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [120,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 178,   0],\n",
      "         [254,   0, 169,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 197,   0],\n",
      "         [  0,   0, 253,  ...,   0, 117,   0],\n",
      "         ...,\n",
      "         [  0,   6,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   2,   0],\n",
      "         [173, 242, 253,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 252,  ...,   0,  16,   0],\n",
      "         ...,\n",
      "         [  0, 253, 187,  ...,   0,   0,   0],\n",
      "         [  0,  28, 186,  ...,   0,   0,   0],\n",
      "         [178, 217,   0,  ..., 169,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 244,   0],\n",
      "         [  0, 254,   0,  ...,   0,   2, 130],\n",
      "         [  0,   0, 254,  ...,   0, 225,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  66,   0,  ...,   0, 254,   0],\n",
      "         [  0,   0,   0,  ..., 219,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 172,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0, 133,   0],\n",
      "         ...,\n",
      "         [  0, 249,   0,  ...,   0,   0,   0],\n",
      "         [  0, 183,   0,  ...,   0,   0,   0],\n",
      "         [182,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0, 141,   0],\n",
      "         ...,\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [189,  48,   0,  ...,   0,   0, 252],\n",
      "         [  0,   0,   0,  ...,  75,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 252],\n",
      "         [  0,   0,  81,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 137,   0,  ...,   0,   0,   0],\n",
      "         [ 27,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 57,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0, 184,  ...,   0,   0,   0],\n",
      "         [  0, 251,   0,  ...,   0,   0,   0],\n",
      "         [  0, 147,   0,  ...,   0, 158,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 108,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [112,   0,   0,  ...,   0,   0, 252],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 124,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 124],\n",
      "         [ 12,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  22,   0,  ...,   0,   0,   0],\n",
      "         [  0, 176,   0,  ...,   0,  44,   0],\n",
      "         ...,\n",
      "         [116,   0,   0,  ...,   0,   0,   0],\n",
      "         [237,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  28]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,  18,  ...,   0,   0,   9],\n",
      "         [  0,   0, 136,  ...,   0,   0,   0],\n",
      "         [  1,   0,   0,  ...,  23,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 190,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 146],\n",
      "         ...,\n",
      "         [  0, 253,  28,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  47,   0,  ...,  46,   0, 163],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 23,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [178,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,  52, 161,  ...,   0,   0, 206],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  2,   0,   0,  ...,   0,   0,  60]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 241,   0,  ...,   0, 246,   0],\n",
      "         [  0,  42,   0,  ...,   0,   0, 169],\n",
      "         ...,\n",
      "         [  0,  62,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 242,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  19],\n",
      "         ...,\n",
      "         [  0,   0,  90,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [254,   0,   0,  ..., 165,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,  39,   0,  ...,   0,   0,   0],\n",
      "         [  0, 226,   0,  ...,   0, 190,   0],\n",
      "         [  0, 242,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 154,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 133,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  12,   0],\n",
      "         [  0,   0,   0,  ...,   0,  84,   0],\n",
      "         [  0,   6,   0,  ...,   0,   0,   7],\n",
      "         ...,\n",
      "         [  0,   0, 228,  ..., 252,   0, 253],\n",
      "         [  0,   0,   0,  ..., 141,   0,   0],\n",
      "         [159,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,  96,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [163, 180,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [198,   0,   0,  ...,   0, 126,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  31,   0],\n",
      "         [  0, 240,   0,  ...,   0, 147,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 208],\n",
      "         [  0,   0,   0,  ..., 158,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,  11,   0,  ...,   0, 101, 128],\n",
      "         [  0,   0,   0,  ...,   0, 111, 152],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,  69],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  8,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,  86,   0,  ...,   0,   4, 126],\n",
      "         [  0,  26,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  76,  ...,   0, 254,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 101],\n",
      "         [180,   0,   0,  ...,  44,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 154,   0],\n",
      "         [ 64,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   1,  ...,   0,   0,   0],\n",
      "         [253, 198,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 225,  ...,   0, 229,   0]],\n",
      "\n",
      "        [[  0,   0, 252,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [225,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 85,   0, 238,  ...,   0,   0, 253],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [ 51,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [159,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253, 253],\n",
      "         ...,\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 147,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 131,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 143,   0],\n",
      "         [255,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 28,   0,  11,  ...,   0,  28,   0],\n",
      "         [  0, 252,  16,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  66,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 217,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 66,   0,  25,  ...,   0,   0, 147],\n",
      "         [  0, 254,   0,  ...,   0,   0, 232],\n",
      "         [  0,   0,   2,  ...,   0,   0,  21]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0, 247,   0,  ...,  70, 154,   0],\n",
      "         ...,\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0, 167,  ...,   0, 228,   0],\n",
      "         ...,\n",
      "         [252,   0,   0,  ..., 198,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0, 225, 253,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 254,   0],\n",
      "         [  0, 169,   0,  ...,   0,   0,   0],\n",
      "         [  0,  39, 162,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 240,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  67,   0,  ...,   0,   0,   0],\n",
      "         [  0, 255,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [242,   0,   0,  ...,   0,   0,  60],\n",
      "         [  0,   0, 241,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  42,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 192],\n",
      "         ...,\n",
      "         [138,   0,   0,  ...,   0,   0,   0],\n",
      "         [110,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 128, 254,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 254,  ...,   0,   0,   0],\n",
      "         [  0,   0,  40,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [167,  71,   0,  ...,   0,   0,   0],\n",
      "         [121,  18,   0,  ...,   0,   0,   0],\n",
      "         [  0, 254, 198,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[212,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 126,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 107,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 183,  ...,   0, 170, 127]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  51,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  48,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 250],\n",
      "         [  0,   0,   0,  ...,   0,   0,  56],\n",
      "         [  0, 159,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 205,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 108,  ...,   0,   0, 255]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 155,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  16,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[193,   0,  59,  ..., 116,   0, 225],\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 230,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,  55,   0,   0],\n",
      "         [212,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ..., 183,   0, 249],\n",
      "         ...,\n",
      "         [  0,  46,   0,  ...,   0,   0,   1],\n",
      "         [  0,   0,   0,  ..., 229, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0, 252],\n",
      "         [  0,   0,   0,  ...,  48,   0, 252],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 238],\n",
      "         [ 86,  12,   0,  ...,   0, 215,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  29,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 137],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0, 108],\n",
      "         [  0,   0,   0,  ..., 108,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 157,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 216],\n",
      "         [  0,   0,   0,  ...,   0,   0, 124],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,  11],\n",
      "         [ 14, 187,   0,  ...,  66, 217,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [193, 203,   0,  ..., 254,   0,  38],\n",
      "         [  0,   0,   0,  ...,   0, 164,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,  25],\n",
      "         [  0,   0,   0,  ...,   0, 216,   0],\n",
      "         [  0,   0,   0,  ...,   0,  73,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,  64,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 171,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,  11, 205]],\n",
      "\n",
      "        [[ 57, 252,   0,  ...,   0, 253, 186],\n",
      "         [  0,   0,  85,  ...,   0,   0, 165],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 199,  ...,   0,   0,  25],\n",
      "         [  0,   0, 227,  ...,   0, 190, 253]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 177,  ..., 153,   0, 169],\n",
      "         [  0,   0,  23,  ...,   0,   0, 254],\n",
      "         ...,\n",
      "         [254,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 254, 177],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0, 146,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 121,   0],\n",
      "         [  0,   0,  41,  ...,   0,  15,   0],\n",
      "         [  0,   0,   0,  ...,   0, 147, 253]],\n",
      "\n",
      "        [[  0, 239,   0,  ...,   0, 252, 216],\n",
      "         [  0,   0,   0,  ...,   0,   0,  87],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 106,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 147],\n",
      "         [  0,   0,   0,  ...,   0, 208, 246]],\n",
      "\n",
      "        [[  0, 209,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 238],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 254,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  97, 254]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[253,   0,  80,  ...,   0,  11,   0],\n",
      "         [253,   0,   0,  ...,   0,  11,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [ 18,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[208,   0, 145,  ...,   0, 190,   0],\n",
      "         [  0,   0,   0,  ...,   0,  37,  79],\n",
      "         [  0,   0,   0,  ...,  50,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,  75,  54,  ...,   0,   0,   0],\n",
      "         [238,   0,   0,  ...,   0,   0, 255]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,  98,   0,   0],\n",
      "         [ 28, 153,   0,  ...,   0,   0, 183],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 254]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253,   0,  98,  ...,   0, 147,   0],\n",
      "         [254,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[199,   0,   0,  ...,   0, 208,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 190,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 18,   0,   0,  ...,  42,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 92,   0,   0,  ..., 130,  97,   0],\n",
      "         [ 60,   0,   0,  ...,   0,   0,  92],\n",
      "         [  0,   0, 162,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 231]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,  36,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   2, 253],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[253, 190,   0,  ..., 189,   0,   0],\n",
      "         [ 38,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0, 159,  50],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 128,  ...,   0,   0, 223],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[254,  47,   0,  ...,  27,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 245,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   5,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 26,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 163,  ...,   0,   0, 108],\n",
      "         [  0, 254,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 241,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  27, 222,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  55,   0,  84],\n",
      "         [  0, 194,  35,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[254,   0,   0,  ..., 237,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 243,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 240],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 249,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [253, 253,   0,  ...,   0, 198,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  18,   0,   0],\n",
      "         [175,   0, 133,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,  82, 253,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   7,   0,  ...,   0,   0,   0],\n",
      "         [252, 208,   0,  ...,   0, 196,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [252,   0, 141,  ...,  50,   0,   0],\n",
      "         [128,   0,   0,  ..., 252, 252,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 163],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 254,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   2,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,  20,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 158,  ...,   0,   0,   0],\n",
      "         [163, 242,   0,  ..., 159,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 112],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 199,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [210,   0,   0,  ..., 190,   0,   0],\n",
      "         [  0, 110, 194,  ...,   0,  42,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [229,  92,   0,  ...,   0,   0, 199],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  44,  ...,   0,   0,   0],\n",
      "         [249, 121,  46,  ..., 212,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0, 253,  ...,   0,   0,   0],\n",
      "         [166,   0,   0,  ...,  78,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,  55],\n",
      "         [  0,   0,  35,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 195,   0,   0],\n",
      "         [  0,   0,   0,  ...,  56,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0, 253,   0],\n",
      "         [  0, 252,   0,  ..., 255,   0,   0],\n",
      "         [  0,   0,  85,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[153,   0,   0,  ...,   0, 119,   0],\n",
      "         [234,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 67,   0,   0,  ..., 255,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  96,   0,   0],\n",
      "         [  0,   0,   0,  ...,  40,   0,   0],\n",
      "         [  0,   0, 177,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,  60,  ...,   0,   0,   0],\n",
      "         [121,   0,   0,  ...,  74,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   9,   0,  ...,   0,   0,   0],\n",
      "         [127,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 169,   0,  ...,   0, 236,   0],\n",
      "         [  0,   0,   5,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [252,   0,   0,  ...,  10,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 219,   0,  ...,   0, 131,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0, 253, 255,  ..., 166,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 225,  14,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 240],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0, 252],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 233,  48,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[254,   0, 232,  ...,  67,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  23,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 241],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0, 213,  ..., 121,   0,  39],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 241, 240,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  84,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  66,   0,   0],\n",
      "         [ 27,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 229],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  48,   0,   0],\n",
      "         [  4,   0,   0,  ...,   0,   0,  97],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,  39,  ...,   0,   0,   0],\n",
      "         [  0,  94,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0, 127],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 119,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [241,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 28,   0,   0,  ...,  21,   0,   0],\n",
      "         ...,\n",
      "         [ 75, 146,   0,  ..., 165,   0,   0],\n",
      "         [  0,  57,   0,  ...,   0, 225,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,  40,  ...,   0,   0,  67],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  94,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 179,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,  23,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [121,   0,   0,  ...,   0,   0, 255],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  80,  97,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [248,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 169,   0,  ...,   0, 180,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,  19,   0,  ...,   0, 146,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 130],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,  82,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   1],\n",
      "         [139,   0, 253,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   2,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 195, 253,  ...,   0,   0,   0],\n",
      "         [ 21,   0,   0,  ...,   0,   0, 238],\n",
      "         [233,   0,  60,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0]],\n",
      "\n",
      "        [[  0,   0, 153,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ..., 198, 198,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 159,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 177,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0, 131,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [253,   0,  10,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  11],\n",
      "         [226,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,  63,  ..., 230,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 110,   0]],\n",
      "\n",
      "        [[  0,  10,  27,  ...,   0,   0,   0],\n",
      "         [  0, 254,   0,  ..., 180,   4,  25],\n",
      "         [255,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 82, 253, 205,  ...,  64,   0,   0],\n",
      "         [  0, 186,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0, 253],\n",
      "         [  0,  36,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 167,   0],\n",
      "         [253, 253, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0, 121,  ..., 252,   0, 165],\n",
      "         ...,\n",
      "         [  0,  12,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0,  85, 252],\n",
      "         [  0,   0,   0,  ...,   0,   7, 252]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 162,   0],\n",
      "         [153,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  91,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 254,   0,  ...,   0, 177,   0],\n",
      "         [  0,   0,   0,  ...,   0, 254,  29]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [131,  52, 253,  ..., 146,   0,   0],\n",
      "         [  0, 192,   0,  ...,  36,   0,   0],\n",
      "         ...,\n",
      "         [  0,  31,   0,  ...,   0,   0,   0],\n",
      "         [  0, 173,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  39,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  62, 246,  ...,   0,   0,   0],\n",
      "         [  0, 218,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 101,   0,  ...,   0,   0,   0],\n",
      "         [  0, 146,   0,  ...,   0,   0,  42],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  40,   0],\n",
      "         [ 27,   0, 254,  ...,   0,   0,   0],\n",
      "         [  0, 181,   0,  ...,   0,   0, 177],\n",
      "         ...,\n",
      "         [  0,   4,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 254]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[244,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  93,   0,  ..., 253,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,  80,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[252,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 178,  85,   0],\n",
      "         [  0, 145,   0,  ..., 225,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 163,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [153,   0,   0,  ...,  94,   0,   0],\n",
      "         [  0, 240,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  67,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[147,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 242,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  98,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 230,   0,  ...,   0,   0,   0],\n",
      "         [  0, 217,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,  36,   0],\n",
      "         [  0,   0,   0,  ..., 128,   0,   0]],\n",
      "\n",
      "        [[244,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 254,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  71,   0,  ...,   0, 142,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [133,   0,   0,  ...,  56,   0,  93],\n",
      "         [  0, 221,   0,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 186,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [141,   0,   0,  ..., 122,   0,  84],\n",
      "         [  0,  85,   0,  ...,   0, 252,   0],\n",
      "         ...,\n",
      "         [  0, 252,   0,  ...,   0,  76,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [168,   0, 159,  ...,   0, 253, 243]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 254,  ..., 210,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,  29,   0,  ...,   0, 207, 163],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [125,  91,   0,  ...,   0,   0,  56]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [158,   0,   0,  ...,  26,   0, 223],\n",
      "         [  0,   0,   0,  ...,   0,   0, 157],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 192,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 211,   0,  ...,   0, 233,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  27,  ...,   0,   0,   0],\n",
      "         [  0, 218,   8,  ...,   0,  18,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 44,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0,  60,   0,  ...,   0,   0,  73],\n",
      "         ...,\n",
      "         [  0, 254,   0,  ..., 230,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [122, 181,   0,  ...,   0,   0, 253]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0, 130,   0,  ...,   9,   0,   0],\n",
      "         [ 14,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,  49],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,  47],\n",
      "         [ 48,   0,   0,  ...,   0, 252, 215],\n",
      "         [  0,   0,   0,  ...,  96,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0, 224,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 198,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  67],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [248,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ..., 206,   0,   0],\n",
      "         [240,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  27,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  94,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 247, 217],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 128,   0,   0],\n",
      "         [ 22,   0,  11,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  35,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   4,   0,  ...,   0,   0, 216],\n",
      "         [  0,   0,   0,  ..., 218,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [233,   0,  62,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [190, 253,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [229,   0,   0,  ...,   0,   0,  25],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [136,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[253, 225,   0,  ...,   0,   0,   0],\n",
      "         [249,   0,   0,  ...,   0, 238,   0],\n",
      "         [ 19,  25,   0,  ...,   0,  21,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 50,   0,   0,  ...,   0,   0,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 153],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 254, 241],\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0, 169,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0, 253,   0],\n",
      "         [253, 252,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  67,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[129, 128,   0,  ...,   0,   0,   0],\n",
      "         [196,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 21,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 66,   0,   0,  ...,   0, 128, 237],\n",
      "         [190,   0,   0,  ...,   0,   0,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 254,   0,  ...,   0,   0,   0],\n",
      "         [153,   0,   0,  ...,  28,  89,   0],\n",
      "         [ 41, 229,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 126,  52],\n",
      "         [  0,   0,   0,  ..., 187,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0, 241,  ...,   0,   0,   0],\n",
      "         [  0,  36,   0,  ...,   0, 130, 219],\n",
      "         [  2,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,  18,   0,  ...,   0, 225, 253],\n",
      "         [  0, 253, 195,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  54,   0],\n",
      "         ...,\n",
      "         [  0,  28,   0,  ...,   0, 233, 165],\n",
      "         [  0,  25, 233,  ...,   0,   0,   0],\n",
      "         [ 51,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 254,   0, 169],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0, 248,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 161,   0,  ...,  39, 241, 253],\n",
      "         [  0, 252,  27,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 128,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  66,  87],\n",
      "         [  0,   0,   0,  ...,   0, 193,   0],\n",
      "         [  0,   0,   0,  ...,   0,  18,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 126,   0,   0],\n",
      "         ...,\n",
      "         [162,  90,   0,  ...,   0,  48,   0],\n",
      "         [  0, 229,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  77,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[253,   0, 190,  ...,   0,   0, 127],\n",
      "         [  0, 187,   0,  ..., 253, 241,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  23],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 242, 249],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[253,   0,  19,  ...,   0,   0,   0],\n",
      "         [  0, 135,   0,  ..., 165,   0, 252],\n",
      "         [  0,   0,   0,  ...,   0,   0, 252],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   6,   7],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 220,   0,  ..., 169,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 180, 169],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 237,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253, 121, 253,  ...,   0,   0, 255],\n",
      "         [  0,   0,   0,  ..., 253, 248,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 253, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[169,   0,  21,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  87,   0, 233],\n",
      "         [  0,   0,   0,  ...,   0,   0, 252],\n",
      "         ...,\n",
      "         [  0, 150,   0,  ...,   0,   0,   9],\n",
      "         [  0,  35,   0,  ...,   0,   9,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  55]],\n",
      "\n",
      "        [[219,   0,  41,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 165],\n",
      "         ...,\n",
      "         [ 21,   0, 213,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 212,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  26,  ...,   0,   0,   0],\n",
      "         [  0,   0,   2,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[  0,   0, 252,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 252],\n",
      "         [  0, 223,   0,  ..., 121,  57,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252, 237,  ...,   0,   0,  75],\n",
      "         [  0,   0,   0,  ...,   0,  50,   0]],\n",
      "\n",
      "        [[169,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 220,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 120,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 159],\n",
      "         [  0,  16,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 169,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[194,   0,  36,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0, 108,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,  60,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  96,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0, 157]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 241],\n",
      "         [  0,  84,   0,  ...,   0,   0, 150],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  14,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 193,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  28,   0,   0],\n",
      "         [  0,  94,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 240,  73]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 190,  ...,  14, 253,  11],\n",
      "         [  0,   0,   0,  ...,  16, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252,  12,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,  84,  ...,  48, 252,  71],\n",
      "         [  0,   0,   0,  ...,   0,  60, 112],\n",
      "         [  0,  85,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 231,   0],\n",
      "         [254,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 153,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ..., 159, 252,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 147,  ..., 240,   0, 253],\n",
      "         [  0,   0,   0,  ..., 253,  10,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 222, 187,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 111,  ...,   0, 138, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0, 226],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 105,   0],\n",
      "         [  0, 243,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 167, 244],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,  18,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  93,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  85,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 223,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 128,  ...,   0,   0,   7]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 102,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 222],\n",
      "         [  0,  96,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 254]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253, 242,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0, 163,  ...,   0,   0,  39]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  56,   0,  ...,  28,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 217,   0],\n",
      "         ...,\n",
      "         [  0, 216,   0,  ...,   0,   0,   0],\n",
      "         [194,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  66,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   6,   0,  ...,   0,   0,   0],\n",
      "         [ 46,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 249,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  23,   0,  ...,  56,  18, 148],\n",
      "         [195,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,  82],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  25,   0,  ...,  90,   0,   0]],\n",
      "\n",
      "        [[196,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ..., 122,   0,   0],\n",
      "         [233,   0,   0,  ...,   0, 252,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  63,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 179,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 254,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ..., 210,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 163, 153],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 241,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  26,   0,   0],\n",
      "         [ 27,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 177,   0, 131],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 184,  ..., 243,   0,   0]],\n",
      "\n",
      "        [[242,   0, 128,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,  22],\n",
      "         [  0,   0,   0,  ...,   0, 239,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [152,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 237,   0,  ..., 236,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 126,  ...,   0,   0,   0],\n",
      "         [  0, 165,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 209,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 192,   0,  27],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 21,  52,   0,  ...,  92,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0, 148,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  11,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 205,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253, 247],\n",
      "         [  0,   0,   0,  ...,  46,  90, 253]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 190,   0],\n",
      "         [  0, 252,   0,  ..., 148, 253,   0],\n",
      "         ...,\n",
      "         [ 57,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 208, 252],\n",
      "         [  0,   0,   0,  ...,   0, 179,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  16,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,  94,   0,  ...,   0,  56, 144],\n",
      "         [  0,   0,   0,  ...,  62,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 147,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 253,   0, 120],\n",
      "         [  0,   0,   0,  ...,   0, 253, 117],\n",
      "         [  0,   0, 253,  ...,   0, 243,   0]],\n",
      "\n",
      "        [[  0,  22,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 208,   0],\n",
      "         [  0,   0,   0,  ..., 232, 129,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 246,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 199,  16],\n",
      "         [  0,   0,   0,  ...,   0, 236,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  59,   0,  ...,   0,  97,   0],\n",
      "         [  0,  94,   0,  ...,   0,   0, 154],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 254, 254,  14],\n",
      "         [  0,   0,   0,  ...,   0,  92, 225],\n",
      "         [  0, 203,   0,  ...,   0,  92,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[182,   0,   0,  ...,   0,  43,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  80,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  16,  ...,   0, 154,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[253,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0, 165,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 85,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,  12]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 150,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [169,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[216,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0, 253,   0],\n",
      "         [ 67,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[222,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  28,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [152,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 64,   0,   0,  ...,   0, 143,   0],\n",
      "         [  0,   0,   0,  ...,   0, 138, 187]],\n",
      "\n",
      "        [[254,   0,   0,  ...,   0,  14,   0],\n",
      "         [  0,   0,   0,  ...,   0, 177,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  76,   0],\n",
      "         [  0,   0,   0,  ...,   0, 217,   0],\n",
      "         [  0,   0,   0,  ...,   0, 167,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  1,   0,   0,  ...,   0,   0,  24],\n",
      "         [  0, 187,   0,  ...,  11,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 139,   0],\n",
      "         [  0, 253,   0,  ..., 247,   0, 253],\n",
      "         [  0,   0,   0,  ..., 240,   0,   0]],\n",
      "\n",
      "        [[238,   0,   0,  ...,   0,   0,  48],\n",
      "         [  0, 135,   0,  ...,  37,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0, 190,   0,  ..., 145, 233,   0],\n",
      "         [  0, 208, 253,  ..., 252,   0,  60],\n",
      "         [  0,   0,   0,  ...,   0,   0,  75]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [163, 220,   0,  ...,   0,   0,  49],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,  47,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 254,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 241,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 242],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [ 69, 253,   0,  ..., 117,   0,  10],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[ 11,   0,   0,  ...,   0,   0,  82],\n",
      "         [  0,   0,   0,  ...,   0,   0, 170],\n",
      "         [  0,   0,   0,  ...,   0, 112, 110],\n",
      "         ...,\n",
      "         [  0, 241,   0,  ..., 110, 226,   0],\n",
      "         [  0, 199,   0,  ...,  16,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 25,   0,   0,  ...,   0,   0,  19],\n",
      "         [  0,   0,   0,  ...,   0,   0, 190],\n",
      "         [  0,   0,   0,  ...,   0,   0, 121],\n",
      "         ...,\n",
      "         [232,   0,   0,  ..., 110, 255,   0],\n",
      "         [  0,  92, 254,  ..., 225,   0,   0],\n",
      "         [  0,   0,   0,  ...,  97,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[207,   0,   0,  ...,   0,  18,   0],\n",
      "         [253, 253,   0,  ...,   0, 226, 253],\n",
      "         [  0,   0,   1,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  14,   0,  ...,   0,   0,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[173,   0, 178,  ...,   0,  48,   0],\n",
      "         [252,   0,   0,  ...,   0,   0, 252],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  48,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[ 57,   0,   0,  ...,   0,   0, 159],\n",
      "         [  0,   5,   0,  ...,   0,   0,   0],\n",
      "         [  0, 254, 178,  ..., 150,   0,   0],\n",
      "         ...,\n",
      "         [  0, 159,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 144],\n",
      "         [102,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253, 254,   0,  ...,   0, 240,   0],\n",
      "         [  0,   0,   2,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 240,   0,  ...,   0,   0, 120],\n",
      "         [253,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[163,   0,   0,  ...,   0,   0,   0],\n",
      "         [222, 194,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  18,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 56,   0,   0,  ...,   0,  18,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [243,   0,   0,  ...,   0,  26, 229],\n",
      "         [  0,   0, 254,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  77,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  14],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[ 35, 213, 139,  ...,   0, 107,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  94,   0,  ...,  11,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 253,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ..., 249, 133, 247],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 229, 233,  ...,   0,  51,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  71,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253, 253,  ...,   0, 208,   0],\n",
      "         [225,   0,   0,  ...,   7, 141,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [254,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 153,  ..., 169,   0,  39],\n",
      "         [  0,   0, 159,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253,   0, 253,  ...,   0, 205,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   6],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 147,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ..., 253, 158, 255],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  5, 253, 226,  ...,   0,   0,   0],\n",
      "         [233,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         ...,\n",
      "         [  0, 236,   0,  ...,   0, 199,   0],\n",
      "         [128,   0,   0,  ...,   9,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,  14, 255,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 244,   0,   0],\n",
      "         ...,\n",
      "         [  0, 131, 222,  ...,   0,  92,   0],\n",
      "         [254,   0,   0,  ...,   0,  44,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[249, 187,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  18,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253, 171],\n",
      "         ...,\n",
      "         [  0,   0, 198,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  49],\n",
      "         [ 55, 253,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  7, 135,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 238,  ...,   0,   0, 253],\n",
      "         [  0,   0, 252,  ...,   0, 253, 199],\n",
      "         ...,\n",
      "         [  0,   0, 196,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,  51,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[169, 220, 120,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  91],\n",
      "         [  0,   0,  16,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 198,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,  41],\n",
      "         ...,\n",
      "         [  0,   0,  20,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 147,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  9,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 191],\n",
      "         [  0,   0,   0,  ...,   0, 169,   0],\n",
      "         ...,\n",
      "         [230,   0,   0,  ...,   0,   0,  18],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 232,   0,   0],\n",
      "         [  0,   0,  94,  ...,   0, 219, 254],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 176,   0,  ..., 180, 244,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [ 55,   0,   0,  ...,   0,   0, 166],\n",
      "         [ 30,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  23,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[252,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0, 223,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 225],\n",
      "         [ 85,   0, 252,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [120,   0, 216,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 119,   0,  67],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 150,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 108,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 121],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[247,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  84,  27],\n",
      "         ...,\n",
      "         [  0,  28,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 128],\n",
      "         [ 36,   0, 252,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 164],\n",
      "         [  0,   0, 239,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [142,   0, 165,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[ 27,   0,   0,  ...,  18,   0,   0],\n",
      "         [  0, 135,   0,  ...,   0, 107,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 23,   0, 253,  ..., 242,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   3],\n",
      "         [ 11,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,  12],\n",
      "         [  0,   0,   0,  ...,   0,  51,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [252,   0,  10,  ...,   6, 252,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [190,   0,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[250, 159,   0,  ...,   0,  49,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 180,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 169,   0],\n",
      "         [  0,   0,   0,  ...,   0, 216,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,  31],\n",
      "         [  0, 253,   0,  ...,   0, 205,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0, 194,   0],\n",
      "         [147,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 84,   0,   0,  ...,   0, 170, 101],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  42,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [252,   0,   0,  ...,   0, 233,   0],\n",
      "         [  0, 222,   0,  ...,   0,   0,   0],\n",
      "         [208,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 190,   4],\n",
      "         [  0, 197, 254,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [165,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 243,   0,  ...,   0,   0,   0],\n",
      "         [ 97,   0,   0,  ...,   0, 239,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[190,   0,   0,  ...,  11,   0,   0],\n",
      "         [  0,   0,   0,  ..., 136,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,  16,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 19,  71,   0,  ...,  71,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  85],\n",
      "         [  0,   0,   0,  ...,   0,   0, 252],\n",
      "         ...,\n",
      "         [  0,   0, 253,  ..., 253,   0,   0],\n",
      "         [  0, 252, 243,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 254,   0,  ...,   0,   0,   0],\n",
      "         [  0, 159,   0,  ...,   0,   0, 207],\n",
      "         ...,\n",
      "         [ 62,   0,   0,  ...,   0,   0,  56],\n",
      "         [  0,   0,  56,  ...,   0,   0,   0],\n",
      "         [  0,   0, 237,  ...,   0,   0, 254]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 147,   0,  ...,   0,   0,   0],\n",
      "         [  0,   6,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 21, 186,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  64],\n",
      "         [  0,   0,   0,  ...,   0,   0, 190],\n",
      "         ...,\n",
      "         [  0,   0,  84,  ..., 128,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 41,   0,   0,  ..., 244,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0, 176, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 147]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0, 212,  ...,   0, 219,  35],\n",
      "         [150,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 127,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0, 253,  ...,   0, 253,   0],\n",
      "         [  0,  14, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,  38, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 114,   0],\n",
      "         [  0,  48, 208,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [233,   0,   0,  ...,   0,   0,   0],\n",
      "         [119,   0,   0,  ...,   0,   0, 234],\n",
      "         ...,\n",
      "         [  0,   0,  28,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0, 253,  ...,  26,   5, 253],\n",
      "         [ 40,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 255,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0, 254,  ...,   0,   0,   0],\n",
      "         [  0, 240, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   5],\n",
      "         [162,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 127],\n",
      "         ...,\n",
      "         [  0,   0, 252,  ..., 152, 128,   0],\n",
      "         [  0,   0, 199,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  16,   0,   0]],\n",
      "\n",
      "        [[  0,   7, 193,  ...,   0, 175,   0],\n",
      "         [  0,   0, 154,  ...,   0, 164, 162],\n",
      "         [  0,   0,   0,  ...,   0,   0, 252],\n",
      "         ...,\n",
      "         [  0,   0,  60,  ...,   0,   0,   0],\n",
      "         [  0,   0,  92,  ..., 130,   0,   0],\n",
      "         [  0,   0, 244,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ..., 253,   0, 171],\n",
      "         [253,   0,   0,  ..., 108, 150,  11],\n",
      "         [  0,   0, 253,  ..., 247, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   3,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  18,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[  0, 243,   0,  ..., 252, 252, 199],\n",
      "         [178,   0,   0,  ...,   0,   0,  37],\n",
      "         [  0,   0, 208,  ...,   0, 128, 189],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[  0,  56,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  86, 233,   0],\n",
      "         [  0,   0,   0,  ...,  39,   0,  27],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 207,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,  41],\n",
      "         [  0,   0,   0,  ...,  91,  40, 253],\n",
      "         [  0,   0, 253,  ..., 255, 163,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  52]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,  42, 124,   0],\n",
      "         [252,   0,   0,  ...,   0, 162,   0],\n",
      "         [  0,   0, 199,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 190,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  62]],\n",
      "\n",
      "        [[  0, 253,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ..., 180,   0,   0],\n",
      "         [154, 254,  92,  ...,   0, 249, 237],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  21,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 175],\n",
      "         ...,\n",
      "         [195,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 223,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  75],\n",
      "         [  0,   0,   0,  ...,   0,   0, 252],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 252,  ...,   0, 252,  96],\n",
      "         [114,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 254,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 39,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ..., 108,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [242,   0,   0,  ..., 157,   0,   0],\n",
      "         [  0,   0,  36,  ...,   0,   0,  27],\n",
      "         [ 28,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,  84,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 210],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 247,   0],\n",
      "         [ 17,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   7,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  73,   0, 203],\n",
      "         [  0,   0,   0,  ..., 116,   0, 218],\n",
      "         [ 67,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [190,   0,   0,  ..., 172,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0, 242]],\n",
      "\n",
      "        [[253, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 19,   0,   0,  ..., 252,   0,   0],\n",
      "         ...,\n",
      "         [243,   0,   0,  ..., 189,   0,   0],\n",
      "         [195,   0,  71,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 163, 230,   6]],\n",
      "\n",
      "        [[254,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  28,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 56,   0,   0,  ...,  27, 153,   0],\n",
      "         [  0, 163,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 177, 180]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0, 147,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         [253,   0,   0,  ..., 251,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 121,   0,  ..., 102,   0, 253]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0],\n",
      "         [ 21,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [137,   0, 186,  ...,   0,   0,   0],\n",
      "         [  0, 106,   0,  ...,   0, 252,   0]],\n",
      "\n",
      "        [[254, 176,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  60,   0,   0],\n",
      "         [ 41,   0,   0,  ...,  22,   0,   0],\n",
      "         ...,\n",
      "         [253,   0,   0,  ..., 237,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   3, 154,  ...,   0,   0, 130],\n",
      "         [ 94,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  18,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,  76,  ...,   0,  96,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 230,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 207,  ...,   0,   0,  98],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  96,   0,  ..., 177,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 120,  ...,   0, 254,   0],\n",
      "         [153,   0,   0,  ..., 254,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  27,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [121,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,  18,  ...,   0,   0, 128],\n",
      "         [106,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 128,   0, 192]],\n",
      "\n",
      "        [[  0, 230,   0,  ...,   0, 218, 130],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,  77,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 248,   0],\n",
      "         [  0,   0,   0,  ..., 126,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   1,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [253,   0,   1,  ...,   0, 139,   0],\n",
      "         [  0,   0, 150,  ...,   0,   0,   0],\n",
      "         [  0, 182,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [252,   0, 238,  ...,   0, 233,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  50,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 178,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 126],\n",
      "         ...,\n",
      "         [  0,  62,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 233,  ...,   0,   0,   0],\n",
      "         [  0,  57,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   2,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 253,  ...,   0, 253,   0],\n",
      "         [  0,   0,  40,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,  11,  ...,   0, 226,   0],\n",
      "         [  0,   0, 162,  ...,   0,   0,   0],\n",
      "         [  0,  12,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 254,   0],\n",
      "         [  0,   0, 254,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [229,   0,  25,  ...,   0, 255,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 240,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ..., 249,  43,   0],\n",
      "         [  0, 154,   0,  ...,  26,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  39,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 21,   0,   0,  ...,   0, 121,   0],\n",
      "         [224,   0,   0,  ...,   7, 253,   0],\n",
      "         [  0, 252,   0,  ..., 237,   0, 163],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 186],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 169,   0,   0],\n",
      "         [  0,   0, 144,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 163,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 94,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0, 253, 120,  ...,  96,   0, 102],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 11,   0,   0,  ...,   9,   0,   0],\n",
      "         [  0, 143,   0,  ...,  14,   0,   0],\n",
      "         ...,\n",
      "         [  9,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 216],\n",
      "         [  0,   0,  11,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,  11,   0,   0],\n",
      "         [ 62,   0,   0,  ...,   0,  14,   0],\n",
      "         [  0, 217,  14,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  86,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [ 25,   0, 195,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 190],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 108, 253,   0],\n",
      "         [  0, 255,  70,  ..., 253,   0,   0],\n",
      "         [ 11,   0,   0,  ...,   0, 249,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  50,   0],\n",
      "         [  0,  47, 233,  ...,   0,   0,   0],\n",
      "         [255,   0,   0,  ...,   0,   0,  19],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  54,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0, 249],\n",
      "         [190,   7,   0,  ...,   0,   7,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [241,   0,   0,  ...,   0,   0,   0],\n",
      "         [254,   0,   0,  ...,   0, 153,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  86,   0,   0],\n",
      "         [254, 232,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 169, 231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,  60,   0,   0],\n",
      "         [  0,   0,  27,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  91,   0,   0],\n",
      "         [ 39, 213,   0,  ...,   0,   0,   0],\n",
      "         [147,   0,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [237,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  21],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 196],\n",
      "         [208,   0,   0,  ...,   0,   9,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 240,   0],\n",
      "         [ 52,   0,   0,  ...,  59,   0,   0],\n",
      "         [231,   0,   0,  ...,   0,   0,  41],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 180,   0,   0],\n",
      "         [  0,   0,   0,  ...,  18,   0, 153],\n",
      "         [ 97,   0,   0,  ...,   0,   0, 105]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[253,   0, 253,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [182,   0, 195,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  18,   0,  ...,   0,   0, 253],\n",
      "         [107,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[223,   0, 239,  ...,   0, 243,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 198,  ...,   0, 253, 253],\n",
      "         [  0, 238,   0,  ...,   0,   0, 252],\n",
      "         [ 51,   0,   0,  ...,   0,  85,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  56,   0],\n",
      "         [  0,   0,   0,  ...,   0, 159,   0],\n",
      "         [ 57, 163,  39,  ...,   0,   0, 163],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 254,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 243,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[108,   0, 157,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0, 242,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 255,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [205,   0,   0,  ..., 254,   0,   0]],\n",
      "\n",
      "        [[ 84,   0, 199,  ..., 150,   0,   0],\n",
      "         [138,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 12,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,  18],\n",
      "         [  0,   0,   0,  ...,   0,   0, 143],\n",
      "         [  0,   0,   0,  ...,  31,   0,   0]],\n",
      "\n",
      "        [[  0,   0,  48,  ...,   0, 253,   0],\n",
      "         [167,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 199],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 248,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 172],\n",
      "         [  0,   0,   0,  ..., 254,   0, 254]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[229,   0,   0,  ...,  81,   0, 166],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,  18],\n",
      "         [  0,  27,   0,  ...,   0,   0,  93],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0, 178,   0],\n",
      "         [  0, 224,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  57,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 150,   0,  67],\n",
      "         [  0, 163,   0,  ...,  46,   0,   0],\n",
      "         [153,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 163,   0,  ...,   0,   0,   0],\n",
      "         [  0, 250,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ..., 197,   0, 121],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  94,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 242],\n",
      "         [  0,   0, 184,  ...,   0, 241,   0]],\n",
      "\n",
      "        [[ 66,   0,   0,  ...,   0, 247,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,  11,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   9,  ...,   0,   0,   0],\n",
      "         [  0,  84,   0,  ...,   0,   0, 217],\n",
      "         [  0,   0,   0,  ...,   0, 254,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   2,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  62,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  23,   0],\n",
      "         [  0,   0,   0,  ...,   0, 198,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,  56],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [119,   0, 253,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 182,   0,   0],\n",
      "         [  0,   0,   0,  ...,  66,   0, 172],\n",
      "         [  0,   0,   0,  ..., 198,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  50, 122],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 239,  ...,   0,   0, 252],\n",
      "         ...,\n",
      "         [196,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 210],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [179,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,  26],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 97,   0, 157,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 216,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 115],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 190,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [180,   0, 199,  ...,   0,   0, 124],\n",
      "         ...,\n",
      "         [242,   0,   0,  ..., 222,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [146,   0,  48,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[160,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,  14,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 189],\n",
      "         [252,   0,   0,  ...,  48,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,  54,   0,  ...,   0,   0, 223],\n",
      "         [  0,   0,   0,  ...,   0,   0, 243],\n",
      "         [ 76,   0,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[ 14,   0, 222,  ...,   0,   0,  27],\n",
      "         [  0,   0,   0,  ...,   0,   0,  91],\n",
      "         [  0,   0, 150,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  62,   0,  56],\n",
      "         [207,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[148,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ..., 240,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  60,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [143,   0,   0,  ...,   0,   0, 191],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 216],\n",
      "         [  0,   0, 194,  ...,   0,  16,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  18]],\n",
      "\n",
      "        [[ 63,   0,   0,  ..., 218,   0, 237],\n",
      "         [172,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 162],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   6],\n",
      "         [  0,   0,  46,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ..., 203,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[221,   0, 253,  ...,   0,   0,   0],\n",
      "         [ 16,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  82,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  39, 253, 219],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 36,   0,   0,  ...,   0,   0, 107]],\n",
      "\n",
      "        [[ 85,   0, 252,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ..., 195,   0,   0],\n",
      "         [148,   0,   0,  ..., 252,   0, 159],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 239,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  51]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 159,   0,  ...,   2,   0,   0],\n",
      "         ...,\n",
      "         [ 62,   0, 254,  ...,  40,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 159,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  23, 157,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 205]],\n",
      "\n",
      "        [[211,   0,  42,  ...,   0,   0,   0],\n",
      "         [  0,  18,   0,  ..., 137,   0,   0],\n",
      "         [232,   0,   0,  ...,   0,   0, 252],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 199,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 60,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 212,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  48,   0],\n",
      "         [ 18,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[253, 249,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  18,   0,   0],\n",
      "         [  0,   0, 201,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  39,   0,   0],\n",
      "         [253, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   7,  21,  ...,  25,   0,   0],\n",
      "         [  0,   0,  47,  ...,   0,   0,   0],\n",
      "         [  0,   0, 167,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [224,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 169,   0,  ..., 177, 150,   0],\n",
      "         [198,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 169,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  40,   0, 120],\n",
      "         [  0,  28,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  23,   0,   0],\n",
      "         [ 94, 254,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   9,   0,  ..., 147,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 16,   0,   7,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 11, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  4,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 62,  60,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[253,   0,   0,  ...,   0, 183,   0],\n",
      "         [  0,   2,   0,  ..., 253,   0,   0],\n",
      "         [  0, 253, 253,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 60,   0,   0,  ...,   0,  48,   0],\n",
      "         [  0,   0,   0,  ..., 238,   0,  85],\n",
      "         [  0,   7, 252,  ...,   0,  79,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 165,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 254,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 254,   0,  ...,   0, 183,   0],\n",
      "         ...,\n",
      "         [159,   0,   0,  ...,   0, 119,   0],\n",
      "         [  0, 216,   0,  ...,   0,  28,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 10,   0,   0,  ...,   0, 108,   0],\n",
      "         [  0,   0,   0,  ..., 108,   0,   0],\n",
      "         [  0,  39, 164,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 254,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  63,   0,  ..., 206,   0,  28],\n",
      "         [  0,   0,  43,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  66],\n",
      "         [  0,   0,  97,  ...,   0,  92,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 177,   0,   0],\n",
      "         [  0, 239,   0,  ...,   0,  60,   0],\n",
      "         [  0, 244,   0,  ...,   0, 254,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 187,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ..., 195,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 171,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,  18,   0,  ...,   0, 249,   0]],\n",
      "\n",
      "        [[  0, 163,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 135,  ..., 131, 255,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 199,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [121,  48,   0,  ...,   0, 252,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 220,  ..., 254,  40,   0],\n",
      "         [  0,   0, 250,  ...,  39,   0,   0],\n",
      "         ...,\n",
      "         [119,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 243,   0, 163],\n",
      "         [  0,   0,   0,  ...,   0, 137,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0, 102,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 159,   0,   0],\n",
      "         [  0,   0,   0,  ..., 242,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  41,   0,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  31,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 124,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 213,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 225,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0, 253,   0,  ...,  80,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [ 45,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 252, 252,  ..., 145,   0,  38],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0, 230,  63],\n",
      "         ...,\n",
      "         [  0, 252,   0,  ...,   0,  50, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 85,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 177,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [143,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 255,   0,  ...,  91,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,  98,   0,  26],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   3,   0,  ...,   0,   0, 177],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [ 72,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 247,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252, 253],\n",
      "         ...,\n",
      "         [  0, 143,   0,  ...,   0,   0, 129],\n",
      "         [ 27,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 64,   0,   0,  ..., 191,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  28,   0,   0],\n",
      "         [  0,  92,   0,  ...,   0,   0, 192],\n",
      "         ...,\n",
      "         [  0, 172, 244,  ...,   0, 240,   0],\n",
      "         [232,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0, 135,  ...,   0,   0,  39],\n",
      "         [  0,   0,   0,  ...,   0,   2,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  23, 171],\n",
      "         [  0,   0,   0,  ..., 201, 150,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 165,  ...,   0,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 253, 252, 196],\n",
      "         [  0,   0,   0,  ...,   0, 252, 199],\n",
      "         [  0,   0,   0,  ..., 167,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  56,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 248, 243,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 96,   0,   0,  ..., 169, 233,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[184,   0, 253,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 108,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 254,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  41],\n",
      "         [  0,   0,   0,  ..., 253,  40,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,  11],\n",
      "         [  0,   0,   0,  ...,   0,  63,   0],\n",
      "         [  0, 216,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,  22,  31,  ...,   0, 239, 242],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   7, 162,   0]],\n",
      "\n",
      "        [[  0,   0, 197,  ...,  92,   0,  86],\n",
      "         [  0, 254, 177,  ...,   0,   0,   0],\n",
      "         [  0,  38,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 233, 254,  ..., 254, 209,   0],\n",
      "         [  0,   0,   0,  ...,   0, 165, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  78,  ...,   0, 190,   0],\n",
      "         [ 25,   0,  23,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [241,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 133,   0,   0],\n",
      "         [ 82,   0,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 159,   0,   0],\n",
      "         [  0,   0,  56,  ...,   0,  19,   0],\n",
      "         [  0,   0, 252,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [252, 249,   0,  ...,   0,   0,   0],\n",
      "         [255, 146,   0,  ..., 141,   0, 186],\n",
      "         [253,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 237,  ...,   0,   0,   0],\n",
      "         [  0,   0, 255,  ...,   0,   0,   0],\n",
      "         [241,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 220,   0,   0],\n",
      "         [ 40,   0,   0,  ...,   0,   0,   0],\n",
      "         [153,   0,   0,  ...,   0,   0, 234]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  74,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 39,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 158,   0,   0],\n",
      "         [131,   0,   0,  ...,   0,   0, 253]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  21,   0],\n",
      "         [237,   0, 252,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 196,   0,  ...,   0,   0,   0],\n",
      "         [253, 169,   0,  ...,   0,   0, 216],\n",
      "         [  0,   0,  27,  ...,   0,   0, 127]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,  41,   0],\n",
      "         [ 52,   0, 165,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [218, 153,   0,  ...,   0,   0,   0],\n",
      "         [  0,  19,   0,  ...,  44,   0,   0],\n",
      "         [ 27,   0,   0,  ...,   0,   0, 252]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0, 249,   0,  ...,   0,   0, 139],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ..., 160,   0,   0],\n",
      "         ...,\n",
      "         [126,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 244,   0,   0],\n",
      "         [  0, 108,  56,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 252,   0,  ...,   0,   0, 233],\n",
      "         [  0,   0,   0,  ...,   0,   0, 195],\n",
      "         [  0,   0, 225,  ...,   0, 190,   0],\n",
      "         ...,\n",
      "         [252,   0,   0,  ...,   0,  51,   0],\n",
      "         [  0,   0,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0, 122,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 137,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  14,  47,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  86, 210,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ..., 253, 253,   0],\n",
      "         [  0,   0,   0,  ..., 148,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 147,   0,   0],\n",
      "         [  0,  91,  26,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 124,   0,  ...,   0,   0, 226],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 252,  ...,   0, 241,   0],\n",
      "         ...,\n",
      "         [155,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  27]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 255],\n",
      "         [  0,   0,   0,  ...,   0,   0,  10],\n",
      "         [  0,   0,   0,  ...,  63,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 244,   0,   0],\n",
      "         [  0, 180,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[253,   0,   0,  ...,   0, 253, 253],\n",
      "         [253,   0,   0,  ...,   0,   0,  35],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 90, 119,   0,  ..., 198,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  24, 132],\n",
      "         [  0,   1,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[253,   0,   0,  ..., 252, 252,   0],\n",
      "         [ 10,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 146,   0],\n",
      "         ...,\n",
      "         [179,   0,   0,  ..., 196, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,  48,   0],\n",
      "         [  0, 238,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 179,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 52,   0,   0,  ...,   0, 218,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [243,  97,   0,  ...,  20,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 62,   0,   0,  ..., 131,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   5],\n",
      "         [  0,   0,   0,  ...,   0, 169,   0],\n",
      "         ...,\n",
      "         [236, 180,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   0,  82,   0],\n",
      "         [152,  11,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  67,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  19,   0],\n",
      "         ...,\n",
      "         [ 92, 146,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  19, 134],\n",
      "         [  0,  25,   0,  ...,   0,   7,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  18,  ..., 195,   0,   0],\n",
      "         [ 25,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 253,  ...,   0,  11,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 246],\n",
      "         [  0,   0,  28,  ..., 233,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 190,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0, 114,   0,  ..., 189,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 207],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [241,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  46, 177,   0],\n",
      "         [  0,   0,   0,  ...,  27, 254,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 161,  ...,  27,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 147,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  28,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   6],\n",
      "         [ 27,   0,   0,  ...,   0,   0,   0],\n",
      "         [237,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 208,   0],\n",
      "         [  0,   0,   8,  ...,   0, 110,   0],\n",
      "         [  0,  17,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  90,  ...,   0,   0,   0],\n",
      "         [ 52,   0, 244,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  97,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  67,   0,  ..., 237,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0, 225,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0, 241,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,  85],\n",
      "         [  0,   0,   0,  ..., 195,   0,   0],\n",
      "         [  0,  85,   0,  ...,   0, 238,   0],\n",
      "         ...,\n",
      "         [  0,   0, 252,  ...,   0,   0,  76],\n",
      "         [ 75, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 215,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 177,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 207],\n",
      "         [  0,   0,   0,  ...,   0,   0,  85],\n",
      "         [198,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0, 147,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0,  39,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 230,   0,  36],\n",
      "         [  0,   0,   0,  ..., 137,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 233,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 217,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   2,  ...,   0, 203, 142],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  23,  ...,   0,  89,   0],\n",
      "         ...,\n",
      "         [  0,   0, 218,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  4,   0,   0,  ..., 216,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[253,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,  90,  66,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  26,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 252,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0, 179, 252,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 86,   0,   0,  ..., 237,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 198,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 126,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [253, 243,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  96,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,  42,   0,   0],\n",
      "         [  0, 222,   0,  ...,   0,   0,   0],\n",
      "         [  0, 236, 252,  ..., 192,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  27,   0,   0],\n",
      "         [ 14,   0,   0,  ...,  14,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 244],\n",
      "         [  0, 243,   0,  ...,   0,   4,   0],\n",
      "         [  0,  92,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 203,   0,  ...,   0,   0,   0],\n",
      "         [  0,  92,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 218,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[ 18,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 171,   0,  ...,  35,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 198],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  16,   0],\n",
      "         [  0, 219, 253,  ...,   0,   0,   0],\n",
      "         [  0, 132,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[238,   0,   0,  ...,   0, 230,   0],\n",
      "         [  0, 199,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 252],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  7, 252, 252,  ...,   0,   0, 255],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 177,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [159,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 163,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  40],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  41,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   5, 147,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,   0,  ...,   5,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 252],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 254,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         ...,\n",
      "         [  0,   0, 199,  ...,   0,   0, 254],\n",
      "         [  0, 175, 176,  ...,   0,   0,   0],\n",
      "         [  0, 134,   0,  ..., 218,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[225,   0,  93,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 212,   0,  18],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [242,   0, 107,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 251,   0]],\n",
      "\n",
      "        [[  0,   0,  84,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 238],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [ 50,   0,   0,  ..., 243,   0,   0],\n",
      "         [  6,   0,  51,  ...,  25,   0,   0],\n",
      "         [252,   0,   0,  ...,   0, 202, 145]],\n",
      "\n",
      "        [[  0, 254,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  96,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,  28,   0,  ...,  56,  46, 177],\n",
      "         [180,   0,   0,  ..., 177,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[147,   0, 223,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 254,   0,  ...,   0,   0,   0],\n",
      "         [253,   0, 205,  ...,   0,   0,   0],\n",
      "         [ 36,   0,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  42,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 236, 194],\n",
      "         ...,\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 147,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  62, 110]],\n",
      "\n",
      "        [[  2,   0, 254,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 193,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 131,   0],\n",
      "         ...,\n",
      "         [240,  60,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 254, 110]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0, 253,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 182,   0],\n",
      "         [ 25,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [253,   0,  80,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 244,   0,  ...,  23, 253,   0]],\n",
      "\n",
      "        [[  0, 215,   0,  ..., 208,   0,   0],\n",
      "         [  0,   0, 112,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 195,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  57],\n",
      "         [240, 252,   0,  ..., 252, 252,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [241,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  5,   0,   0,  ...,   0,   0,   0],\n",
      "         [163,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 216,   0],\n",
      "         [  0,   0,  60,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [254,   0,   0,  ...,  60,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [222, 147,   0,  ...,   0, 253,   0]],\n",
      "\n",
      "        [[  0, 217,   0,  ..., 199,   0,   0],\n",
      "         [  0,   0, 226,  ...,   0, 222,   0],\n",
      "         [237,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [194,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [254,   0,   0,  ..., 252, 143,   0]],\n",
      "\n",
      "        [[  0, 216,   0,  ...,  92,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 254,   0],\n",
      "         [ 52,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,  10,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [167, 244,   0,  ..., 165, 172,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,  26,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 166,   0,  ...,   0,   0,   0],\n",
      "         [  0, 150,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [178, 237,   0,  ...,   0,   0,   0],\n",
      "         [  0, 225,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,  25],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,  23,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 177],\n",
      "         [  0,  67,   0,  ...,   0,   0,   0],\n",
      "         [  0, 233,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  96,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 121,   0,  ...,   0, 208,   0],\n",
      "         [ 36,  40,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [252,  14,   0,  ...,   0,   0,   0],\n",
      "         [  0, 128,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,  28,   0,  ...,   0,   0, 147],\n",
      "         [  0,   0,   0,  ...,   0,  69,   0],\n",
      "         [  0, 162,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 254,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 101,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0, 253, 253,  ...,   0,   0, 253],\n",
      "         [  0,   0, 242,  ...,   0,   0,  45],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0, 253, 253]],\n",
      "\n",
      "        [[  0, 165, 252,  ...,   0,   0,   0],\n",
      "         [  0,   0,   6,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  57,   0],\n",
      "         ...,\n",
      "         [ 47,   0, 252,  ...,   0,   0,   0],\n",
      "         [165,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,  10, 255,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 169, 254,  ...,   0,   0,   5],\n",
      "         [  0,   0, 180,  ...,   0,   0, 143],\n",
      "         [  0,   0,   0,  ...,   0, 120,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,  85,   0,   0],\n",
      "         [ 67,   0,  40,  ...,   0, 243,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0, 253, 173,  ...,   0,   0, 254],\n",
      "         [  0,   0, 253,  ...,   0,   0,  72],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 254,   0]],\n",
      "\n",
      "        [[  0,  87, 146,  ...,   0,   0, 194],\n",
      "         [  0,   0,   0,  ...,   0,   0,  27],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 239,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 253,  ...,   0,  31,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  21,   0],\n",
      "         [  0,   0,   0,  ..., 218,   0, 232],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 209,  ...,   0,   0, 238],\n",
      "         [177,   0, 254,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 254,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 18,   0,   0,  ..., 253,   0, 250],\n",
      "         [  0,   0, 166,  ...,   0, 139,   0],\n",
      "         ...,\n",
      "         [187,   0, 130,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0, 212],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,  63,   0],\n",
      "         [ 48,   0,   0,  ...,   0,   0, 162],\n",
      "         [  0,   0,   0,  ...,   0, 233,   0],\n",
      "         ...,\n",
      "         [135, 243,   0,  ...,   0,   0,   0],\n",
      "         [  7, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 165,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 159,   0,  ...,   0,   0,   0],\n",
      "         [  0, 126,   0,  ..., 243,   0, 254],\n",
      "         [  0,   0,  67,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [220,  56,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 177,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0, 173],\n",
      "         [  0,   0, 121,  ...,   0, 253,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0, 253],\n",
      "         [  0,   0,  80,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0,   0,   0,  ...,  31,   0, 178],\n",
      "         [  0,   0,   0,  ...,   0, 226,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 169,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 192,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 255,   0],\n",
      "         ...,\n",
      "         [  0, 253,   0,  ...,   0,   0,   0],\n",
      "         [  0, 219,   0,  ...,   0,   0, 193],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0, 253,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   3,   0,  ...,   0,  14,   0],\n",
      "         ...,\n",
      "         [  0,   0, 253,  ...,   0,   0,   0],\n",
      "         [136, 253,   0,  ...,   0, 130,   0],\n",
      "         [108,  39,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[240,  85,   0,  ..., 252,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  48,   0],\n",
      "         ...,\n",
      "         [  0,   0, 252,  ...,   0, 253,   0],\n",
      "         [252,   7,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,  28,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 159,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 254,   0,  ...,   0,   0,  81],\n",
      "         [  0, 254,   0,  ...,  23,   0,   0],\n",
      "         [ 86,  40,   0,  ...,   0,   0, 254]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[222,   0, 254,  ..., 173,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 240,   0],\n",
      "         ...,\n",
      "         [  0,  15, 253,  ...,   0,   0,   0],\n",
      "         [  0,  39,   0,  ...,   0,   0,   0],\n",
      "         [ 91,  23, 253,  ...,   0,   0,  39]],\n",
      "\n",
      "        [[254,  64, 252,  ..., 146,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  18],\n",
      "         ...,\n",
      "         [  0,   0, 143,  ...,   0, 112,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[167,   0,  60,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 203],\n",
      "         [  0,   0,   0,  ...,   0,   0,  77],\n",
      "         ...,\n",
      "         [  0,   0, 172,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [180,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 136,   0,  ...,   0,   0,   0],\n",
      "         [  0, 250,   0,  ...,   0, 253, 240],\n",
      "         ...,\n",
      "         [253,   0, 182,  ...,   0,   0,  81],\n",
      "         [212,   0,   0,  ...,  90,   0,   0],\n",
      "         [229,   0, 225,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[238,   0,   0,  ..., 195,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0, 162,   0,  ...,   0, 252,   0],\n",
      "         ...,\n",
      "         [252,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 179,   0,   0],\n",
      "         [  0, 253,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 198,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 254,   0,  ...,   0,   0, 241],\n",
      "         ...,\n",
      "         [  0,   0,  57,  ...,   0,   0, 150],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[108,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 173,   0,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [164,   0,   0,  ...,   0,   0, 197],\n",
      "         [253,   0,   0,  ..., 243,   0,   0],\n",
      "         [  0,   0, 147,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[206,   0,   0,  ..., 137,   0,   0],\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0, 178,   0,  ...,   0, 138,   0],\n",
      "         ...,\n",
      "         [ 43,   0,  12,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 236,   0,   0],\n",
      "         [ 66,  84,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   4,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 236, 167,  97],\n",
      "         ...,\n",
      "         [ 97,   0,   0,  ...,   0,   0,   2],\n",
      "         [193,   0,   0,  ...,  92,   0,   0],\n",
      "         [  0,   0,   2,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[ 18,   0,   0,  ..., 253,   0,   0],\n",
      "         [ 18,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  39],\n",
      "         [126, 136,   0,  ...,   0,   9,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ...,   0,   0, 208],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 253, 255],\n",
      "         [  0,   0, 252,  ...,   0,   0,   0],\n",
      "         [252,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 254,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0, 163,  ...,   0,   0, 254],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0, 121,  ...,   0, 242,   0],\n",
      "         [  0,   0,   0,  ...,  39,   0,   0],\n",
      "         [ 52,   0,   0,  ...,   0,   0, 253],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 206,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 128, 110,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 62,   0,   0,  ...,   0,   0, 199],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0, 129,   0],\n",
      "         [  0,   0, 239,  ..., 193,   0,  11],\n",
      "         [155,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0, 121,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  92],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0, 231],\n",
      "         [  0,   0, 209,  ...,   0,   0,  86],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[135,   0,   0,  ..., 253, 241,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [253,   0,   0,  ..., 127,   0,  16],\n",
      "         ...,\n",
      "         [253,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 252, 253,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 165,   0,  ...,   0, 252,   0],\n",
      "         [  0,   0,  75,  ...,   0,   0,   0],\n",
      "         [ 28, 186,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0, 252,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 223,   0],\n",
      "         [  0,   0,   0,  ...,   0, 159,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ..., 243,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 102,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,  67]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[253,   0, 196,  ..., 254,  39,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [121,   0,   0,  ..., 255,   0, 253],\n",
      "         ...,\n",
      "         [157,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253, 108,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,  31,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 216,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,  16,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,  56,  84,   0],\n",
      "         [  0,   0,   0,  ...,   0, 252,   0]],\n",
      "\n",
      "        [[197, 177,   0,  ..., 254, 218,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [ 73,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,   0,  66,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0, 198],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 252,  ...,   0, 253,   0],\n",
      "         [165,   0,   0,  ..., 163, 190,   0],\n",
      "         [ 79,   0,   0,  ...,   0,   0, 196],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  38,  ...,   0,   0,   0],\n",
      "         [  0,   0, 252,  ..., 252,   0,   0]],\n",
      "\n",
      "        [[  0, 163,   0,  ...,   0, 216,   0],\n",
      "         [  0,   0,   0,  ...,   0,  47,   0],\n",
      "         [183,   0, 169,  ..., 153,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 163,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 102,   0,   0],\n",
      "         [  0,   0,  67,  ...,   0,   0,  20],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,  26,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 253,   0,   0]],\n",
      "\n",
      "        [[  0,   0, 252,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 241,   0],\n",
      "         [  0,  55,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0, 233,  ..., 246,   0,  16]],\n",
      "\n",
      "        [[ 11,   0,   0,  ...,   0, 239, 254],\n",
      "         [177,   0,   0,  ...,   0,   0,   0],\n",
      "         [ 92,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 116,   0,  ..., 242, 232,   0]]], dtype=torch.uint8)\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8]) tensor([[[  0,  93,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [  0, 229,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 133, 186,   0],\n",
      "         [  0,   0,   0,  ...,   0, 253,   0],\n",
      "         [241,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0, 253],\n",
      "         [253,   0,   0,  ..., 196,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [246,   0,   0,  ..., 141,   0,   0],\n",
      "         [252,   0,   0,  ...,   0,  60,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ..., 163,   0,   0],\n",
      "         ...,\n",
      "         [207,   0,   0,  ...,   0,  91,   0],\n",
      "         [ 29,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0, 242,   0,  ..., 196,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,  60,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ..., 158, 192,   0],\n",
      "         [  0,   0,   0,  ...,   0,  10,   0],\n",
      "         [248,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0, 217,  27,  ...,   0,   0, 112],\n",
      "         [ 18,   0,   0,  ..., 242,   0,   0],\n",
      "         [  0,  66,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  6,   0,   0,  ...,   0, 218,   0],\n",
      "         [  0,   0,   0,  ...,  27,   0, 252],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0, 162,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,  44, 181,   0],\n",
      "         [254,   0,   0,  ...,   4,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "permuted_datasets[3][1][2]\n",
    "for batch_idx, (x,y) in enumerate(permuted_datasets):\n",
    "  print(y,x)\n",
    "\n",
    "# list of datasets, which are tuples (data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FFNet, self).__init__()\n",
    "\n",
    "        # Input layer\n",
    "        self.input = nn.Linear(28*28, 100)\n",
    "\n",
    "        # Hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(3):\n",
    "            self.hidden_layers.append(nn.Linear(100, 100))\n",
    "\n",
    "        # Output layer\n",
    "        self.output = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.input(x))\n",
    "        for i in range(3):\n",
    "            x = F.relu(self.hidden_layers[i](x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset):\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for i in range(len(dataset)):\n",
    "      x = dataset[i][0].float().unsqueeze(0)\n",
    "      y = dataset[i][1].long().unsqueeze(0)\n",
    "      y_pred = model(x)\n",
    "      correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "  return correct / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_2(model, optimizer, datasets, loss_fn, epochs=1):\n",
    "  training_data = [[0 for i in range(epochs)] for j in range(len(datasets))] \n",
    "\n",
    "  model.train()\n",
    "  for batch_idx, (xs, ys) in enumerate(datasets):\n",
    "    train_test_split = int(len(xs)*0.8)\n",
    "    train_dataset = xs[:train_test_split]\n",
    "    test_dataset = xs[train_test_split:]\n",
    "    print('Dataset', batch_idx)\n",
    "    for epoch in range(epochs):\n",
    "      for i in range(len(train_dataset)):\n",
    "        x = train_dataset[i].float().view(-1, 28*28)\n",
    "        y = ys[i].long().view(-1)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_data[batch_idx][epoch] += loss.item()\n",
    "      training_data[batch_idx][epoch] /= len(train_dataset)\n",
    "      print('Epoch', epoch, 'Loss', training_data[batch_idx][epoch])\n",
    "    test_accuracy = evaluate(model, test_dataset)\n",
    "    print('Task ' + str(batch_idx) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "\n",
    "  return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working code, I think\n",
    "def train_1(model, optimizer, datasets, loss_fn, epochs=1):\n",
    "  training_data = [[0 for i in range(epochs)] for j in range(len(datasets))] \n",
    "\n",
    "  model.train()\n",
    "  for batch_idx, (xs, ys) in enumerate(datasets):\n",
    "    print('Dataset', batch_idx)\n",
    "    for epoch in range(epochs):\n",
    "      data, target = xs.float(), ys.long()\n",
    "      optimizer.zero_grad()\n",
    "      output = model(data)\n",
    "      loss = loss_fn(output, target)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # if epoch % 10 == 0:\n",
    "      pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "      correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "      accuracy = correct / target.size(0)\n",
    "      training_data[batch_idx][epoch] = accuracy\n",
    "      # if epoch % 10 == 0:\n",
    "      print(f'Epoch: {epoch}, Loss: {loss.item()}, Training Accuracy: {accuracy}')\n",
    "  return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_3(model, optimizer, datasets, loss_fn, epochs=1, test_size=0.2):\n",
    "    training_data = [[0 for i in range(epochs)] for j in range(len(datasets))] \n",
    "    model.train()\n",
    "    for batch_idx, (xs, ys) in enumerate(datasets):\n",
    "        print('Dataset', batch_idx)\n",
    "        # Split the dataset into training and validation sets\n",
    "        train_xs, val_xs, train_ys, val_ys = train_test_split(xs, ys, test_size=test_size)\n",
    "        for epoch in range(epochs):\n",
    "            data, target = train_xs.float(), train_ys.long()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Evaluate on the validation set\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_data, val_target = val_xs.float(), val_ys.long()\n",
    "                val_output = model(val_data)\n",
    "                val_pred = val_output.argmax(dim=1, keepdim=True)\n",
    "                val_correct = val_pred.eq(val_target.view_as(val_pred)).sum().item()\n",
    "                val_accuracy = val_correct / val_target.size(0)\n",
    "            model.train()\n",
    "            training_data[batch_idx][epoch] = val_accuracy\n",
    "            print(f'Epoch: {epoch}, Loss: {loss.item()}, Validation Accuracy: {val_accuracy}')\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0\n",
      "Epoch: 0, Loss: 3.162961006164551, Validation Accuracy: 0.15458333333333332\n",
      "Epoch: 1, Loss: 2.46479868888855, Validation Accuracy: 0.22858333333333333\n",
      "Epoch: 2, Loss: 2.1624653339385986, Validation Accuracy: 0.32033333333333336\n",
      "Epoch: 3, Loss: 2.0087671279907227, Validation Accuracy: 0.4081666666666667\n",
      "Epoch: 4, Loss: 1.8764721155166626, Validation Accuracy: 0.5009166666666667\n",
      "Epoch: 5, Loss: 1.742108702659607, Validation Accuracy: 0.5574166666666667\n",
      "Epoch: 6, Loss: 1.6072598695755005, Validation Accuracy: 0.6050833333333333\n",
      "Epoch: 7, Loss: 1.4769988059997559, Validation Accuracy: 0.63975\n",
      "Epoch: 8, Loss: 1.354759693145752, Validation Accuracy: 0.6745\n",
      "Epoch: 9, Loss: 1.243640422821045, Validation Accuracy: 0.6968333333333333\n",
      "Epoch: 10, Loss: 1.1460198163986206, Validation Accuracy: 0.7169166666666666\n",
      "Epoch: 11, Loss: 1.0697118043899536, Validation Accuracy: 0.69525\n",
      "Epoch: 12, Loss: 1.0553239583969116, Validation Accuracy: 0.6030833333333333\n",
      "Epoch: 13, Loss: 1.26009202003479, Validation Accuracy: 0.41525\n",
      "Epoch: 14, Loss: 1.9447650909423828, Validation Accuracy: 0.5273333333333333\n",
      "Epoch: 15, Loss: 1.403375267982483, Validation Accuracy: 0.674\n",
      "Epoch: 16, Loss: 1.0798616409301758, Validation Accuracy: 0.7329166666666667\n",
      "Epoch: 17, Loss: 0.9221370220184326, Validation Accuracy: 0.7660833333333333\n",
      "Epoch: 18, Loss: 0.834510087966919, Validation Accuracy: 0.77325\n",
      "Epoch: 19, Loss: 0.7947856187820435, Validation Accuracy: 0.7573333333333333\n",
      "Epoch: 20, Loss: 0.7887500524520874, Validation Accuracy: 0.7481666666666666\n",
      "Epoch: 21, Loss: 0.8116623759269714, Validation Accuracy: 0.7188333333333333\n",
      "Epoch: 22, Loss: 0.8471806049346924, Validation Accuracy: 0.7220833333333333\n",
      "Epoch: 23, Loss: 0.8501600027084351, Validation Accuracy: 0.74125\n",
      "Epoch: 24, Loss: 0.7930607795715332, Validation Accuracy: 0.7818333333333334\n",
      "Epoch: 25, Loss: 0.7038208842277527, Validation Accuracy: 0.812\n",
      "Epoch: 26, Loss: 0.6349759697914124, Validation Accuracy: 0.8286666666666667\n",
      "Epoch: 27, Loss: 0.5862364172935486, Validation Accuracy: 0.8391666666666666\n",
      "Epoch: 28, Loss: 0.5583828091621399, Validation Accuracy: 0.8453333333333334\n",
      "Epoch: 29, Loss: 0.5352981686592102, Validation Accuracy: 0.84875\n",
      "Epoch: 30, Loss: 0.5202429890632629, Validation Accuracy: 0.8513333333333334\n",
      "Epoch: 31, Loss: 0.5067224502563477, Validation Accuracy: 0.8530833333333333\n",
      "Epoch: 32, Loss: 0.49777254462242126, Validation Accuracy: 0.8533333333333334\n",
      "Epoch: 33, Loss: 0.49160531163215637, Validation Accuracy: 0.8523333333333334\n",
      "Epoch: 34, Loss: 0.4900614023208618, Validation Accuracy: 0.84725\n",
      "Epoch: 35, Loss: 0.5028840899467468, Validation Accuracy: 0.8303333333333334\n",
      "Epoch: 36, Loss: 0.5245099663734436, Validation Accuracy: 0.7961666666666667\n",
      "Epoch: 37, Loss: 0.6242833137512207, Validation Accuracy: 0.7594166666666666\n",
      "Epoch: 38, Loss: 0.7203146815299988, Validation Accuracy: 0.716\n",
      "Epoch: 39, Loss: 0.9247302412986755, Validation Accuracy: 0.7734166666666666\n",
      "Epoch: 40, Loss: 0.7497445344924927, Validation Accuracy: 0.8423333333333334\n",
      "Epoch: 41, Loss: 0.5108091235160828, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 42, Loss: 0.4614817202091217, Validation Accuracy: 0.874\n",
      "Epoch: 43, Loss: 0.429854154586792, Validation Accuracy: 0.8775\n",
      "Epoch: 44, Loss: 0.4171338975429535, Validation Accuracy: 0.8800833333333333\n",
      "Epoch: 45, Loss: 0.40764889121055603, Validation Accuracy: 0.8813333333333333\n",
      "Epoch: 46, Loss: 0.40027132630348206, Validation Accuracy: 0.8833333333333333\n",
      "Epoch: 47, Loss: 0.39403536915779114, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 48, Loss: 0.3888666033744812, Validation Accuracy: 0.886\n",
      "Epoch: 49, Loss: 0.38447466492652893, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 50, Loss: 0.3809156119823456, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 51, Loss: 0.3780641555786133, Validation Accuracy: 0.88775\n",
      "Epoch: 52, Loss: 0.3762524425983429, Validation Accuracy: 0.8871666666666667\n",
      "Epoch: 53, Loss: 0.37532031536102295, Validation Accuracy: 0.8868333333333334\n",
      "Epoch: 54, Loss: 0.37626996636390686, Validation Accuracy: 0.8846666666666667\n",
      "Epoch: 55, Loss: 0.3784947097301483, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 56, Loss: 0.3844490945339203, Validation Accuracy: 0.87975\n",
      "Epoch: 57, Loss: 0.3924369215965271, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 58, Loss: 0.40755560994148254, Validation Accuracy: 0.8655\n",
      "Epoch: 59, Loss: 0.4234820604324341, Validation Accuracy: 0.85725\n",
      "Epoch: 60, Loss: 0.44898882508277893, Validation Accuracy: 0.8465833333333334\n",
      "Epoch: 61, Loss: 0.4642619490623474, Validation Accuracy: 0.8459166666666667\n",
      "Epoch: 62, Loss: 0.47411003708839417, Validation Accuracy: 0.8523333333333334\n",
      "Epoch: 63, Loss: 0.45073381066322327, Validation Accuracy: 0.86975\n",
      "Epoch: 64, Loss: 0.4159832298755646, Validation Accuracy: 0.8839166666666667\n",
      "Epoch: 65, Loss: 0.37558215856552124, Validation Accuracy: 0.8943333333333333\n",
      "Epoch: 66, Loss: 0.35042423009872437, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 67, Loss: 0.336151659488678, Validation Accuracy: 0.90325\n",
      "Epoch: 68, Loss: 0.32860663533210754, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 69, Loss: 0.3238457143306732, Validation Accuracy: 0.9046666666666666\n",
      "Epoch: 70, Loss: 0.3204227089881897, Validation Accuracy: 0.90475\n",
      "Epoch: 71, Loss: 0.31755557656288147, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 72, Loss: 0.3150072693824768, Validation Accuracy: 0.9063333333333333\n",
      "Epoch: 73, Loss: 0.31264519691467285, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 74, Loss: 0.31041276454925537, Validation Accuracy: 0.9070833333333334\n",
      "Epoch: 75, Loss: 0.3082793354988098, Validation Accuracy: 0.908\n",
      "Epoch: 76, Loss: 0.30622628331184387, Validation Accuracy: 0.908\n",
      "Epoch: 77, Loss: 0.3042408227920532, Validation Accuracy: 0.9081666666666667\n",
      "Epoch: 78, Loss: 0.3023141622543335, Validation Accuracy: 0.9089166666666667\n",
      "Epoch: 79, Loss: 0.30044057965278625, Validation Accuracy: 0.90875\n",
      "Epoch: 80, Loss: 0.298617422580719, Validation Accuracy: 0.9094166666666667\n",
      "Epoch: 81, Loss: 0.29684317111968994, Validation Accuracy: 0.9094166666666667\n",
      "Epoch: 82, Loss: 0.2951134741306305, Validation Accuracy: 0.9100833333333334\n",
      "Epoch: 83, Loss: 0.2934214770793915, Validation Accuracy: 0.9096666666666666\n",
      "Epoch: 84, Loss: 0.2917715311050415, Validation Accuracy: 0.9104166666666667\n",
      "Epoch: 85, Loss: 0.29016247391700745, Validation Accuracy: 0.9106666666666666\n",
      "Epoch: 86, Loss: 0.28858521580696106, Validation Accuracy: 0.9111666666666667\n",
      "Epoch: 87, Loss: 0.28704240918159485, Validation Accuracy: 0.9116666666666666\n",
      "Epoch: 88, Loss: 0.28552883863449097, Validation Accuracy: 0.9119166666666667\n",
      "Epoch: 89, Loss: 0.28404757380485535, Validation Accuracy: 0.9124166666666667\n",
      "Epoch: 90, Loss: 0.28259724378585815, Validation Accuracy: 0.91225\n",
      "Epoch: 91, Loss: 0.28117260336875916, Validation Accuracy: 0.9128333333333334\n",
      "Epoch: 92, Loss: 0.2797732949256897, Validation Accuracy: 0.9131666666666667\n",
      "Epoch: 93, Loss: 0.27840137481689453, Validation Accuracy: 0.9133333333333333\n",
      "Epoch: 94, Loss: 0.2770567238330841, Validation Accuracy: 0.9135\n",
      "Epoch: 95, Loss: 0.2757352888584137, Validation Accuracy: 0.9135833333333333\n",
      "Epoch: 96, Loss: 0.27443283796310425, Validation Accuracy: 0.9140833333333334\n",
      "Epoch: 97, Loss: 0.27315089106559753, Validation Accuracy: 0.9145833333333333\n",
      "Epoch: 98, Loss: 0.2718888819217682, Validation Accuracy: 0.915\n",
      "Epoch: 99, Loss: 0.2706468403339386, Validation Accuracy: 0.9153333333333333\n",
      "Dataset 1\n",
      "Epoch: 0, Loss: 3.6935274600982666, Validation Accuracy: 0.11933333333333333\n",
      "Epoch: 1, Loss: 3.658820629119873, Validation Accuracy: 0.25625\n",
      "Epoch: 2, Loss: 2.5817573070526123, Validation Accuracy: 0.22783333333333333\n",
      "Epoch: 3, Loss: 2.1542201042175293, Validation Accuracy: 0.3395\n",
      "Epoch: 4, Loss: 1.859973669052124, Validation Accuracy: 0.42791666666666667\n",
      "Epoch: 5, Loss: 1.7147821187973022, Validation Accuracy: 0.4995833333333333\n",
      "Epoch: 6, Loss: 1.5866841077804565, Validation Accuracy: 0.49616666666666664\n",
      "Epoch: 7, Loss: 1.5002671480178833, Validation Accuracy: 0.5503333333333333\n",
      "Epoch: 8, Loss: 1.4274049997329712, Validation Accuracy: 0.5196666666666667\n",
      "Epoch: 9, Loss: 1.3900245428085327, Validation Accuracy: 0.57475\n",
      "Epoch: 10, Loss: 1.3202255964279175, Validation Accuracy: 0.5726666666666667\n",
      "Epoch: 11, Loss: 1.2733579874038696, Validation Accuracy: 0.6536666666666666\n",
      "Epoch: 12, Loss: 1.123065710067749, Validation Accuracy: 0.656\n",
      "Epoch: 13, Loss: 1.063199758529663, Validation Accuracy: 0.6985833333333333\n",
      "Epoch: 14, Loss: 0.9815632104873657, Validation Accuracy: 0.6895\n",
      "Epoch: 15, Loss: 0.9685388207435608, Validation Accuracy: 0.6934166666666667\n",
      "Epoch: 16, Loss: 0.9593687057495117, Validation Accuracy: 0.6713333333333333\n",
      "Epoch: 17, Loss: 0.999387800693512, Validation Accuracy: 0.6604166666666667\n",
      "Epoch: 18, Loss: 1.0166622400283813, Validation Accuracy: 0.6871666666666667\n",
      "Epoch: 19, Loss: 0.970986545085907, Validation Accuracy: 0.7288333333333333\n",
      "Epoch: 20, Loss: 0.8503825068473816, Validation Accuracy: 0.7664166666666666\n",
      "Epoch: 21, Loss: 0.7641438841819763, Validation Accuracy: 0.7698333333333334\n",
      "Epoch: 22, Loss: 0.7267490029335022, Validation Accuracy: 0.7675833333333333\n",
      "Epoch: 23, Loss: 0.7300247550010681, Validation Accuracy: 0.7330833333333333\n",
      "Epoch: 24, Loss: 0.7810472249984741, Validation Accuracy: 0.72725\n",
      "Epoch: 25, Loss: 0.8159140348434448, Validation Accuracy: 0.6925833333333333\n",
      "Epoch: 26, Loss: 0.856634259223938, Validation Accuracy: 0.77\n",
      "Epoch: 27, Loss: 0.7096381187438965, Validation Accuracy: 0.8035833333333333\n",
      "Epoch: 28, Loss: 0.6231896877288818, Validation Accuracy: 0.8251666666666667\n",
      "Epoch: 29, Loss: 0.5765278935432434, Validation Accuracy: 0.834\n",
      "Epoch: 30, Loss: 0.5516046285629272, Validation Accuracy: 0.8388333333333333\n",
      "Epoch: 31, Loss: 0.5335199236869812, Validation Accuracy: 0.84225\n",
      "Epoch: 32, Loss: 0.5200608968734741, Validation Accuracy: 0.84475\n",
      "Epoch: 33, Loss: 0.5083068609237671, Validation Accuracy: 0.84725\n",
      "Epoch: 34, Loss: 0.49942871928215027, Validation Accuracy: 0.848\n",
      "Epoch: 35, Loss: 0.4914076030254364, Validation Accuracy: 0.8488333333333333\n",
      "Epoch: 36, Loss: 0.48712629079818726, Validation Accuracy: 0.8490833333333333\n",
      "Epoch: 37, Loss: 0.48405390977859497, Validation Accuracy: 0.8446666666666667\n",
      "Epoch: 38, Loss: 0.488228976726532, Validation Accuracy: 0.8438333333333333\n",
      "Epoch: 39, Loss: 0.49504056572914124, Validation Accuracy: 0.8296666666666667\n",
      "Epoch: 40, Loss: 0.517961859703064, Validation Accuracy: 0.8275833333333333\n",
      "Epoch: 41, Loss: 0.5396690368652344, Validation Accuracy: 0.8048333333333333\n",
      "Epoch: 42, Loss: 0.5788968801498413, Validation Accuracy: 0.8230833333333333\n",
      "Epoch: 43, Loss: 0.5575746297836304, Validation Accuracy: 0.8229166666666666\n",
      "Epoch: 44, Loss: 0.5390568375587463, Validation Accuracy: 0.8558333333333333\n",
      "Epoch: 45, Loss: 0.47244516015052795, Validation Accuracy: 0.8585833333333334\n",
      "Epoch: 46, Loss: 0.4474314749240875, Validation Accuracy: 0.8719166666666667\n",
      "Epoch: 47, Loss: 0.4256296455860138, Validation Accuracy: 0.87275\n",
      "Epoch: 48, Loss: 0.41560807824134827, Validation Accuracy: 0.8781666666666667\n",
      "Epoch: 49, Loss: 0.4064532518386841, Validation Accuracy: 0.87625\n",
      "Epoch: 50, Loss: 0.40092799067497253, Validation Accuracy: 0.8805833333333334\n",
      "Epoch: 51, Loss: 0.39526042342185974, Validation Accuracy: 0.87925\n",
      "Epoch: 52, Loss: 0.3918246626853943, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 53, Loss: 0.38817790150642395, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 54, Loss: 0.38685107231140137, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 55, Loss: 0.3856576681137085, Validation Accuracy: 0.8810833333333333\n",
      "Epoch: 56, Loss: 0.3880421221256256, Validation Accuracy: 0.8760833333333333\n",
      "Epoch: 57, Loss: 0.39202624559402466, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 58, Loss: 0.40284451842308044, Validation Accuracy: 0.8649166666666667\n",
      "Epoch: 59, Loss: 0.41945022344589233, Validation Accuracy: 0.8564166666666667\n",
      "Epoch: 60, Loss: 0.4455362856388092, Validation Accuracy: 0.84525\n",
      "Epoch: 61, Loss: 0.4799171984195709, Validation Accuracy: 0.8425833333333334\n",
      "Epoch: 62, Loss: 0.48990684747695923, Validation Accuracy: 0.8490833333333333\n",
      "Epoch: 63, Loss: 0.4748784899711609, Validation Accuracy: 0.86525\n",
      "Epoch: 64, Loss: 0.42676541209220886, Validation Accuracy: 0.8755833333333334\n",
      "Epoch: 65, Loss: 0.3850489854812622, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 66, Loss: 0.3596525192260742, Validation Accuracy: 0.893\n",
      "Epoch: 67, Loss: 0.34719228744506836, Validation Accuracy: 0.8991666666666667\n",
      "Epoch: 68, Loss: 0.34010881185531616, Validation Accuracy: 0.8978333333333334\n",
      "Epoch: 69, Loss: 0.3356143534183502, Validation Accuracy: 0.90075\n",
      "Epoch: 70, Loss: 0.33209726214408875, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 71, Loss: 0.3290419280529022, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 72, Loss: 0.326253205537796, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 73, Loss: 0.3236268162727356, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 74, Loss: 0.3211401700973511, Validation Accuracy: 0.9035\n",
      "Epoch: 75, Loss: 0.31875619292259216, Validation Accuracy: 0.90475\n",
      "Epoch: 76, Loss: 0.3164503872394562, Validation Accuracy: 0.9048333333333334\n",
      "Epoch: 77, Loss: 0.3142254054546356, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 78, Loss: 0.3120673596858978, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 79, Loss: 0.30997565388679504, Validation Accuracy: 0.9066666666666666\n",
      "Epoch: 80, Loss: 0.3079521358013153, Validation Accuracy: 0.90675\n",
      "Epoch: 81, Loss: 0.30597540736198425, Validation Accuracy: 0.9075833333333333\n",
      "Epoch: 82, Loss: 0.304047554731369, Validation Accuracy: 0.9076666666666666\n",
      "Epoch: 83, Loss: 0.3021675944328308, Validation Accuracy: 0.9089166666666667\n",
      "Epoch: 84, Loss: 0.30033326148986816, Validation Accuracy: 0.9086666666666666\n",
      "Epoch: 85, Loss: 0.2985445559024811, Validation Accuracy: 0.9095\n",
      "Epoch: 86, Loss: 0.2967990040779114, Validation Accuracy: 0.9096666666666666\n",
      "Epoch: 87, Loss: 0.29508471488952637, Validation Accuracy: 0.9105833333333333\n",
      "Epoch: 88, Loss: 0.2934094965457916, Validation Accuracy: 0.9106666666666666\n",
      "Epoch: 89, Loss: 0.29177126288414, Validation Accuracy: 0.9116666666666666\n",
      "Epoch: 90, Loss: 0.2901652455329895, Validation Accuracy: 0.9116666666666666\n",
      "Epoch: 91, Loss: 0.288595974445343, Validation Accuracy: 0.9123333333333333\n",
      "Epoch: 92, Loss: 0.2870596647262573, Validation Accuracy: 0.9128333333333334\n",
      "Epoch: 93, Loss: 0.28556397557258606, Validation Accuracy: 0.913\n",
      "Epoch: 94, Loss: 0.28411105275154114, Validation Accuracy: 0.9139166666666667\n",
      "Epoch: 95, Loss: 0.2826894521713257, Validation Accuracy: 0.9135\n",
      "Epoch: 96, Loss: 0.28131526708602905, Validation Accuracy: 0.9148333333333334\n",
      "Epoch: 97, Loss: 0.2799645662307739, Validation Accuracy: 0.9149166666666667\n",
      "Epoch: 98, Loss: 0.27865320444107056, Validation Accuracy: 0.915\n",
      "Epoch: 99, Loss: 0.2773715853691101, Validation Accuracy: 0.9161666666666667\n",
      "Dataset 2\n",
      "Epoch: 0, Loss: 2.908930778503418, Validation Accuracy: 0.2685\n",
      "Epoch: 1, Loss: 2.1776490211486816, Validation Accuracy: 0.24141666666666667\n",
      "Epoch: 2, Loss: 2.991227149963379, Validation Accuracy: 0.2828333333333333\n",
      "Epoch: 3, Loss: 2.5004398822784424, Validation Accuracy: 0.3715833333333333\n",
      "Epoch: 4, Loss: 1.9693125486373901, Validation Accuracy: 0.4925833333333333\n",
      "Epoch: 5, Loss: 1.6234757900238037, Validation Accuracy: 0.55575\n",
      "Epoch: 6, Loss: 1.4195665121078491, Validation Accuracy: 0.61775\n",
      "Epoch: 7, Loss: 1.2771475315093994, Validation Accuracy: 0.63275\n",
      "Epoch: 8, Loss: 1.1565216779708862, Validation Accuracy: 0.6651666666666667\n",
      "Epoch: 9, Loss: 1.050450325012207, Validation Accuracy: 0.6913333333333334\n",
      "Epoch: 10, Loss: 0.955858051776886, Validation Accuracy: 0.728\n",
      "Epoch: 11, Loss: 0.8779852986335754, Validation Accuracy: 0.7401666666666666\n",
      "Epoch: 12, Loss: 0.8304988741874695, Validation Accuracy: 0.7203333333333334\n",
      "Epoch: 13, Loss: 0.8343350291252136, Validation Accuracy: 0.67225\n",
      "Epoch: 14, Loss: 0.9444183111190796, Validation Accuracy: 0.63925\n",
      "Epoch: 15, Loss: 1.124414086341858, Validation Accuracy: 0.6914166666666667\n",
      "Epoch: 16, Loss: 0.9791843891143799, Validation Accuracy: 0.7701666666666667\n",
      "Epoch: 17, Loss: 0.7193149328231812, Validation Accuracy: 0.8048333333333333\n",
      "Epoch: 18, Loss: 0.6365844011306763, Validation Accuracy: 0.8118333333333333\n",
      "Epoch: 19, Loss: 0.6124211549758911, Validation Accuracy: 0.8015833333333333\n",
      "Epoch: 20, Loss: 0.6059898138046265, Validation Accuracy: 0.7949166666666667\n",
      "Epoch: 21, Loss: 0.6336638331413269, Validation Accuracy: 0.7479166666666667\n",
      "Epoch: 22, Loss: 0.7173969745635986, Validation Accuracy: 0.7239166666666667\n",
      "Epoch: 23, Loss: 0.8542664647102356, Validation Accuracy: 0.7065833333333333\n",
      "Epoch: 24, Loss: 0.8278118371963501, Validation Accuracy: 0.7799166666666667\n",
      "Epoch: 25, Loss: 0.6708397269248962, Validation Accuracy: 0.813\n",
      "Epoch: 26, Loss: 0.5773448944091797, Validation Accuracy: 0.82425\n",
      "Epoch: 27, Loss: 0.5457133650779724, Validation Accuracy: 0.8276666666666667\n",
      "Epoch: 28, Loss: 0.5347134470939636, Validation Accuracy: 0.8269166666666666\n",
      "Epoch: 29, Loss: 0.5226292014122009, Validation Accuracy: 0.8250833333333333\n",
      "Epoch: 30, Loss: 0.5329821109771729, Validation Accuracy: 0.8190833333333334\n",
      "Epoch: 31, Loss: 0.528944194316864, Validation Accuracy: 0.8209166666666666\n",
      "Epoch: 32, Loss: 0.543832004070282, Validation Accuracy: 0.8148333333333333\n",
      "Epoch: 33, Loss: 0.5367183685302734, Validation Accuracy: 0.8285\n",
      "Epoch: 34, Loss: 0.525335431098938, Validation Accuracy: 0.8296666666666667\n",
      "Epoch: 35, Loss: 0.5093428492546082, Validation Accuracy: 0.8459166666666667\n",
      "Epoch: 36, Loss: 0.4809151589870453, Validation Accuracy: 0.8474166666666667\n",
      "Epoch: 37, Loss: 0.4678103029727936, Validation Accuracy: 0.8604166666666667\n",
      "Epoch: 38, Loss: 0.445532888174057, Validation Accuracy: 0.8610833333333333\n",
      "Epoch: 39, Loss: 0.4377315938472748, Validation Accuracy: 0.8666666666666667\n",
      "Epoch: 40, Loss: 0.4223780930042267, Validation Accuracy: 0.8676666666666667\n",
      "Epoch: 41, Loss: 0.41797974705696106, Validation Accuracy: 0.8715\n",
      "Epoch: 42, Loss: 0.4070620536804199, Validation Accuracy: 0.871\n",
      "Epoch: 43, Loss: 0.40464672446250916, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 44, Loss: 0.39603087306022644, Validation Accuracy: 0.8745833333333334\n",
      "Epoch: 45, Loss: 0.3951377868652344, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 46, Loss: 0.3877447545528412, Validation Accuracy: 0.877\n",
      "Epoch: 47, Loss: 0.38829830288887024, Validation Accuracy: 0.8783333333333333\n",
      "Epoch: 48, Loss: 0.38146883249282837, Validation Accuracy: 0.8770833333333333\n",
      "Epoch: 49, Loss: 0.3834468126296997, Validation Accuracy: 0.87975\n",
      "Epoch: 50, Loss: 0.37664830684661865, Validation Accuracy: 0.8781666666666667\n",
      "Epoch: 51, Loss: 0.3798503875732422, Validation Accuracy: 0.8810833333333333\n",
      "Epoch: 52, Loss: 0.37295666337013245, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 53, Loss: 0.37726667523384094, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 54, Loss: 0.37002918124198914, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 55, Loss: 0.3743803799152374, Validation Accuracy: 0.88175\n",
      "Epoch: 56, Loss: 0.3671495318412781, Validation Accuracy: 0.881\n",
      "Epoch: 57, Loss: 0.37060245871543884, Validation Accuracy: 0.8821666666666667\n",
      "Epoch: 58, Loss: 0.3638853430747986, Validation Accuracy: 0.8830833333333333\n",
      "Epoch: 59, Loss: 0.3660651445388794, Validation Accuracy: 0.8825\n",
      "Epoch: 60, Loss: 0.36013033986091614, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 61, Loss: 0.3606654107570648, Validation Accuracy: 0.8845\n",
      "Epoch: 62, Loss: 0.3548849821090698, Validation Accuracy: 0.88875\n",
      "Epoch: 63, Loss: 0.3540286421775818, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 64, Loss: 0.3480089008808136, Validation Accuracy: 0.8914166666666666\n",
      "Epoch: 65, Loss: 0.3461185395717621, Validation Accuracy: 0.8903333333333333\n",
      "Epoch: 66, Loss: 0.33928704261779785, Validation Accuracy: 0.89525\n",
      "Epoch: 67, Loss: 0.3366347551345825, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 68, Loss: 0.3295745849609375, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 69, Loss: 0.3267163932323456, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 70, Loss: 0.3204230070114136, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 71, Loss: 0.3177802860736847, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 72, Loss: 0.312818318605423, Validation Accuracy: 0.90225\n",
      "Epoch: 73, Loss: 0.3105820417404175, Validation Accuracy: 0.902\n",
      "Epoch: 74, Loss: 0.30666080117225647, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 75, Loss: 0.3049045503139496, Validation Accuracy: 0.903\n",
      "Epoch: 76, Loss: 0.30181655287742615, Validation Accuracy: 0.9041666666666667\n",
      "Epoch: 77, Loss: 0.30050724744796753, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 78, Loss: 0.29806554317474365, Validation Accuracy: 0.9054166666666666\n",
      "Epoch: 79, Loss: 0.2970380187034607, Validation Accuracy: 0.9046666666666666\n",
      "Epoch: 80, Loss: 0.29511648416519165, Validation Accuracy: 0.9064166666666666\n",
      "Epoch: 81, Loss: 0.2943847179412842, Validation Accuracy: 0.905\n",
      "Epoch: 82, Loss: 0.2929544150829315, Validation Accuracy: 0.9069166666666667\n",
      "Epoch: 83, Loss: 0.292446494102478, Validation Accuracy: 0.9055\n",
      "Epoch: 84, Loss: 0.29151472449302673, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 85, Loss: 0.2913491427898407, Validation Accuracy: 0.90475\n",
      "Epoch: 86, Loss: 0.2909293472766876, Validation Accuracy: 0.9065\n",
      "Epoch: 87, Loss: 0.29085204005241394, Validation Accuracy: 0.90375\n",
      "Epoch: 88, Loss: 0.2909601330757141, Validation Accuracy: 0.9071666666666667\n",
      "Epoch: 89, Loss: 0.2908690869808197, Validation Accuracy: 0.9025\n",
      "Epoch: 90, Loss: 0.29141658544540405, Validation Accuracy: 0.907\n",
      "Epoch: 91, Loss: 0.29096826910972595, Validation Accuracy: 0.90225\n",
      "Epoch: 92, Loss: 0.2916110157966614, Validation Accuracy: 0.907\n",
      "Epoch: 93, Loss: 0.29052263498306274, Validation Accuracy: 0.9025\n",
      "Epoch: 94, Loss: 0.29069775342941284, Validation Accuracy: 0.90775\n",
      "Epoch: 95, Loss: 0.288657009601593, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 96, Loss: 0.28794801235198975, Validation Accuracy: 0.9095\n",
      "Epoch: 97, Loss: 0.2850382626056671, Validation Accuracy: 0.90525\n",
      "Epoch: 98, Loss: 0.28312817215919495, Validation Accuracy: 0.91175\n",
      "Epoch: 99, Loss: 0.2797701954841614, Validation Accuracy: 0.9069166666666667\n",
      "Dataset 3\n",
      "Epoch: 0, Loss: 3.900117874145508, Validation Accuracy: 0.14766666666666667\n",
      "Epoch: 1, Loss: 3.227180242538452, Validation Accuracy: 0.3115\n",
      "Epoch: 2, Loss: 2.357910394668579, Validation Accuracy: 0.2659166666666667\n",
      "Epoch: 3, Loss: 2.114168882369995, Validation Accuracy: 0.374\n",
      "Epoch: 4, Loss: 1.853298306465149, Validation Accuracy: 0.5071666666666667\n",
      "Epoch: 5, Loss: 1.511709451675415, Validation Accuracy: 0.5793333333333334\n",
      "Epoch: 6, Loss: 1.3517305850982666, Validation Accuracy: 0.625\n",
      "Epoch: 7, Loss: 1.2171111106872559, Validation Accuracy: 0.6576666666666666\n",
      "Epoch: 8, Loss: 1.1115028858184814, Validation Accuracy: 0.6813333333333333\n",
      "Epoch: 9, Loss: 1.035306692123413, Validation Accuracy: 0.6835\n",
      "Epoch: 10, Loss: 0.9974271059036255, Validation Accuracy: 0.68\n",
      "Epoch: 11, Loss: 0.9927483201026917, Validation Accuracy: 0.6631666666666667\n",
      "Epoch: 12, Loss: 1.049682855606079, Validation Accuracy: 0.6843333333333333\n",
      "Epoch: 13, Loss: 0.9826264381408691, Validation Accuracy: 0.6905833333333333\n",
      "Epoch: 14, Loss: 0.9328618049621582, Validation Accuracy: 0.73975\n",
      "Epoch: 15, Loss: 0.8213400840759277, Validation Accuracy: 0.7458333333333333\n",
      "Epoch: 16, Loss: 0.7652571797370911, Validation Accuracy: 0.7631666666666667\n",
      "Epoch: 17, Loss: 0.7508330941200256, Validation Accuracy: 0.7494166666666666\n",
      "Epoch: 18, Loss: 0.7465118765830994, Validation Accuracy: 0.7585833333333334\n",
      "Epoch: 19, Loss: 0.7504011988639832, Validation Accuracy: 0.7528333333333334\n",
      "Epoch: 20, Loss: 0.7353429198265076, Validation Accuracy: 0.7761666666666667\n",
      "Epoch: 21, Loss: 0.6932932138442993, Validation Accuracy: 0.7871666666666667\n",
      "Epoch: 22, Loss: 0.6483972668647766, Validation Accuracy: 0.79925\n",
      "Epoch: 23, Loss: 0.6158279776573181, Validation Accuracy: 0.8040833333333334\n",
      "Epoch: 24, Loss: 0.6011487245559692, Validation Accuracy: 0.79825\n",
      "Epoch: 25, Loss: 0.6038073897361755, Validation Accuracy: 0.7975\n",
      "Epoch: 26, Loss: 0.6186486482620239, Validation Accuracy: 0.77975\n",
      "Epoch: 27, Loss: 0.6363637447357178, Validation Accuracy: 0.787\n",
      "Epoch: 28, Loss: 0.6465171575546265, Validation Accuracy: 0.78675\n",
      "Epoch: 29, Loss: 0.6208149790763855, Validation Accuracy: 0.8141666666666667\n",
      "Epoch: 30, Loss: 0.5765333771705627, Validation Accuracy: 0.8328333333333333\n",
      "Epoch: 31, Loss: 0.5244826078414917, Validation Accuracy: 0.8446666666666667\n",
      "Epoch: 32, Loss: 0.49085351824760437, Validation Accuracy: 0.85725\n",
      "Epoch: 33, Loss: 0.46641451120376587, Validation Accuracy: 0.86225\n",
      "Epoch: 34, Loss: 0.4516410827636719, Validation Accuracy: 0.86675\n",
      "Epoch: 35, Loss: 0.4402870237827301, Validation Accuracy: 0.8696666666666667\n",
      "Epoch: 36, Loss: 0.431863933801651, Validation Accuracy: 0.8705833333333334\n",
      "Epoch: 37, Loss: 0.42475810647010803, Validation Accuracy: 0.87225\n",
      "Epoch: 38, Loss: 0.4191092848777771, Validation Accuracy: 0.8724166666666666\n",
      "Epoch: 39, Loss: 0.41440150141716003, Validation Accuracy: 0.8743333333333333\n",
      "Epoch: 40, Loss: 0.41066670417785645, Validation Accuracy: 0.8720833333333333\n",
      "Epoch: 41, Loss: 0.40832820534706116, Validation Accuracy: 0.8735833333333334\n",
      "Epoch: 42, Loss: 0.4067237675189972, Validation Accuracy: 0.8698333333333333\n",
      "Epoch: 43, Loss: 0.40802672505378723, Validation Accuracy: 0.87225\n",
      "Epoch: 44, Loss: 0.40881267189979553, Validation Accuracy: 0.8650833333333333\n",
      "Epoch: 45, Loss: 0.41570451855659485, Validation Accuracy: 0.8680833333333333\n",
      "Epoch: 46, Loss: 0.41783633828163147, Validation Accuracy: 0.8578333333333333\n",
      "Epoch: 47, Loss: 0.4309035539627075, Validation Accuracy: 0.8628333333333333\n",
      "Epoch: 48, Loss: 0.42901676893234253, Validation Accuracy: 0.85325\n",
      "Epoch: 49, Loss: 0.44050776958465576, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 50, Loss: 0.42616787552833557, Validation Accuracy: 0.861\n",
      "Epoch: 51, Loss: 0.4234122037887573, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 52, Loss: 0.40177324414253235, Validation Accuracy: 0.8739166666666667\n",
      "Epoch: 53, Loss: 0.38968920707702637, Validation Accuracy: 0.88325\n",
      "Epoch: 54, Loss: 0.3740134537220001, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 55, Loss: 0.3638666570186615, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 56, Loss: 0.35539233684539795, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 57, Loss: 0.3490537106990814, Validation Accuracy: 0.8935833333333333\n",
      "Epoch: 58, Loss: 0.3439251780509949, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 59, Loss: 0.3396320641040802, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 60, Loss: 0.3360089361667633, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 61, Loss: 0.3327513337135315, Validation Accuracy: 0.8955\n",
      "Epoch: 62, Loss: 0.32981380820274353, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 63, Loss: 0.327070415019989, Validation Accuracy: 0.897\n",
      "Epoch: 64, Loss: 0.3244663178920746, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 65, Loss: 0.32201823592185974, Validation Accuracy: 0.89825\n",
      "Epoch: 66, Loss: 0.3196432292461395, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 67, Loss: 0.3173975646495819, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 68, Loss: 0.31522369384765625, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 69, Loss: 0.31312841176986694, Validation Accuracy: 0.9005833333333333\n",
      "Epoch: 70, Loss: 0.3110824525356293, Validation Accuracy: 0.902\n",
      "Epoch: 71, Loss: 0.309113472700119, Validation Accuracy: 0.9023333333333333\n",
      "Epoch: 72, Loss: 0.30717694759368896, Validation Accuracy: 0.903\n",
      "Epoch: 73, Loss: 0.3053145408630371, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 74, Loss: 0.30347105860710144, Validation Accuracy: 0.9039166666666667\n",
      "Epoch: 75, Loss: 0.30170413851737976, Validation Accuracy: 0.9039166666666667\n",
      "Epoch: 76, Loss: 0.29995644092559814, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 77, Loss: 0.29828280210494995, Validation Accuracy: 0.905\n",
      "Epoch: 78, Loss: 0.2966170310974121, Validation Accuracy: 0.9059166666666667\n",
      "Epoch: 79, Loss: 0.29503414034843445, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 80, Loss: 0.29344141483306885, Validation Accuracy: 0.9064166666666666\n",
      "Epoch: 81, Loss: 0.29193708300590515, Validation Accuracy: 0.9065\n",
      "Epoch: 82, Loss: 0.2904147803783417, Validation Accuracy: 0.9070833333333334\n",
      "Epoch: 83, Loss: 0.2889825999736786, Validation Accuracy: 0.90675\n",
      "Epoch: 84, Loss: 0.2875314950942993, Validation Accuracy: 0.9079166666666667\n",
      "Epoch: 85, Loss: 0.28618016839027405, Validation Accuracy: 0.90775\n",
      "Epoch: 86, Loss: 0.2847841680049896, Validation Accuracy: 0.90775\n",
      "Epoch: 87, Loss: 0.2835102677345276, Validation Accuracy: 0.9086666666666666\n",
      "Epoch: 88, Loss: 0.282172292470932, Validation Accuracy: 0.9083333333333333\n",
      "Epoch: 89, Loss: 0.2809778153896332, Validation Accuracy: 0.90925\n",
      "Epoch: 90, Loss: 0.27968642115592957, Validation Accuracy: 0.9094166666666667\n",
      "Epoch: 91, Loss: 0.2785758674144745, Validation Accuracy: 0.9096666666666666\n",
      "Epoch: 92, Loss: 0.27732762694358826, Validation Accuracy: 0.90975\n",
      "Epoch: 93, Loss: 0.2763218283653259, Validation Accuracy: 0.9103333333333333\n",
      "Epoch: 94, Loss: 0.27510663866996765, Validation Accuracy: 0.91025\n",
      "Epoch: 95, Loss: 0.27417659759521484, Validation Accuracy: 0.9104166666666667\n",
      "Epoch: 96, Loss: 0.27300527691841125, Validation Accuracy: 0.9109166666666667\n",
      "Epoch: 97, Loss: 0.2721865773200989, Validation Accuracy: 0.9105\n",
      "Epoch: 98, Loss: 0.27108117938041687, Validation Accuracy: 0.9114166666666667\n",
      "Epoch: 99, Loss: 0.27037015557289124, Validation Accuracy: 0.9105833333333333\n",
      "Dataset 4\n",
      "Epoch: 0, Loss: 3.7557575702667236, Validation Accuracy: 0.2950833333333333\n",
      "Epoch: 1, Loss: 2.7264339923858643, Validation Accuracy: 0.3525\n",
      "Epoch: 2, Loss: 2.032538652420044, Validation Accuracy: 0.33508333333333334\n",
      "Epoch: 3, Loss: 1.9995874166488647, Validation Accuracy: 0.38908333333333334\n",
      "Epoch: 4, Loss: 1.8325062990188599, Validation Accuracy: 0.52325\n",
      "Epoch: 5, Loss: 1.4310963153839111, Validation Accuracy: 0.5805\n",
      "Epoch: 6, Loss: 1.2874531745910645, Validation Accuracy: 0.602\n",
      "Epoch: 7, Loss: 1.1924052238464355, Validation Accuracy: 0.60675\n",
      "Epoch: 8, Loss: 1.1612046957015991, Validation Accuracy: 0.6370833333333333\n",
      "Epoch: 9, Loss: 1.0652308464050293, Validation Accuracy: 0.6483333333333333\n",
      "Epoch: 10, Loss: 1.0301207304000854, Validation Accuracy: 0.67175\n",
      "Epoch: 11, Loss: 0.9605944156646729, Validation Accuracy: 0.6590833333333334\n",
      "Epoch: 12, Loss: 0.9689550995826721, Validation Accuracy: 0.6860833333333334\n",
      "Epoch: 13, Loss: 0.9189325571060181, Validation Accuracy: 0.7318333333333333\n",
      "Epoch: 14, Loss: 0.8228915929794312, Validation Accuracy: 0.7623333333333333\n",
      "Epoch: 15, Loss: 0.724772036075592, Validation Accuracy: 0.79625\n",
      "Epoch: 16, Loss: 0.6691526174545288, Validation Accuracy: 0.79675\n",
      "Epoch: 17, Loss: 0.6374747157096863, Validation Accuracy: 0.8100833333333334\n",
      "Epoch: 18, Loss: 0.6147263646125793, Validation Accuracy: 0.8053333333333333\n",
      "Epoch: 19, Loss: 0.603134274482727, Validation Accuracy: 0.8141666666666667\n",
      "Epoch: 20, Loss: 0.5948548913002014, Validation Accuracy: 0.8006666666666666\n",
      "Epoch: 21, Loss: 0.600161075592041, Validation Accuracy: 0.8068333333333333\n",
      "Epoch: 22, Loss: 0.601953387260437, Validation Accuracy: 0.7901666666666667\n",
      "Epoch: 23, Loss: 0.6188569068908691, Validation Accuracy: 0.8009166666666667\n",
      "Epoch: 24, Loss: 0.6135203838348389, Validation Accuracy: 0.7910833333333334\n",
      "Epoch: 25, Loss: 0.6107538938522339, Validation Accuracy: 0.8104166666666667\n",
      "Epoch: 26, Loss: 0.5915853977203369, Validation Accuracy: 0.8143333333333334\n",
      "Epoch: 27, Loss: 0.5647130012512207, Validation Accuracy: 0.8295\n",
      "Epoch: 28, Loss: 0.5417681932449341, Validation Accuracy: 0.84075\n",
      "Epoch: 29, Loss: 0.5124686360359192, Validation Accuracy: 0.845\n",
      "Epoch: 30, Loss: 0.49323615431785583, Validation Accuracy: 0.8555\n",
      "Epoch: 31, Loss: 0.4738740622997284, Validation Accuracy: 0.8578333333333333\n",
      "Epoch: 32, Loss: 0.46084803342819214, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 33, Loss: 0.44888147711753845, Validation Accuracy: 0.86425\n",
      "Epoch: 34, Loss: 0.4399084746837616, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 35, Loss: 0.43170365691185, Validation Accuracy: 0.8683333333333333\n",
      "Epoch: 36, Loss: 0.4249323010444641, Validation Accuracy: 0.8720833333333333\n",
      "Epoch: 37, Loss: 0.4188168942928314, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 38, Loss: 0.41339659690856934, Validation Accuracy: 0.8745833333333334\n",
      "Epoch: 39, Loss: 0.4084910452365875, Validation Accuracy: 0.87625\n",
      "Epoch: 40, Loss: 0.4039958119392395, Validation Accuracy: 0.8761666666666666\n",
      "Epoch: 41, Loss: 0.3999159038066864, Validation Accuracy: 0.8786666666666667\n",
      "Epoch: 42, Loss: 0.39607319235801697, Validation Accuracy: 0.8785\n",
      "Epoch: 43, Loss: 0.39258691668510437, Validation Accuracy: 0.8804166666666666\n",
      "Epoch: 44, Loss: 0.38939449191093445, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 45, Loss: 0.38645556569099426, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 46, Loss: 0.38398098945617676, Validation Accuracy: 0.8805\n",
      "Epoch: 47, Loss: 0.38136762380599976, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 48, Loss: 0.3795948028564453, Validation Accuracy: 0.8821666666666667\n",
      "Epoch: 49, Loss: 0.37711259722709656, Validation Accuracy: 0.88425\n",
      "Epoch: 50, Loss: 0.3759140074253082, Validation Accuracy: 0.8825\n",
      "Epoch: 51, Loss: 0.3733430504798889, Validation Accuracy: 0.8851666666666667\n",
      "Epoch: 52, Loss: 0.3725410997867584, Validation Accuracy: 0.8839166666666667\n",
      "Epoch: 53, Loss: 0.36945411562919617, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 54, Loss: 0.3686690628528595, Validation Accuracy: 0.8850833333333333\n",
      "Epoch: 55, Loss: 0.3649861216545105, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 56, Loss: 0.3639695942401886, Validation Accuracy: 0.88625\n",
      "Epoch: 57, Loss: 0.35941997170448303, Validation Accuracy: 0.88975\n",
      "Epoch: 58, Loss: 0.35791394114494324, Validation Accuracy: 0.8890833333333333\n",
      "Epoch: 59, Loss: 0.3529879152774811, Validation Accuracy: 0.8923333333333333\n",
      "Epoch: 60, Loss: 0.3509129583835602, Validation Accuracy: 0.8913333333333333\n",
      "Epoch: 61, Loss: 0.3460138738155365, Validation Accuracy: 0.895\n",
      "Epoch: 62, Loss: 0.3436644673347473, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 63, Loss: 0.33915144205093384, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 64, Loss: 0.3367062509059906, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 65, Loss: 0.3328166902065277, Validation Accuracy: 0.89925\n",
      "Epoch: 66, Loss: 0.33042898774147034, Validation Accuracy: 0.8996666666666666\n",
      "Epoch: 67, Loss: 0.32716691493988037, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 68, Loss: 0.32487601041793823, Validation Accuracy: 0.9016666666666666\n",
      "Epoch: 69, Loss: 0.32207420468330383, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 70, Loss: 0.31985700130462646, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 71, Loss: 0.31741589307785034, Validation Accuracy: 0.90475\n",
      "Epoch: 72, Loss: 0.3153524100780487, Validation Accuracy: 0.9055\n",
      "Epoch: 73, Loss: 0.3131335377693176, Validation Accuracy: 0.90575\n",
      "Epoch: 74, Loss: 0.3111621141433716, Validation Accuracy: 0.9063333333333333\n",
      "Epoch: 75, Loss: 0.3091432750225067, Validation Accuracy: 0.9066666666666666\n",
      "Epoch: 76, Loss: 0.30725178122520447, Validation Accuracy: 0.90725\n",
      "Epoch: 77, Loss: 0.3053829073905945, Validation Accuracy: 0.90775\n",
      "Epoch: 78, Loss: 0.3035803735256195, Validation Accuracy: 0.9088333333333334\n",
      "Epoch: 79, Loss: 0.301808625459671, Validation Accuracy: 0.9085833333333333\n",
      "Epoch: 80, Loss: 0.3001067042350769, Validation Accuracy: 0.9093333333333333\n",
      "Epoch: 81, Loss: 0.2984289824962616, Validation Accuracy: 0.90975\n",
      "Epoch: 82, Loss: 0.29681533575057983, Validation Accuracy: 0.9104166666666667\n",
      "Epoch: 83, Loss: 0.29520753026008606, Validation Accuracy: 0.9109166666666667\n",
      "Epoch: 84, Loss: 0.2936595380306244, Validation Accuracy: 0.9115\n",
      "Epoch: 85, Loss: 0.29211869835853577, Validation Accuracy: 0.91175\n",
      "Epoch: 86, Loss: 0.29064035415649414, Validation Accuracy: 0.9125833333333333\n",
      "Epoch: 87, Loss: 0.28917214274406433, Validation Accuracy: 0.9125\n",
      "Epoch: 88, Loss: 0.28773635625839233, Validation Accuracy: 0.9134166666666667\n",
      "Epoch: 89, Loss: 0.28629690408706665, Validation Accuracy: 0.9133333333333333\n",
      "Epoch: 90, Loss: 0.2849004864692688, Validation Accuracy: 0.9145\n",
      "Epoch: 91, Loss: 0.28351372480392456, Validation Accuracy: 0.91375\n",
      "Epoch: 92, Loss: 0.28215402364730835, Validation Accuracy: 0.9155\n",
      "Epoch: 93, Loss: 0.2807981073856354, Validation Accuracy: 0.91425\n",
      "Epoch: 94, Loss: 0.2794828712940216, Validation Accuracy: 0.9161666666666667\n",
      "Epoch: 95, Loss: 0.27818626165390015, Validation Accuracy: 0.9154166666666667\n",
      "Epoch: 96, Loss: 0.27688226103782654, Validation Accuracy: 0.91675\n",
      "Epoch: 97, Loss: 0.27561718225479126, Validation Accuracy: 0.9160833333333334\n",
      "Epoch: 98, Loss: 0.2743500769138336, Validation Accuracy: 0.91725\n",
      "Epoch: 99, Loss: 0.27312690019607544, Validation Accuracy: 0.91725\n",
      "Dataset 5\n",
      "Epoch: 0, Loss: 4.1721906661987305, Validation Accuracy: 0.12775\n",
      "Epoch: 1, Loss: 5.677589416503906, Validation Accuracy: 0.12225\n",
      "Epoch: 2, Loss: 8.064651489257812, Validation Accuracy: 0.14\n",
      "Epoch: 3, Loss: 3.160003662109375, Validation Accuracy: 0.14575\n",
      "Epoch: 4, Loss: 2.563417434692383, Validation Accuracy: 0.31466666666666665\n",
      "Epoch: 5, Loss: 2.1697561740875244, Validation Accuracy: 0.39425\n",
      "Epoch: 6, Loss: 1.9951750040054321, Validation Accuracy: 0.4375\n",
      "Epoch: 7, Loss: 1.8874890804290771, Validation Accuracy: 0.4718333333333333\n",
      "Epoch: 8, Loss: 1.7902220487594604, Validation Accuracy: 0.4995\n",
      "Epoch: 9, Loss: 1.6986079216003418, Validation Accuracy: 0.5204166666666666\n",
      "Epoch: 10, Loss: 1.6110082864761353, Validation Accuracy: 0.5393333333333333\n",
      "Epoch: 11, Loss: 1.527117133140564, Validation Accuracy: 0.5613333333333334\n",
      "Epoch: 12, Loss: 1.4461809396743774, Validation Accuracy: 0.5823333333333334\n",
      "Epoch: 13, Loss: 1.3673789501190186, Validation Accuracy: 0.6035833333333334\n",
      "Epoch: 14, Loss: 1.291414499282837, Validation Accuracy: 0.6314166666666666\n",
      "Epoch: 15, Loss: 1.219217300415039, Validation Accuracy: 0.6490833333333333\n",
      "Epoch: 16, Loss: 1.151145577430725, Validation Accuracy: 0.6643333333333333\n",
      "Epoch: 17, Loss: 1.0872844457626343, Validation Accuracy: 0.6789166666666666\n",
      "Epoch: 18, Loss: 1.0265535116195679, Validation Accuracy: 0.69325\n",
      "Epoch: 19, Loss: 0.9683395028114319, Validation Accuracy: 0.71325\n",
      "Epoch: 20, Loss: 0.9127317070960999, Validation Accuracy: 0.73825\n",
      "Epoch: 21, Loss: 0.860511302947998, Validation Accuracy: 0.7604166666666666\n",
      "Epoch: 22, Loss: 0.8127096891403198, Validation Accuracy: 0.7748333333333334\n",
      "Epoch: 23, Loss: 0.7701694965362549, Validation Accuracy: 0.7870833333333334\n",
      "Epoch: 24, Loss: 0.7327730059623718, Validation Accuracy: 0.7969166666666667\n",
      "Epoch: 25, Loss: 0.7002153992652893, Validation Accuracy: 0.8046666666666666\n",
      "Epoch: 26, Loss: 0.6722835898399353, Validation Accuracy: 0.8093333333333333\n",
      "Epoch: 27, Loss: 0.6498947143554688, Validation Accuracy: 0.8070833333333334\n",
      "Epoch: 28, Loss: 0.6396065950393677, Validation Accuracy: 0.7776666666666666\n",
      "Epoch: 29, Loss: 0.6786333918571472, Validation Accuracy: 0.6985\n",
      "Epoch: 30, Loss: 0.8669841289520264, Validation Accuracy: 0.5833333333333334\n",
      "Epoch: 31, Loss: 1.4756910800933838, Validation Accuracy: 0.6430833333333333\n",
      "Epoch: 32, Loss: 1.1654424667358398, Validation Accuracy: 0.7109166666666666\n",
      "Epoch: 33, Loss: 0.896567165851593, Validation Accuracy: 0.7816666666666666\n",
      "Epoch: 34, Loss: 0.7231354117393494, Validation Accuracy: 0.8085833333333333\n",
      "Epoch: 35, Loss: 0.6328706741333008, Validation Accuracy: 0.8306666666666667\n",
      "Epoch: 36, Loss: 0.5807470679283142, Validation Accuracy: 0.83425\n",
      "Epoch: 37, Loss: 0.5590556263923645, Validation Accuracy: 0.8355\n",
      "Epoch: 38, Loss: 0.544717013835907, Validation Accuracy: 0.8343333333333334\n",
      "Epoch: 39, Loss: 0.5396782755851746, Validation Accuracy: 0.82275\n",
      "Epoch: 40, Loss: 0.5475447177886963, Validation Accuracy: 0.82125\n",
      "Epoch: 41, Loss: 0.5580930113792419, Validation Accuracy: 0.7920833333333334\n",
      "Epoch: 42, Loss: 0.603179931640625, Validation Accuracy: 0.7981666666666667\n",
      "Epoch: 43, Loss: 0.6066897511482239, Validation Accuracy: 0.7760833333333333\n",
      "Epoch: 44, Loss: 0.6436306834220886, Validation Accuracy: 0.8155\n",
      "Epoch: 45, Loss: 0.5793085694313049, Validation Accuracy: 0.8145833333333333\n",
      "Epoch: 46, Loss: 0.5421997308731079, Validation Accuracy: 0.84925\n",
      "Epoch: 47, Loss: 0.49932679533958435, Validation Accuracy: 0.8500833333333333\n",
      "Epoch: 48, Loss: 0.47427257895469666, Validation Accuracy: 0.8645833333333334\n",
      "Epoch: 49, Loss: 0.45895418524742126, Validation Accuracy: 0.863\n",
      "Epoch: 50, Loss: 0.4451116919517517, Validation Accuracy: 0.8709166666666667\n",
      "Epoch: 51, Loss: 0.4371871054172516, Validation Accuracy: 0.8699166666666667\n",
      "Epoch: 52, Loss: 0.4279259443283081, Validation Accuracy: 0.8741666666666666\n",
      "Epoch: 53, Loss: 0.4221854507923126, Validation Accuracy: 0.8750833333333333\n",
      "Epoch: 54, Loss: 0.415303111076355, Validation Accuracy: 0.8765833333333334\n",
      "Epoch: 55, Loss: 0.41058826446533203, Validation Accuracy: 0.8786666666666667\n",
      "Epoch: 56, Loss: 0.4050844609737396, Validation Accuracy: 0.8790833333333333\n",
      "Epoch: 57, Loss: 0.4010874032974243, Validation Accuracy: 0.8813333333333333\n",
      "Epoch: 58, Loss: 0.3964499235153198, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 59, Loss: 0.39300838112831116, Validation Accuracy: 0.8834166666666666\n",
      "Epoch: 60, Loss: 0.3889042139053345, Validation Accuracy: 0.8835\n",
      "Epoch: 61, Loss: 0.38593006134033203, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 62, Loss: 0.3823062777519226, Validation Accuracy: 0.8845833333333334\n",
      "Epoch: 63, Loss: 0.3797491490840912, Validation Accuracy: 0.88725\n",
      "Epoch: 64, Loss: 0.3765316605567932, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 65, Loss: 0.37435075640678406, Validation Accuracy: 0.8883333333333333\n",
      "Epoch: 66, Loss: 0.37147578597068787, Validation Accuracy: 0.8875\n",
      "Epoch: 67, Loss: 0.369717001914978, Validation Accuracy: 0.8895\n",
      "Epoch: 68, Loss: 0.3671260178089142, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 69, Loss: 0.3657083213329315, Validation Accuracy: 0.8903333333333333\n",
      "Epoch: 70, Loss: 0.3631803095340729, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 71, Loss: 0.3620937466621399, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 72, Loss: 0.3596537709236145, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 73, Loss: 0.358835905790329, Validation Accuracy: 0.892\n",
      "Epoch: 74, Loss: 0.3564413785934448, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 75, Loss: 0.3556835949420929, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 76, Loss: 0.3530753254890442, Validation Accuracy: 0.893\n",
      "Epoch: 77, Loss: 0.3522733449935913, Validation Accuracy: 0.89375\n",
      "Epoch: 78, Loss: 0.34935542941093445, Validation Accuracy: 0.894\n",
      "Epoch: 79, Loss: 0.34831127524375916, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 80, Loss: 0.3451266586780548, Validation Accuracy: 0.8959166666666667\n",
      "Epoch: 81, Loss: 0.34364330768585205, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 82, Loss: 0.3402239978313446, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 83, Loss: 0.33832499384880066, Validation Accuracy: 0.898\n",
      "Epoch: 84, Loss: 0.3348517119884491, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 85, Loss: 0.33259397745132446, Validation Accuracy: 0.9\n",
      "Epoch: 86, Loss: 0.3292010426521301, Validation Accuracy: 0.90025\n",
      "Epoch: 87, Loss: 0.32677793502807617, Validation Accuracy: 0.90225\n",
      "Epoch: 88, Loss: 0.3236231803894043, Validation Accuracy: 0.90175\n",
      "Epoch: 89, Loss: 0.32123473286628723, Validation Accuracy: 0.9035\n",
      "Epoch: 90, Loss: 0.31837698817253113, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 91, Loss: 0.31611499190330505, Validation Accuracy: 0.9054166666666666\n",
      "Epoch: 92, Loss: 0.31356391310691833, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 93, Loss: 0.31145262718200684, Validation Accuracy: 0.9061666666666667\n",
      "Epoch: 94, Loss: 0.3092179596424103, Validation Accuracy: 0.9073333333333333\n",
      "Epoch: 95, Loss: 0.30727124214172363, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 96, Loss: 0.3052610158920288, Validation Accuracy: 0.909\n",
      "Epoch: 97, Loss: 0.30347490310668945, Validation Accuracy: 0.90825\n",
      "Epoch: 98, Loss: 0.3016431927680969, Validation Accuracy: 0.909\n",
      "Epoch: 99, Loss: 0.29998868703842163, Validation Accuracy: 0.90925\n",
      "Dataset 6\n",
      "Epoch: 0, Loss: 3.083411693572998, Validation Accuracy: 0.18558333333333332\n",
      "Epoch: 1, Loss: 3.4478135108947754, Validation Accuracy: 0.24633333333333332\n",
      "Epoch: 2, Loss: 2.322525978088379, Validation Accuracy: 0.27016666666666667\n",
      "Epoch: 3, Loss: 2.0768895149230957, Validation Accuracy: 0.3555833333333333\n",
      "Epoch: 4, Loss: 1.8302220106124878, Validation Accuracy: 0.46708333333333335\n",
      "Epoch: 5, Loss: 1.6344538927078247, Validation Accuracy: 0.49975\n",
      "Epoch: 6, Loss: 1.497646689414978, Validation Accuracy: 0.5415833333333333\n",
      "Epoch: 7, Loss: 1.3888883590698242, Validation Accuracy: 0.5726666666666667\n",
      "Epoch: 8, Loss: 1.2862980365753174, Validation Accuracy: 0.6144166666666667\n",
      "Epoch: 9, Loss: 1.1896679401397705, Validation Accuracy: 0.64875\n",
      "Epoch: 10, Loss: 1.1020607948303223, Validation Accuracy: 0.6731666666666667\n",
      "Epoch: 11, Loss: 1.0327297449111938, Validation Accuracy: 0.6571666666666667\n",
      "Epoch: 12, Loss: 1.0180000066757202, Validation Accuracy: 0.6155833333333334\n",
      "Epoch: 13, Loss: 1.1393203735351562, Validation Accuracy: 0.52525\n",
      "Epoch: 14, Loss: 1.5500246286392212, Validation Accuracy: 0.6245833333333334\n",
      "Epoch: 15, Loss: 1.151545524597168, Validation Accuracy: 0.7165\n",
      "Epoch: 16, Loss: 0.8990698456764221, Validation Accuracy: 0.7443333333333333\n",
      "Epoch: 17, Loss: 0.8119431138038635, Validation Accuracy: 0.7566666666666667\n",
      "Epoch: 18, Loss: 0.7637431025505066, Validation Accuracy: 0.76975\n",
      "Epoch: 19, Loss: 0.7272037863731384, Validation Accuracy: 0.7708333333333334\n",
      "Epoch: 20, Loss: 0.7054011225700378, Validation Accuracy: 0.7811666666666667\n",
      "Epoch: 21, Loss: 0.6848523020744324, Validation Accuracy: 0.7763333333333333\n",
      "Epoch: 22, Loss: 0.6807446479797363, Validation Accuracy: 0.7803333333333333\n",
      "Epoch: 23, Loss: 0.672365128993988, Validation Accuracy: 0.7731666666666667\n",
      "Epoch: 24, Loss: 0.6905922293663025, Validation Accuracy: 0.7675833333333333\n",
      "Epoch: 25, Loss: 0.6895266771316528, Validation Accuracy: 0.7654166666666666\n",
      "Epoch: 26, Loss: 0.712347149848938, Validation Accuracy: 0.7629166666666667\n",
      "Epoch: 27, Loss: 0.6905599236488342, Validation Accuracy: 0.7859166666666667\n",
      "Epoch: 28, Loss: 0.6606470346450806, Validation Accuracy: 0.7885833333333333\n",
      "Epoch: 29, Loss: 0.6226136684417725, Validation Accuracy: 0.8155\n",
      "Epoch: 30, Loss: 0.5801951885223389, Validation Accuracy: 0.8191666666666667\n",
      "Epoch: 31, Loss: 0.5589808821678162, Validation Accuracy: 0.82975\n",
      "Epoch: 32, Loss: 0.5367017984390259, Validation Accuracy: 0.8318333333333333\n",
      "Epoch: 33, Loss: 0.5252460241317749, Validation Accuracy: 0.8386666666666667\n",
      "Epoch: 34, Loss: 0.512685239315033, Validation Accuracy: 0.8384166666666667\n",
      "Epoch: 35, Loss: 0.5047491192817688, Validation Accuracy: 0.8431666666666666\n",
      "Epoch: 36, Loss: 0.4964730143547058, Validation Accuracy: 0.8421666666666666\n",
      "Epoch: 37, Loss: 0.4905267357826233, Validation Accuracy: 0.8469166666666667\n",
      "Epoch: 38, Loss: 0.48473188281059265, Validation Accuracy: 0.8451666666666666\n",
      "Epoch: 39, Loss: 0.480366975069046, Validation Accuracy: 0.8500833333333333\n",
      "Epoch: 40, Loss: 0.47640275955200195, Validation Accuracy: 0.84625\n",
      "Epoch: 41, Loss: 0.47346600890159607, Validation Accuracy: 0.8501666666666666\n",
      "Epoch: 42, Loss: 0.47064071893692017, Validation Accuracy: 0.847\n",
      "Epoch: 43, Loss: 0.4690093696117401, Validation Accuracy: 0.8504166666666667\n",
      "Epoch: 44, Loss: 0.46677929162979126, Validation Accuracy: 0.8469166666666667\n",
      "Epoch: 45, Loss: 0.4661328196525574, Validation Accuracy: 0.8511666666666666\n",
      "Epoch: 46, Loss: 0.4638741910457611, Validation Accuracy: 0.8448333333333333\n",
      "Epoch: 47, Loss: 0.46391531825065613, Validation Accuracy: 0.8518333333333333\n",
      "Epoch: 48, Loss: 0.4593610465526581, Validation Accuracy: 0.84575\n",
      "Epoch: 49, Loss: 0.45825842022895813, Validation Accuracy: 0.8555833333333334\n",
      "Epoch: 50, Loss: 0.45010456442832947, Validation Accuracy: 0.8513333333333334\n",
      "Epoch: 51, Loss: 0.44629812240600586, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 52, Loss: 0.43496569991111755, Validation Accuracy: 0.8595\n",
      "Epoch: 53, Loss: 0.4294370412826538, Validation Accuracy: 0.86825\n",
      "Epoch: 54, Loss: 0.4178985059261322, Validation Accuracy: 0.86725\n",
      "Epoch: 55, Loss: 0.4126652479171753, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 56, Loss: 0.40324822068214417, Validation Accuracy: 0.87525\n",
      "Epoch: 57, Loss: 0.39893656969070435, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 58, Loss: 0.3914450407028198, Validation Accuracy: 0.8794166666666666\n",
      "Epoch: 59, Loss: 0.38772669434547424, Validation Accuracy: 0.8830833333333333\n",
      "Epoch: 60, Loss: 0.3816465139389038, Validation Accuracy: 0.8823333333333333\n",
      "Epoch: 61, Loss: 0.3780869245529175, Validation Accuracy: 0.8855\n",
      "Epoch: 62, Loss: 0.37311193346977234, Validation Accuracy: 0.8854166666666666\n",
      "Epoch: 63, Loss: 0.36979466676712036, Validation Accuracy: 0.8883333333333333\n",
      "Epoch: 64, Loss: 0.36556798219680786, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 65, Loss: 0.362488716840744, Validation Accuracy: 0.8905\n",
      "Epoch: 66, Loss: 0.35874974727630615, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 67, Loss: 0.35590001940727234, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 68, Loss: 0.35258257389068604, Validation Accuracy: 0.8905\n",
      "Epoch: 69, Loss: 0.34999987483024597, Validation Accuracy: 0.89475\n",
      "Epoch: 70, Loss: 0.3470150828361511, Validation Accuracy: 0.89275\n",
      "Epoch: 71, Loss: 0.3446090817451477, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 72, Loss: 0.3418506979942322, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 73, Loss: 0.3395874500274658, Validation Accuracy: 0.8978333333333334\n",
      "Epoch: 74, Loss: 0.3370197117328644, Validation Accuracy: 0.89675\n",
      "Epoch: 75, Loss: 0.334900438785553, Validation Accuracy: 0.8986666666666666\n",
      "Epoch: 76, Loss: 0.33250972628593445, Validation Accuracy: 0.898\n",
      "Epoch: 77, Loss: 0.33050718903541565, Validation Accuracy: 0.89975\n",
      "Epoch: 78, Loss: 0.32832181453704834, Validation Accuracy: 0.8995\n",
      "Epoch: 79, Loss: 0.32640141248703003, Validation Accuracy: 0.901\n",
      "Epoch: 80, Loss: 0.3243521451950073, Validation Accuracy: 0.9001666666666667\n",
      "Epoch: 81, Loss: 0.32253512740135193, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 82, Loss: 0.32058557868003845, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 83, Loss: 0.3188909590244293, Validation Accuracy: 0.9033333333333333\n",
      "Epoch: 84, Loss: 0.31706535816192627, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 85, Loss: 0.3154583275318146, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 86, Loss: 0.31370076537132263, Validation Accuracy: 0.903\n",
      "Epoch: 87, Loss: 0.31217628717422485, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 88, Loss: 0.31050705909729004, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 89, Loss: 0.30910417437553406, Validation Accuracy: 0.906\n",
      "Epoch: 90, Loss: 0.30753323435783386, Validation Accuracy: 0.9048333333333334\n",
      "Epoch: 91, Loss: 0.3062019348144531, Validation Accuracy: 0.9071666666666667\n",
      "Epoch: 92, Loss: 0.3047010004520416, Validation Accuracy: 0.90525\n",
      "Epoch: 93, Loss: 0.3034820258617401, Validation Accuracy: 0.9081666666666667\n",
      "Epoch: 94, Loss: 0.30207037925720215, Validation Accuracy: 0.9061666666666667\n",
      "Epoch: 95, Loss: 0.300884872674942, Validation Accuracy: 0.9086666666666666\n",
      "Epoch: 96, Loss: 0.2995227575302124, Validation Accuracy: 0.9070833333333334\n",
      "Epoch: 97, Loss: 0.2984159290790558, Validation Accuracy: 0.91\n",
      "Epoch: 98, Loss: 0.29709315299987793, Validation Accuracy: 0.908\n",
      "Epoch: 99, Loss: 0.2960890829563141, Validation Accuracy: 0.9105833333333333\n",
      "Dataset 7\n",
      "Epoch: 0, Loss: 4.179474830627441, Validation Accuracy: 0.14108333333333334\n",
      "Epoch: 1, Loss: 3.5477066040039062, Validation Accuracy: 0.22566666666666665\n",
      "Epoch: 2, Loss: 2.5072081089019775, Validation Accuracy: 0.295\n",
      "Epoch: 3, Loss: 2.0979995727539062, Validation Accuracy: 0.4025\n",
      "Epoch: 4, Loss: 1.8378123044967651, Validation Accuracy: 0.46191666666666664\n",
      "Epoch: 5, Loss: 1.685447096824646, Validation Accuracy: 0.5101666666666667\n",
      "Epoch: 6, Loss: 1.55653715133667, Validation Accuracy: 0.5458333333333333\n",
      "Epoch: 7, Loss: 1.4397916793823242, Validation Accuracy: 0.58475\n",
      "Epoch: 8, Loss: 1.3436421155929565, Validation Accuracy: 0.5960833333333333\n",
      "Epoch: 9, Loss: 1.2721253633499146, Validation Accuracy: 0.6049166666666667\n",
      "Epoch: 10, Loss: 1.2432136535644531, Validation Accuracy: 0.5703333333333334\n",
      "Epoch: 11, Loss: 1.272855281829834, Validation Accuracy: 0.5255833333333333\n",
      "Epoch: 12, Loss: 1.381365180015564, Validation Accuracy: 0.5604166666666667\n",
      "Epoch: 13, Loss: 1.2344447374343872, Validation Accuracy: 0.6375\n",
      "Epoch: 14, Loss: 1.078201174736023, Validation Accuracy: 0.6764166666666667\n",
      "Epoch: 15, Loss: 0.9638311266899109, Validation Accuracy: 0.7051666666666667\n",
      "Epoch: 16, Loss: 0.893342137336731, Validation Accuracy: 0.7221666666666666\n",
      "Epoch: 17, Loss: 0.8462046980857849, Validation Accuracy: 0.7405833333333334\n",
      "Epoch: 18, Loss: 0.8113309144973755, Validation Accuracy: 0.7325833333333334\n",
      "Epoch: 19, Loss: 0.8177454471588135, Validation Accuracy: 0.71075\n",
      "Epoch: 20, Loss: 0.870927095413208, Validation Accuracy: 0.6438333333333334\n",
      "Epoch: 21, Loss: 1.0295462608337402, Validation Accuracy: 0.6434166666666666\n",
      "Epoch: 22, Loss: 1.075368046760559, Validation Accuracy: 0.7021666666666667\n",
      "Epoch: 23, Loss: 0.8876668810844421, Validation Accuracy: 0.7380833333333333\n",
      "Epoch: 24, Loss: 0.8003761172294617, Validation Accuracy: 0.7629166666666667\n",
      "Epoch: 25, Loss: 0.7394304275512695, Validation Accuracy: 0.7900833333333334\n",
      "Epoch: 26, Loss: 0.667441189289093, Validation Accuracy: 0.8033333333333333\n",
      "Epoch: 27, Loss: 0.6314705610275269, Validation Accuracy: 0.8156666666666667\n",
      "Epoch: 28, Loss: 0.6013760566711426, Validation Accuracy: 0.81975\n",
      "Epoch: 29, Loss: 0.5807486772537231, Validation Accuracy: 0.8266666666666667\n",
      "Epoch: 30, Loss: 0.5638201832771301, Validation Accuracy: 0.8268333333333333\n",
      "Epoch: 31, Loss: 0.5525562763214111, Validation Accuracy: 0.8325833333333333\n",
      "Epoch: 32, Loss: 0.5417650938034058, Validation Accuracy: 0.832\n",
      "Epoch: 33, Loss: 0.5360530018806458, Validation Accuracy: 0.8354166666666667\n",
      "Epoch: 34, Loss: 0.5282053351402283, Validation Accuracy: 0.8360833333333333\n",
      "Epoch: 35, Loss: 0.5258047580718994, Validation Accuracy: 0.83725\n",
      "Epoch: 36, Loss: 0.5188125371932983, Validation Accuracy: 0.8395833333333333\n",
      "Epoch: 37, Loss: 0.5170823931694031, Validation Accuracy: 0.8393333333333334\n",
      "Epoch: 38, Loss: 0.508208155632019, Validation Accuracy: 0.84325\n",
      "Epoch: 39, Loss: 0.5038179159164429, Validation Accuracy: 0.846\n",
      "Epoch: 40, Loss: 0.4915856122970581, Validation Accuracy: 0.85025\n",
      "Epoch: 41, Loss: 0.483750581741333, Validation Accuracy: 0.85425\n",
      "Epoch: 42, Loss: 0.47020772099494934, Validation Accuracy: 0.8578333333333333\n",
      "Epoch: 43, Loss: 0.461002916097641, Validation Accuracy: 0.8605833333333334\n",
      "Epoch: 44, Loss: 0.4493076205253601, Validation Accuracy: 0.86575\n",
      "Epoch: 45, Loss: 0.44107693433761597, Validation Accuracy: 0.8661666666666666\n",
      "Epoch: 46, Loss: 0.43185755610466003, Validation Accuracy: 0.8706666666666667\n",
      "Epoch: 47, Loss: 0.4250703454017639, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 48, Loss: 0.4180309772491455, Validation Accuracy: 0.8745\n",
      "Epoch: 49, Loss: 0.4125942289829254, Validation Accuracy: 0.8749166666666667\n",
      "Epoch: 50, Loss: 0.40702342987060547, Validation Accuracy: 0.8775833333333334\n",
      "Epoch: 51, Loss: 0.40250682830810547, Validation Accuracy: 0.8780833333333333\n",
      "Epoch: 52, Loss: 0.39774665236473083, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 53, Loss: 0.39389538764953613, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 54, Loss: 0.3897537887096405, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 55, Loss: 0.38632315397262573, Validation Accuracy: 0.8835\n",
      "Epoch: 56, Loss: 0.3827073276042938, Validation Accuracy: 0.8839166666666667\n",
      "Epoch: 57, Loss: 0.37962666153907776, Validation Accuracy: 0.8855833333333333\n",
      "Epoch: 58, Loss: 0.3762824833393097, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 59, Loss: 0.3735103905200958, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 60, Loss: 0.37049663066864014, Validation Accuracy: 0.8875\n",
      "Epoch: 61, Loss: 0.3679302930831909, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 62, Loss: 0.36514267325401306, Validation Accuracy: 0.8895\n",
      "Epoch: 63, Loss: 0.3627828359603882, Validation Accuracy: 0.89175\n",
      "Epoch: 64, Loss: 0.3602164387702942, Validation Accuracy: 0.89075\n",
      "Epoch: 65, Loss: 0.3580840528011322, Validation Accuracy: 0.89375\n",
      "Epoch: 66, Loss: 0.35569271445274353, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 67, Loss: 0.35375064611434937, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 68, Loss: 0.35153499245643616, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 69, Loss: 0.3497241735458374, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 70, Loss: 0.34754011034965515, Validation Accuracy: 0.8944166666666666\n",
      "Epoch: 71, Loss: 0.345929354429245, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 72, Loss: 0.3438534438610077, Validation Accuracy: 0.8955\n",
      "Epoch: 73, Loss: 0.34236687421798706, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 74, Loss: 0.340315043926239, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 75, Loss: 0.3389279842376709, Validation Accuracy: 0.89925\n",
      "Epoch: 76, Loss: 0.33687856793403625, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 77, Loss: 0.3354664444923401, Validation Accuracy: 0.90025\n",
      "Epoch: 78, Loss: 0.33342084288597107, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 79, Loss: 0.33198410272598267, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 80, Loss: 0.32998770475387573, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 81, Loss: 0.32861024141311646, Validation Accuracy: 0.90175\n",
      "Epoch: 82, Loss: 0.3265840709209442, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 83, Loss: 0.3252091109752655, Validation Accuracy: 0.9025\n",
      "Epoch: 84, Loss: 0.3232260048389435, Validation Accuracy: 0.9034166666666666\n",
      "Epoch: 85, Loss: 0.3218303322792053, Validation Accuracy: 0.9035\n",
      "Epoch: 86, Loss: 0.3199293315410614, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 87, Loss: 0.3185459077358246, Validation Accuracy: 0.90475\n",
      "Epoch: 88, Loss: 0.3166883885860443, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 89, Loss: 0.31528955698013306, Validation Accuracy: 0.90575\n",
      "Epoch: 90, Loss: 0.3134772479534149, Validation Accuracy: 0.906\n",
      "Epoch: 91, Loss: 0.3120252788066864, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 92, Loss: 0.3102326989173889, Validation Accuracy: 0.9066666666666666\n",
      "Epoch: 93, Loss: 0.3087688386440277, Validation Accuracy: 0.9085\n",
      "Epoch: 94, Loss: 0.30700406432151794, Validation Accuracy: 0.9075833333333333\n",
      "Epoch: 95, Loss: 0.30553776025772095, Validation Accuracy: 0.91\n",
      "Epoch: 96, Loss: 0.30380773544311523, Validation Accuracy: 0.9093333333333333\n",
      "Epoch: 97, Loss: 0.30235326290130615, Validation Accuracy: 0.9108333333333334\n",
      "Epoch: 98, Loss: 0.3007355034351349, Validation Accuracy: 0.9103333333333333\n",
      "Epoch: 99, Loss: 0.2992956042289734, Validation Accuracy: 0.9115\n",
      "Dataset 8\n",
      "Epoch: 0, Loss: 4.053699016571045, Validation Accuracy: 0.1305\n",
      "Epoch: 1, Loss: 3.8542425632476807, Validation Accuracy: 0.2823333333333333\n",
      "Epoch: 2, Loss: 2.3988938331604004, Validation Accuracy: 0.33808333333333335\n",
      "Epoch: 3, Loss: 2.044506788253784, Validation Accuracy: 0.4439166666666667\n",
      "Epoch: 4, Loss: 1.7610862255096436, Validation Accuracy: 0.48675\n",
      "Epoch: 5, Loss: 1.6390843391418457, Validation Accuracy: 0.5214166666666666\n",
      "Epoch: 6, Loss: 1.5342381000518799, Validation Accuracy: 0.5515\n",
      "Epoch: 7, Loss: 1.4402011632919312, Validation Accuracy: 0.5786666666666667\n",
      "Epoch: 8, Loss: 1.3552281856536865, Validation Accuracy: 0.60475\n",
      "Epoch: 9, Loss: 1.2787686586380005, Validation Accuracy: 0.62825\n",
      "Epoch: 10, Loss: 1.2112431526184082, Validation Accuracy: 0.6373333333333333\n",
      "Epoch: 11, Loss: 1.1530630588531494, Validation Accuracy: 0.6486666666666666\n",
      "Epoch: 12, Loss: 1.1087688207626343, Validation Accuracy: 0.63725\n",
      "Epoch: 13, Loss: 1.0886930227279663, Validation Accuracy: 0.6106666666666667\n",
      "Epoch: 14, Loss: 1.1252444982528687, Validation Accuracy: 0.5776666666666667\n",
      "Epoch: 15, Loss: 1.2015961408615112, Validation Accuracy: 0.5535833333333333\n",
      "Epoch: 16, Loss: 1.2149955034255981, Validation Accuracy: 0.6266666666666667\n",
      "Epoch: 17, Loss: 1.0687493085861206, Validation Accuracy: 0.6905\n",
      "Epoch: 18, Loss: 0.9168755412101746, Validation Accuracy: 0.7335833333333334\n",
      "Epoch: 19, Loss: 0.8416607975959778, Validation Accuracy: 0.7489166666666667\n",
      "Epoch: 20, Loss: 0.7905610203742981, Validation Accuracy: 0.76575\n",
      "Epoch: 21, Loss: 0.7522063851356506, Validation Accuracy: 0.77475\n",
      "Epoch: 22, Loss: 0.7205568552017212, Validation Accuracy: 0.7808333333333334\n",
      "Epoch: 23, Loss: 0.696230411529541, Validation Accuracy: 0.7853333333333333\n",
      "Epoch: 24, Loss: 0.6758187413215637, Validation Accuracy: 0.7884166666666667\n",
      "Epoch: 25, Loss: 0.6630733609199524, Validation Accuracy: 0.7875\n",
      "Epoch: 26, Loss: 0.6522034406661987, Validation Accuracy: 0.7866666666666666\n",
      "Epoch: 27, Loss: 0.6526317596435547, Validation Accuracy: 0.7810833333333334\n",
      "Epoch: 28, Loss: 0.6526992917060852, Validation Accuracy: 0.7745\n",
      "Epoch: 29, Loss: 0.667930543422699, Validation Accuracy: 0.7695833333333333\n",
      "Epoch: 30, Loss: 0.6799336075782776, Validation Accuracy: 0.7639166666666667\n",
      "Epoch: 31, Loss: 0.6831985116004944, Validation Accuracy: 0.7674166666666666\n",
      "Epoch: 32, Loss: 0.678823709487915, Validation Accuracy: 0.7895\n",
      "Epoch: 33, Loss: 0.6259363889694214, Validation Accuracy: 0.8075\n",
      "Epoch: 34, Loss: 0.5865233540534973, Validation Accuracy: 0.8236666666666667\n",
      "Epoch: 35, Loss: 0.5421794652938843, Validation Accuracy: 0.8398333333333333\n",
      "Epoch: 36, Loss: 0.5178086161613464, Validation Accuracy: 0.8425\n",
      "Epoch: 37, Loss: 0.49784138798713684, Validation Accuracy: 0.8506666666666667\n",
      "Epoch: 38, Loss: 0.4850391149520874, Validation Accuracy: 0.8521666666666666\n",
      "Epoch: 39, Loss: 0.473696768283844, Validation Accuracy: 0.8566666666666667\n",
      "Epoch: 40, Loss: 0.46487659215927124, Validation Accuracy: 0.8565833333333334\n",
      "Epoch: 41, Loss: 0.45672354102134705, Validation Accuracy: 0.8609166666666667\n",
      "Epoch: 42, Loss: 0.4496675729751587, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 43, Loss: 0.44305163621902466, Validation Accuracy: 0.8645833333333334\n",
      "Epoch: 44, Loss: 0.4370653033256531, Validation Accuracy: 0.8651666666666666\n",
      "Epoch: 45, Loss: 0.43138256669044495, Validation Accuracy: 0.867\n",
      "Epoch: 46, Loss: 0.42614033818244934, Validation Accuracy: 0.8690833333333333\n",
      "Epoch: 47, Loss: 0.4211907684803009, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 48, Loss: 0.416546106338501, Validation Accuracy: 0.871\n",
      "Epoch: 49, Loss: 0.41220223903656006, Validation Accuracy: 0.8716666666666667\n",
      "Epoch: 50, Loss: 0.40817883610725403, Validation Accuracy: 0.8729166666666667\n",
      "Epoch: 51, Loss: 0.40446531772613525, Validation Accuracy: 0.874\n",
      "Epoch: 52, Loss: 0.4011782109737396, Validation Accuracy: 0.8748333333333334\n",
      "Epoch: 53, Loss: 0.3982838988304138, Validation Accuracy: 0.87675\n",
      "Epoch: 54, Loss: 0.39592939615249634, Validation Accuracy: 0.8764166666666666\n",
      "Epoch: 55, Loss: 0.39423513412475586, Validation Accuracy: 0.8785\n",
      "Epoch: 56, Loss: 0.39346691966056824, Validation Accuracy: 0.8764166666666666\n",
      "Epoch: 57, Loss: 0.39357221126556396, Validation Accuracy: 0.8766666666666667\n",
      "Epoch: 58, Loss: 0.3951074481010437, Validation Accuracy: 0.87475\n",
      "Epoch: 59, Loss: 0.3979840576648712, Validation Accuracy: 0.8728333333333333\n",
      "Epoch: 60, Loss: 0.4027160704135895, Validation Accuracy: 0.8713333333333333\n",
      "Epoch: 61, Loss: 0.4082395136356354, Validation Accuracy: 0.8665833333333334\n",
      "Epoch: 62, Loss: 0.41574743390083313, Validation Accuracy: 0.8669166666666667\n",
      "Epoch: 63, Loss: 0.4206898510456085, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 64, Loss: 0.4264656603336334, Validation Accuracy: 0.8654166666666666\n",
      "Epoch: 65, Loss: 0.42245274782180786, Validation Accuracy: 0.86525\n",
      "Epoch: 66, Loss: 0.417949378490448, Validation Accuracy: 0.8725833333333334\n",
      "Epoch: 67, Loss: 0.4023335874080658, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 68, Loss: 0.3897862136363983, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 69, Loss: 0.3739989697933197, Validation Accuracy: 0.8865\n",
      "Epoch: 70, Loss: 0.36333245038986206, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 71, Loss: 0.3539638817310333, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 72, Loss: 0.34778210520744324, Validation Accuracy: 0.8925\n",
      "Epoch: 73, Loss: 0.3426451086997986, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 74, Loss: 0.33877214789390564, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 75, Loss: 0.3354457914829254, Validation Accuracy: 0.8961666666666667\n",
      "Epoch: 76, Loss: 0.3325877785682678, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 77, Loss: 0.32999661564826965, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 78, Loss: 0.3276357352733612, Validation Accuracy: 0.8985833333333333\n",
      "Epoch: 79, Loss: 0.32537686824798584, Validation Accuracy: 0.899\n",
      "Epoch: 80, Loss: 0.32326561212539673, Validation Accuracy: 0.8998333333333334\n",
      "Epoch: 81, Loss: 0.3212195038795471, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 82, Loss: 0.31925177574157715, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 83, Loss: 0.3173378109931946, Validation Accuracy: 0.9005833333333333\n",
      "Epoch: 84, Loss: 0.3154732882976532, Validation Accuracy: 0.9016666666666666\n",
      "Epoch: 85, Loss: 0.3136584460735321, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 86, Loss: 0.31188833713531494, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 87, Loss: 0.3101615309715271, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 88, Loss: 0.3084688186645508, Validation Accuracy: 0.90425\n",
      "Epoch: 89, Loss: 0.3068164885044098, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 90, Loss: 0.3051995038986206, Validation Accuracy: 0.9046666666666666\n",
      "Epoch: 91, Loss: 0.3036085069179535, Validation Accuracy: 0.9054166666666666\n",
      "Epoch: 92, Loss: 0.30204737186431885, Validation Accuracy: 0.9054166666666666\n",
      "Epoch: 93, Loss: 0.30051374435424805, Validation Accuracy: 0.9061666666666667\n",
      "Epoch: 94, Loss: 0.2990059554576874, Validation Accuracy: 0.9061666666666667\n",
      "Epoch: 95, Loss: 0.2975271940231323, Validation Accuracy: 0.90675\n",
      "Epoch: 96, Loss: 0.29606863856315613, Validation Accuracy: 0.907\n",
      "Epoch: 97, Loss: 0.29463377594947815, Validation Accuracy: 0.9075\n",
      "Epoch: 98, Loss: 0.2932214140892029, Validation Accuracy: 0.9076666666666666\n",
      "Epoch: 99, Loss: 0.29183289408683777, Validation Accuracy: 0.90825\n",
      "Dataset 9\n",
      "Epoch: 0, Loss: 3.6290276050567627, Validation Accuracy: 0.18483333333333332\n",
      "Epoch: 1, Loss: 3.2383062839508057, Validation Accuracy: 0.22258333333333333\n",
      "Epoch: 2, Loss: 3.355187177658081, Validation Accuracy: 0.13616666666666666\n",
      "Epoch: 3, Loss: 3.061859369277954, Validation Accuracy: 0.11783333333333333\n",
      "Epoch: 4, Loss: 3.1465108394622803, Validation Accuracy: 0.2510833333333333\n",
      "Epoch: 5, Loss: 2.2490735054016113, Validation Accuracy: 0.388\n",
      "Epoch: 6, Loss: 1.7987256050109863, Validation Accuracy: 0.45416666666666666\n",
      "Epoch: 7, Loss: 1.6244804859161377, Validation Accuracy: 0.5123333333333333\n",
      "Epoch: 8, Loss: 1.4884366989135742, Validation Accuracy: 0.5634166666666667\n",
      "Epoch: 9, Loss: 1.3593195676803589, Validation Accuracy: 0.60625\n",
      "Epoch: 10, Loss: 1.2379159927368164, Validation Accuracy: 0.63875\n",
      "Epoch: 11, Loss: 1.1284995079040527, Validation Accuracy: 0.6741666666666667\n",
      "Epoch: 12, Loss: 1.033601999282837, Validation Accuracy: 0.7025833333333333\n",
      "Epoch: 13, Loss: 0.9530907273292542, Validation Accuracy: 0.7325\n",
      "Epoch: 14, Loss: 0.886119544506073, Validation Accuracy: 0.7444166666666666\n",
      "Epoch: 15, Loss: 0.8319284915924072, Validation Accuracy: 0.75475\n",
      "Epoch: 16, Loss: 0.7897375226020813, Validation Accuracy: 0.762\n",
      "Epoch: 17, Loss: 0.7611503005027771, Validation Accuracy: 0.7593333333333333\n",
      "Epoch: 18, Loss: 0.751430332660675, Validation Accuracy: 0.7439166666666667\n",
      "Epoch: 19, Loss: 0.7833057641983032, Validation Accuracy: 0.7036666666666667\n",
      "Epoch: 20, Loss: 0.8734943866729736, Validation Accuracy: 0.6555\n",
      "Epoch: 21, Loss: 1.0204194784164429, Validation Accuracy: 0.6736666666666666\n",
      "Epoch: 22, Loss: 0.9623942971229553, Validation Accuracy: 0.7510833333333333\n",
      "Epoch: 23, Loss: 0.7574878931045532, Validation Accuracy: 0.7970833333333334\n",
      "Epoch: 24, Loss: 0.6583403944969177, Validation Accuracy: 0.81325\n",
      "Epoch: 25, Loss: 0.599564790725708, Validation Accuracy: 0.82425\n",
      "Epoch: 26, Loss: 0.5759464502334595, Validation Accuracy: 0.8275\n",
      "Epoch: 27, Loss: 0.5576955080032349, Validation Accuracy: 0.8318333333333333\n",
      "Epoch: 28, Loss: 0.5450578927993774, Validation Accuracy: 0.8325\n",
      "Epoch: 29, Loss: 0.5348148345947266, Validation Accuracy: 0.8351666666666666\n",
      "Epoch: 30, Loss: 0.5294275879859924, Validation Accuracy: 0.8320833333333333\n",
      "Epoch: 31, Loss: 0.5276057124137878, Validation Accuracy: 0.8310833333333333\n",
      "Epoch: 32, Loss: 0.535129189491272, Validation Accuracy: 0.8228333333333333\n",
      "Epoch: 33, Loss: 0.5508111119270325, Validation Accuracy: 0.8105\n",
      "Epoch: 34, Loss: 0.5803585648536682, Validation Accuracy: 0.8026666666666666\n",
      "Epoch: 35, Loss: 0.6070530414581299, Validation Accuracy: 0.79575\n",
      "Epoch: 36, Loss: 0.6199761033058167, Validation Accuracy: 0.8141666666666667\n",
      "Epoch: 37, Loss: 0.5800466537475586, Validation Accuracy: 0.8319166666666666\n",
      "Epoch: 38, Loss: 0.5248864889144897, Validation Accuracy: 0.85025\n",
      "Epoch: 39, Loss: 0.47920674085617065, Validation Accuracy: 0.862\n",
      "Epoch: 40, Loss: 0.453158438205719, Validation Accuracy: 0.8640833333333333\n",
      "Epoch: 41, Loss: 0.4395214319229126, Validation Accuracy: 0.8686666666666667\n",
      "Epoch: 42, Loss: 0.43041253089904785, Validation Accuracy: 0.8711666666666666\n",
      "Epoch: 43, Loss: 0.42346426844596863, Validation Accuracy: 0.8719166666666667\n",
      "Epoch: 44, Loss: 0.4175247848033905, Validation Accuracy: 0.8740833333333333\n",
      "Epoch: 45, Loss: 0.4121934473514557, Validation Accuracy: 0.8755833333333334\n",
      "Epoch: 46, Loss: 0.40723490715026855, Validation Accuracy: 0.8758333333333334\n",
      "Epoch: 47, Loss: 0.4025830924510956, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 48, Loss: 0.39817720651626587, Validation Accuracy: 0.87825\n",
      "Epoch: 49, Loss: 0.3939860761165619, Validation Accuracy: 0.87975\n",
      "Epoch: 50, Loss: 0.38996052742004395, Validation Accuracy: 0.8810833333333333\n",
      "Epoch: 51, Loss: 0.38609054684638977, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 52, Loss: 0.38237902522087097, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 53, Loss: 0.37880221009254456, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 54, Loss: 0.3753497302532196, Validation Accuracy: 0.885\n",
      "Epoch: 55, Loss: 0.37201163172721863, Validation Accuracy: 0.88525\n",
      "Epoch: 56, Loss: 0.36878299713134766, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 57, Loss: 0.36566630005836487, Validation Accuracy: 0.8873333333333333\n",
      "Epoch: 58, Loss: 0.36264485120773315, Validation Accuracy: 0.8876666666666667\n",
      "Epoch: 59, Loss: 0.35971829295158386, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 60, Loss: 0.3568859100341797, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 61, Loss: 0.35413679480552673, Validation Accuracy: 0.8896666666666667\n",
      "Epoch: 62, Loss: 0.3514658510684967, Validation Accuracy: 0.8908333333333334\n",
      "Epoch: 63, Loss: 0.34888216853141785, Validation Accuracy: 0.8913333333333333\n",
      "Epoch: 64, Loss: 0.3463723063468933, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 65, Loss: 0.34393250942230225, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 66, Loss: 0.3415675163269043, Validation Accuracy: 0.8936666666666667\n",
      "Epoch: 67, Loss: 0.33927062153816223, Validation Accuracy: 0.89475\n",
      "Epoch: 68, Loss: 0.3370438814163208, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 69, Loss: 0.33487603068351746, Validation Accuracy: 0.8965\n",
      "Epoch: 70, Loss: 0.33277228474617004, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 71, Loss: 0.3307354152202606, Validation Accuracy: 0.898\n",
      "Epoch: 72, Loss: 0.3287322223186493, Validation Accuracy: 0.89725\n",
      "Epoch: 73, Loss: 0.32680079340934753, Validation Accuracy: 0.8988333333333334\n",
      "Epoch: 74, Loss: 0.3249020278453827, Validation Accuracy: 0.8991666666666667\n",
      "Epoch: 75, Loss: 0.32307013869285583, Validation Accuracy: 0.8996666666666666\n",
      "Epoch: 76, Loss: 0.3213004469871521, Validation Accuracy: 0.9000833333333333\n",
      "Epoch: 77, Loss: 0.3195752501487732, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 78, Loss: 0.31791922450065613, Validation Accuracy: 0.9008333333333334\n",
      "Epoch: 79, Loss: 0.31635239720344543, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 80, Loss: 0.31488052010536194, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 81, Loss: 0.31348103284835815, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 82, Loss: 0.31217679381370544, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 83, Loss: 0.3110080063343048, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 84, Loss: 0.30988582968711853, Validation Accuracy: 0.9025833333333333\n",
      "Epoch: 85, Loss: 0.3089692294597626, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 86, Loss: 0.30802422761917114, Validation Accuracy: 0.9026666666666666\n",
      "Epoch: 87, Loss: 0.3073550760746002, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 88, Loss: 0.30666735768318176, Validation Accuracy: 0.9028333333333334\n",
      "Epoch: 89, Loss: 0.30622154474258423, Validation Accuracy: 0.9035\n",
      "Epoch: 90, Loss: 0.30566149950027466, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 91, Loss: 0.30552399158477783, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 92, Loss: 0.304959774017334, Validation Accuracy: 0.9015\n",
      "Epoch: 93, Loss: 0.30482223629951477, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 94, Loss: 0.3041188716888428, Validation Accuracy: 0.9016666666666666\n",
      "Epoch: 95, Loss: 0.3038772940635681, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 96, Loss: 0.30285894870758057, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 97, Loss: 0.3022748529911041, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 98, Loss: 0.3006610572338104, Validation Accuracy: 0.90275\n",
      "Epoch: 99, Loss: 0.2995067238807678, Validation Accuracy: 0.9060833333333334\n",
      "Dataset 10\n",
      "Epoch: 0, Loss: 3.369288682937622, Validation Accuracy: 0.149\n",
      "Epoch: 1, Loss: 3.0048775672912598, Validation Accuracy: 0.21433333333333332\n",
      "Epoch: 2, Loss: 2.4598653316497803, Validation Accuracy: 0.31333333333333335\n",
      "Epoch: 3, Loss: 1.9524445533752441, Validation Accuracy: 0.40708333333333335\n",
      "Epoch: 4, Loss: 1.7548719644546509, Validation Accuracy: 0.5138333333333334\n",
      "Epoch: 5, Loss: 1.547002911567688, Validation Accuracy: 0.568\n",
      "Epoch: 6, Loss: 1.374927282333374, Validation Accuracy: 0.6265833333333334\n",
      "Epoch: 7, Loss: 1.2197139263153076, Validation Accuracy: 0.657\n",
      "Epoch: 8, Loss: 1.0914726257324219, Validation Accuracy: 0.6904166666666667\n",
      "Epoch: 9, Loss: 0.9984591603279114, Validation Accuracy: 0.6845\n",
      "Epoch: 10, Loss: 0.9554738998413086, Validation Accuracy: 0.6690833333333334\n",
      "Epoch: 11, Loss: 1.0009158849716187, Validation Accuracy: 0.6009166666666667\n",
      "Epoch: 12, Loss: 1.1477737426757812, Validation Accuracy: 0.6035\n",
      "Epoch: 13, Loss: 1.2082116603851318, Validation Accuracy: 0.6854166666666667\n",
      "Epoch: 14, Loss: 0.9332816004753113, Validation Accuracy: 0.77225\n",
      "Epoch: 15, Loss: 0.7382896542549133, Validation Accuracy: 0.78525\n",
      "Epoch: 16, Loss: 0.6827884912490845, Validation Accuracy: 0.79575\n",
      "Epoch: 17, Loss: 0.653118371963501, Validation Accuracy: 0.7994166666666667\n",
      "Epoch: 18, Loss: 0.6356751918792725, Validation Accuracy: 0.7964166666666667\n",
      "Epoch: 19, Loss: 0.6337220072746277, Validation Accuracy: 0.7961666666666667\n",
      "Epoch: 20, Loss: 0.6369012594223022, Validation Accuracy: 0.7836666666666666\n",
      "Epoch: 21, Loss: 0.6573293805122375, Validation Accuracy: 0.7875\n",
      "Epoch: 22, Loss: 0.6584115624427795, Validation Accuracy: 0.7841666666666667\n",
      "Epoch: 23, Loss: 0.6561399102210999, Validation Accuracy: 0.8070833333333334\n",
      "Epoch: 24, Loss: 0.6083658337593079, Validation Accuracy: 0.8186666666666667\n",
      "Epoch: 25, Loss: 0.5651438236236572, Validation Accuracy: 0.83525\n",
      "Epoch: 26, Loss: 0.5243433713912964, Validation Accuracy: 0.84425\n",
      "Epoch: 27, Loss: 0.49824950098991394, Validation Accuracy: 0.8498333333333333\n",
      "Epoch: 28, Loss: 0.4805237948894501, Validation Accuracy: 0.8546666666666667\n",
      "Epoch: 29, Loss: 0.4675937592983246, Validation Accuracy: 0.8580833333333333\n",
      "Epoch: 30, Loss: 0.4577120244503021, Validation Accuracy: 0.8595\n",
      "Epoch: 31, Loss: 0.44963008165359497, Validation Accuracy: 0.8610833333333333\n",
      "Epoch: 32, Loss: 0.44285908341407776, Validation Accuracy: 0.8620833333333333\n",
      "Epoch: 33, Loss: 0.43802183866500854, Validation Accuracy: 0.862\n",
      "Epoch: 34, Loss: 0.4338395297527313, Validation Accuracy: 0.86225\n",
      "Epoch: 35, Loss: 0.43292236328125, Validation Accuracy: 0.86275\n",
      "Epoch: 36, Loss: 0.43219128251075745, Validation Accuracy: 0.8588333333333333\n",
      "Epoch: 37, Loss: 0.4371298551559448, Validation Accuracy: 0.8589166666666667\n",
      "Epoch: 38, Loss: 0.4411802589893341, Validation Accuracy: 0.8493333333333334\n",
      "Epoch: 39, Loss: 0.45430731773376465, Validation Accuracy: 0.8503333333333334\n",
      "Epoch: 40, Loss: 0.46100589632987976, Validation Accuracy: 0.8414166666666667\n",
      "Epoch: 41, Loss: 0.47815316915512085, Validation Accuracy: 0.84425\n",
      "Epoch: 42, Loss: 0.47328126430511475, Validation Accuracy: 0.8429166666666666\n",
      "Epoch: 43, Loss: 0.471957266330719, Validation Accuracy: 0.8569166666666667\n",
      "Epoch: 44, Loss: 0.44107794761657715, Validation Accuracy: 0.86325\n",
      "Epoch: 45, Loss: 0.4179396629333496, Validation Accuracy: 0.8760833333333333\n",
      "Epoch: 46, Loss: 0.3910459280014038, Validation Accuracy: 0.8800833333333333\n",
      "Epoch: 47, Loss: 0.37612462043762207, Validation Accuracy: 0.88425\n",
      "Epoch: 48, Loss: 0.36585351824760437, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 49, Loss: 0.3594592809677124, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 50, Loss: 0.35456714034080505, Validation Accuracy: 0.8886666666666667\n",
      "Epoch: 51, Loss: 0.35063180327415466, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 52, Loss: 0.3471052646636963, Validation Accuracy: 0.89075\n",
      "Epoch: 53, Loss: 0.34387874603271484, Validation Accuracy: 0.8926666666666667\n",
      "Epoch: 54, Loss: 0.3408450782299042, Validation Accuracy: 0.8935\n",
      "Epoch: 55, Loss: 0.3379600942134857, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 56, Loss: 0.335204541683197, Validation Accuracy: 0.8955\n",
      "Epoch: 57, Loss: 0.33256471157073975, Validation Accuracy: 0.8959166666666667\n",
      "Epoch: 58, Loss: 0.3300168812274933, Validation Accuracy: 0.8966666666666666\n",
      "Epoch: 59, Loss: 0.3275499939918518, Validation Accuracy: 0.8970833333333333\n",
      "Epoch: 60, Loss: 0.3251640498638153, Validation Accuracy: 0.8978333333333334\n",
      "Epoch: 61, Loss: 0.32285064458847046, Validation Accuracy: 0.8979166666666667\n",
      "Epoch: 62, Loss: 0.32060372829437256, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 63, Loss: 0.3184163570404053, Validation Accuracy: 0.8999166666666667\n",
      "Epoch: 64, Loss: 0.31628844141960144, Validation Accuracy: 0.90025\n",
      "Epoch: 65, Loss: 0.3142155110836029, Validation Accuracy: 0.901\n",
      "Epoch: 66, Loss: 0.31219473481178284, Validation Accuracy: 0.9015\n",
      "Epoch: 67, Loss: 0.3102167248725891, Validation Accuracy: 0.90225\n",
      "Epoch: 68, Loss: 0.30828526616096497, Validation Accuracy: 0.9028333333333334\n",
      "Epoch: 69, Loss: 0.30639490485191345, Validation Accuracy: 0.90325\n",
      "Epoch: 70, Loss: 0.3045479953289032, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 71, Loss: 0.30273908376693726, Validation Accuracy: 0.9044166666666666\n",
      "Epoch: 72, Loss: 0.30096617341041565, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 73, Loss: 0.29922905564308167, Validation Accuracy: 0.9055\n",
      "Epoch: 74, Loss: 0.29752710461616516, Validation Accuracy: 0.9063333333333333\n",
      "Epoch: 75, Loss: 0.29585933685302734, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 76, Loss: 0.29422593116760254, Validation Accuracy: 0.90725\n",
      "Epoch: 77, Loss: 0.2926218509674072, Validation Accuracy: 0.9078333333333334\n",
      "Epoch: 78, Loss: 0.2910457253456116, Validation Accuracy: 0.90825\n",
      "Epoch: 79, Loss: 0.2894982397556305, Validation Accuracy: 0.9091666666666667\n",
      "Epoch: 80, Loss: 0.2879786491394043, Validation Accuracy: 0.9095\n",
      "Epoch: 81, Loss: 0.2864881455898285, Validation Accuracy: 0.90975\n",
      "Epoch: 82, Loss: 0.2850199043750763, Validation Accuracy: 0.9105833333333333\n",
      "Epoch: 83, Loss: 0.28357505798339844, Validation Accuracy: 0.9108333333333334\n",
      "Epoch: 84, Loss: 0.28215330839157104, Validation Accuracy: 0.9115833333333333\n",
      "Epoch: 85, Loss: 0.2807527780532837, Validation Accuracy: 0.9115833333333333\n",
      "Epoch: 86, Loss: 0.2793741822242737, Validation Accuracy: 0.9120833333333334\n",
      "Epoch: 87, Loss: 0.27801862359046936, Validation Accuracy: 0.9118333333333334\n",
      "Epoch: 88, Loss: 0.27668359875679016, Validation Accuracy: 0.9121666666666667\n",
      "Epoch: 89, Loss: 0.2753698527812958, Validation Accuracy: 0.9124166666666667\n",
      "Epoch: 90, Loss: 0.27407780289649963, Validation Accuracy: 0.9130833333333334\n",
      "Epoch: 91, Loss: 0.2728021442890167, Validation Accuracy: 0.9129166666666667\n",
      "Epoch: 92, Loss: 0.271546334028244, Validation Accuracy: 0.9135833333333333\n",
      "Epoch: 93, Loss: 0.2703092694282532, Validation Accuracy: 0.9138333333333334\n",
      "Epoch: 94, Loss: 0.2690875232219696, Validation Accuracy: 0.9145833333333333\n",
      "Epoch: 95, Loss: 0.26788249611854553, Validation Accuracy: 0.9141666666666667\n",
      "Epoch: 96, Loss: 0.2666928172111511, Validation Accuracy: 0.9150833333333334\n",
      "Epoch: 97, Loss: 0.26551976799964905, Validation Accuracy: 0.91475\n",
      "Epoch: 98, Loss: 0.26436156034469604, Validation Accuracy: 0.9153333333333333\n",
      "Epoch: 99, Loss: 0.2632186710834503, Validation Accuracy: 0.9150833333333334\n",
      "Dataset 11\n",
      "Epoch: 0, Loss: 3.239055871963501, Validation Accuracy: 0.21866666666666668\n",
      "Epoch: 1, Loss: 3.052198648452759, Validation Accuracy: 0.2826666666666667\n",
      "Epoch: 2, Loss: 2.4121510982513428, Validation Accuracy: 0.3275\n",
      "Epoch: 3, Loss: 1.9123579263687134, Validation Accuracy: 0.44558333333333333\n",
      "Epoch: 4, Loss: 1.5982820987701416, Validation Accuracy: 0.5123333333333333\n",
      "Epoch: 5, Loss: 1.4206960201263428, Validation Accuracy: 0.5488333333333333\n",
      "Epoch: 6, Loss: 1.2894606590270996, Validation Accuracy: 0.58475\n",
      "Epoch: 7, Loss: 1.178600788116455, Validation Accuracy: 0.6188333333333333\n",
      "Epoch: 8, Loss: 1.0841938257217407, Validation Accuracy: 0.6478333333333334\n",
      "Epoch: 9, Loss: 1.0151207447052002, Validation Accuracy: 0.6571666666666667\n",
      "Epoch: 10, Loss: 1.0007184743881226, Validation Accuracy: 0.6039166666666667\n",
      "Epoch: 11, Loss: 1.1235624551773071, Validation Accuracy: 0.5310833333333334\n",
      "Epoch: 12, Loss: 1.460113763809204, Validation Accuracy: 0.5511666666666667\n",
      "Epoch: 13, Loss: 1.2694058418273926, Validation Accuracy: 0.68325\n",
      "Epoch: 14, Loss: 0.9578374624252319, Validation Accuracy: 0.72725\n",
      "Epoch: 15, Loss: 0.8114287257194519, Validation Accuracy: 0.7564166666666666\n",
      "Epoch: 16, Loss: 0.7296351790428162, Validation Accuracy: 0.7736666666666666\n",
      "Epoch: 17, Loss: 0.6904168128967285, Validation Accuracy: 0.7768333333333334\n",
      "Epoch: 18, Loss: 0.6626185178756714, Validation Accuracy: 0.7878333333333334\n",
      "Epoch: 19, Loss: 0.6470072865486145, Validation Accuracy: 0.7841666666666667\n",
      "Epoch: 20, Loss: 0.6361847519874573, Validation Accuracy: 0.7895833333333333\n",
      "Epoch: 21, Loss: 0.6398793458938599, Validation Accuracy: 0.7784166666666666\n",
      "Epoch: 22, Loss: 0.6387266516685486, Validation Accuracy: 0.7836666666666666\n",
      "Epoch: 23, Loss: 0.6547885537147522, Validation Accuracy: 0.7774166666666666\n",
      "Epoch: 24, Loss: 0.6330764293670654, Validation Accuracy: 0.7968333333333333\n",
      "Epoch: 25, Loss: 0.6184900999069214, Validation Accuracy: 0.8045\n",
      "Epoch: 26, Loss: 0.5719274282455444, Validation Accuracy: 0.8244166666666667\n",
      "Epoch: 27, Loss: 0.5429279208183289, Validation Accuracy: 0.8288333333333333\n",
      "Epoch: 28, Loss: 0.5148295760154724, Validation Accuracy: 0.8411666666666666\n",
      "Epoch: 29, Loss: 0.4980860948562622, Validation Accuracy: 0.8405833333333333\n",
      "Epoch: 30, Loss: 0.48321953415870667, Validation Accuracy: 0.8485\n",
      "Epoch: 31, Loss: 0.47259625792503357, Validation Accuracy: 0.8483333333333334\n",
      "Epoch: 32, Loss: 0.4627276659011841, Validation Accuracy: 0.8543333333333333\n",
      "Epoch: 33, Loss: 0.4549618065357208, Validation Accuracy: 0.8545833333333334\n",
      "Epoch: 34, Loss: 0.4472777843475342, Validation Accuracy: 0.8595\n",
      "Epoch: 35, Loss: 0.4410713016986847, Validation Accuracy: 0.85925\n",
      "Epoch: 36, Loss: 0.43462085723876953, Validation Accuracy: 0.86325\n",
      "Epoch: 37, Loss: 0.4296153485774994, Validation Accuracy: 0.863\n",
      "Epoch: 38, Loss: 0.4240107536315918, Validation Accuracy: 0.86575\n",
      "Epoch: 39, Loss: 0.42001110315322876, Validation Accuracy: 0.8665\n",
      "Epoch: 40, Loss: 0.41519930958747864, Validation Accuracy: 0.8686666666666667\n",
      "Epoch: 41, Loss: 0.41215503215789795, Validation Accuracy: 0.8676666666666667\n",
      "Epoch: 42, Loss: 0.40781277418136597, Validation Accuracy: 0.87025\n",
      "Epoch: 43, Loss: 0.4055861830711365, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 44, Loss: 0.4016024172306061, Validation Accuracy: 0.8726666666666667\n",
      "Epoch: 45, Loss: 0.3998931348323822, Validation Accuracy: 0.8708333333333333\n",
      "Epoch: 46, Loss: 0.39601245522499084, Validation Accuracy: 0.87475\n",
      "Epoch: 47, Loss: 0.39457860589027405, Validation Accuracy: 0.8720833333333333\n",
      "Epoch: 48, Loss: 0.3902546763420105, Validation Accuracy: 0.8769166666666667\n",
      "Epoch: 49, Loss: 0.38844209909439087, Validation Accuracy: 0.8749166666666667\n",
      "Epoch: 50, Loss: 0.3834365904331207, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 51, Loss: 0.3808794617652893, Validation Accuracy: 0.87825\n",
      "Epoch: 52, Loss: 0.37539854645729065, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 53, Loss: 0.3720947802066803, Validation Accuracy: 0.8818333333333334\n",
      "Epoch: 54, Loss: 0.3664790987968445, Validation Accuracy: 0.8841666666666667\n",
      "Epoch: 55, Loss: 0.36279961466789246, Validation Accuracy: 0.8864166666666666\n",
      "Epoch: 56, Loss: 0.3576403856277466, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 57, Loss: 0.3540738523006439, Validation Accuracy: 0.8895\n",
      "Epoch: 58, Loss: 0.34958910942077637, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 59, Loss: 0.34624043107032776, Validation Accuracy: 0.89175\n",
      "Epoch: 60, Loss: 0.34247350692749023, Validation Accuracy: 0.892\n",
      "Epoch: 61, Loss: 0.3394905924797058, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 62, Loss: 0.33628204464912415, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 63, Loss: 0.33359333872795105, Validation Accuracy: 0.8944166666666666\n",
      "Epoch: 64, Loss: 0.3308204412460327, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 65, Loss: 0.3283129334449768, Validation Accuracy: 0.89625\n",
      "Epoch: 66, Loss: 0.3258163332939148, Validation Accuracy: 0.897\n",
      "Epoch: 67, Loss: 0.3235073387622833, Validation Accuracy: 0.89725\n",
      "Epoch: 68, Loss: 0.3212326765060425, Validation Accuracy: 0.899\n",
      "Epoch: 69, Loss: 0.31906363368034363, Validation Accuracy: 0.8986666666666666\n",
      "Epoch: 70, Loss: 0.31694984436035156, Validation Accuracy: 0.9000833333333333\n",
      "Epoch: 71, Loss: 0.3148886561393738, Validation Accuracy: 0.9005\n",
      "Epoch: 72, Loss: 0.3128732144832611, Validation Accuracy: 0.9023333333333333\n",
      "Epoch: 73, Loss: 0.31089696288108826, Validation Accuracy: 0.902\n",
      "Epoch: 74, Loss: 0.30897897481918335, Validation Accuracy: 0.9035\n",
      "Epoch: 75, Loss: 0.30709385871887207, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 76, Loss: 0.3052441477775574, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 77, Loss: 0.30344969034194946, Validation Accuracy: 0.9045\n",
      "Epoch: 78, Loss: 0.301703542470932, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 79, Loss: 0.2999826669692993, Validation Accuracy: 0.9061666666666667\n",
      "Epoch: 80, Loss: 0.2983008027076721, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 81, Loss: 0.2966163456439972, Validation Accuracy: 0.9070833333333334\n",
      "Epoch: 82, Loss: 0.2949810326099396, Validation Accuracy: 0.9078333333333334\n",
      "Epoch: 83, Loss: 0.2933684289455414, Validation Accuracy: 0.9080833333333334\n",
      "Epoch: 84, Loss: 0.2918087840080261, Validation Accuracy: 0.9084166666666667\n",
      "Epoch: 85, Loss: 0.2902648150920868, Validation Accuracy: 0.9091666666666667\n",
      "Epoch: 86, Loss: 0.2887571454048157, Validation Accuracy: 0.9091666666666667\n",
      "Epoch: 87, Loss: 0.2872457206249237, Validation Accuracy: 0.9103333333333333\n",
      "Epoch: 88, Loss: 0.2857568860054016, Validation Accuracy: 0.9099166666666667\n",
      "Epoch: 89, Loss: 0.28426477313041687, Validation Accuracy: 0.9119166666666667\n",
      "Epoch: 90, Loss: 0.28283044695854187, Validation Accuracy: 0.9113333333333333\n",
      "Epoch: 91, Loss: 0.28139081597328186, Validation Accuracy: 0.9134166666666667\n",
      "Epoch: 92, Loss: 0.28000596165657043, Validation Accuracy: 0.9129166666666667\n",
      "Epoch: 93, Loss: 0.2786235809326172, Validation Accuracy: 0.91425\n",
      "Epoch: 94, Loss: 0.2772649824619293, Validation Accuracy: 0.91375\n",
      "Epoch: 95, Loss: 0.27590110898017883, Validation Accuracy: 0.9145\n",
      "Epoch: 96, Loss: 0.27458637952804565, Validation Accuracy: 0.91525\n",
      "Epoch: 97, Loss: 0.2732594311237335, Validation Accuracy: 0.9153333333333333\n",
      "Epoch: 98, Loss: 0.2719767093658447, Validation Accuracy: 0.91625\n",
      "Epoch: 99, Loss: 0.270691454410553, Validation Accuracy: 0.9159166666666667\n",
      "Dataset 12\n",
      "Epoch: 0, Loss: 3.389589309692383, Validation Accuracy: 0.1705\n",
      "Epoch: 1, Loss: 3.4862451553344727, Validation Accuracy: 0.23725\n",
      "Epoch: 2, Loss: 2.639328718185425, Validation Accuracy: 0.14375\n",
      "Epoch: 3, Loss: 2.5163848400115967, Validation Accuracy: 0.31766666666666665\n",
      "Epoch: 4, Loss: 2.058166027069092, Validation Accuracy: 0.3715\n",
      "Epoch: 5, Loss: 1.7821598052978516, Validation Accuracy: 0.488\n",
      "Epoch: 6, Loss: 1.486501932144165, Validation Accuracy: 0.5641666666666667\n",
      "Epoch: 7, Loss: 1.3115437030792236, Validation Accuracy: 0.6290833333333333\n",
      "Epoch: 8, Loss: 1.1696807146072388, Validation Accuracy: 0.67025\n",
      "Epoch: 9, Loss: 1.0548896789550781, Validation Accuracy: 0.6918333333333333\n",
      "Epoch: 10, Loss: 0.9746387004852295, Validation Accuracy: 0.70075\n",
      "Epoch: 11, Loss: 0.9347886443138123, Validation Accuracy: 0.6845833333333333\n",
      "Epoch: 12, Loss: 0.9503204226493835, Validation Accuracy: 0.66575\n",
      "Epoch: 13, Loss: 0.9873956441879272, Validation Accuracy: 0.6686666666666666\n",
      "Epoch: 14, Loss: 0.9643097519874573, Validation Accuracy: 0.7284166666666667\n",
      "Epoch: 15, Loss: 0.8142279982566833, Validation Accuracy: 0.75675\n",
      "Epoch: 16, Loss: 0.7255547046661377, Validation Accuracy: 0.7906666666666666\n",
      "Epoch: 17, Loss: 0.666121780872345, Validation Accuracy: 0.7933333333333333\n",
      "Epoch: 18, Loss: 0.634810209274292, Validation Accuracy: 0.8068333333333333\n",
      "Epoch: 19, Loss: 0.6123641133308411, Validation Accuracy: 0.8059166666666666\n",
      "Epoch: 20, Loss: 0.595007598400116, Validation Accuracy: 0.81375\n",
      "Epoch: 21, Loss: 0.5853833556175232, Validation Accuracy: 0.81075\n",
      "Epoch: 22, Loss: 0.575222909450531, Validation Accuracy: 0.8179166666666666\n",
      "Epoch: 23, Loss: 0.5700605511665344, Validation Accuracy: 0.8149166666666666\n",
      "Epoch: 24, Loss: 0.5598354935646057, Validation Accuracy: 0.82675\n",
      "Epoch: 25, Loss: 0.5482982397079468, Validation Accuracy: 0.82575\n",
      "Epoch: 26, Loss: 0.5314514636993408, Validation Accuracy: 0.8401666666666666\n",
      "Epoch: 27, Loss: 0.5129532814025879, Validation Accuracy: 0.8389166666666666\n",
      "Epoch: 28, Loss: 0.49410709738731384, Validation Accuracy: 0.8526666666666667\n",
      "Epoch: 29, Loss: 0.47694066166877747, Validation Accuracy: 0.8534166666666667\n",
      "Epoch: 30, Loss: 0.4625570774078369, Validation Accuracy: 0.8596666666666667\n",
      "Epoch: 31, Loss: 0.45022302865982056, Validation Accuracy: 0.8615\n",
      "Epoch: 32, Loss: 0.4401208162307739, Validation Accuracy: 0.8660833333333333\n",
      "Epoch: 33, Loss: 0.4313214123249054, Validation Accuracy: 0.8676666666666667\n",
      "Epoch: 34, Loss: 0.42364004254341125, Validation Accuracy: 0.8714166666666666\n",
      "Epoch: 35, Loss: 0.4167995750904083, Validation Accuracy: 0.87275\n",
      "Epoch: 36, Loss: 0.41051289439201355, Validation Accuracy: 0.8763333333333333\n",
      "Epoch: 37, Loss: 0.4047381579875946, Validation Accuracy: 0.8771666666666667\n",
      "Epoch: 38, Loss: 0.39933305978775024, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 39, Loss: 0.3942488729953766, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 40, Loss: 0.3894447982311249, Validation Accuracy: 0.8823333333333333\n",
      "Epoch: 41, Loss: 0.3848734498023987, Validation Accuracy: 0.884\n",
      "Epoch: 42, Loss: 0.38052913546562195, Validation Accuracy: 0.8851666666666667\n",
      "Epoch: 43, Loss: 0.37638115882873535, Validation Accuracy: 0.88725\n",
      "Epoch: 44, Loss: 0.37241503596305847, Validation Accuracy: 0.8876666666666667\n",
      "Epoch: 45, Loss: 0.3686210513114929, Validation Accuracy: 0.88875\n",
      "Epoch: 46, Loss: 0.36499133706092834, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 47, Loss: 0.36149272322654724, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 48, Loss: 0.3581221103668213, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 49, Loss: 0.35487833619117737, Validation Accuracy: 0.89375\n",
      "Epoch: 50, Loss: 0.35174334049224854, Validation Accuracy: 0.89475\n",
      "Epoch: 51, Loss: 0.3487050235271454, Validation Accuracy: 0.8951666666666667\n",
      "Epoch: 52, Loss: 0.34576213359832764, Validation Accuracy: 0.8961666666666667\n",
      "Epoch: 53, Loss: 0.3429064154624939, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 54, Loss: 0.34013932943344116, Validation Accuracy: 0.8978333333333334\n",
      "Epoch: 55, Loss: 0.33745062351226807, Validation Accuracy: 0.89825\n",
      "Epoch: 56, Loss: 0.33483460545539856, Validation Accuracy: 0.89975\n",
      "Epoch: 57, Loss: 0.3322843015193939, Validation Accuracy: 0.9001666666666667\n",
      "Epoch: 58, Loss: 0.3298027217388153, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 59, Loss: 0.3273935616016388, Validation Accuracy: 0.9008333333333334\n",
      "Epoch: 60, Loss: 0.32504385709762573, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 61, Loss: 0.32275334000587463, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 62, Loss: 0.3205210864543915, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 63, Loss: 0.31834617257118225, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 64, Loss: 0.31622472405433655, Validation Accuracy: 0.904\n",
      "Epoch: 65, Loss: 0.31415316462516785, Validation Accuracy: 0.9048333333333334\n",
      "Epoch: 66, Loss: 0.3121277391910553, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 67, Loss: 0.31015145778656006, Validation Accuracy: 0.9059166666666667\n",
      "Epoch: 68, Loss: 0.30821922421455383, Validation Accuracy: 0.9065\n",
      "Epoch: 69, Loss: 0.3063339591026306, Validation Accuracy: 0.9071666666666667\n",
      "Epoch: 70, Loss: 0.30449172854423523, Validation Accuracy: 0.9075\n",
      "Epoch: 71, Loss: 0.30268895626068115, Validation Accuracy: 0.9080833333333334\n",
      "Epoch: 72, Loss: 0.30092400312423706, Validation Accuracy: 0.9084166666666667\n",
      "Epoch: 73, Loss: 0.2991974353790283, Validation Accuracy: 0.9088333333333334\n",
      "Epoch: 74, Loss: 0.2975032925605774, Validation Accuracy: 0.9094166666666667\n",
      "Epoch: 75, Loss: 0.29583942890167236, Validation Accuracy: 0.9096666666666666\n",
      "Epoch: 76, Loss: 0.2942098081111908, Validation Accuracy: 0.9096666666666666\n",
      "Epoch: 77, Loss: 0.29261279106140137, Validation Accuracy: 0.9103333333333333\n",
      "Epoch: 78, Loss: 0.29104727506637573, Validation Accuracy: 0.9111666666666667\n",
      "Epoch: 79, Loss: 0.28950950503349304, Validation Accuracy: 0.9114166666666667\n",
      "Epoch: 80, Loss: 0.2879961133003235, Validation Accuracy: 0.9119166666666667\n",
      "Epoch: 81, Loss: 0.28650808334350586, Validation Accuracy: 0.9120833333333334\n",
      "Epoch: 82, Loss: 0.28504472970962524, Validation Accuracy: 0.91275\n",
      "Epoch: 83, Loss: 0.28360578417778015, Validation Accuracy: 0.9131666666666667\n",
      "Epoch: 84, Loss: 0.2821897566318512, Validation Accuracy: 0.9136666666666666\n",
      "Epoch: 85, Loss: 0.28079426288604736, Validation Accuracy: 0.9143333333333333\n",
      "Epoch: 86, Loss: 0.2794211506843567, Validation Accuracy: 0.915\n",
      "Epoch: 87, Loss: 0.2780676782131195, Validation Accuracy: 0.9151666666666667\n",
      "Epoch: 88, Loss: 0.27673518657684326, Validation Accuracy: 0.9156666666666666\n",
      "Epoch: 89, Loss: 0.2754233181476593, Validation Accuracy: 0.916\n",
      "Epoch: 90, Loss: 0.27412959933280945, Validation Accuracy: 0.9163333333333333\n",
      "Epoch: 91, Loss: 0.27285557985305786, Validation Accuracy: 0.91675\n",
      "Epoch: 92, Loss: 0.2716020941734314, Validation Accuracy: 0.9169166666666667\n",
      "Epoch: 93, Loss: 0.27036628127098083, Validation Accuracy: 0.9171666666666667\n",
      "Epoch: 94, Loss: 0.2691513001918793, Validation Accuracy: 0.9175\n",
      "Epoch: 95, Loss: 0.26795822381973267, Validation Accuracy: 0.9178333333333333\n",
      "Epoch: 96, Loss: 0.2667836844921112, Validation Accuracy: 0.9181666666666667\n",
      "Epoch: 97, Loss: 0.26562514901161194, Validation Accuracy: 0.9190833333333334\n",
      "Epoch: 98, Loss: 0.26448166370391846, Validation Accuracy: 0.9194166666666667\n",
      "Epoch: 99, Loss: 0.2633572816848755, Validation Accuracy: 0.9198333333333333\n",
      "Dataset 13\n",
      "Epoch: 0, Loss: 3.523022413253784, Validation Accuracy: 0.17791666666666667\n",
      "Epoch: 1, Loss: 2.796724319458008, Validation Accuracy: 0.16275\n",
      "Epoch: 2, Loss: 3.2435436248779297, Validation Accuracy: 0.2865\n",
      "Epoch: 3, Loss: 2.5780375003814697, Validation Accuracy: 0.23941666666666667\n",
      "Epoch: 4, Loss: 2.3474323749542236, Validation Accuracy: 0.29233333333333333\n",
      "Epoch: 5, Loss: 2.04541277885437, Validation Accuracy: 0.407\n",
      "Epoch: 6, Loss: 1.7534468173980713, Validation Accuracy: 0.4474166666666667\n",
      "Epoch: 7, Loss: 1.6295616626739502, Validation Accuracy: 0.48966666666666664\n",
      "Epoch: 8, Loss: 1.5218702554702759, Validation Accuracy: 0.539\n",
      "Epoch: 9, Loss: 1.4082742929458618, Validation Accuracy: 0.5926666666666667\n",
      "Epoch: 10, Loss: 1.2875882387161255, Validation Accuracy: 0.6416666666666667\n",
      "Epoch: 11, Loss: 1.1693042516708374, Validation Accuracy: 0.683\n",
      "Epoch: 12, Loss: 1.0621559619903564, Validation Accuracy: 0.71075\n",
      "Epoch: 13, Loss: 0.9706870317459106, Validation Accuracy: 0.7361666666666666\n",
      "Epoch: 14, Loss: 0.8959105610847473, Validation Accuracy: 0.75425\n",
      "Epoch: 15, Loss: 0.835164487361908, Validation Accuracy: 0.7681666666666667\n",
      "Epoch: 16, Loss: 0.785234272480011, Validation Accuracy: 0.77925\n",
      "Epoch: 17, Loss: 0.7436065077781677, Validation Accuracy: 0.7884166666666667\n",
      "Epoch: 18, Loss: 0.7086443901062012, Validation Accuracy: 0.7956666666666666\n",
      "Epoch: 19, Loss: 0.6790593862533569, Validation Accuracy: 0.8011666666666667\n",
      "Epoch: 20, Loss: 0.6544682383537292, Validation Accuracy: 0.8068333333333333\n",
      "Epoch: 21, Loss: 0.6362957954406738, Validation Accuracy: 0.8045\n",
      "Epoch: 22, Loss: 0.6336293816566467, Validation Accuracy: 0.7876666666666666\n",
      "Epoch: 23, Loss: 0.6735472083091736, Validation Accuracy: 0.7133333333333334\n",
      "Epoch: 24, Loss: 0.904270350933075, Validation Accuracy: 0.6191666666666666\n",
      "Epoch: 25, Loss: 1.1406623125076294, Validation Accuracy: 0.6028333333333333\n",
      "Epoch: 26, Loss: 1.3415733575820923, Validation Accuracy: 0.6035\n",
      "Epoch: 27, Loss: 1.2282172441482544, Validation Accuracy: 0.5936666666666667\n",
      "Epoch: 28, Loss: 1.2500975131988525, Validation Accuracy: 0.80225\n",
      "Epoch: 29, Loss: 0.6678588390350342, Validation Accuracy: 0.8344166666666667\n",
      "Epoch: 30, Loss: 0.5873807072639465, Validation Accuracy: 0.8404166666666667\n",
      "Epoch: 31, Loss: 0.5548641681671143, Validation Accuracy: 0.84475\n",
      "Epoch: 32, Loss: 0.5331699252128601, Validation Accuracy: 0.84925\n",
      "Epoch: 33, Loss: 0.5163816809654236, Validation Accuracy: 0.853\n",
      "Epoch: 34, Loss: 0.5024657249450684, Validation Accuracy: 0.8555\n",
      "Epoch: 35, Loss: 0.4905432462692261, Validation Accuracy: 0.8573333333333333\n",
      "Epoch: 36, Loss: 0.48009195923805237, Validation Accuracy: 0.8600833333333333\n",
      "Epoch: 37, Loss: 0.4707963168621063, Validation Accuracy: 0.8623333333333333\n",
      "Epoch: 38, Loss: 0.46243783831596375, Validation Accuracy: 0.8640833333333333\n",
      "Epoch: 39, Loss: 0.45484021306037903, Validation Accuracy: 0.866\n",
      "Epoch: 40, Loss: 0.4478610157966614, Validation Accuracy: 0.8670833333333333\n",
      "Epoch: 41, Loss: 0.44138553738594055, Validation Accuracy: 0.869\n",
      "Epoch: 42, Loss: 0.4353460967540741, Validation Accuracy: 0.87025\n",
      "Epoch: 43, Loss: 0.42966604232788086, Validation Accuracy: 0.8718333333333333\n",
      "Epoch: 44, Loss: 0.42430341243743896, Validation Accuracy: 0.8736666666666667\n",
      "Epoch: 45, Loss: 0.4192172884941101, Validation Accuracy: 0.8751666666666666\n",
      "Epoch: 46, Loss: 0.4143792688846588, Validation Accuracy: 0.8774166666666666\n",
      "Epoch: 47, Loss: 0.40978047251701355, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 48, Loss: 0.405405193567276, Validation Accuracy: 0.8795833333333334\n",
      "Epoch: 49, Loss: 0.4012317657470703, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 50, Loss: 0.397238552570343, Validation Accuracy: 0.882\n",
      "Epoch: 51, Loss: 0.3933999836444855, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 52, Loss: 0.38970881700515747, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 53, Loss: 0.3861691355705261, Validation Accuracy: 0.88425\n",
      "Epoch: 54, Loss: 0.382750540971756, Validation Accuracy: 0.8855833333333333\n",
      "Epoch: 55, Loss: 0.3794269263744354, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 56, Loss: 0.376207560300827, Validation Accuracy: 0.8879166666666667\n",
      "Epoch: 57, Loss: 0.37309154868125916, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 58, Loss: 0.370067834854126, Validation Accuracy: 0.8895\n",
      "Epoch: 59, Loss: 0.3671380579471588, Validation Accuracy: 0.8900833333333333\n",
      "Epoch: 60, Loss: 0.3642871081829071, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 61, Loss: 0.3615087866783142, Validation Accuracy: 0.89175\n",
      "Epoch: 62, Loss: 0.3588012158870697, Validation Accuracy: 0.89325\n",
      "Epoch: 63, Loss: 0.35616743564605713, Validation Accuracy: 0.894\n",
      "Epoch: 64, Loss: 0.35360202193260193, Validation Accuracy: 0.89475\n",
      "Epoch: 65, Loss: 0.35110118985176086, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 66, Loss: 0.34865373373031616, Validation Accuracy: 0.8963333333333333\n",
      "Epoch: 67, Loss: 0.34626510739326477, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 68, Loss: 0.3439370095729828, Validation Accuracy: 0.8975\n",
      "Epoch: 69, Loss: 0.34166157245635986, Validation Accuracy: 0.89825\n",
      "Epoch: 70, Loss: 0.33943963050842285, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 71, Loss: 0.3372613787651062, Validation Accuracy: 0.8995\n",
      "Epoch: 72, Loss: 0.3351278603076935, Validation Accuracy: 0.89975\n",
      "Epoch: 73, Loss: 0.3330462574958801, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 74, Loss: 0.33101433515548706, Validation Accuracy: 0.9008333333333334\n",
      "Epoch: 75, Loss: 0.32902541756629944, Validation Accuracy: 0.90175\n",
      "Epoch: 76, Loss: 0.3270791471004486, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 77, Loss: 0.32518070936203003, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 78, Loss: 0.3233298361301422, Validation Accuracy: 0.903\n",
      "Epoch: 79, Loss: 0.32152804732322693, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 80, Loss: 0.31978335976600647, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 81, Loss: 0.31809502840042114, Validation Accuracy: 0.904\n",
      "Epoch: 82, Loss: 0.31649643182754517, Validation Accuracy: 0.90425\n",
      "Epoch: 83, Loss: 0.3149688243865967, Validation Accuracy: 0.9055\n",
      "Epoch: 84, Loss: 0.31361621618270874, Validation Accuracy: 0.90425\n",
      "Epoch: 85, Loss: 0.3124134838581085, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 86, Loss: 0.31153199076652527, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 87, Loss: 0.3109672963619232, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 88, Loss: 0.3110380172729492, Validation Accuracy: 0.9025833333333333\n",
      "Epoch: 89, Loss: 0.31180912256240845, Validation Accuracy: 0.9035\n",
      "Epoch: 90, Loss: 0.3139241933822632, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 91, Loss: 0.3177739679813385, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 92, Loss: 0.3250237703323364, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 93, Loss: 0.33613163232803345, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 94, Loss: 0.3558276891708374, Validation Accuracy: 0.8754166666666666\n",
      "Epoch: 95, Loss: 0.38444462418556213, Validation Accuracy: 0.8575833333333334\n",
      "Epoch: 96, Loss: 0.43158504366874695, Validation Accuracy: 0.84275\n",
      "Epoch: 97, Loss: 0.48667338490486145, Validation Accuracy: 0.8188333333333333\n",
      "Epoch: 98, Loss: 0.530261754989624, Validation Accuracy: 0.84075\n",
      "Epoch: 99, Loss: 0.48640841245651245, Validation Accuracy: 0.8734166666666666\n",
      "Dataset 14\n",
      "Epoch: 0, Loss: 3.2248172760009766, Validation Accuracy: 0.14575\n",
      "Epoch: 1, Loss: 2.6550838947296143, Validation Accuracy: 0.27458333333333335\n",
      "Epoch: 2, Loss: 2.104900360107422, Validation Accuracy: 0.3595\n",
      "Epoch: 3, Loss: 1.9019564390182495, Validation Accuracy: 0.323\n",
      "Epoch: 4, Loss: 1.8741137981414795, Validation Accuracy: 0.43083333333333335\n",
      "Epoch: 5, Loss: 1.6821221113204956, Validation Accuracy: 0.52775\n",
      "Epoch: 6, Loss: 1.4870524406433105, Validation Accuracy: 0.5756666666666667\n",
      "Epoch: 7, Loss: 1.3392938375473022, Validation Accuracy: 0.6188333333333333\n",
      "Epoch: 8, Loss: 1.2199957370758057, Validation Accuracy: 0.65075\n",
      "Epoch: 9, Loss: 1.1151552200317383, Validation Accuracy: 0.68325\n",
      "Epoch: 10, Loss: 1.0250149965286255, Validation Accuracy: 0.70025\n",
      "Epoch: 11, Loss: 0.9512669444084167, Validation Accuracy: 0.7191666666666666\n",
      "Epoch: 12, Loss: 0.8964181542396545, Validation Accuracy: 0.7250833333333333\n",
      "Epoch: 13, Loss: 0.8576844930648804, Validation Accuracy: 0.7259166666666667\n",
      "Epoch: 14, Loss: 0.8509017825126648, Validation Accuracy: 0.72925\n",
      "Epoch: 15, Loss: 0.8430528044700623, Validation Accuracy: 0.70975\n",
      "Epoch: 16, Loss: 0.8854064345359802, Validation Accuracy: 0.7383333333333333\n",
      "Epoch: 17, Loss: 0.8251183032989502, Validation Accuracy: 0.7374166666666667\n",
      "Epoch: 18, Loss: 0.7966381311416626, Validation Accuracy: 0.7649166666666667\n",
      "Epoch: 19, Loss: 0.7306403517723083, Validation Accuracy: 0.7796666666666666\n",
      "Epoch: 20, Loss: 0.6753712296485901, Validation Accuracy: 0.7863333333333333\n",
      "Epoch: 21, Loss: 0.6626338362693787, Validation Accuracy: 0.7915833333333333\n",
      "Epoch: 22, Loss: 0.6287910342216492, Validation Accuracy: 0.7999166666666667\n",
      "Epoch: 23, Loss: 0.6185997724533081, Validation Accuracy: 0.7990833333333334\n",
      "Epoch: 24, Loss: 0.5968865752220154, Validation Accuracy: 0.8101666666666667\n",
      "Epoch: 25, Loss: 0.582991898059845, Validation Accuracy: 0.8105833333333333\n",
      "Epoch: 26, Loss: 0.5664495229721069, Validation Accuracy: 0.82025\n",
      "Epoch: 27, Loss: 0.5505006313323975, Validation Accuracy: 0.8220833333333334\n",
      "Epoch: 28, Loss: 0.5357059240341187, Validation Accuracy: 0.8326666666666667\n",
      "Epoch: 29, Loss: 0.5203688144683838, Validation Accuracy: 0.834\n",
      "Epoch: 30, Loss: 0.5071355700492859, Validation Accuracy: 0.8424166666666667\n",
      "Epoch: 31, Loss: 0.4941658675670624, Validation Accuracy: 0.84325\n",
      "Epoch: 32, Loss: 0.4829064905643463, Validation Accuracy: 0.8508333333333333\n",
      "Epoch: 33, Loss: 0.47219258546829224, Validation Accuracy: 0.8503333333333334\n",
      "Epoch: 34, Loss: 0.4628792405128479, Validation Accuracy: 0.8568333333333333\n",
      "Epoch: 35, Loss: 0.4541546702384949, Validation Accuracy: 0.8569166666666667\n",
      "Epoch: 36, Loss: 0.4462195932865143, Validation Accuracy: 0.8628333333333333\n",
      "Epoch: 37, Loss: 0.43885213136672974, Validation Accuracy: 0.86225\n",
      "Epoch: 38, Loss: 0.43209269642829895, Validation Accuracy: 0.8663333333333333\n",
      "Epoch: 39, Loss: 0.42577454447746277, Validation Accuracy: 0.8656666666666667\n",
      "Epoch: 40, Loss: 0.4199794828891754, Validation Accuracy: 0.8701666666666666\n",
      "Epoch: 41, Loss: 0.41451355814933777, Validation Accuracy: 0.8696666666666667\n",
      "Epoch: 42, Loss: 0.40936967730522156, Validation Accuracy: 0.873\n",
      "Epoch: 43, Loss: 0.40454432368278503, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 44, Loss: 0.3999370038509369, Validation Accuracy: 0.8761666666666666\n",
      "Epoch: 45, Loss: 0.395626962184906, Validation Accuracy: 0.8760833333333333\n",
      "Epoch: 46, Loss: 0.39150187373161316, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 47, Loss: 0.38762688636779785, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 48, Loss: 0.3839988708496094, Validation Accuracy: 0.8804166666666666\n",
      "Epoch: 49, Loss: 0.38064321875572205, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 50, Loss: 0.3774236738681793, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 51, Loss: 0.3746486306190491, Validation Accuracy: 0.8831666666666667\n",
      "Epoch: 52, Loss: 0.37196001410484314, Validation Accuracy: 0.8840833333333333\n",
      "Epoch: 53, Loss: 0.3699677288532257, Validation Accuracy: 0.88325\n",
      "Epoch: 54, Loss: 0.3680257499217987, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 55, Loss: 0.3672678768634796, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 56, Loss: 0.36646634340286255, Validation Accuracy: 0.8855\n",
      "Epoch: 57, Loss: 0.3680334985256195, Validation Accuracy: 0.8821666666666667\n",
      "Epoch: 58, Loss: 0.36874374747276306, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 59, Loss: 0.37381839752197266, Validation Accuracy: 0.8779166666666667\n",
      "Epoch: 60, Loss: 0.3761114180088043, Validation Accuracy: 0.8749166666666667\n",
      "Epoch: 61, Loss: 0.38559141755104065, Validation Accuracy: 0.8739166666666667\n",
      "Epoch: 62, Loss: 0.3870890438556671, Validation Accuracy: 0.8695\n",
      "Epoch: 63, Loss: 0.39814746379852295, Validation Accuracy: 0.8711666666666666\n",
      "Epoch: 64, Loss: 0.39351680874824524, Validation Accuracy: 0.8706666666666667\n",
      "Epoch: 65, Loss: 0.39775794744491577, Validation Accuracy: 0.87525\n",
      "Epoch: 66, Loss: 0.38228487968444824, Validation Accuracy: 0.8783333333333333\n",
      "Epoch: 67, Loss: 0.3749598264694214, Validation Accuracy: 0.887\n",
      "Epoch: 68, Loss: 0.35726994276046753, Validation Accuracy: 0.8895\n",
      "Epoch: 69, Loss: 0.3476656377315521, Validation Accuracy: 0.89375\n",
      "Epoch: 70, Loss: 0.3370908498764038, Validation Accuracy: 0.8953333333333333\n",
      "Epoch: 71, Loss: 0.33091118931770325, Validation Accuracy: 0.89925\n",
      "Epoch: 72, Loss: 0.32575181126594543, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 73, Loss: 0.3222097158432007, Validation Accuracy: 0.9008333333333334\n",
      "Epoch: 74, Loss: 0.3192301094532013, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 75, Loss: 0.31675952672958374, Validation Accuracy: 0.9016666666666666\n",
      "Epoch: 76, Loss: 0.31454572081565857, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 77, Loss: 0.31251582503318787, Validation Accuracy: 0.90275\n",
      "Epoch: 78, Loss: 0.3106398582458496, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 79, Loss: 0.3088362514972687, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 80, Loss: 0.30712205171585083, Validation Accuracy: 0.9044166666666666\n",
      "Epoch: 81, Loss: 0.30545201897621155, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 82, Loss: 0.3038443922996521, Validation Accuracy: 0.9051666666666667\n",
      "Epoch: 83, Loss: 0.3022747337818146, Validation Accuracy: 0.9054166666666666\n",
      "Epoch: 84, Loss: 0.30075308680534363, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 85, Loss: 0.2992616295814514, Validation Accuracy: 0.9065\n",
      "Epoch: 86, Loss: 0.2978012263774872, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 87, Loss: 0.2963704764842987, Validation Accuracy: 0.90725\n",
      "Epoch: 88, Loss: 0.29496514797210693, Validation Accuracy: 0.9079166666666667\n",
      "Epoch: 89, Loss: 0.29358091950416565, Validation Accuracy: 0.9083333333333333\n",
      "Epoch: 90, Loss: 0.29221799969673157, Validation Accuracy: 0.9090833333333334\n",
      "Epoch: 91, Loss: 0.2908746004104614, Validation Accuracy: 0.90925\n",
      "Epoch: 92, Loss: 0.28955504298210144, Validation Accuracy: 0.9095833333333333\n",
      "Epoch: 93, Loss: 0.28825438022613525, Validation Accuracy: 0.91\n",
      "Epoch: 94, Loss: 0.28697100281715393, Validation Accuracy: 0.91\n",
      "Epoch: 95, Loss: 0.2857044041156769, Validation Accuracy: 0.9105833333333333\n",
      "Epoch: 96, Loss: 0.28445515036582947, Validation Accuracy: 0.9105\n",
      "Epoch: 97, Loss: 0.2832232713699341, Validation Accuracy: 0.91125\n",
      "Epoch: 98, Loss: 0.28200697898864746, Validation Accuracy: 0.9113333333333333\n",
      "Epoch: 99, Loss: 0.2808072865009308, Validation Accuracy: 0.91225\n",
      "Dataset 15\n",
      "Epoch: 0, Loss: 3.9528348445892334, Validation Accuracy: 0.17633333333333334\n",
      "Epoch: 1, Loss: 3.887742757797241, Validation Accuracy: 0.20358333333333334\n",
      "Epoch: 2, Loss: 3.4965009689331055, Validation Accuracy: 0.17733333333333334\n",
      "Epoch: 3, Loss: 2.933109760284424, Validation Accuracy: 0.38433333333333336\n",
      "Epoch: 4, Loss: 1.8127957582473755, Validation Accuracy: 0.4519166666666667\n",
      "Epoch: 5, Loss: 1.6070436239242554, Validation Accuracy: 0.5144166666666666\n",
      "Epoch: 6, Loss: 1.4673349857330322, Validation Accuracy: 0.5565\n",
      "Epoch: 7, Loss: 1.3448505401611328, Validation Accuracy: 0.6008333333333333\n",
      "Epoch: 8, Loss: 1.2369108200073242, Validation Accuracy: 0.6318333333333334\n",
      "Epoch: 9, Loss: 1.135862112045288, Validation Accuracy: 0.67125\n",
      "Epoch: 10, Loss: 1.0433281660079956, Validation Accuracy: 0.6973333333333334\n",
      "Epoch: 11, Loss: 0.960673987865448, Validation Accuracy: 0.7213333333333334\n",
      "Epoch: 12, Loss: 0.8904704451560974, Validation Accuracy: 0.74025\n",
      "Epoch: 13, Loss: 0.832269549369812, Validation Accuracy: 0.7486666666666667\n",
      "Epoch: 14, Loss: 0.7896054983139038, Validation Accuracy: 0.7521666666666667\n",
      "Epoch: 15, Loss: 0.7687752842903137, Validation Accuracy: 0.7269166666666667\n",
      "Epoch: 16, Loss: 0.8156802654266357, Validation Accuracy: 0.65775\n",
      "Epoch: 17, Loss: 0.9731218814849854, Validation Accuracy: 0.5500833333333334\n",
      "Epoch: 18, Loss: 1.4568909406661987, Validation Accuracy: 0.6675\n",
      "Epoch: 19, Loss: 0.9371756911277771, Validation Accuracy: 0.76525\n",
      "Epoch: 20, Loss: 0.706710934638977, Validation Accuracy: 0.8031666666666667\n",
      "Epoch: 21, Loss: 0.6436551809310913, Validation Accuracy: 0.8064166666666667\n",
      "Epoch: 22, Loss: 0.609225332736969, Validation Accuracy: 0.8175\n",
      "Epoch: 23, Loss: 0.583922803401947, Validation Accuracy: 0.8211666666666667\n",
      "Epoch: 24, Loss: 0.5631680488586426, Validation Accuracy: 0.82825\n",
      "Epoch: 25, Loss: 0.5445189476013184, Validation Accuracy: 0.8305833333333333\n",
      "Epoch: 26, Loss: 0.5296024680137634, Validation Accuracy: 0.8375833333333333\n",
      "Epoch: 27, Loss: 0.5151480436325073, Validation Accuracy: 0.8388333333333333\n",
      "Epoch: 28, Loss: 0.5036485195159912, Validation Accuracy: 0.8444166666666667\n",
      "Epoch: 29, Loss: 0.4918341040611267, Validation Accuracy: 0.8455\n",
      "Epoch: 30, Loss: 0.4825363755226135, Validation Accuracy: 0.8508333333333333\n",
      "Epoch: 31, Loss: 0.4730110764503479, Validation Accuracy: 0.8515\n",
      "Epoch: 32, Loss: 0.4657038152217865, Validation Accuracy: 0.8551666666666666\n",
      "Epoch: 33, Loss: 0.4579966962337494, Validation Accuracy: 0.8565\n",
      "Epoch: 34, Loss: 0.4523670971393585, Validation Accuracy: 0.8585\n",
      "Epoch: 35, Loss: 0.44666194915771484, Validation Accuracy: 0.8593333333333333\n",
      "Epoch: 36, Loss: 0.44242990016937256, Validation Accuracy: 0.8596666666666667\n",
      "Epoch: 37, Loss: 0.4391151964664459, Validation Accuracy: 0.8616666666666667\n",
      "Epoch: 38, Loss: 0.43534040451049805, Validation Accuracy: 0.8589166666666667\n",
      "Epoch: 39, Loss: 0.43490833044052124, Validation Accuracy: 0.863\n",
      "Epoch: 40, Loss: 0.4295675456523895, Validation Accuracy: 0.8583333333333333\n",
      "Epoch: 41, Loss: 0.43111804127693176, Validation Accuracy: 0.86475\n",
      "Epoch: 42, Loss: 0.4224837124347687, Validation Accuracy: 0.86075\n",
      "Epoch: 43, Loss: 0.4234926402568817, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 44, Loss: 0.4117567837238312, Validation Accuracy: 0.8655\n",
      "Epoch: 45, Loss: 0.41066494584083557, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 46, Loss: 0.39870476722717285, Validation Accuracy: 0.8706666666666667\n",
      "Epoch: 47, Loss: 0.39569851756095886, Validation Accuracy: 0.8765833333333334\n",
      "Epoch: 48, Loss: 0.38607755303382874, Validation Accuracy: 0.8764166666666666\n",
      "Epoch: 49, Loss: 0.3825036883354187, Validation Accuracy: 0.8783333333333333\n",
      "Epoch: 50, Loss: 0.37550806999206543, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 51, Loss: 0.37187203764915466, Validation Accuracy: 0.88075\n",
      "Epoch: 52, Loss: 0.36679720878601074, Validation Accuracy: 0.8823333333333333\n",
      "Epoch: 53, Loss: 0.3634812533855438, Validation Accuracy: 0.8825\n",
      "Epoch: 54, Loss: 0.3595525324344635, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 55, Loss: 0.35655444860458374, Validation Accuracy: 0.885\n",
      "Epoch: 56, Loss: 0.3533780872821808, Validation Accuracy: 0.8851666666666667\n",
      "Epoch: 57, Loss: 0.3506618142127991, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 58, Loss: 0.348013311624527, Validation Accuracy: 0.8864166666666666\n",
      "Epoch: 59, Loss: 0.34554538130760193, Validation Accuracy: 0.888\n",
      "Epoch: 60, Loss: 0.34337544441223145, Validation Accuracy: 0.8881666666666667\n",
      "Epoch: 61, Loss: 0.34124991297721863, Validation Accuracy: 0.889\n",
      "Epoch: 62, Loss: 0.33947721123695374, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 63, Loss: 0.33766767382621765, Validation Accuracy: 0.8899166666666667\n",
      "Epoch: 64, Loss: 0.3362875282764435, Validation Accuracy: 0.8899166666666667\n",
      "Epoch: 65, Loss: 0.3347039818763733, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 66, Loss: 0.33361735939979553, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 67, Loss: 0.3322925567626953, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 68, Loss: 0.3313955068588257, Validation Accuracy: 0.8905\n",
      "Epoch: 69, Loss: 0.33020180463790894, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 70, Loss: 0.32948651909828186, Validation Accuracy: 0.891\n",
      "Epoch: 71, Loss: 0.3283367455005646, Validation Accuracy: 0.892\n",
      "Epoch: 72, Loss: 0.3274804949760437, Validation Accuracy: 0.8915\n",
      "Epoch: 73, Loss: 0.32608574628829956, Validation Accuracy: 0.8926666666666667\n",
      "Epoch: 74, Loss: 0.32490456104278564, Validation Accuracy: 0.89275\n",
      "Epoch: 75, Loss: 0.32304608821868896, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 76, Loss: 0.3212721049785614, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 77, Loss: 0.31897562742233276, Validation Accuracy: 0.895\n",
      "Epoch: 78, Loss: 0.31664663553237915, Validation Accuracy: 0.8959166666666667\n",
      "Epoch: 79, Loss: 0.313809871673584, Validation Accuracy: 0.897\n",
      "Epoch: 80, Loss: 0.3111151158809662, Validation Accuracy: 0.8971666666666667\n",
      "Epoch: 81, Loss: 0.30820339918136597, Validation Accuracy: 0.89925\n",
      "Epoch: 82, Loss: 0.3054049015045166, Validation Accuracy: 0.9\n",
      "Epoch: 83, Loss: 0.3026048243045807, Validation Accuracy: 0.9008333333333334\n",
      "Epoch: 84, Loss: 0.2999527156352997, Validation Accuracy: 0.90175\n",
      "Epoch: 85, Loss: 0.2975442409515381, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 86, Loss: 0.29517489671707153, Validation Accuracy: 0.90325\n",
      "Epoch: 87, Loss: 0.2930420935153961, Validation Accuracy: 0.9055\n",
      "Epoch: 88, Loss: 0.2909418046474457, Validation Accuracy: 0.90575\n",
      "Epoch: 89, Loss: 0.28905773162841797, Validation Accuracy: 0.9071666666666667\n",
      "Epoch: 90, Loss: 0.2872054874897003, Validation Accuracy: 0.9066666666666666\n",
      "Epoch: 91, Loss: 0.28553307056427, Validation Accuracy: 0.9078333333333334\n",
      "Epoch: 92, Loss: 0.28389212489128113, Validation Accuracy: 0.90875\n",
      "Epoch: 93, Loss: 0.2823721468448639, Validation Accuracy: 0.9085\n",
      "Epoch: 94, Loss: 0.28087732195854187, Validation Accuracy: 0.9101666666666667\n",
      "Epoch: 95, Loss: 0.2794716954231262, Validation Accuracy: 0.90975\n",
      "Epoch: 96, Loss: 0.27810245752334595, Validation Accuracy: 0.9101666666666667\n",
      "Epoch: 97, Loss: 0.2767607569694519, Validation Accuracy: 0.9105833333333333\n",
      "Epoch: 98, Loss: 0.27546852827072144, Validation Accuracy: 0.9110833333333334\n",
      "Epoch: 99, Loss: 0.2741865813732147, Validation Accuracy: 0.9111666666666667\n",
      "Dataset 16\n",
      "Epoch: 0, Loss: 3.8491623401641846, Validation Accuracy: 0.18025\n",
      "Epoch: 1, Loss: 2.7500436305999756, Validation Accuracy: 0.23675\n",
      "Epoch: 2, Loss: 2.251342296600342, Validation Accuracy: 0.3268333333333333\n",
      "Epoch: 3, Loss: 2.0769522190093994, Validation Accuracy: 0.3385\n",
      "Epoch: 4, Loss: 1.8405851125717163, Validation Accuracy: 0.39616666666666667\n",
      "Epoch: 5, Loss: 1.6954426765441895, Validation Accuracy: 0.4529166666666667\n",
      "Epoch: 6, Loss: 1.5523009300231934, Validation Accuracy: 0.5093333333333333\n",
      "Epoch: 7, Loss: 1.4233700037002563, Validation Accuracy: 0.5421666666666667\n",
      "Epoch: 8, Loss: 1.324802279472351, Validation Accuracy: 0.5746666666666667\n",
      "Epoch: 9, Loss: 1.2359179258346558, Validation Accuracy: 0.60275\n",
      "Epoch: 10, Loss: 1.1545426845550537, Validation Accuracy: 0.6321666666666667\n",
      "Epoch: 11, Loss: 1.0793211460113525, Validation Accuracy: 0.6620833333333334\n",
      "Epoch: 12, Loss: 1.0113765001296997, Validation Accuracy: 0.6875\n",
      "Epoch: 13, Loss: 0.9509497880935669, Validation Accuracy: 0.70875\n",
      "Epoch: 14, Loss: 0.8995817303657532, Validation Accuracy: 0.7210833333333333\n",
      "Epoch: 15, Loss: 0.856905996799469, Validation Accuracy: 0.7305833333333334\n",
      "Epoch: 16, Loss: 0.8258309960365295, Validation Accuracy: 0.7306666666666667\n",
      "Epoch: 17, Loss: 0.8111823201179504, Validation Accuracy: 0.7261666666666666\n",
      "Epoch: 18, Loss: 0.8158511519432068, Validation Accuracy: 0.6954166666666667\n",
      "Epoch: 19, Loss: 0.8788329362869263, Validation Accuracy: 0.6970833333333334\n",
      "Epoch: 20, Loss: 0.872842013835907, Validation Accuracy: 0.66925\n",
      "Epoch: 21, Loss: 0.9388547539710999, Validation Accuracy: 0.74675\n",
      "Epoch: 22, Loss: 0.7602747678756714, Validation Accuracy: 0.7675\n",
      "Epoch: 23, Loss: 0.6976381540298462, Validation Accuracy: 0.7933333333333333\n",
      "Epoch: 24, Loss: 0.6488351821899414, Validation Accuracy: 0.79775\n",
      "Epoch: 25, Loss: 0.6228857636451721, Validation Accuracy: 0.8098333333333333\n",
      "Epoch: 26, Loss: 0.6052657961845398, Validation Accuracy: 0.8088333333333333\n",
      "Epoch: 27, Loss: 0.5930208563804626, Validation Accuracy: 0.8155833333333333\n",
      "Epoch: 28, Loss: 0.5840164422988892, Validation Accuracy: 0.8114166666666667\n",
      "Epoch: 29, Loss: 0.5796781182289124, Validation Accuracy: 0.8165833333333333\n",
      "Epoch: 30, Loss: 0.575739860534668, Validation Accuracy: 0.8121666666666667\n",
      "Epoch: 31, Loss: 0.5771024823188782, Validation Accuracy: 0.814\n",
      "Epoch: 32, Loss: 0.5728784799575806, Validation Accuracy: 0.8125833333333333\n",
      "Epoch: 33, Loss: 0.5729115605354309, Validation Accuracy: 0.8185833333333333\n",
      "Epoch: 34, Loss: 0.559095025062561, Validation Accuracy: 0.8205\n",
      "Epoch: 35, Loss: 0.5489769577980042, Validation Accuracy: 0.8306666666666667\n",
      "Epoch: 36, Loss: 0.5270268321037292, Validation Accuracy: 0.8350833333333333\n",
      "Epoch: 37, Loss: 0.5124557614326477, Validation Accuracy: 0.8425\n",
      "Epoch: 38, Loss: 0.49350640177726746, Validation Accuracy: 0.84625\n",
      "Epoch: 39, Loss: 0.4824804365634918, Validation Accuracy: 0.8521666666666666\n",
      "Epoch: 40, Loss: 0.4698958396911621, Validation Accuracy: 0.8521666666666666\n",
      "Epoch: 41, Loss: 0.4624215066432953, Validation Accuracy: 0.8580833333333333\n",
      "Epoch: 42, Loss: 0.45379194617271423, Validation Accuracy: 0.85725\n",
      "Epoch: 43, Loss: 0.44844356179237366, Validation Accuracy: 0.86175\n",
      "Epoch: 44, Loss: 0.4418661296367645, Validation Accuracy: 0.861\n",
      "Epoch: 45, Loss: 0.4378548562526703, Validation Accuracy: 0.8651666666666666\n",
      "Epoch: 46, Loss: 0.43235448002815247, Validation Accuracy: 0.8634166666666667\n",
      "Epoch: 47, Loss: 0.4291113018989563, Validation Accuracy: 0.8681666666666666\n",
      "Epoch: 48, Loss: 0.42402124404907227, Validation Accuracy: 0.8656666666666667\n",
      "Epoch: 49, Loss: 0.4212404787540436, Validation Accuracy: 0.8699166666666667\n",
      "Epoch: 50, Loss: 0.41622644662857056, Validation Accuracy: 0.8689166666666667\n",
      "Epoch: 51, Loss: 0.41364240646362305, Validation Accuracy: 0.87325\n",
      "Epoch: 52, Loss: 0.4085329473018646, Validation Accuracy: 0.8708333333333333\n",
      "Epoch: 53, Loss: 0.4058874845504761, Validation Accuracy: 0.8759166666666667\n",
      "Epoch: 54, Loss: 0.4007253348827362, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 55, Loss: 0.3978741765022278, Validation Accuracy: 0.878\n",
      "Epoch: 56, Loss: 0.39274176955223083, Validation Accuracy: 0.87675\n",
      "Epoch: 57, Loss: 0.38971146941185, Validation Accuracy: 0.88025\n",
      "Epoch: 58, Loss: 0.3847443163394928, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 59, Loss: 0.3815174102783203, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 60, Loss: 0.37702131271362305, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 61, Loss: 0.37375256419181824, Validation Accuracy: 0.8855833333333333\n",
      "Epoch: 62, Loss: 0.36965593695640564, Validation Accuracy: 0.885\n",
      "Epoch: 63, Loss: 0.366487592458725, Validation Accuracy: 0.88775\n",
      "Epoch: 64, Loss: 0.3628145456314087, Validation Accuracy: 0.88725\n",
      "Epoch: 65, Loss: 0.359834223985672, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 66, Loss: 0.35653388500213623, Validation Accuracy: 0.8899166666666667\n",
      "Epoch: 67, Loss: 0.35374850034713745, Validation Accuracy: 0.89125\n",
      "Epoch: 68, Loss: 0.3507406413555145, Validation Accuracy: 0.8913333333333333\n",
      "Epoch: 69, Loss: 0.34814316034317017, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 70, Loss: 0.34539517760276794, Validation Accuracy: 0.8935\n",
      "Epoch: 71, Loss: 0.34294214844703674, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 72, Loss: 0.3404273986816406, Validation Accuracy: 0.8945\n",
      "Epoch: 73, Loss: 0.3380871117115021, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 74, Loss: 0.3357446491718292, Validation Accuracy: 0.8953333333333333\n",
      "Epoch: 75, Loss: 0.3335457444190979, Validation Accuracy: 0.8966666666666666\n",
      "Epoch: 76, Loss: 0.33136072754859924, Validation Accuracy: 0.8961666666666667\n",
      "Epoch: 77, Loss: 0.32925742864608765, Validation Accuracy: 0.898\n",
      "Epoch: 78, Loss: 0.32718604803085327, Validation Accuracy: 0.89725\n",
      "Epoch: 79, Loss: 0.32518133521080017, Validation Accuracy: 0.899\n",
      "Epoch: 80, Loss: 0.32321760058403015, Validation Accuracy: 0.8988333333333334\n",
      "Epoch: 81, Loss: 0.3212937116622925, Validation Accuracy: 0.90025\n",
      "Epoch: 82, Loss: 0.3193916380405426, Validation Accuracy: 0.8998333333333334\n",
      "Epoch: 83, Loss: 0.31754523515701294, Validation Accuracy: 0.9005\n",
      "Epoch: 84, Loss: 0.31574591994285583, Validation Accuracy: 0.9003333333333333\n",
      "Epoch: 85, Loss: 0.3139860928058624, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 86, Loss: 0.3122647702693939, Validation Accuracy: 0.90175\n",
      "Epoch: 87, Loss: 0.31058964133262634, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 88, Loss: 0.3089384436607361, Validation Accuracy: 0.903\n",
      "Epoch: 89, Loss: 0.3073269724845886, Validation Accuracy: 0.90375\n",
      "Epoch: 90, Loss: 0.30572518706321716, Validation Accuracy: 0.90375\n",
      "Epoch: 91, Loss: 0.3041745722293854, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 92, Loss: 0.3026498854160309, Validation Accuracy: 0.9041666666666667\n",
      "Epoch: 93, Loss: 0.30115634202957153, Validation Accuracy: 0.9055\n",
      "Epoch: 94, Loss: 0.29968541860580444, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 95, Loss: 0.29824480414390564, Validation Accuracy: 0.9063333333333333\n",
      "Epoch: 96, Loss: 0.29682931303977966, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 97, Loss: 0.29544544219970703, Validation Accuracy: 0.90675\n",
      "Epoch: 98, Loss: 0.29408472776412964, Validation Accuracy: 0.90725\n",
      "Epoch: 99, Loss: 0.2927305996417999, Validation Accuracy: 0.9076666666666666\n",
      "Dataset 17\n",
      "Epoch: 0, Loss: 3.679081439971924, Validation Accuracy: 0.22908333333333333\n",
      "Epoch: 1, Loss: 2.6785664558410645, Validation Accuracy: 0.2975833333333333\n",
      "Epoch: 2, Loss: 2.1994123458862305, Validation Accuracy: 0.30791666666666667\n",
      "Epoch: 3, Loss: 2.1834118366241455, Validation Accuracy: 0.322\n",
      "Epoch: 4, Loss: 2.057331085205078, Validation Accuracy: 0.3878333333333333\n",
      "Epoch: 5, Loss: 1.7975397109985352, Validation Accuracy: 0.5194166666666666\n",
      "Epoch: 6, Loss: 1.4668883085250854, Validation Accuracy: 0.603\n",
      "Epoch: 7, Loss: 1.2234816551208496, Validation Accuracy: 0.6809166666666666\n",
      "Epoch: 8, Loss: 1.0508850812911987, Validation Accuracy: 0.7111666666666666\n",
      "Epoch: 9, Loss: 0.9439996480941772, Validation Accuracy: 0.7260833333333333\n",
      "Epoch: 10, Loss: 0.8794796466827393, Validation Accuracy: 0.7301666666666666\n",
      "Epoch: 11, Loss: 0.8559606671333313, Validation Accuracy: 0.7030833333333333\n",
      "Epoch: 12, Loss: 0.8855291604995728, Validation Accuracy: 0.63425\n",
      "Epoch: 13, Loss: 1.078627109527588, Validation Accuracy: 0.6466666666666666\n",
      "Epoch: 14, Loss: 0.9955702424049377, Validation Accuracy: 0.654\n",
      "Epoch: 15, Loss: 1.0157134532928467, Validation Accuracy: 0.7794166666666666\n",
      "Epoch: 16, Loss: 0.6993736028671265, Validation Accuracy: 0.8015833333333333\n",
      "Epoch: 17, Loss: 0.639866054058075, Validation Accuracy: 0.8079166666666666\n",
      "Epoch: 18, Loss: 0.6065592169761658, Validation Accuracy: 0.8146666666666667\n",
      "Epoch: 19, Loss: 0.5834025740623474, Validation Accuracy: 0.8203333333333334\n",
      "Epoch: 20, Loss: 0.5647969841957092, Validation Accuracy: 0.8244166666666667\n",
      "Epoch: 21, Loss: 0.5489335656166077, Validation Accuracy: 0.8289166666666666\n",
      "Epoch: 22, Loss: 0.5350907444953918, Validation Accuracy: 0.8333333333333334\n",
      "Epoch: 23, Loss: 0.522710919380188, Validation Accuracy: 0.83625\n",
      "Epoch: 24, Loss: 0.5116303563117981, Validation Accuracy: 0.8384166666666667\n",
      "Epoch: 25, Loss: 0.501493513584137, Validation Accuracy: 0.8405\n",
      "Epoch: 26, Loss: 0.4923308789730072, Validation Accuracy: 0.8445833333333334\n",
      "Epoch: 27, Loss: 0.4838655889034271, Validation Accuracy: 0.84625\n",
      "Epoch: 28, Loss: 0.4762299358844757, Validation Accuracy: 0.8491666666666666\n",
      "Epoch: 29, Loss: 0.4690799415111542, Validation Accuracy: 0.8506666666666667\n",
      "Epoch: 30, Loss: 0.4627087414264679, Validation Accuracy: 0.8521666666666666\n",
      "Epoch: 31, Loss: 0.45654818415641785, Validation Accuracy: 0.8538333333333333\n",
      "Epoch: 32, Loss: 0.4513137936592102, Validation Accuracy: 0.8558333333333333\n",
      "Epoch: 33, Loss: 0.44585180282592773, Validation Accuracy: 0.85775\n",
      "Epoch: 34, Loss: 0.44156187772750854, Validation Accuracy: 0.8580833333333333\n",
      "Epoch: 35, Loss: 0.4366198182106018, Validation Accuracy: 0.85975\n",
      "Epoch: 36, Loss: 0.4334735870361328, Validation Accuracy: 0.8603333333333333\n",
      "Epoch: 37, Loss: 0.4288861155509949, Validation Accuracy: 0.86275\n",
      "Epoch: 38, Loss: 0.42673835158348083, Validation Accuracy: 0.86275\n",
      "Epoch: 39, Loss: 0.4224768877029419, Validation Accuracy: 0.8645833333333334\n",
      "Epoch: 40, Loss: 0.4211844801902771, Validation Accuracy: 0.8644166666666667\n",
      "Epoch: 41, Loss: 0.41742730140686035, Validation Accuracy: 0.8654166666666666\n",
      "Epoch: 42, Loss: 0.41710010170936584, Validation Accuracy: 0.86525\n",
      "Epoch: 43, Loss: 0.41402649879455566, Validation Accuracy: 0.86625\n",
      "Epoch: 44, Loss: 0.4139224588871002, Validation Accuracy: 0.86525\n",
      "Epoch: 45, Loss: 0.41129255294799805, Validation Accuracy: 0.867\n",
      "Epoch: 46, Loss: 0.41063904762268066, Validation Accuracy: 0.867\n",
      "Epoch: 47, Loss: 0.40811604261398315, Validation Accuracy: 0.8688333333333333\n",
      "Epoch: 48, Loss: 0.40548965334892273, Validation Accuracy: 0.8694166666666666\n",
      "Epoch: 49, Loss: 0.40188276767730713, Validation Accuracy: 0.8723333333333333\n",
      "Epoch: 50, Loss: 0.3967972695827484, Validation Accuracy: 0.873\n",
      "Epoch: 51, Loss: 0.391695111989975, Validation Accuracy: 0.8759166666666667\n",
      "Epoch: 52, Loss: 0.3853396773338318, Validation Accuracy: 0.8776666666666667\n",
      "Epoch: 53, Loss: 0.37941038608551025, Validation Accuracy: 0.88025\n",
      "Epoch: 54, Loss: 0.373575896024704, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 55, Loss: 0.3684481680393219, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 56, Loss: 0.36374858021736145, Validation Accuracy: 0.8855\n",
      "Epoch: 57, Loss: 0.3596608340740204, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 58, Loss: 0.35599565505981445, Validation Accuracy: 0.88825\n",
      "Epoch: 59, Loss: 0.35270312428474426, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 60, Loss: 0.34973835945129395, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 61, Loss: 0.3469786047935486, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 62, Loss: 0.34440577030181885, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 63, Loss: 0.341960608959198, Validation Accuracy: 0.8908333333333334\n",
      "Epoch: 64, Loss: 0.3396734297275543, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 65, Loss: 0.33746346831321716, Validation Accuracy: 0.89275\n",
      "Epoch: 66, Loss: 0.33536508679389954, Validation Accuracy: 0.89325\n",
      "Epoch: 67, Loss: 0.33332759141921997, Validation Accuracy: 0.8944166666666666\n",
      "Epoch: 68, Loss: 0.3313712477684021, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 69, Loss: 0.3294667899608612, Validation Accuracy: 0.89575\n",
      "Epoch: 70, Loss: 0.327616423368454, Validation Accuracy: 0.8961666666666667\n",
      "Epoch: 71, Loss: 0.3258221745491028, Validation Accuracy: 0.89675\n",
      "Epoch: 72, Loss: 0.3240700960159302, Validation Accuracy: 0.8975\n",
      "Epoch: 73, Loss: 0.32235828042030334, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 74, Loss: 0.32067975401878357, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 75, Loss: 0.3190336227416992, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 76, Loss: 0.31742459535598755, Validation Accuracy: 0.8991666666666667\n",
      "Epoch: 77, Loss: 0.3158453106880188, Validation Accuracy: 0.8995\n",
      "Epoch: 78, Loss: 0.31429505348205566, Validation Accuracy: 0.9003333333333333\n",
      "Epoch: 79, Loss: 0.3127709627151489, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 80, Loss: 0.3112776577472687, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 81, Loss: 0.30980920791625977, Validation Accuracy: 0.9015\n",
      "Epoch: 82, Loss: 0.3083631694316864, Validation Accuracy: 0.9020833333333333\n",
      "Epoch: 83, Loss: 0.30693840980529785, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 84, Loss: 0.3055391311645508, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 85, Loss: 0.3041642904281616, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 86, Loss: 0.302810400724411, Validation Accuracy: 0.904\n",
      "Epoch: 87, Loss: 0.3014795184135437, Validation Accuracy: 0.90425\n",
      "Epoch: 88, Loss: 0.3001682460308075, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 89, Loss: 0.2988731861114502, Validation Accuracy: 0.905\n",
      "Epoch: 90, Loss: 0.2975958585739136, Validation Accuracy: 0.9051666666666667\n",
      "Epoch: 91, Loss: 0.29633334279060364, Validation Accuracy: 0.9056666666666666\n",
      "Epoch: 92, Loss: 0.2950896620750427, Validation Accuracy: 0.90575\n",
      "Epoch: 93, Loss: 0.29386258125305176, Validation Accuracy: 0.9064166666666666\n",
      "Epoch: 94, Loss: 0.29264992475509644, Validation Accuracy: 0.9065\n",
      "Epoch: 95, Loss: 0.2914522588253021, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 96, Loss: 0.2902725338935852, Validation Accuracy: 0.90675\n",
      "Epoch: 97, Loss: 0.28910771012306213, Validation Accuracy: 0.9070833333333334\n",
      "Epoch: 98, Loss: 0.28795966506004333, Validation Accuracy: 0.9071666666666667\n",
      "Epoch: 99, Loss: 0.2868252098560333, Validation Accuracy: 0.9075\n",
      "Dataset 18\n",
      "Epoch: 0, Loss: 3.736572265625, Validation Accuracy: 0.14675\n",
      "Epoch: 1, Loss: 4.002289295196533, Validation Accuracy: 0.15733333333333333\n",
      "Epoch: 2, Loss: 3.2552623748779297, Validation Accuracy: 0.26216666666666666\n",
      "Epoch: 3, Loss: 2.4460575580596924, Validation Accuracy: 0.3780833333333333\n",
      "Epoch: 4, Loss: 1.8174365758895874, Validation Accuracy: 0.4405\n",
      "Epoch: 5, Loss: 1.6617279052734375, Validation Accuracy: 0.4708333333333333\n",
      "Epoch: 6, Loss: 1.537660002708435, Validation Accuracy: 0.5128333333333334\n",
      "Epoch: 7, Loss: 1.424757480621338, Validation Accuracy: 0.5469166666666667\n",
      "Epoch: 8, Loss: 1.3191437721252441, Validation Accuracy: 0.5930833333333333\n",
      "Epoch: 9, Loss: 1.2177777290344238, Validation Accuracy: 0.6299166666666667\n",
      "Epoch: 10, Loss: 1.1204791069030762, Validation Accuracy: 0.6640833333333334\n",
      "Epoch: 11, Loss: 1.0329921245574951, Validation Accuracy: 0.6805833333333333\n",
      "Epoch: 12, Loss: 0.9582114815711975, Validation Accuracy: 0.707\n",
      "Epoch: 13, Loss: 0.8944838643074036, Validation Accuracy: 0.715\n",
      "Epoch: 14, Loss: 0.8397032022476196, Validation Accuracy: 0.7405833333333334\n",
      "Epoch: 15, Loss: 0.7931892275810242, Validation Accuracy: 0.744\n",
      "Epoch: 16, Loss: 0.7539763450622559, Validation Accuracy: 0.7654166666666666\n",
      "Epoch: 17, Loss: 0.7222409844398499, Validation Accuracy: 0.7659166666666667\n",
      "Epoch: 18, Loss: 0.6962111592292786, Validation Accuracy: 0.7766666666666666\n",
      "Epoch: 19, Loss: 0.6802927851676941, Validation Accuracy: 0.7783333333333333\n",
      "Epoch: 20, Loss: 0.6651054620742798, Validation Accuracy: 0.7780833333333333\n",
      "Epoch: 21, Loss: 0.6674765944480896, Validation Accuracy: 0.78225\n",
      "Epoch: 22, Loss: 0.6508760452270508, Validation Accuracy: 0.7785833333333333\n",
      "Epoch: 23, Loss: 0.6611570119857788, Validation Accuracy: 0.7921666666666667\n",
      "Epoch: 24, Loss: 0.6277763247489929, Validation Accuracy: 0.79075\n",
      "Epoch: 25, Loss: 0.6198801398277283, Validation Accuracy: 0.80775\n",
      "Epoch: 26, Loss: 0.5858060121536255, Validation Accuracy: 0.8096666666666666\n",
      "Epoch: 27, Loss: 0.5661417245864868, Validation Accuracy: 0.8201666666666667\n",
      "Epoch: 28, Loss: 0.5467352271080017, Validation Accuracy: 0.8229166666666666\n",
      "Epoch: 29, Loss: 0.5277429223060608, Validation Accuracy: 0.8300833333333333\n",
      "Epoch: 30, Loss: 0.516034722328186, Validation Accuracy: 0.8303333333333334\n",
      "Epoch: 31, Loss: 0.5006778836250305, Validation Accuracy: 0.8408333333333333\n",
      "Epoch: 32, Loss: 0.49154436588287354, Validation Accuracy: 0.8374166666666667\n",
      "Epoch: 33, Loss: 0.4797258675098419, Validation Accuracy: 0.8470833333333333\n",
      "Epoch: 34, Loss: 0.47187820076942444, Validation Accuracy: 0.8445\n",
      "Epoch: 35, Loss: 0.46237480640411377, Validation Accuracy: 0.8508333333333333\n",
      "Epoch: 36, Loss: 0.455023854970932, Validation Accuracy: 0.8496666666666667\n",
      "Epoch: 37, Loss: 0.44687604904174805, Validation Accuracy: 0.8555\n",
      "Epoch: 38, Loss: 0.44015058875083923, Validation Accuracy: 0.8565\n",
      "Epoch: 39, Loss: 0.4330722391605377, Validation Accuracy: 0.8600833333333333\n",
      "Epoch: 40, Loss: 0.426882803440094, Validation Accuracy: 0.8616666666666667\n",
      "Epoch: 41, Loss: 0.4205262362957001, Validation Accuracy: 0.8640833333333333\n",
      "Epoch: 42, Loss: 0.41494977474212646, Validation Accuracy: 0.86525\n",
      "Epoch: 43, Loss: 0.4093446433544159, Validation Accuracy: 0.8675\n",
      "Epoch: 44, Loss: 0.4042070806026459, Validation Accuracy: 0.8680833333333333\n",
      "Epoch: 45, Loss: 0.3991554379463196, Validation Accuracy: 0.87075\n",
      "Epoch: 46, Loss: 0.39451462030410767, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 47, Loss: 0.39003533124923706, Validation Accuracy: 0.8723333333333333\n",
      "Epoch: 48, Loss: 0.3858916461467743, Validation Accuracy: 0.8754166666666666\n",
      "Epoch: 49, Loss: 0.3818187713623047, Validation Accuracy: 0.875\n",
      "Epoch: 50, Loss: 0.3780079782009125, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 51, Loss: 0.3742663562297821, Validation Accuracy: 0.8765\n",
      "Epoch: 52, Loss: 0.37070757150650024, Validation Accuracy: 0.8804166666666666\n",
      "Epoch: 53, Loss: 0.3672559857368469, Validation Accuracy: 0.8781666666666667\n",
      "Epoch: 54, Loss: 0.3639567196369171, Validation Accuracy: 0.882\n",
      "Epoch: 55, Loss: 0.3607507050037384, Validation Accuracy: 0.8810833333333333\n",
      "Epoch: 56, Loss: 0.3576433062553406, Validation Accuracy: 0.8834166666666666\n",
      "Epoch: 57, Loss: 0.35466769337654114, Validation Accuracy: 0.88325\n",
      "Epoch: 58, Loss: 0.351784348487854, Validation Accuracy: 0.8856666666666667\n",
      "Epoch: 59, Loss: 0.3490094542503357, Validation Accuracy: 0.8854166666666666\n",
      "Epoch: 60, Loss: 0.34630724787712097, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 61, Loss: 0.3436838686466217, Validation Accuracy: 0.8871666666666667\n",
      "Epoch: 62, Loss: 0.34117552638053894, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 63, Loss: 0.33870962262153625, Validation Accuracy: 0.8889166666666667\n",
      "Epoch: 64, Loss: 0.33635130524635315, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 65, Loss: 0.3340136408805847, Validation Accuracy: 0.88975\n",
      "Epoch: 66, Loss: 0.33175981044769287, Validation Accuracy: 0.8916666666666667\n",
      "Epoch: 67, Loss: 0.32955077290534973, Validation Accuracy: 0.891\n",
      "Epoch: 68, Loss: 0.3274034559726715, Validation Accuracy: 0.89325\n",
      "Epoch: 69, Loss: 0.32529300451278687, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 70, Loss: 0.3232576251029968, Validation Accuracy: 0.8939166666666667\n",
      "Epoch: 71, Loss: 0.3212341368198395, Validation Accuracy: 0.8939166666666667\n",
      "Epoch: 72, Loss: 0.31927743554115295, Validation Accuracy: 0.8955\n",
      "Epoch: 73, Loss: 0.31736108660697937, Validation Accuracy: 0.895\n",
      "Epoch: 74, Loss: 0.3155016601085663, Validation Accuracy: 0.8965\n",
      "Epoch: 75, Loss: 0.3136653006076813, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 76, Loss: 0.31188538670539856, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 77, Loss: 0.31012511253356934, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 78, Loss: 0.30841776728630066, Validation Accuracy: 0.8985\n",
      "Epoch: 79, Loss: 0.3067093789577484, Validation Accuracy: 0.8985\n",
      "Epoch: 80, Loss: 0.3050524890422821, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 81, Loss: 0.30340397357940674, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 82, Loss: 0.3017895817756653, Validation Accuracy: 0.90075\n",
      "Epoch: 83, Loss: 0.30019062757492065, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 84, Loss: 0.2986215054988861, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 85, Loss: 0.2970718443393707, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 86, Loss: 0.29555386304855347, Validation Accuracy: 0.90275\n",
      "Epoch: 87, Loss: 0.2940651774406433, Validation Accuracy: 0.9026666666666666\n",
      "Epoch: 88, Loss: 0.29260608553886414, Validation Accuracy: 0.9033333333333333\n",
      "Epoch: 89, Loss: 0.29115983843803406, Validation Accuracy: 0.90325\n",
      "Epoch: 90, Loss: 0.28975924849510193, Validation Accuracy: 0.9045\n",
      "Epoch: 91, Loss: 0.2883586287498474, Validation Accuracy: 0.904\n",
      "Epoch: 92, Loss: 0.2870171368122101, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 93, Loss: 0.2856738567352295, Validation Accuracy: 0.905\n",
      "Epoch: 94, Loss: 0.28437545895576477, Validation Accuracy: 0.9056666666666666\n",
      "Epoch: 95, Loss: 0.2830760180950165, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 96, Loss: 0.28181910514831543, Validation Accuracy: 0.9063333333333333\n",
      "Epoch: 97, Loss: 0.2805499732494354, Validation Accuracy: 0.90625\n",
      "Epoch: 98, Loss: 0.27933448553085327, Validation Accuracy: 0.9075\n",
      "Epoch: 99, Loss: 0.27809348702430725, Validation Accuracy: 0.907\n",
      "Dataset 19\n",
      "Epoch: 0, Loss: 3.4778213500976562, Validation Accuracy: 0.15058333333333335\n",
      "Epoch: 1, Loss: 2.8973329067230225, Validation Accuracy: 0.23316666666666666\n",
      "Epoch: 2, Loss: 2.4846508502960205, Validation Accuracy: 0.24933333333333332\n",
      "Epoch: 3, Loss: 2.366698980331421, Validation Accuracy: 0.2623333333333333\n",
      "Epoch: 4, Loss: 2.060133218765259, Validation Accuracy: 0.39966666666666667\n",
      "Epoch: 5, Loss: 1.7215758562088013, Validation Accuracy: 0.4583333333333333\n",
      "Epoch: 6, Loss: 1.5418994426727295, Validation Accuracy: 0.5131666666666667\n",
      "Epoch: 7, Loss: 1.4166290760040283, Validation Accuracy: 0.5573333333333333\n",
      "Epoch: 8, Loss: 1.3119263648986816, Validation Accuracy: 0.5933333333333334\n",
      "Epoch: 9, Loss: 1.2177225351333618, Validation Accuracy: 0.6223333333333333\n",
      "Epoch: 10, Loss: 1.1332367658615112, Validation Accuracy: 0.64975\n",
      "Epoch: 11, Loss: 1.0568187236785889, Validation Accuracy: 0.6739166666666667\n",
      "Epoch: 12, Loss: 0.9886251091957092, Validation Accuracy: 0.6953333333333334\n",
      "Epoch: 13, Loss: 0.9285058379173279, Validation Accuracy: 0.7134166666666667\n",
      "Epoch: 14, Loss: 0.8791717886924744, Validation Accuracy: 0.7180833333333333\n",
      "Epoch: 15, Loss: 0.8454124927520752, Validation Accuracy: 0.71275\n",
      "Epoch: 16, Loss: 0.847337007522583, Validation Accuracy: 0.6741666666666667\n",
      "Epoch: 17, Loss: 0.9160940647125244, Validation Accuracy: 0.6005833333333334\n",
      "Epoch: 18, Loss: 1.0774245262145996, Validation Accuracy: 0.58625\n",
      "Epoch: 19, Loss: 1.1700268983840942, Validation Accuracy: 0.6906666666666667\n",
      "Epoch: 20, Loss: 0.9018692374229431, Validation Accuracy: 0.7515\n",
      "Epoch: 21, Loss: 0.746420681476593, Validation Accuracy: 0.79825\n",
      "Epoch: 22, Loss: 0.6506633162498474, Validation Accuracy: 0.8115833333333333\n",
      "Epoch: 23, Loss: 0.612038254737854, Validation Accuracy: 0.8186666666666667\n",
      "Epoch: 24, Loss: 0.5848091840744019, Validation Accuracy: 0.8230833333333333\n",
      "Epoch: 25, Loss: 0.5638737678527832, Validation Accuracy: 0.8293333333333334\n",
      "Epoch: 26, Loss: 0.5461477637290955, Validation Accuracy: 0.8305\n",
      "Epoch: 27, Loss: 0.5307872891426086, Validation Accuracy: 0.8359166666666666\n",
      "Epoch: 28, Loss: 0.5171082615852356, Validation Accuracy: 0.838\n",
      "Epoch: 29, Loss: 0.5048949718475342, Validation Accuracy: 0.8418333333333333\n",
      "Epoch: 30, Loss: 0.4937308728694916, Validation Accuracy: 0.84425\n",
      "Epoch: 31, Loss: 0.4835681915283203, Validation Accuracy: 0.8479166666666667\n",
      "Epoch: 32, Loss: 0.4741317927837372, Validation Accuracy: 0.8496666666666667\n",
      "Epoch: 33, Loss: 0.4654468894004822, Validation Accuracy: 0.85125\n",
      "Epoch: 34, Loss: 0.457370400428772, Validation Accuracy: 0.8541666666666666\n",
      "Epoch: 35, Loss: 0.44982579350471497, Validation Accuracy: 0.8550833333333333\n",
      "Epoch: 36, Loss: 0.4427986741065979, Validation Accuracy: 0.8581666666666666\n",
      "Epoch: 37, Loss: 0.4361875057220459, Validation Accuracy: 0.8583333333333333\n",
      "Epoch: 38, Loss: 0.43006035685539246, Validation Accuracy: 0.8624166666666667\n",
      "Epoch: 39, Loss: 0.42421582341194153, Validation Accuracy: 0.8618333333333333\n",
      "Epoch: 40, Loss: 0.41875573992729187, Validation Accuracy: 0.8656666666666667\n",
      "Epoch: 41, Loss: 0.41356778144836426, Validation Accuracy: 0.8655833333333334\n",
      "Epoch: 42, Loss: 0.40869709849357605, Validation Accuracy: 0.86875\n",
      "Epoch: 43, Loss: 0.4039981961250305, Validation Accuracy: 0.8690833333333333\n",
      "Epoch: 44, Loss: 0.3996751010417938, Validation Accuracy: 0.87025\n",
      "Epoch: 45, Loss: 0.39546263217926025, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 46, Loss: 0.3914852738380432, Validation Accuracy: 0.8736666666666667\n",
      "Epoch: 47, Loss: 0.38769787549972534, Validation Accuracy: 0.87375\n",
      "Epoch: 48, Loss: 0.38395681977272034, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 49, Loss: 0.38060930371284485, Validation Accuracy: 0.8754166666666666\n",
      "Epoch: 50, Loss: 0.3772762715816498, Validation Accuracy: 0.87925\n",
      "Epoch: 51, Loss: 0.3743843138217926, Validation Accuracy: 0.878\n",
      "Epoch: 52, Loss: 0.3716413974761963, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 53, Loss: 0.36956098675727844, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 54, Loss: 0.36809608340263367, Validation Accuracy: 0.88\n",
      "Epoch: 55, Loss: 0.3676580786705017, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 56, Loss: 0.369036465883255, Validation Accuracy: 0.8775833333333334\n",
      "Epoch: 57, Loss: 0.3721593916416168, Validation Accuracy: 0.8760833333333333\n",
      "Epoch: 58, Loss: 0.379914790391922, Validation Accuracy: 0.8694166666666666\n",
      "Epoch: 59, Loss: 0.38965746760368347, Validation Accuracy: 0.8655\n",
      "Epoch: 60, Loss: 0.40819647908210754, Validation Accuracy: 0.8565\n",
      "Epoch: 61, Loss: 0.4259888529777527, Validation Accuracy: 0.8500833333333333\n",
      "Epoch: 62, Loss: 0.45286524295806885, Validation Accuracy: 0.83875\n",
      "Epoch: 63, Loss: 0.4660126566886902, Validation Accuracy: 0.8400833333333333\n",
      "Epoch: 64, Loss: 0.4722285568714142, Validation Accuracy: 0.8455833333333334\n",
      "Epoch: 65, Loss: 0.4457857608795166, Validation Accuracy: 0.8611666666666666\n",
      "Epoch: 66, Loss: 0.41180989146232605, Validation Accuracy: 0.8718333333333333\n",
      "Epoch: 67, Loss: 0.37538155913352966, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 68, Loss: 0.34882014989852905, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 69, Loss: 0.33379143476486206, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 70, Loss: 0.3250312805175781, Validation Accuracy: 0.894\n",
      "Epoch: 71, Loss: 0.3202194571495056, Validation Accuracy: 0.896\n",
      "Epoch: 72, Loss: 0.3169139623641968, Validation Accuracy: 0.8963333333333333\n",
      "Epoch: 73, Loss: 0.31435859203338623, Validation Accuracy: 0.8959166666666667\n",
      "Epoch: 74, Loss: 0.3121251165866852, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 75, Loss: 0.3100717067718506, Validation Accuracy: 0.89725\n",
      "Epoch: 76, Loss: 0.3081279993057251, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 77, Loss: 0.3062574565410614, Validation Accuracy: 0.8986666666666666\n",
      "Epoch: 78, Loss: 0.30444419384002686, Validation Accuracy: 0.89925\n",
      "Epoch: 79, Loss: 0.3026808798313141, Validation Accuracy: 0.8999166666666667\n",
      "Epoch: 80, Loss: 0.30096256732940674, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 81, Loss: 0.29928281903266907, Validation Accuracy: 0.901\n",
      "Epoch: 82, Loss: 0.29763585329055786, Validation Accuracy: 0.9015\n",
      "Epoch: 83, Loss: 0.2960202693939209, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 84, Loss: 0.2944399416446686, Validation Accuracy: 0.9026666666666666\n",
      "Epoch: 85, Loss: 0.29288703203201294, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 86, Loss: 0.2913684546947479, Validation Accuracy: 0.9034166666666666\n",
      "Epoch: 87, Loss: 0.2898769676685333, Validation Accuracy: 0.904\n",
      "Epoch: 88, Loss: 0.28841260075569153, Validation Accuracy: 0.9044166666666666\n",
      "Epoch: 89, Loss: 0.2869747579097748, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 90, Loss: 0.2855628728866577, Validation Accuracy: 0.9054166666666666\n",
      "Epoch: 91, Loss: 0.28417325019836426, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 92, Loss: 0.2828083038330078, Validation Accuracy: 0.906\n",
      "Epoch: 93, Loss: 0.28146645426750183, Validation Accuracy: 0.9066666666666666\n",
      "Epoch: 94, Loss: 0.2801448702812195, Validation Accuracy: 0.9071666666666667\n",
      "Epoch: 95, Loss: 0.2788439393043518, Validation Accuracy: 0.9078333333333334\n",
      "Epoch: 96, Loss: 0.27756381034851074, Validation Accuracy: 0.9081666666666667\n",
      "Epoch: 97, Loss: 0.27629968523979187, Validation Accuracy: 0.9086666666666666\n",
      "Epoch: 98, Loss: 0.27505210041999817, Validation Accuracy: 0.9088333333333334\n",
      "Epoch: 99, Loss: 0.27382516860961914, Validation Accuracy: 0.90925\n",
      "Dataset 20\n",
      "Epoch: 0, Loss: 3.332444906234741, Validation Accuracy: 0.15475\n",
      "Epoch: 1, Loss: 3.886162757873535, Validation Accuracy: 0.15166666666666667\n",
      "Epoch: 2, Loss: 2.850252628326416, Validation Accuracy: 0.19908333333333333\n",
      "Epoch: 3, Loss: 2.2300832271575928, Validation Accuracy: 0.31375\n",
      "Epoch: 4, Loss: 1.9646793603897095, Validation Accuracy: 0.409\n",
      "Epoch: 5, Loss: 1.7917633056640625, Validation Accuracy: 0.491\n",
      "Epoch: 6, Loss: 1.6334023475646973, Validation Accuracy: 0.5483333333333333\n",
      "Epoch: 7, Loss: 1.4839450120925903, Validation Accuracy: 0.5885\n",
      "Epoch: 8, Loss: 1.3513193130493164, Validation Accuracy: 0.61775\n",
      "Epoch: 9, Loss: 1.239330530166626, Validation Accuracy: 0.6395833333333333\n",
      "Epoch: 10, Loss: 1.150142788887024, Validation Accuracy: 0.6463333333333333\n",
      "Epoch: 11, Loss: 1.0937397480010986, Validation Accuracy: 0.6375\n",
      "Epoch: 12, Loss: 1.1004958152770996, Validation Accuracy: 0.58625\n",
      "Epoch: 13, Loss: 1.1979576349258423, Validation Accuracy: 0.5490833333333334\n",
      "Epoch: 14, Loss: 1.2990822792053223, Validation Accuracy: 0.6115\n",
      "Epoch: 15, Loss: 1.1319135427474976, Validation Accuracy: 0.71525\n",
      "Epoch: 16, Loss: 0.885726809501648, Validation Accuracy: 0.73825\n",
      "Epoch: 17, Loss: 0.7956515550613403, Validation Accuracy: 0.76075\n",
      "Epoch: 18, Loss: 0.748441219329834, Validation Accuracy: 0.7695\n",
      "Epoch: 19, Loss: 0.7110928297042847, Validation Accuracy: 0.7810833333333334\n",
      "Epoch: 20, Loss: 0.6852602362632751, Validation Accuracy: 0.78425\n",
      "Epoch: 21, Loss: 0.661626398563385, Validation Accuracy: 0.79025\n",
      "Epoch: 22, Loss: 0.64634108543396, Validation Accuracy: 0.7905833333333333\n",
      "Epoch: 23, Loss: 0.6305638551712036, Validation Accuracy: 0.7920833333333334\n",
      "Epoch: 24, Loss: 0.6287763118743896, Validation Accuracy: 0.7883333333333333\n",
      "Epoch: 25, Loss: 0.620441198348999, Validation Accuracy: 0.7789166666666667\n",
      "Epoch: 26, Loss: 0.6414884924888611, Validation Accuracy: 0.7740833333333333\n",
      "Epoch: 27, Loss: 0.6379244923591614, Validation Accuracy: 0.75625\n",
      "Epoch: 28, Loss: 0.6796964406967163, Validation Accuracy: 0.7498333333333334\n",
      "Epoch: 29, Loss: 0.689858078956604, Validation Accuracy: 0.733\n",
      "Epoch: 30, Loss: 0.7450167536735535, Validation Accuracy: 0.7274166666666667\n",
      "Epoch: 31, Loss: 0.7603493928909302, Validation Accuracy: 0.7419166666666667\n",
      "Epoch: 32, Loss: 0.784909725189209, Validation Accuracy: 0.7566666666666667\n",
      "Epoch: 33, Loss: 0.7012088894844055, Validation Accuracy: 0.8105\n",
      "Epoch: 34, Loss: 0.590345025062561, Validation Accuracy: 0.8228333333333333\n",
      "Epoch: 35, Loss: 0.5354682803153992, Validation Accuracy: 0.842\n",
      "Epoch: 36, Loss: 0.4982089102268219, Validation Accuracy: 0.8471666666666666\n",
      "Epoch: 37, Loss: 0.48038458824157715, Validation Accuracy: 0.8518333333333333\n",
      "Epoch: 38, Loss: 0.46805354952812195, Validation Accuracy: 0.85425\n",
      "Epoch: 39, Loss: 0.4587232768535614, Validation Accuracy: 0.857\n",
      "Epoch: 40, Loss: 0.4507245421409607, Validation Accuracy: 0.8600833333333333\n",
      "Epoch: 41, Loss: 0.44362497329711914, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 42, Loss: 0.43707287311553955, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 43, Loss: 0.4309963881969452, Validation Accuracy: 0.8648333333333333\n",
      "Epoch: 44, Loss: 0.4253234565258026, Validation Accuracy: 0.8663333333333333\n",
      "Epoch: 45, Loss: 0.4200165867805481, Validation Accuracy: 0.8686666666666667\n",
      "Epoch: 46, Loss: 0.41502538323402405, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 47, Loss: 0.4102932810783386, Validation Accuracy: 0.8715\n",
      "Epoch: 48, Loss: 0.40577831864356995, Validation Accuracy: 0.873\n",
      "Epoch: 49, Loss: 0.40150025486946106, Validation Accuracy: 0.8735833333333334\n",
      "Epoch: 50, Loss: 0.39743173122406006, Validation Accuracy: 0.87575\n",
      "Epoch: 51, Loss: 0.3935786187648773, Validation Accuracy: 0.8756666666666667\n",
      "Epoch: 52, Loss: 0.38994190096855164, Validation Accuracy: 0.87725\n",
      "Epoch: 53, Loss: 0.3865317404270172, Validation Accuracy: 0.8779166666666667\n",
      "Epoch: 54, Loss: 0.3834143579006195, Validation Accuracy: 0.8785\n",
      "Epoch: 55, Loss: 0.380623996257782, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 56, Loss: 0.37829455733299255, Validation Accuracy: 0.8784166666666666\n",
      "Epoch: 57, Loss: 0.37663590908050537, Validation Accuracy: 0.8794166666666666\n",
      "Epoch: 58, Loss: 0.3755801320075989, Validation Accuracy: 0.8780833333333333\n",
      "Epoch: 59, Loss: 0.3759036064147949, Validation Accuracy: 0.878\n",
      "Epoch: 60, Loss: 0.3771202266216278, Validation Accuracy: 0.87325\n",
      "Epoch: 61, Loss: 0.3816404640674591, Validation Accuracy: 0.87275\n",
      "Epoch: 62, Loss: 0.3878781199455261, Validation Accuracy: 0.8633333333333333\n",
      "Epoch: 63, Loss: 0.4009679853916168, Validation Accuracy: 0.8596666666666667\n",
      "Epoch: 64, Loss: 0.41486552357673645, Validation Accuracy: 0.8469166666666667\n",
      "Epoch: 65, Loss: 0.4395805299282074, Validation Accuracy: 0.84525\n",
      "Epoch: 66, Loss: 0.45410746335983276, Validation Accuracy: 0.835\n",
      "Epoch: 67, Loss: 0.46901464462280273, Validation Accuracy: 0.8479166666666667\n",
      "Epoch: 68, Loss: 0.4474104046821594, Validation Accuracy: 0.8558333333333333\n",
      "Epoch: 69, Loss: 0.41814374923706055, Validation Accuracy: 0.87725\n",
      "Epoch: 70, Loss: 0.3806464970111847, Validation Accuracy: 0.8824166666666666\n",
      "Epoch: 71, Loss: 0.35658708214759827, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 72, Loss: 0.3433864712715149, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 73, Loss: 0.33663538098335266, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 74, Loss: 0.33254367113113403, Validation Accuracy: 0.8935\n",
      "Epoch: 75, Loss: 0.329477995634079, Validation Accuracy: 0.8955\n",
      "Epoch: 76, Loss: 0.32692620158195496, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 77, Loss: 0.32457906007766724, Validation Accuracy: 0.8963333333333333\n",
      "Epoch: 78, Loss: 0.322396457195282, Validation Accuracy: 0.89675\n",
      "Epoch: 79, Loss: 0.320309579372406, Validation Accuracy: 0.8975\n",
      "Epoch: 80, Loss: 0.3183141350746155, Validation Accuracy: 0.8979166666666667\n",
      "Epoch: 81, Loss: 0.31638094782829285, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 82, Loss: 0.31449636816978455, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 83, Loss: 0.31266242265701294, Validation Accuracy: 0.8995\n",
      "Epoch: 84, Loss: 0.3108765184879303, Validation Accuracy: 0.90025\n",
      "Epoch: 85, Loss: 0.3091374337673187, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 86, Loss: 0.30744290351867676, Validation Accuracy: 0.90125\n",
      "Epoch: 87, Loss: 0.3057889938354492, Validation Accuracy: 0.90175\n",
      "Epoch: 88, Loss: 0.30416756868362427, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 89, Loss: 0.30258315801620483, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 90, Loss: 0.3010307550430298, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 91, Loss: 0.2995045781135559, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 92, Loss: 0.29800814390182495, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 93, Loss: 0.2965388000011444, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 94, Loss: 0.295096218585968, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 95, Loss: 0.29367852210998535, Validation Accuracy: 0.9056666666666666\n",
      "Epoch: 96, Loss: 0.2922830581665039, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 97, Loss: 0.29090872406959534, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 98, Loss: 0.28955644369125366, Validation Accuracy: 0.907\n",
      "Epoch: 99, Loss: 0.28822532296180725, Validation Accuracy: 0.9073333333333333\n",
      "Dataset 21\n",
      "Epoch: 0, Loss: 3.3873932361602783, Validation Accuracy: 0.15133333333333332\n",
      "Epoch: 1, Loss: 3.491009473800659, Validation Accuracy: 0.11208333333333333\n",
      "Epoch: 2, Loss: 4.786777496337891, Validation Accuracy: 0.17708333333333334\n",
      "Epoch: 3, Loss: 2.9421093463897705, Validation Accuracy: 0.20758333333333334\n",
      "Epoch: 4, Loss: 2.559248685836792, Validation Accuracy: 0.235\n",
      "Epoch: 5, Loss: 2.0933022499084473, Validation Accuracy: 0.3455\n",
      "Epoch: 6, Loss: 1.8660900592803955, Validation Accuracy: 0.4171666666666667\n",
      "Epoch: 7, Loss: 1.7348384857177734, Validation Accuracy: 0.46058333333333334\n",
      "Epoch: 8, Loss: 1.6399773359298706, Validation Accuracy: 0.49275\n",
      "Epoch: 9, Loss: 1.5546482801437378, Validation Accuracy: 0.52025\n",
      "Epoch: 10, Loss: 1.4775758981704712, Validation Accuracy: 0.5409166666666667\n",
      "Epoch: 11, Loss: 1.4084855318069458, Validation Accuracy: 0.5629166666666666\n",
      "Epoch: 12, Loss: 1.3459869623184204, Validation Accuracy: 0.58075\n",
      "Epoch: 13, Loss: 1.2875334024429321, Validation Accuracy: 0.6000833333333333\n",
      "Epoch: 14, Loss: 1.2314538955688477, Validation Accuracy: 0.6163333333333333\n",
      "Epoch: 15, Loss: 1.1769617795944214, Validation Accuracy: 0.63275\n",
      "Epoch: 16, Loss: 1.1238057613372803, Validation Accuracy: 0.6473333333333333\n",
      "Epoch: 17, Loss: 1.0720587968826294, Validation Accuracy: 0.6661666666666667\n",
      "Epoch: 18, Loss: 1.0220056772232056, Validation Accuracy: 0.6834166666666667\n",
      "Epoch: 19, Loss: 0.9738575220108032, Validation Accuracy: 0.70125\n",
      "Epoch: 20, Loss: 0.9278116226196289, Validation Accuracy: 0.7206666666666667\n",
      "Epoch: 21, Loss: 0.8840906620025635, Validation Accuracy: 0.7343333333333333\n",
      "Epoch: 22, Loss: 0.8431311249732971, Validation Accuracy: 0.7470833333333333\n",
      "Epoch: 23, Loss: 0.8058308362960815, Validation Accuracy: 0.7565\n",
      "Epoch: 24, Loss: 0.774768054485321, Validation Accuracy: 0.76275\n",
      "Epoch: 25, Loss: 0.7560889720916748, Validation Accuracy: 0.7451666666666666\n",
      "Epoch: 26, Loss: 0.7763181924819946, Validation Accuracy: 0.7093333333333334\n",
      "Epoch: 27, Loss: 0.876812756061554, Validation Accuracy: 0.57725\n",
      "Epoch: 28, Loss: 1.2677512168884277, Validation Accuracy: 0.6668333333333333\n",
      "Epoch: 29, Loss: 1.0036101341247559, Validation Accuracy: 0.6819166666666666\n",
      "Epoch: 30, Loss: 0.9372859001159668, Validation Accuracy: 0.7883333333333333\n",
      "Epoch: 31, Loss: 0.688711941242218, Validation Accuracy: 0.8005833333333333\n",
      "Epoch: 32, Loss: 0.6339294910430908, Validation Accuracy: 0.8141666666666667\n",
      "Epoch: 33, Loss: 0.6027833223342896, Validation Accuracy: 0.8155833333333333\n",
      "Epoch: 34, Loss: 0.5824461579322815, Validation Accuracy: 0.8235833333333333\n",
      "Epoch: 35, Loss: 0.565918505191803, Validation Accuracy: 0.82575\n",
      "Epoch: 36, Loss: 0.5518891215324402, Validation Accuracy: 0.8301666666666667\n",
      "Epoch: 37, Loss: 0.5395054221153259, Validation Accuracy: 0.8325833333333333\n",
      "Epoch: 38, Loss: 0.5284519195556641, Validation Accuracy: 0.83775\n",
      "Epoch: 39, Loss: 0.518374502658844, Validation Accuracy: 0.839\n",
      "Epoch: 40, Loss: 0.5092867016792297, Validation Accuracy: 0.8425\n",
      "Epoch: 41, Loss: 0.5010385513305664, Validation Accuracy: 0.8438333333333333\n",
      "Epoch: 42, Loss: 0.49356940388679504, Validation Accuracy: 0.8465833333333334\n",
      "Epoch: 43, Loss: 0.48685982823371887, Validation Accuracy: 0.8471666666666666\n",
      "Epoch: 44, Loss: 0.4811214208602905, Validation Accuracy: 0.8495833333333334\n",
      "Epoch: 45, Loss: 0.4765644073486328, Validation Accuracy: 0.8490833333333333\n",
      "Epoch: 46, Loss: 0.47382670640945435, Validation Accuracy: 0.851\n",
      "Epoch: 47, Loss: 0.47386083006858826, Validation Accuracy: 0.84525\n",
      "Epoch: 48, Loss: 0.4781217575073242, Validation Accuracy: 0.84475\n",
      "Epoch: 49, Loss: 0.4894079267978668, Validation Accuracy: 0.8319166666666666\n",
      "Epoch: 50, Loss: 0.5096206665039062, Validation Accuracy: 0.826\n",
      "Epoch: 51, Loss: 0.5425200462341309, Validation Accuracy: 0.8028333333333333\n",
      "Epoch: 52, Loss: 0.580487072467804, Validation Accuracy: 0.8055833333333333\n",
      "Epoch: 53, Loss: 0.6019320487976074, Validation Accuracy: 0.8020833333333334\n",
      "Epoch: 54, Loss: 0.5907655954360962, Validation Accuracy: 0.82575\n",
      "Epoch: 55, Loss: 0.5336027145385742, Validation Accuracy: 0.8420833333333333\n",
      "Epoch: 56, Loss: 0.4869263470172882, Validation Accuracy: 0.8586666666666667\n",
      "Epoch: 57, Loss: 0.4493824541568756, Validation Accuracy: 0.864\n",
      "Epoch: 58, Loss: 0.42951950430870056, Validation Accuracy: 0.8690833333333333\n",
      "Epoch: 59, Loss: 0.41825228929519653, Validation Accuracy: 0.873\n",
      "Epoch: 60, Loss: 0.4105552136898041, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 61, Loss: 0.4050631821155548, Validation Accuracy: 0.8769166666666667\n",
      "Epoch: 62, Loss: 0.4001343250274658, Validation Accuracy: 0.8780833333333333\n",
      "Epoch: 63, Loss: 0.39601704478263855, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 64, Loss: 0.3920191526412964, Validation Accuracy: 0.88075\n",
      "Epoch: 65, Loss: 0.38843753933906555, Validation Accuracy: 0.88275\n",
      "Epoch: 66, Loss: 0.3848482668399811, Validation Accuracy: 0.883\n",
      "Epoch: 67, Loss: 0.3815940022468567, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 68, Loss: 0.37831583619117737, Validation Accuracy: 0.8856666666666667\n",
      "Epoch: 69, Loss: 0.3753221929073334, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 70, Loss: 0.3723348081111908, Validation Accuracy: 0.887\n",
      "Epoch: 71, Loss: 0.36959245800971985, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 72, Loss: 0.3667944669723511, Validation Accuracy: 0.88875\n",
      "Epoch: 73, Loss: 0.3642217218875885, Validation Accuracy: 0.88925\n",
      "Epoch: 74, Loss: 0.3615962266921997, Validation Accuracy: 0.8905\n",
      "Epoch: 75, Loss: 0.3591805100440979, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 76, Loss: 0.35669711232185364, Validation Accuracy: 0.89225\n",
      "Epoch: 77, Loss: 0.35444173216819763, Validation Accuracy: 0.8923333333333333\n",
      "Epoch: 78, Loss: 0.3520839810371399, Validation Accuracy: 0.8935833333333333\n",
      "Epoch: 79, Loss: 0.3499509394168854, Validation Accuracy: 0.89325\n",
      "Epoch: 80, Loss: 0.34768179059028625, Validation Accuracy: 0.8944166666666666\n",
      "Epoch: 81, Loss: 0.3456818163394928, Validation Accuracy: 0.8945\n",
      "Epoch: 82, Loss: 0.34358468651771545, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 83, Loss: 0.34168174862861633, Validation Accuracy: 0.8955\n",
      "Epoch: 84, Loss: 0.3396185040473938, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 85, Loss: 0.33778151869773865, Validation Accuracy: 0.89675\n",
      "Epoch: 86, Loss: 0.33582553267478943, Validation Accuracy: 0.8983333333333333\n",
      "Epoch: 87, Loss: 0.33410191535949707, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 88, Loss: 0.33225613832473755, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 89, Loss: 0.33052918314933777, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 90, Loss: 0.32875198125839233, Validation Accuracy: 0.9001666666666667\n",
      "Epoch: 91, Loss: 0.327094703912735, Validation Accuracy: 0.9005\n",
      "Epoch: 92, Loss: 0.32544735074043274, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 93, Loss: 0.32387790083885193, Validation Accuracy: 0.90075\n",
      "Epoch: 94, Loss: 0.3224015533924103, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 95, Loss: 0.32096171379089355, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 96, Loss: 0.31964966654777527, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 97, Loss: 0.31832581758499146, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 98, Loss: 0.3172570466995239, Validation Accuracy: 0.90175\n",
      "Epoch: 99, Loss: 0.31603336334228516, Validation Accuracy: 0.90125\n",
      "Dataset 22\n",
      "Epoch: 0, Loss: 3.0863733291625977, Validation Accuracy: 0.21225\n",
      "Epoch: 1, Loss: 2.416855573654175, Validation Accuracy: 0.2876666666666667\n",
      "Epoch: 2, Loss: 2.0339999198913574, Validation Accuracy: 0.3324166666666667\n",
      "Epoch: 3, Loss: 1.8966689109802246, Validation Accuracy: 0.38108333333333333\n",
      "Epoch: 4, Loss: 1.7994318008422852, Validation Accuracy: 0.41483333333333333\n",
      "Epoch: 5, Loss: 1.7199187278747559, Validation Accuracy: 0.469\n",
      "Epoch: 6, Loss: 1.5644543170928955, Validation Accuracy: 0.48491666666666666\n",
      "Epoch: 7, Loss: 1.5180257558822632, Validation Accuracy: 0.4191666666666667\n",
      "Epoch: 8, Loss: 1.7006008625030518, Validation Accuracy: 0.4256666666666667\n",
      "Epoch: 9, Loss: 1.7047978639602661, Validation Accuracy: 0.50075\n",
      "Epoch: 10, Loss: 1.3983728885650635, Validation Accuracy: 0.6103333333333333\n",
      "Epoch: 11, Loss: 1.1813899278640747, Validation Accuracy: 0.68625\n",
      "Epoch: 12, Loss: 1.023315191268921, Validation Accuracy: 0.7075\n",
      "Epoch: 13, Loss: 0.9379194378852844, Validation Accuracy: 0.7275\n",
      "Epoch: 14, Loss: 0.8782826066017151, Validation Accuracy: 0.7375\n",
      "Epoch: 15, Loss: 0.8326582908630371, Validation Accuracy: 0.74825\n",
      "Epoch: 16, Loss: 0.8033100366592407, Validation Accuracy: 0.7455\n",
      "Epoch: 17, Loss: 0.7883093953132629, Validation Accuracy: 0.7386666666666667\n",
      "Epoch: 18, Loss: 0.8184090852737427, Validation Accuracy: 0.72075\n",
      "Epoch: 19, Loss: 0.8558138012886047, Validation Accuracy: 0.6846666666666666\n",
      "Epoch: 20, Loss: 0.9961724281311035, Validation Accuracy: 0.7040833333333333\n",
      "Epoch: 21, Loss: 0.8835743069648743, Validation Accuracy: 0.7478333333333333\n",
      "Epoch: 22, Loss: 0.7879469990730286, Validation Accuracy: 0.78375\n",
      "Epoch: 23, Loss: 0.6652888059616089, Validation Accuracy: 0.8074166666666667\n",
      "Epoch: 24, Loss: 0.6204497218132019, Validation Accuracy: 0.8106666666666666\n",
      "Epoch: 25, Loss: 0.5951501727104187, Validation Accuracy: 0.8216666666666667\n",
      "Epoch: 26, Loss: 0.5800533294677734, Validation Accuracy: 0.8181666666666667\n",
      "Epoch: 27, Loss: 0.5687083005905151, Validation Accuracy: 0.8243333333333334\n",
      "Epoch: 28, Loss: 0.5633016228675842, Validation Accuracy: 0.8148333333333333\n",
      "Epoch: 29, Loss: 0.5619686841964722, Validation Accuracy: 0.8173333333333334\n",
      "Epoch: 30, Loss: 0.573535144329071, Validation Accuracy: 0.8015833333333333\n",
      "Epoch: 31, Loss: 0.5858907103538513, Validation Accuracy: 0.7935833333333333\n",
      "Epoch: 32, Loss: 0.6222015023231506, Validation Accuracy: 0.7888333333333334\n",
      "Epoch: 33, Loss: 0.6188426613807678, Validation Accuracy: 0.79075\n",
      "Epoch: 34, Loss: 0.6298324465751648, Validation Accuracy: 0.8088333333333333\n",
      "Epoch: 35, Loss: 0.5690503716468811, Validation Accuracy: 0.8308333333333333\n",
      "Epoch: 36, Loss: 0.5368874669075012, Validation Accuracy: 0.8383333333333334\n",
      "Epoch: 37, Loss: 0.4993734657764435, Validation Accuracy: 0.8534166666666667\n",
      "Epoch: 38, Loss: 0.4813220500946045, Validation Accuracy: 0.8525\n",
      "Epoch: 39, Loss: 0.4668618142604828, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 40, Loss: 0.4572222828865051, Validation Accuracy: 0.8594166666666667\n",
      "Epoch: 41, Loss: 0.44878479838371277, Validation Accuracy: 0.8655833333333334\n",
      "Epoch: 42, Loss: 0.44180554151535034, Validation Accuracy: 0.8635\n",
      "Epoch: 43, Loss: 0.4354150891304016, Validation Accuracy: 0.8686666666666667\n",
      "Epoch: 44, Loss: 0.4297211766242981, Validation Accuracy: 0.8675833333333334\n",
      "Epoch: 45, Loss: 0.4242995083332062, Validation Accuracy: 0.8714166666666666\n",
      "Epoch: 46, Loss: 0.4194139540195465, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 47, Loss: 0.4146752655506134, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 48, Loss: 0.41037455201148987, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 49, Loss: 0.40627148747444153, Validation Accuracy: 0.8771666666666667\n",
      "Epoch: 50, Loss: 0.4026872515678406, Validation Accuracy: 0.8759166666666667\n",
      "Epoch: 51, Loss: 0.39929041266441345, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 52, Loss: 0.3965182304382324, Validation Accuracy: 0.878\n",
      "Epoch: 53, Loss: 0.3937188386917114, Validation Accuracy: 0.8810833333333333\n",
      "Epoch: 54, Loss: 0.39198726415634155, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 55, Loss: 0.39003244042396545, Validation Accuracy: 0.88225\n",
      "Epoch: 56, Loss: 0.3898545801639557, Validation Accuracy: 0.8780833333333333\n",
      "Epoch: 57, Loss: 0.3890426456928253, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 58, Loss: 0.3910951316356659, Validation Accuracy: 0.8766666666666667\n",
      "Epoch: 59, Loss: 0.39099445939064026, Validation Accuracy: 0.8814166666666666\n",
      "Epoch: 60, Loss: 0.39550021290779114, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 61, Loss: 0.3953371047973633, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 62, Loss: 0.401062548160553, Validation Accuracy: 0.8725\n",
      "Epoch: 63, Loss: 0.3970516622066498, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 64, Loss: 0.39871060848236084, Validation Accuracy: 0.8755833333333334\n",
      "Epoch: 65, Loss: 0.3882066309452057, Validation Accuracy: 0.8859166666666667\n",
      "Epoch: 66, Loss: 0.38298138976097107, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 67, Loss: 0.3699180781841278, Validation Accuracy: 0.89075\n",
      "Epoch: 68, Loss: 0.3621678054332733, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 69, Loss: 0.3524656593799591, Validation Accuracy: 0.895\n",
      "Epoch: 70, Loss: 0.3463422358036041, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 71, Loss: 0.34040510654449463, Validation Accuracy: 0.897\n",
      "Epoch: 72, Loss: 0.33630356192588806, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 73, Loss: 0.3325173854827881, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 74, Loss: 0.32951557636260986, Validation Accuracy: 0.8985\n",
      "Epoch: 75, Loss: 0.32667434215545654, Validation Accuracy: 0.9003333333333333\n",
      "Epoch: 76, Loss: 0.32417017221450806, Validation Accuracy: 0.8999166666666667\n",
      "Epoch: 77, Loss: 0.3217906653881073, Validation Accuracy: 0.90175\n",
      "Epoch: 78, Loss: 0.3195318579673767, Validation Accuracy: 0.90075\n",
      "Epoch: 79, Loss: 0.3173791766166687, Validation Accuracy: 0.903\n",
      "Epoch: 80, Loss: 0.3153020739555359, Validation Accuracy: 0.9020833333333333\n",
      "Epoch: 81, Loss: 0.31330445408821106, Validation Accuracy: 0.90375\n",
      "Epoch: 82, Loss: 0.3113457262516022, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 83, Loss: 0.309449702501297, Validation Accuracy: 0.9051666666666667\n",
      "Epoch: 84, Loss: 0.30758675932884216, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 85, Loss: 0.30576789379119873, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 86, Loss: 0.3039872944355011, Validation Accuracy: 0.9064166666666666\n",
      "Epoch: 87, Loss: 0.3022236227989197, Validation Accuracy: 0.9069166666666667\n",
      "Epoch: 88, Loss: 0.30050286650657654, Validation Accuracy: 0.9075\n",
      "Epoch: 89, Loss: 0.2988072633743286, Validation Accuracy: 0.90775\n",
      "Epoch: 90, Loss: 0.2971530854701996, Validation Accuracy: 0.9085833333333333\n",
      "Epoch: 91, Loss: 0.29552364349365234, Validation Accuracy: 0.9084166666666667\n",
      "Epoch: 92, Loss: 0.29393360018730164, Validation Accuracy: 0.9093333333333333\n",
      "Epoch: 93, Loss: 0.29235246777534485, Validation Accuracy: 0.9090833333333334\n",
      "Epoch: 94, Loss: 0.290810227394104, Validation Accuracy: 0.91\n",
      "Epoch: 95, Loss: 0.28929388523101807, Validation Accuracy: 0.91\n",
      "Epoch: 96, Loss: 0.28780484199523926, Validation Accuracy: 0.9108333333333334\n",
      "Epoch: 97, Loss: 0.28633737564086914, Validation Accuracy: 0.9108333333333334\n",
      "Epoch: 98, Loss: 0.28489747643470764, Validation Accuracy: 0.9118333333333334\n",
      "Epoch: 99, Loss: 0.28347015380859375, Validation Accuracy: 0.9121666666666667\n",
      "Dataset 23\n",
      "Epoch: 0, Loss: 3.456094741821289, Validation Accuracy: 0.18558333333333332\n",
      "Epoch: 1, Loss: 4.534286975860596, Validation Accuracy: 0.13783333333333334\n",
      "Epoch: 2, Loss: 4.592686176300049, Validation Accuracy: 0.178\n",
      "Epoch: 3, Loss: 2.773210287094116, Validation Accuracy: 0.26708333333333334\n",
      "Epoch: 4, Loss: 2.070075511932373, Validation Accuracy: 0.3015833333333333\n",
      "Epoch: 5, Loss: 1.958942174911499, Validation Accuracy: 0.3278333333333333\n",
      "Epoch: 6, Loss: 1.873003363609314, Validation Accuracy: 0.3565833333333333\n",
      "Epoch: 7, Loss: 1.7903385162353516, Validation Accuracy: 0.38916666666666666\n",
      "Epoch: 8, Loss: 1.708828091621399, Validation Accuracy: 0.42633333333333334\n",
      "Epoch: 9, Loss: 1.627384066581726, Validation Accuracy: 0.4643333333333333\n",
      "Epoch: 10, Loss: 1.5449031591415405, Validation Accuracy: 0.501\n",
      "Epoch: 11, Loss: 1.4603177309036255, Validation Accuracy: 0.5375\n",
      "Epoch: 12, Loss: 1.3734883069992065, Validation Accuracy: 0.57\n",
      "Epoch: 13, Loss: 1.2871079444885254, Validation Accuracy: 0.6016666666666667\n",
      "Epoch: 14, Loss: 1.2029279470443726, Validation Accuracy: 0.6366666666666667\n",
      "Epoch: 15, Loss: 1.1235383749008179, Validation Accuracy: 0.66325\n",
      "Epoch: 16, Loss: 1.0521934032440186, Validation Accuracy: 0.6835\n",
      "Epoch: 17, Loss: 0.9942710995674133, Validation Accuracy: 0.694\n",
      "Epoch: 18, Loss: 0.9691530466079712, Validation Accuracy: 0.6479166666666667\n",
      "Epoch: 19, Loss: 1.0482419729232788, Validation Accuracy: 0.5050833333333333\n",
      "Epoch: 20, Loss: 1.4362351894378662, Validation Accuracy: 0.554\n",
      "Epoch: 21, Loss: 1.3158512115478516, Validation Accuracy: 0.7088333333333333\n",
      "Epoch: 22, Loss: 0.9533898234367371, Validation Accuracy: 0.7538333333333334\n",
      "Epoch: 23, Loss: 0.8015055060386658, Validation Accuracy: 0.77725\n",
      "Epoch: 24, Loss: 0.7500945925712585, Validation Accuracy: 0.78025\n",
      "Epoch: 25, Loss: 0.720522403717041, Validation Accuracy: 0.7663333333333333\n",
      "Epoch: 26, Loss: 0.7300263047218323, Validation Accuracy: 0.726\n",
      "Epoch: 27, Loss: 0.824182391166687, Validation Accuracy: 0.6195833333333334\n",
      "Epoch: 28, Loss: 1.0938804149627686, Validation Accuracy: 0.5793333333333334\n",
      "Epoch: 29, Loss: 1.3152273893356323, Validation Accuracy: 0.6870833333333334\n",
      "Epoch: 30, Loss: 0.9449942111968994, Validation Accuracy: 0.7814166666666666\n",
      "Epoch: 31, Loss: 0.7057640552520752, Validation Accuracy: 0.8091666666666667\n",
      "Epoch: 32, Loss: 0.6167948246002197, Validation Accuracy: 0.8266666666666667\n",
      "Epoch: 33, Loss: 0.5804223418235779, Validation Accuracy: 0.8306666666666667\n",
      "Epoch: 34, Loss: 0.5585402846336365, Validation Accuracy: 0.8354166666666667\n",
      "Epoch: 35, Loss: 0.5420136451721191, Validation Accuracy: 0.8380833333333333\n",
      "Epoch: 36, Loss: 0.5283473134040833, Validation Accuracy: 0.8415\n",
      "Epoch: 37, Loss: 0.5164220929145813, Validation Accuracy: 0.844\n",
      "Epoch: 38, Loss: 0.5058023929595947, Validation Accuracy: 0.8461666666666666\n",
      "Epoch: 39, Loss: 0.49626362323760986, Validation Accuracy: 0.8489166666666667\n",
      "Epoch: 40, Loss: 0.48763635754585266, Validation Accuracy: 0.8500833333333333\n",
      "Epoch: 41, Loss: 0.47973933815956116, Validation Accuracy: 0.85275\n",
      "Epoch: 42, Loss: 0.4725241959095001, Validation Accuracy: 0.8544166666666667\n",
      "Epoch: 43, Loss: 0.46593478322029114, Validation Accuracy: 0.8558333333333333\n",
      "Epoch: 44, Loss: 0.4599190652370453, Validation Accuracy: 0.8578333333333333\n",
      "Epoch: 45, Loss: 0.4545319676399231, Validation Accuracy: 0.8580833333333333\n",
      "Epoch: 46, Loss: 0.44994762539863586, Validation Accuracy: 0.8603333333333333\n",
      "Epoch: 47, Loss: 0.44620251655578613, Validation Accuracy: 0.8580833333333333\n",
      "Epoch: 48, Loss: 0.44391128420829773, Validation Accuracy: 0.8619166666666667\n",
      "Epoch: 49, Loss: 0.44303572177886963, Validation Accuracy: 0.8563333333333333\n",
      "Epoch: 50, Loss: 0.4457626938819885, Validation Accuracy: 0.8590833333333333\n",
      "Epoch: 51, Loss: 0.4514462947845459, Validation Accuracy: 0.8445\n",
      "Epoch: 52, Loss: 0.4645434021949768, Validation Accuracy: 0.8486666666666667\n",
      "Epoch: 53, Loss: 0.48225656151771545, Validation Accuracy: 0.8280833333333333\n",
      "Epoch: 54, Loss: 0.5081517100334167, Validation Accuracy: 0.8315\n",
      "Epoch: 55, Loss: 0.5265349745750427, Validation Accuracy: 0.8201666666666667\n",
      "Epoch: 56, Loss: 0.5299303531646729, Validation Accuracy: 0.8414166666666667\n",
      "Epoch: 57, Loss: 0.5057199001312256, Validation Accuracy: 0.8440833333333333\n",
      "Epoch: 58, Loss: 0.46663424372673035, Validation Accuracy: 0.8660833333333333\n",
      "Epoch: 59, Loss: 0.4329986572265625, Validation Accuracy: 0.8668333333333333\n",
      "Epoch: 60, Loss: 0.40984880924224854, Validation Accuracy: 0.8779166666666667\n",
      "Epoch: 61, Loss: 0.3965012729167938, Validation Accuracy: 0.87675\n",
      "Epoch: 62, Loss: 0.3880830407142639, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 63, Loss: 0.3825215697288513, Validation Accuracy: 0.88025\n",
      "Epoch: 64, Loss: 0.37809813022613525, Validation Accuracy: 0.88325\n",
      "Epoch: 65, Loss: 0.374338835477829, Validation Accuracy: 0.8824166666666666\n",
      "Epoch: 66, Loss: 0.370933473110199, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 67, Loss: 0.36777547001838684, Validation Accuracy: 0.8840833333333333\n",
      "Epoch: 68, Loss: 0.3647827208042145, Validation Accuracy: 0.8855833333333333\n",
      "Epoch: 69, Loss: 0.3619377017021179, Validation Accuracy: 0.8855833333333333\n",
      "Epoch: 70, Loss: 0.35919189453125, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 71, Loss: 0.3565387427806854, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 72, Loss: 0.35396671295166016, Validation Accuracy: 0.889\n",
      "Epoch: 73, Loss: 0.35146239399909973, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 74, Loss: 0.3490249514579773, Validation Accuracy: 0.8905\n",
      "Epoch: 75, Loss: 0.34664228558540344, Validation Accuracy: 0.8913333333333333\n",
      "Epoch: 76, Loss: 0.3443102538585663, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 77, Loss: 0.3420373797416687, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 78, Loss: 0.3398244380950928, Validation Accuracy: 0.8936666666666667\n",
      "Epoch: 79, Loss: 0.3376600742340088, Validation Accuracy: 0.8936666666666667\n",
      "Epoch: 80, Loss: 0.33554235100746155, Validation Accuracy: 0.8945\n",
      "Epoch: 81, Loss: 0.3334624767303467, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 82, Loss: 0.3314320147037506, Validation Accuracy: 0.895\n",
      "Epoch: 83, Loss: 0.3294394016265869, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 84, Loss: 0.32748350501060486, Validation Accuracy: 0.8961666666666667\n",
      "Epoch: 85, Loss: 0.32556241750717163, Validation Accuracy: 0.8966666666666666\n",
      "Epoch: 86, Loss: 0.32367023825645447, Validation Accuracy: 0.8975\n",
      "Epoch: 87, Loss: 0.32181450724601746, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 88, Loss: 0.3199974596500397, Validation Accuracy: 0.89825\n",
      "Epoch: 89, Loss: 0.31820952892303467, Validation Accuracy: 0.8985\n",
      "Epoch: 90, Loss: 0.31645190715789795, Validation Accuracy: 0.89925\n",
      "Epoch: 91, Loss: 0.31472262740135193, Validation Accuracy: 0.90025\n",
      "Epoch: 92, Loss: 0.31302109360694885, Validation Accuracy: 0.9003333333333333\n",
      "Epoch: 93, Loss: 0.3113442361354828, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 94, Loss: 0.3096916973590851, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 95, Loss: 0.30807244777679443, Validation Accuracy: 0.90225\n",
      "Epoch: 96, Loss: 0.3064773678779602, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 97, Loss: 0.30491018295288086, Validation Accuracy: 0.90325\n",
      "Epoch: 98, Loss: 0.30336815118789673, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 99, Loss: 0.3018491268157959, Validation Accuracy: 0.9040833333333333\n",
      "Dataset 24\n",
      "Epoch: 0, Loss: 3.0066916942596436, Validation Accuracy: 0.19066666666666668\n",
      "Epoch: 1, Loss: 2.3057711124420166, Validation Accuracy: 0.305\n",
      "Epoch: 2, Loss: 1.9096150398254395, Validation Accuracy: 0.37216666666666665\n",
      "Epoch: 3, Loss: 1.7047284841537476, Validation Accuracy: 0.4549166666666667\n",
      "Epoch: 4, Loss: 1.5786186456680298, Validation Accuracy: 0.4111666666666667\n",
      "Epoch: 5, Loss: 1.6041474342346191, Validation Accuracy: 0.45075\n",
      "Epoch: 6, Loss: 1.5695452690124512, Validation Accuracy: 0.37616666666666665\n",
      "Epoch: 7, Loss: 1.6826118230819702, Validation Accuracy: 0.5283333333333333\n",
      "Epoch: 8, Loss: 1.3372113704681396, Validation Accuracy: 0.5974166666666667\n",
      "Epoch: 9, Loss: 1.242734432220459, Validation Accuracy: 0.6770833333333334\n",
      "Epoch: 10, Loss: 1.023724913597107, Validation Accuracy: 0.678\n",
      "Epoch: 11, Loss: 0.9994553327560425, Validation Accuracy: 0.68925\n",
      "Epoch: 12, Loss: 0.9712494015693665, Validation Accuracy: 0.6609166666666667\n",
      "Epoch: 13, Loss: 1.0149492025375366, Validation Accuracy: 0.7123333333333334\n",
      "Epoch: 14, Loss: 0.9082530736923218, Validation Accuracy: 0.7193333333333334\n",
      "Epoch: 15, Loss: 0.8622353672981262, Validation Accuracy: 0.7636666666666667\n",
      "Epoch: 16, Loss: 0.7573176026344299, Validation Accuracy: 0.7774166666666666\n",
      "Epoch: 17, Loss: 0.7106147408485413, Validation Accuracy: 0.7948333333333333\n",
      "Epoch: 18, Loss: 0.6654794812202454, Validation Accuracy: 0.7986666666666666\n",
      "Epoch: 19, Loss: 0.6388229727745056, Validation Accuracy: 0.8068333333333333\n",
      "Epoch: 20, Loss: 0.616769552230835, Validation Accuracy: 0.8055833333333333\n",
      "Epoch: 21, Loss: 0.6057934761047363, Validation Accuracy: 0.8034166666666667\n",
      "Epoch: 22, Loss: 0.6105119585990906, Validation Accuracy: 0.7676666666666667\n",
      "Epoch: 23, Loss: 0.662648618221283, Validation Accuracy: 0.73575\n",
      "Epoch: 24, Loss: 0.7645491361618042, Validation Accuracy: 0.68825\n",
      "Epoch: 25, Loss: 0.894497811794281, Validation Accuracy: 0.7454166666666666\n",
      "Epoch: 26, Loss: 0.7190567255020142, Validation Accuracy: 0.7849166666666667\n",
      "Epoch: 27, Loss: 0.6270781755447388, Validation Accuracy: 0.8165\n",
      "Epoch: 28, Loss: 0.5643730759620667, Validation Accuracy: 0.8344166666666667\n",
      "Epoch: 29, Loss: 0.5296216607093811, Validation Accuracy: 0.8414166666666667\n",
      "Epoch: 30, Loss: 0.5108941197395325, Validation Accuracy: 0.84575\n",
      "Epoch: 31, Loss: 0.4967515766620636, Validation Accuracy: 0.84975\n",
      "Epoch: 32, Loss: 0.4859248399734497, Validation Accuracy: 0.852\n",
      "Epoch: 33, Loss: 0.47676709294319153, Validation Accuracy: 0.8546666666666667\n",
      "Epoch: 34, Loss: 0.46879658102989197, Validation Accuracy: 0.8568333333333333\n",
      "Epoch: 35, Loss: 0.4617806375026703, Validation Accuracy: 0.8579166666666667\n",
      "Epoch: 36, Loss: 0.4554486870765686, Validation Accuracy: 0.8605\n",
      "Epoch: 37, Loss: 0.4498503506183624, Validation Accuracy: 0.8608333333333333\n",
      "Epoch: 38, Loss: 0.444919228553772, Validation Accuracy: 0.86325\n",
      "Epoch: 39, Loss: 0.44069725275039673, Validation Accuracy: 0.863\n",
      "Epoch: 40, Loss: 0.43725889921188354, Validation Accuracy: 0.8651666666666666\n",
      "Epoch: 41, Loss: 0.43517249822616577, Validation Accuracy: 0.8625\n",
      "Epoch: 42, Loss: 0.4339887797832489, Validation Accuracy: 0.8626666666666667\n",
      "Epoch: 43, Loss: 0.4356420934200287, Validation Accuracy: 0.86\n",
      "Epoch: 44, Loss: 0.43798828125, Validation Accuracy: 0.8556666666666667\n",
      "Epoch: 45, Loss: 0.44529810547828674, Validation Accuracy: 0.8518333333333333\n",
      "Epoch: 46, Loss: 0.4514438807964325, Validation Accuracy: 0.84625\n",
      "Epoch: 47, Loss: 0.4635659456253052, Validation Accuracy: 0.8454166666666667\n",
      "Epoch: 48, Loss: 0.46586593985557556, Validation Accuracy: 0.8433333333333334\n",
      "Epoch: 49, Loss: 0.47171956300735474, Validation Accuracy: 0.8495833333333334\n",
      "Epoch: 50, Loss: 0.45726126432418823, Validation Accuracy: 0.8536666666666667\n",
      "Epoch: 51, Loss: 0.4463425278663635, Validation Accuracy: 0.8629166666666667\n",
      "Epoch: 52, Loss: 0.424958199262619, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 53, Loss: 0.41077157855033875, Validation Accuracy: 0.873\n",
      "Epoch: 54, Loss: 0.3969707787036896, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 55, Loss: 0.3884102404117584, Validation Accuracy: 0.88025\n",
      "Epoch: 56, Loss: 0.3810346722602844, Validation Accuracy: 0.882\n",
      "Epoch: 57, Loss: 0.3758866488933563, Validation Accuracy: 0.8825\n",
      "Epoch: 58, Loss: 0.3715144097805023, Validation Accuracy: 0.884\n",
      "Epoch: 59, Loss: 0.36786913871765137, Validation Accuracy: 0.8855\n",
      "Epoch: 60, Loss: 0.36453986167907715, Validation Accuracy: 0.88725\n",
      "Epoch: 61, Loss: 0.36152657866477966, Validation Accuracy: 0.8876666666666667\n",
      "Epoch: 62, Loss: 0.35866063833236694, Validation Accuracy: 0.8885\n",
      "Epoch: 63, Loss: 0.35599109530448914, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 64, Loss: 0.3534436821937561, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 65, Loss: 0.351000040769577, Validation Accuracy: 0.8904166666666666\n",
      "Epoch: 66, Loss: 0.3486558496952057, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 67, Loss: 0.3463914096355438, Validation Accuracy: 0.892\n",
      "Epoch: 68, Loss: 0.3441953659057617, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 69, Loss: 0.3420758843421936, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 70, Loss: 0.34000682830810547, Validation Accuracy: 0.8935833333333333\n",
      "Epoch: 71, Loss: 0.3380032777786255, Validation Accuracy: 0.89475\n",
      "Epoch: 72, Loss: 0.3360387086868286, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 73, Loss: 0.33411726355552673, Validation Accuracy: 0.896\n",
      "Epoch: 74, Loss: 0.3322382867336273, Validation Accuracy: 0.89625\n",
      "Epoch: 75, Loss: 0.33038944005966187, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 76, Loss: 0.32858145236968994, Validation Accuracy: 0.8975\n",
      "Epoch: 77, Loss: 0.3268033564090729, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 78, Loss: 0.3250599503517151, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 79, Loss: 0.32335448265075684, Validation Accuracy: 0.8988333333333334\n",
      "Epoch: 80, Loss: 0.3216823935508728, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 81, Loss: 0.320050984621048, Validation Accuracy: 0.8996666666666666\n",
      "Epoch: 82, Loss: 0.318438321352005, Validation Accuracy: 0.89975\n",
      "Epoch: 83, Loss: 0.31686702370643616, Validation Accuracy: 0.9005\n",
      "Epoch: 84, Loss: 0.31530269980430603, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 85, Loss: 0.3137935996055603, Validation Accuracy: 0.90125\n",
      "Epoch: 86, Loss: 0.31228190660476685, Validation Accuracy: 0.9015\n",
      "Epoch: 87, Loss: 0.3108330965042114, Validation Accuracy: 0.902\n",
      "Epoch: 88, Loss: 0.3093733787536621, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 89, Loss: 0.3079845905303955, Validation Accuracy: 0.90225\n",
      "Epoch: 90, Loss: 0.3065709173679352, Validation Accuracy: 0.9028333333333334\n",
      "Epoch: 91, Loss: 0.3052188754081726, Validation Accuracy: 0.90275\n",
      "Epoch: 92, Loss: 0.3038523495197296, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 93, Loss: 0.30252423882484436, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 94, Loss: 0.3012162148952484, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 95, Loss: 0.2999396026134491, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 96, Loss: 0.29867616295814514, Validation Accuracy: 0.90525\n",
      "Epoch: 97, Loss: 0.2974582314491272, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 98, Loss: 0.2962324917316437, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 99, Loss: 0.2950725257396698, Validation Accuracy: 0.9054166666666666\n",
      "Dataset 25\n",
      "Epoch: 0, Loss: 3.7510130405426025, Validation Accuracy: 0.18325\n",
      "Epoch: 1, Loss: 3.0429649353027344, Validation Accuracy: 0.19225\n",
      "Epoch: 2, Loss: 2.3819336891174316, Validation Accuracy: 0.2715\n",
      "Epoch: 3, Loss: 2.2173497676849365, Validation Accuracy: 0.32858333333333334\n",
      "Epoch: 4, Loss: 1.8656753301620483, Validation Accuracy: 0.4013333333333333\n",
      "Epoch: 5, Loss: 1.6967213153839111, Validation Accuracy: 0.5075833333333334\n",
      "Epoch: 6, Loss: 1.4637768268585205, Validation Accuracy: 0.5720833333333334\n",
      "Epoch: 7, Loss: 1.312770962715149, Validation Accuracy: 0.60625\n",
      "Epoch: 8, Loss: 1.2086312770843506, Validation Accuracy: 0.6310833333333333\n",
      "Epoch: 9, Loss: 1.1288461685180664, Validation Accuracy: 0.64875\n",
      "Epoch: 10, Loss: 1.0701067447662354, Validation Accuracy: 0.6349166666666667\n",
      "Epoch: 11, Loss: 1.0755313634872437, Validation Accuracy: 0.629\n",
      "Epoch: 12, Loss: 1.0932228565216064, Validation Accuracy: 0.5603333333333333\n",
      "Epoch: 13, Loss: 1.258956789970398, Validation Accuracy: 0.6676666666666666\n",
      "Epoch: 14, Loss: 0.9932727813720703, Validation Accuracy: 0.6838333333333333\n",
      "Epoch: 15, Loss: 0.9194099307060242, Validation Accuracy: 0.731\n",
      "Epoch: 16, Loss: 0.8290601372718811, Validation Accuracy: 0.7249166666666667\n",
      "Epoch: 17, Loss: 0.8025568723678589, Validation Accuracy: 0.73875\n",
      "Epoch: 18, Loss: 0.780251681804657, Validation Accuracy: 0.7321666666666666\n",
      "Epoch: 19, Loss: 0.775791585445404, Validation Accuracy: 0.7386666666666667\n",
      "Epoch: 20, Loss: 0.7759358882904053, Validation Accuracy: 0.7345833333333334\n",
      "Epoch: 21, Loss: 0.7668610215187073, Validation Accuracy: 0.7429166666666667\n",
      "Epoch: 22, Loss: 0.7526493072509766, Validation Accuracy: 0.7384166666666667\n",
      "Epoch: 23, Loss: 0.7572140097618103, Validation Accuracy: 0.7505\n",
      "Epoch: 24, Loss: 0.7309365272521973, Validation Accuracy: 0.7576666666666667\n",
      "Epoch: 25, Loss: 0.7169545888900757, Validation Accuracy: 0.7798333333333334\n",
      "Epoch: 26, Loss: 0.6612890958786011, Validation Accuracy: 0.7989166666666667\n",
      "Epoch: 27, Loss: 0.6172921061515808, Validation Accuracy: 0.815\n",
      "Epoch: 28, Loss: 0.5786637663841248, Validation Accuracy: 0.8235\n",
      "Epoch: 29, Loss: 0.5542197227478027, Validation Accuracy: 0.8281666666666667\n",
      "Epoch: 30, Loss: 0.5366722345352173, Validation Accuracy: 0.83425\n",
      "Epoch: 31, Loss: 0.523289144039154, Validation Accuracy: 0.8360833333333333\n",
      "Epoch: 32, Loss: 0.5124477744102478, Validation Accuracy: 0.8400833333333333\n",
      "Epoch: 33, Loss: 0.5032715797424316, Validation Accuracy: 0.8418333333333333\n",
      "Epoch: 34, Loss: 0.49506157636642456, Validation Accuracy: 0.844\n",
      "Epoch: 35, Loss: 0.48802176117897034, Validation Accuracy: 0.8450833333333333\n",
      "Epoch: 36, Loss: 0.4813426434993744, Validation Accuracy: 0.8471666666666666\n",
      "Epoch: 37, Loss: 0.47574713826179504, Validation Accuracy: 0.8481666666666666\n",
      "Epoch: 38, Loss: 0.47027596831321716, Validation Accuracy: 0.8503333333333334\n",
      "Epoch: 39, Loss: 0.46594005823135376, Validation Accuracy: 0.8516666666666667\n",
      "Epoch: 40, Loss: 0.46143627166748047, Validation Accuracy: 0.85225\n",
      "Epoch: 41, Loss: 0.45844337344169617, Validation Accuracy: 0.8535\n",
      "Epoch: 42, Loss: 0.45461341738700867, Validation Accuracy: 0.8543333333333333\n",
      "Epoch: 43, Loss: 0.45279479026794434, Validation Accuracy: 0.8558333333333333\n",
      "Epoch: 44, Loss: 0.449230432510376, Validation Accuracy: 0.8551666666666666\n",
      "Epoch: 45, Loss: 0.4481518268585205, Validation Accuracy: 0.8580833333333333\n",
      "Epoch: 46, Loss: 0.44423291087150574, Validation Accuracy: 0.85725\n",
      "Epoch: 47, Loss: 0.44302257895469666, Validation Accuracy: 0.8601666666666666\n",
      "Epoch: 48, Loss: 0.438211590051651, Validation Accuracy: 0.8596666666666667\n",
      "Epoch: 49, Loss: 0.4359595477581024, Validation Accuracy: 0.8629166666666667\n",
      "Epoch: 50, Loss: 0.43038925528526306, Validation Accuracy: 0.8623333333333333\n",
      "Epoch: 51, Loss: 0.4267508089542389, Validation Accuracy: 0.8653333333333333\n",
      "Epoch: 52, Loss: 0.4207365810871124, Validation Accuracy: 0.86675\n",
      "Epoch: 53, Loss: 0.4161490797996521, Validation Accuracy: 0.8683333333333333\n",
      "Epoch: 54, Loss: 0.4104735553264618, Validation Accuracy: 0.8703333333333333\n",
      "Epoch: 55, Loss: 0.4055598974227905, Validation Accuracy: 0.8716666666666667\n",
      "Epoch: 56, Loss: 0.40055912733078003, Validation Accuracy: 0.8745833333333334\n",
      "Epoch: 57, Loss: 0.39595967531204224, Validation Accuracy: 0.87475\n",
      "Epoch: 58, Loss: 0.39160603284835815, Validation Accuracy: 0.878\n",
      "Epoch: 59, Loss: 0.3875200152397156, Validation Accuracy: 0.8775833333333334\n",
      "Epoch: 60, Loss: 0.38378795981407166, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 61, Loss: 0.3801274001598358, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 62, Loss: 0.37678542733192444, Validation Accuracy: 0.883\n",
      "Epoch: 63, Loss: 0.37350037693977356, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 64, Loss: 0.37044021487236023, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 65, Loss: 0.36752772331237793, Validation Accuracy: 0.8846666666666667\n",
      "Epoch: 66, Loss: 0.3647383749485016, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 67, Loss: 0.36204230785369873, Validation Accuracy: 0.8865\n",
      "Epoch: 68, Loss: 0.3594835698604584, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 69, Loss: 0.3569907546043396, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 70, Loss: 0.35455530881881714, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 71, Loss: 0.35219699144363403, Validation Accuracy: 0.88975\n",
      "Epoch: 72, Loss: 0.3498711884021759, Validation Accuracy: 0.89175\n",
      "Epoch: 73, Loss: 0.34764569997787476, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 74, Loss: 0.3454517424106598, Validation Accuracy: 0.89225\n",
      "Epoch: 75, Loss: 0.3433048129081726, Validation Accuracy: 0.893\n",
      "Epoch: 76, Loss: 0.3412133753299713, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 77, Loss: 0.3391737937927246, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 78, Loss: 0.3371616303920746, Validation Accuracy: 0.8943333333333333\n",
      "Epoch: 79, Loss: 0.33520787954330444, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 80, Loss: 0.33328473567962646, Validation Accuracy: 0.896\n",
      "Epoch: 81, Loss: 0.33139413595199585, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 82, Loss: 0.32953616976737976, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 83, Loss: 0.3277110457420349, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 84, Loss: 0.32592326402664185, Validation Accuracy: 0.898\n",
      "Epoch: 85, Loss: 0.32416588068008423, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 86, Loss: 0.32243722677230835, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 87, Loss: 0.3207341432571411, Validation Accuracy: 0.90025\n",
      "Epoch: 88, Loss: 0.31905418634414673, Validation Accuracy: 0.90025\n",
      "Epoch: 89, Loss: 0.31741005182266235, Validation Accuracy: 0.90075\n",
      "Epoch: 90, Loss: 0.3157828748226166, Validation Accuracy: 0.90125\n",
      "Epoch: 91, Loss: 0.31418925523757935, Validation Accuracy: 0.9016666666666666\n",
      "Epoch: 92, Loss: 0.312615305185318, Validation Accuracy: 0.9023333333333333\n",
      "Epoch: 93, Loss: 0.31107527017593384, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 94, Loss: 0.3095473349094391, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 95, Loss: 0.3080475330352783, Validation Accuracy: 0.9033333333333333\n",
      "Epoch: 96, Loss: 0.30656954646110535, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 97, Loss: 0.30511438846588135, Validation Accuracy: 0.904\n",
      "Epoch: 98, Loss: 0.30368122458457947, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 99, Loss: 0.3022696375846863, Validation Accuracy: 0.9045\n",
      "Dataset 26\n",
      "Epoch: 0, Loss: 4.235371112823486, Validation Accuracy: 0.12966666666666668\n",
      "Epoch: 1, Loss: 3.4154343605041504, Validation Accuracy: 0.19191666666666668\n",
      "Epoch: 2, Loss: 2.866581916809082, Validation Accuracy: 0.24558333333333332\n",
      "Epoch: 3, Loss: 2.2098422050476074, Validation Accuracy: 0.3085\n",
      "Epoch: 4, Loss: 1.9495697021484375, Validation Accuracy: 0.32116666666666666\n",
      "Epoch: 5, Loss: 1.821422815322876, Validation Accuracy: 0.389\n",
      "Epoch: 6, Loss: 1.682565450668335, Validation Accuracy: 0.38433333333333336\n",
      "Epoch: 7, Loss: 1.6365984678268433, Validation Accuracy: 0.45775\n",
      "Epoch: 8, Loss: 1.5448020696640015, Validation Accuracy: 0.4545\n",
      "Epoch: 9, Loss: 1.4995286464691162, Validation Accuracy: 0.5148333333333334\n",
      "Epoch: 10, Loss: 1.4045957326889038, Validation Accuracy: 0.5223333333333333\n",
      "Epoch: 11, Loss: 1.3564915657043457, Validation Accuracy: 0.553\n",
      "Epoch: 12, Loss: 1.2762929201126099, Validation Accuracy: 0.5666666666666667\n",
      "Epoch: 13, Loss: 1.2325998544692993, Validation Accuracy: 0.5835833333333333\n",
      "Epoch: 14, Loss: 1.1673822402954102, Validation Accuracy: 0.6033333333333334\n",
      "Epoch: 15, Loss: 1.1260040998458862, Validation Accuracy: 0.6113333333333333\n",
      "Epoch: 16, Loss: 1.0720820426940918, Validation Accuracy: 0.635\n",
      "Epoch: 17, Loss: 1.0341969728469849, Validation Accuracy: 0.6388333333333334\n",
      "Epoch: 18, Loss: 0.9881832003593445, Validation Accuracy: 0.65925\n",
      "Epoch: 19, Loss: 0.9533353447914124, Validation Accuracy: 0.6668333333333333\n",
      "Epoch: 20, Loss: 0.9123063683509827, Validation Accuracy: 0.6878333333333333\n",
      "Epoch: 21, Loss: 0.8813342452049255, Validation Accuracy: 0.6978333333333333\n",
      "Epoch: 22, Loss: 0.8455563187599182, Validation Accuracy: 0.7148333333333333\n",
      "Epoch: 23, Loss: 0.8215070962905884, Validation Accuracy: 0.72575\n",
      "Epoch: 24, Loss: 0.7938200831413269, Validation Accuracy: 0.7425833333333334\n",
      "Epoch: 25, Loss: 0.7806444764137268, Validation Accuracy: 0.7400833333333333\n",
      "Epoch: 26, Loss: 0.766761064529419, Validation Accuracy: 0.7568333333333334\n",
      "Epoch: 27, Loss: 0.764514148235321, Validation Accuracy: 0.7406666666666667\n",
      "Epoch: 28, Loss: 0.776344895362854, Validation Accuracy: 0.7606666666666667\n",
      "Epoch: 29, Loss: 0.7594330310821533, Validation Accuracy: 0.7340833333333333\n",
      "Epoch: 30, Loss: 0.7909271717071533, Validation Accuracy: 0.7836666666666666\n",
      "Epoch: 31, Loss: 0.6970423460006714, Validation Accuracy: 0.7745833333333333\n",
      "Epoch: 32, Loss: 0.6864665746688843, Validation Accuracy: 0.8088333333333333\n",
      "Epoch: 33, Loss: 0.622218668460846, Validation Accuracy: 0.8075833333333333\n",
      "Epoch: 34, Loss: 0.606602132320404, Validation Accuracy: 0.8198333333333333\n",
      "Epoch: 35, Loss: 0.5842655301094055, Validation Accuracy: 0.8191666666666667\n",
      "Epoch: 36, Loss: 0.5763568878173828, Validation Accuracy: 0.8201666666666667\n",
      "Epoch: 37, Loss: 0.5681508779525757, Validation Accuracy: 0.8205833333333333\n",
      "Epoch: 38, Loss: 0.5647394061088562, Validation Accuracy: 0.8173333333333334\n",
      "Epoch: 39, Loss: 0.5636886954307556, Validation Accuracy: 0.8176666666666667\n",
      "Epoch: 40, Loss: 0.5625482797622681, Validation Accuracy: 0.81475\n",
      "Epoch: 41, Loss: 0.5633187890052795, Validation Accuracy: 0.8169166666666666\n",
      "Epoch: 42, Loss: 0.5592857003211975, Validation Accuracy: 0.8170833333333334\n",
      "Epoch: 43, Loss: 0.5541929006576538, Validation Accuracy: 0.8226666666666667\n",
      "Epoch: 44, Loss: 0.5425233840942383, Validation Accuracy: 0.8276666666666667\n",
      "Epoch: 45, Loss: 0.5290830731391907, Validation Accuracy: 0.8376666666666667\n",
      "Epoch: 46, Loss: 0.5117437243461609, Validation Accuracy: 0.8413333333333334\n",
      "Epoch: 47, Loss: 0.49575865268707275, Validation Accuracy: 0.8515\n",
      "Epoch: 48, Loss: 0.480549156665802, Validation Accuracy: 0.8521666666666666\n",
      "Epoch: 49, Loss: 0.46771129965782166, Validation Accuracy: 0.86125\n",
      "Epoch: 50, Loss: 0.4568465054035187, Validation Accuracy: 0.8596666666666667\n",
      "Epoch: 51, Loss: 0.4478425979614258, Validation Accuracy: 0.8664166666666666\n",
      "Epoch: 52, Loss: 0.4402226209640503, Validation Accuracy: 0.8640833333333333\n",
      "Epoch: 53, Loss: 0.4335803985595703, Validation Accuracy: 0.8698333333333333\n",
      "Epoch: 54, Loss: 0.4277515411376953, Validation Accuracy: 0.8680833333333333\n",
      "Epoch: 55, Loss: 0.4223995804786682, Validation Accuracy: 0.8729166666666667\n",
      "Epoch: 56, Loss: 0.4175156354904175, Validation Accuracy: 0.8703333333333333\n",
      "Epoch: 57, Loss: 0.4129393994808197, Validation Accuracy: 0.8750833333333333\n",
      "Epoch: 58, Loss: 0.40867680311203003, Validation Accuracy: 0.8733333333333333\n",
      "Epoch: 59, Loss: 0.40464404225349426, Validation Accuracy: 0.8770833333333333\n",
      "Epoch: 60, Loss: 0.4008028507232666, Validation Accuracy: 0.8755\n",
      "Epoch: 61, Loss: 0.3971327841281891, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 62, Loss: 0.3936191499233246, Validation Accuracy: 0.877\n",
      "Epoch: 63, Loss: 0.39025357365608215, Validation Accuracy: 0.8800833333333333\n",
      "Epoch: 64, Loss: 0.3869975209236145, Validation Accuracy: 0.87925\n",
      "Epoch: 65, Loss: 0.3838617205619812, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 66, Loss: 0.3808245062828064, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 67, Loss: 0.3778945207595825, Validation Accuracy: 0.8823333333333333\n",
      "Epoch: 68, Loss: 0.37506088614463806, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 69, Loss: 0.37230607867240906, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 70, Loss: 0.36963117122650146, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 71, Loss: 0.36703237891197205, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 72, Loss: 0.3645016551017761, Validation Accuracy: 0.88525\n",
      "Epoch: 73, Loss: 0.36203500628471375, Validation Accuracy: 0.8856666666666667\n",
      "Epoch: 74, Loss: 0.3596247434616089, Validation Accuracy: 0.8864166666666666\n",
      "Epoch: 75, Loss: 0.35727542638778687, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 76, Loss: 0.3549812436103821, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 77, Loss: 0.3527325391769409, Validation Accuracy: 0.8889166666666667\n",
      "Epoch: 78, Loss: 0.3505282402038574, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 79, Loss: 0.348371297121048, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 80, Loss: 0.34626248478889465, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 81, Loss: 0.344199001789093, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 82, Loss: 0.3421761989593506, Validation Accuracy: 0.8923333333333333\n",
      "Epoch: 83, Loss: 0.3401931822299957, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 84, Loss: 0.33825284242630005, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 85, Loss: 0.33635103702545166, Validation Accuracy: 0.8939166666666667\n",
      "Epoch: 86, Loss: 0.33448338508605957, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 87, Loss: 0.3326514959335327, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 88, Loss: 0.3308568596839905, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 89, Loss: 0.3290984630584717, Validation Accuracy: 0.8955\n",
      "Epoch: 90, Loss: 0.3273713290691376, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 91, Loss: 0.3256746232509613, Validation Accuracy: 0.89675\n",
      "Epoch: 92, Loss: 0.3240050673484802, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 93, Loss: 0.3223653733730316, Validation Accuracy: 0.89725\n",
      "Epoch: 94, Loss: 0.32075318694114685, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 95, Loss: 0.31916818022727966, Validation Accuracy: 0.89825\n",
      "Epoch: 96, Loss: 0.3176107108592987, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 97, Loss: 0.3160768747329712, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 98, Loss: 0.3145676553249359, Validation Accuracy: 0.89925\n",
      "Epoch: 99, Loss: 0.3130837678909302, Validation Accuracy: 0.8994166666666666\n",
      "Dataset 27\n",
      "Epoch: 0, Loss: 3.1458051204681396, Validation Accuracy: 0.17158333333333334\n",
      "Epoch: 1, Loss: 3.8361828327178955, Validation Accuracy: 0.17258333333333334\n",
      "Epoch: 2, Loss: 2.7228214740753174, Validation Accuracy: 0.23875\n",
      "Epoch: 3, Loss: 2.160264015197754, Validation Accuracy: 0.34608333333333335\n",
      "Epoch: 4, Loss: 1.826411485671997, Validation Accuracy: 0.41883333333333334\n",
      "Epoch: 5, Loss: 1.6762629747390747, Validation Accuracy: 0.4925833333333333\n",
      "Epoch: 6, Loss: 1.4527912139892578, Validation Accuracy: 0.5560833333333334\n",
      "Epoch: 7, Loss: 1.3029723167419434, Validation Accuracy: 0.5964166666666667\n",
      "Epoch: 8, Loss: 1.1830867528915405, Validation Accuracy: 0.6216666666666667\n",
      "Epoch: 9, Loss: 1.1027607917785645, Validation Accuracy: 0.6419166666666667\n",
      "Epoch: 10, Loss: 1.0423423051834106, Validation Accuracy: 0.6444166666666666\n",
      "Epoch: 11, Loss: 1.0361413955688477, Validation Accuracy: 0.6719166666666667\n",
      "Epoch: 12, Loss: 0.9565891027450562, Validation Accuracy: 0.6775833333333333\n",
      "Epoch: 13, Loss: 0.9342001676559448, Validation Accuracy: 0.71225\n",
      "Epoch: 14, Loss: 0.8399794697761536, Validation Accuracy: 0.7235\n",
      "Epoch: 15, Loss: 0.8025338649749756, Validation Accuracy: 0.7369166666666667\n",
      "Epoch: 16, Loss: 0.7660576105117798, Validation Accuracy: 0.7401666666666666\n",
      "Epoch: 17, Loss: 0.7461861371994019, Validation Accuracy: 0.7470833333333333\n",
      "Epoch: 18, Loss: 0.7300896048545837, Validation Accuracy: 0.7486666666666667\n",
      "Epoch: 19, Loss: 0.7177348732948303, Validation Accuracy: 0.7588333333333334\n",
      "Epoch: 20, Loss: 0.694989025592804, Validation Accuracy: 0.76775\n",
      "Epoch: 21, Loss: 0.6722491979598999, Validation Accuracy: 0.781\n",
      "Epoch: 22, Loss: 0.6382745504379272, Validation Accuracy: 0.7975833333333333\n",
      "Epoch: 23, Loss: 0.6119257211685181, Validation Accuracy: 0.8029166666666666\n",
      "Epoch: 24, Loss: 0.5863854289054871, Validation Accuracy: 0.8144166666666667\n",
      "Epoch: 25, Loss: 0.5671342015266418, Validation Accuracy: 0.8174166666666667\n",
      "Epoch: 26, Loss: 0.5515658855438232, Validation Accuracy: 0.8235\n",
      "Epoch: 27, Loss: 0.5381358861923218, Validation Accuracy: 0.8254166666666667\n",
      "Epoch: 28, Loss: 0.5280853509902954, Validation Accuracy: 0.8308333333333333\n",
      "Epoch: 29, Loss: 0.5175420641899109, Validation Accuracy: 0.8315\n",
      "Epoch: 30, Loss: 0.5108490586280823, Validation Accuracy: 0.8339166666666666\n",
      "Epoch: 31, Loss: 0.5023514628410339, Validation Accuracy: 0.8371666666666666\n",
      "Epoch: 32, Loss: 0.4975256323814392, Validation Accuracy: 0.838\n",
      "Epoch: 33, Loss: 0.4907454550266266, Validation Accuracy: 0.8399166666666666\n",
      "Epoch: 34, Loss: 0.48698246479034424, Validation Accuracy: 0.8408333333333333\n",
      "Epoch: 35, Loss: 0.48126065731048584, Validation Accuracy: 0.8449166666666666\n",
      "Epoch: 36, Loss: 0.4774872660636902, Validation Accuracy: 0.8431666666666666\n",
      "Epoch: 37, Loss: 0.471759557723999, Validation Accuracy: 0.8496666666666667\n",
      "Epoch: 38, Loss: 0.4669012129306793, Validation Accuracy: 0.8474166666666667\n",
      "Epoch: 39, Loss: 0.46061471104621887, Validation Accuracy: 0.855\n",
      "Epoch: 40, Loss: 0.4543897807598114, Validation Accuracy: 0.8525\n",
      "Epoch: 41, Loss: 0.44752588868141174, Validation Accuracy: 0.8606666666666667\n",
      "Epoch: 42, Loss: 0.4405728876590729, Validation Accuracy: 0.8576666666666667\n",
      "Epoch: 43, Loss: 0.4334886074066162, Validation Accuracy: 0.8651666666666666\n",
      "Epoch: 44, Loss: 0.4267059862613678, Validation Accuracy: 0.8628333333333333\n",
      "Epoch: 45, Loss: 0.42032313346862793, Validation Accuracy: 0.8701666666666666\n",
      "Epoch: 46, Loss: 0.41413992643356323, Validation Accuracy: 0.8681666666666666\n",
      "Epoch: 47, Loss: 0.40855884552001953, Validation Accuracy: 0.8738333333333334\n",
      "Epoch: 48, Loss: 0.40307605266571045, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 49, Loss: 0.39819392561912537, Validation Accuracy: 0.8775\n",
      "Epoch: 50, Loss: 0.3935427665710449, Validation Accuracy: 0.8761666666666666\n",
      "Epoch: 51, Loss: 0.3893381357192993, Validation Accuracy: 0.8804166666666666\n",
      "Epoch: 52, Loss: 0.3853229880332947, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 53, Loss: 0.3816910684108734, Validation Accuracy: 0.882\n",
      "Epoch: 54, Loss: 0.37819185853004456, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 55, Loss: 0.37487515807151794, Validation Accuracy: 0.884\n",
      "Epoch: 56, Loss: 0.3717028498649597, Validation Accuracy: 0.8840833333333333\n",
      "Epoch: 57, Loss: 0.3686375021934509, Validation Accuracy: 0.886\n",
      "Epoch: 58, Loss: 0.3657006323337555, Validation Accuracy: 0.8854166666666666\n",
      "Epoch: 59, Loss: 0.3629757761955261, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 60, Loss: 0.360262006521225, Validation Accuracy: 0.8875\n",
      "Epoch: 61, Loss: 0.35780471563339233, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 62, Loss: 0.355214923620224, Validation Accuracy: 0.88875\n",
      "Epoch: 63, Loss: 0.3528282344341278, Validation Accuracy: 0.8900833333333333\n",
      "Epoch: 64, Loss: 0.3502885401248932, Validation Accuracy: 0.89\n",
      "Epoch: 65, Loss: 0.34794437885284424, Validation Accuracy: 0.8915\n",
      "Epoch: 66, Loss: 0.345539391040802, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 67, Loss: 0.34322965145111084, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 68, Loss: 0.3409695327281952, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 69, Loss: 0.3387872576713562, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 70, Loss: 0.33661749958992004, Validation Accuracy: 0.89325\n",
      "Epoch: 71, Loss: 0.3345259726047516, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 72, Loss: 0.332449734210968, Validation Accuracy: 0.89425\n",
      "Epoch: 73, Loss: 0.33049315214157104, Validation Accuracy: 0.897\n",
      "Epoch: 74, Loss: 0.3285022974014282, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 75, Loss: 0.3266294002532959, Validation Accuracy: 0.8985\n",
      "Epoch: 76, Loss: 0.32466191053390503, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 77, Loss: 0.3228361904621124, Validation Accuracy: 0.8996666666666666\n",
      "Epoch: 78, Loss: 0.3209519386291504, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 79, Loss: 0.319182813167572, Validation Accuracy: 0.9005\n",
      "Epoch: 80, Loss: 0.3173657953739166, Validation Accuracy: 0.8999166666666667\n",
      "Epoch: 81, Loss: 0.31566542387008667, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 82, Loss: 0.3138941824436188, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 83, Loss: 0.3122729957103729, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 84, Loss: 0.31059762835502625, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 85, Loss: 0.3090323805809021, Validation Accuracy: 0.903\n",
      "Epoch: 86, Loss: 0.3074088394641876, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 87, Loss: 0.3059018850326538, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 88, Loss: 0.3043503165245056, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 89, Loss: 0.30287468433380127, Validation Accuracy: 0.905\n",
      "Epoch: 90, Loss: 0.3013870120048523, Validation Accuracy: 0.9044166666666666\n",
      "Epoch: 91, Loss: 0.2999473214149475, Validation Accuracy: 0.9059166666666667\n",
      "Epoch: 92, Loss: 0.2984957695007324, Validation Accuracy: 0.905\n",
      "Epoch: 93, Loss: 0.2971155047416687, Validation Accuracy: 0.90725\n",
      "Epoch: 94, Loss: 0.2957315146923065, Validation Accuracy: 0.9061666666666667\n",
      "Epoch: 95, Loss: 0.2943730056285858, Validation Accuracy: 0.908\n",
      "Epoch: 96, Loss: 0.29303231835365295, Validation Accuracy: 0.9064166666666666\n",
      "Epoch: 97, Loss: 0.29172635078430176, Validation Accuracy: 0.90825\n",
      "Epoch: 98, Loss: 0.29042860865592957, Validation Accuracy: 0.9071666666666667\n",
      "Epoch: 99, Loss: 0.2891799211502075, Validation Accuracy: 0.9091666666666667\n",
      "Dataset 28\n",
      "Epoch: 0, Loss: 4.062385082244873, Validation Accuracy: 0.132\n",
      "Epoch: 1, Loss: 3.4989137649536133, Validation Accuracy: 0.23983333333333334\n",
      "Epoch: 2, Loss: 2.6561379432678223, Validation Accuracy: 0.2515833333333333\n",
      "Epoch: 3, Loss: 2.026671886444092, Validation Accuracy: 0.384\n",
      "Epoch: 4, Loss: 1.7715247869491577, Validation Accuracy: 0.46158333333333335\n",
      "Epoch: 5, Loss: 1.5997934341430664, Validation Accuracy: 0.5008333333333334\n",
      "Epoch: 6, Loss: 1.4660530090332031, Validation Accuracy: 0.546\n",
      "Epoch: 7, Loss: 1.383249044418335, Validation Accuracy: 0.55725\n",
      "Epoch: 8, Loss: 1.2890000343322754, Validation Accuracy: 0.5766666666666667\n",
      "Epoch: 9, Loss: 1.2703163623809814, Validation Accuracy: 0.5978333333333333\n",
      "Epoch: 10, Loss: 1.165008783340454, Validation Accuracy: 0.6060833333333333\n",
      "Epoch: 11, Loss: 1.159376859664917, Validation Accuracy: 0.6425\n",
      "Epoch: 12, Loss: 1.0507386922836304, Validation Accuracy: 0.6625833333333333\n",
      "Epoch: 13, Loss: 1.0005182027816772, Validation Accuracy: 0.6928333333333333\n",
      "Epoch: 14, Loss: 0.9238690733909607, Validation Accuracy: 0.7156666666666667\n",
      "Epoch: 15, Loss: 0.866093099117279, Validation Accuracy: 0.7320833333333333\n",
      "Epoch: 16, Loss: 0.8129038214683533, Validation Accuracy: 0.74375\n",
      "Epoch: 17, Loss: 0.7740128636360168, Validation Accuracy: 0.7505\n",
      "Epoch: 18, Loss: 0.7569676637649536, Validation Accuracy: 0.7216666666666667\n",
      "Epoch: 19, Loss: 0.7868849039077759, Validation Accuracy: 0.67625\n",
      "Epoch: 20, Loss: 0.9469515681266785, Validation Accuracy: 0.5688333333333333\n",
      "Epoch: 21, Loss: 1.209681510925293, Validation Accuracy: 0.6414166666666666\n",
      "Epoch: 22, Loss: 1.0035706758499146, Validation Accuracy: 0.7381666666666666\n",
      "Epoch: 23, Loss: 0.7716991305351257, Validation Accuracy: 0.802\n",
      "Epoch: 24, Loss: 0.6327338218688965, Validation Accuracy: 0.8213333333333334\n",
      "Epoch: 25, Loss: 0.5848382711410522, Validation Accuracy: 0.82775\n",
      "Epoch: 26, Loss: 0.560512363910675, Validation Accuracy: 0.8334166666666667\n",
      "Epoch: 27, Loss: 0.5426520705223083, Validation Accuracy: 0.8365\n",
      "Epoch: 28, Loss: 0.5278753042221069, Validation Accuracy: 0.8405833333333333\n",
      "Epoch: 29, Loss: 0.5150524377822876, Validation Accuracy: 0.8441666666666666\n",
      "Epoch: 30, Loss: 0.5035902261734009, Validation Accuracy: 0.8471666666666666\n",
      "Epoch: 31, Loss: 0.49321097135543823, Validation Accuracy: 0.8500833333333333\n",
      "Epoch: 32, Loss: 0.4837007224559784, Validation Accuracy: 0.8539166666666667\n",
      "Epoch: 33, Loss: 0.47492143511772156, Validation Accuracy: 0.8553333333333333\n",
      "Epoch: 34, Loss: 0.4667540192604065, Validation Accuracy: 0.8593333333333333\n",
      "Epoch: 35, Loss: 0.4591232240200043, Validation Accuracy: 0.86125\n",
      "Epoch: 36, Loss: 0.45195165276527405, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 37, Loss: 0.44520121812820435, Validation Accuracy: 0.8650833333333333\n",
      "Epoch: 38, Loss: 0.43883511424064636, Validation Accuracy: 0.8673333333333333\n",
      "Epoch: 39, Loss: 0.43282467126846313, Validation Accuracy: 0.8688333333333333\n",
      "Epoch: 40, Loss: 0.4271257221698761, Validation Accuracy: 0.871\n",
      "Epoch: 41, Loss: 0.4217112362384796, Validation Accuracy: 0.872\n",
      "Epoch: 42, Loss: 0.41654670238494873, Validation Accuracy: 0.8736666666666667\n",
      "Epoch: 43, Loss: 0.41163337230682373, Validation Accuracy: 0.875\n",
      "Epoch: 44, Loss: 0.40697526931762695, Validation Accuracy: 0.87625\n",
      "Epoch: 45, Loss: 0.4025767147541046, Validation Accuracy: 0.87675\n",
      "Epoch: 46, Loss: 0.3984205722808838, Validation Accuracy: 0.8795\n",
      "Epoch: 47, Loss: 0.39453941583633423, Validation Accuracy: 0.8783333333333333\n",
      "Epoch: 48, Loss: 0.39088374376296997, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 49, Loss: 0.387568861246109, Validation Accuracy: 0.8814166666666666\n",
      "Epoch: 50, Loss: 0.3845798373222351, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 51, Loss: 0.38190552592277527, Validation Accuracy: 0.8835\n",
      "Epoch: 52, Loss: 0.37981411814689636, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 53, Loss: 0.37815937399864197, Validation Accuracy: 0.88325\n",
      "Epoch: 54, Loss: 0.37734460830688477, Validation Accuracy: 0.8805833333333334\n",
      "Epoch: 55, Loss: 0.3770698606967926, Validation Accuracy: 0.8840833333333333\n",
      "Epoch: 56, Loss: 0.37829020619392395, Validation Accuracy: 0.8773333333333333\n",
      "Epoch: 57, Loss: 0.37983617186546326, Validation Accuracy: 0.88125\n",
      "Epoch: 58, Loss: 0.38371163606643677, Validation Accuracy: 0.87275\n",
      "Epoch: 59, Loss: 0.38739073276519775, Validation Accuracy: 0.8788333333333334\n",
      "Epoch: 60, Loss: 0.39450910687446594, Validation Accuracy: 0.8683333333333333\n",
      "Epoch: 61, Loss: 0.3980778753757477, Validation Accuracy: 0.8733333333333333\n",
      "Epoch: 62, Loss: 0.4044393301010132, Validation Accuracy: 0.8664166666666666\n",
      "Epoch: 63, Loss: 0.40246424078941345, Validation Accuracy: 0.87525\n",
      "Epoch: 64, Loss: 0.40054458379745483, Validation Accuracy: 0.8715\n",
      "Epoch: 65, Loss: 0.38920533657073975, Validation Accuracy: 0.8831666666666667\n",
      "Epoch: 66, Loss: 0.3776847720146179, Validation Accuracy: 0.88175\n",
      "Epoch: 67, Loss: 0.3631138801574707, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 68, Loss: 0.3518214821815491, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 69, Loss: 0.34233561158180237, Validation Accuracy: 0.8971666666666667\n",
      "Epoch: 70, Loss: 0.3358074128627777, Validation Accuracy: 0.896\n",
      "Epoch: 71, Loss: 0.3308035135269165, Validation Accuracy: 0.8999166666666667\n",
      "Epoch: 72, Loss: 0.32724887132644653, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 73, Loss: 0.3242585062980652, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 74, Loss: 0.32172074913978577, Validation Accuracy: 0.9005833333333333\n",
      "Epoch: 75, Loss: 0.3194196820259094, Validation Accuracy: 0.9033333333333333\n",
      "Epoch: 76, Loss: 0.3173178732395172, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 77, Loss: 0.31534087657928467, Validation Accuracy: 0.9039166666666667\n",
      "Epoch: 78, Loss: 0.3134711980819702, Validation Accuracy: 0.9039166666666667\n",
      "Epoch: 79, Loss: 0.3116695284843445, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 80, Loss: 0.30992820858955383, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 81, Loss: 0.30823004245758057, Validation Accuracy: 0.9054166666666666\n",
      "Epoch: 82, Loss: 0.3065783977508545, Validation Accuracy: 0.9059166666666667\n",
      "Epoch: 83, Loss: 0.30496591329574585, Validation Accuracy: 0.90625\n",
      "Epoch: 84, Loss: 0.3033856153488159, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 85, Loss: 0.30184248089790344, Validation Accuracy: 0.907\n",
      "Epoch: 86, Loss: 0.300332248210907, Validation Accuracy: 0.9073333333333333\n",
      "Epoch: 87, Loss: 0.2988504469394684, Validation Accuracy: 0.9075833333333333\n",
      "Epoch: 88, Loss: 0.2973940968513489, Validation Accuracy: 0.9075833333333333\n",
      "Epoch: 89, Loss: 0.29596397280693054, Validation Accuracy: 0.9086666666666666\n",
      "Epoch: 90, Loss: 0.2945575714111328, Validation Accuracy: 0.9088333333333334\n",
      "Epoch: 91, Loss: 0.2931767702102661, Validation Accuracy: 0.9094166666666667\n",
      "Epoch: 92, Loss: 0.29182082414627075, Validation Accuracy: 0.90925\n",
      "Epoch: 93, Loss: 0.29048457741737366, Validation Accuracy: 0.9098333333333334\n",
      "Epoch: 94, Loss: 0.28916263580322266, Validation Accuracy: 0.9101666666666667\n",
      "Epoch: 95, Loss: 0.2878628969192505, Validation Accuracy: 0.9106666666666666\n",
      "Epoch: 96, Loss: 0.2865838408470154, Validation Accuracy: 0.91125\n",
      "Epoch: 97, Loss: 0.28532564640045166, Validation Accuracy: 0.9115\n",
      "Epoch: 98, Loss: 0.2840871214866638, Validation Accuracy: 0.91175\n",
      "Epoch: 99, Loss: 0.2828676700592041, Validation Accuracy: 0.9119166666666667\n",
      "Dataset 29\n",
      "Epoch: 0, Loss: 3.3446991443634033, Validation Accuracy: 0.20191666666666666\n",
      "Epoch: 1, Loss: 2.8382253646850586, Validation Accuracy: 0.18725\n",
      "Epoch: 2, Loss: 2.4311325550079346, Validation Accuracy: 0.2385\n",
      "Epoch: 3, Loss: 2.4045908451080322, Validation Accuracy: 0.27391666666666664\n",
      "Epoch: 4, Loss: 2.072075128555298, Validation Accuracy: 0.3328333333333333\n",
      "Epoch: 5, Loss: 1.8087446689605713, Validation Accuracy: 0.5121666666666667\n",
      "Epoch: 6, Loss: 1.534975290298462, Validation Accuracy: 0.5751666666666667\n",
      "Epoch: 7, Loss: 1.379213571548462, Validation Accuracy: 0.6196666666666667\n",
      "Epoch: 8, Loss: 1.245893120765686, Validation Accuracy: 0.6540833333333333\n",
      "Epoch: 9, Loss: 1.122910499572754, Validation Accuracy: 0.685\n",
      "Epoch: 10, Loss: 1.0159051418304443, Validation Accuracy: 0.7073333333333334\n",
      "Epoch: 11, Loss: 0.9278010129928589, Validation Accuracy: 0.72575\n",
      "Epoch: 12, Loss: 0.8574906587600708, Validation Accuracy: 0.7430833333333333\n",
      "Epoch: 13, Loss: 0.8011623620986938, Validation Accuracy: 0.7561666666666667\n",
      "Epoch: 14, Loss: 0.7559793591499329, Validation Accuracy: 0.76925\n",
      "Epoch: 15, Loss: 0.7214000821113586, Validation Accuracy: 0.7684166666666666\n",
      "Epoch: 16, Loss: 0.7027571797370911, Validation Accuracy: 0.75675\n",
      "Epoch: 17, Loss: 0.7301620244979858, Validation Accuracy: 0.6905833333333333\n",
      "Epoch: 18, Loss: 0.8539339303970337, Validation Accuracy: 0.5875\n",
      "Epoch: 19, Loss: 1.2030667066574097, Validation Accuracy: 0.69925\n",
      "Epoch: 20, Loss: 0.8623746633529663, Validation Accuracy: 0.74925\n",
      "Epoch: 21, Loss: 0.7320033311843872, Validation Accuracy: 0.80075\n",
      "Epoch: 22, Loss: 0.6236657500267029, Validation Accuracy: 0.8194166666666667\n",
      "Epoch: 23, Loss: 0.5816306471824646, Validation Accuracy: 0.825\n",
      "Epoch: 24, Loss: 0.5579111576080322, Validation Accuracy: 0.832\n",
      "Epoch: 25, Loss: 0.5411977171897888, Validation Accuracy: 0.8350833333333333\n",
      "Epoch: 26, Loss: 0.5275724530220032, Validation Accuracy: 0.8410833333333333\n",
      "Epoch: 27, Loss: 0.5159289836883545, Validation Accuracy: 0.8420833333333333\n",
      "Epoch: 28, Loss: 0.5054857134819031, Validation Accuracy: 0.8460833333333333\n",
      "Epoch: 29, Loss: 0.4960929751396179, Validation Accuracy: 0.8471666666666666\n",
      "Epoch: 30, Loss: 0.4874974489212036, Validation Accuracy: 0.852\n",
      "Epoch: 31, Loss: 0.4796992540359497, Validation Accuracy: 0.8520833333333333\n",
      "Epoch: 32, Loss: 0.4725083112716675, Validation Accuracy: 0.856\n",
      "Epoch: 33, Loss: 0.46595799922943115, Validation Accuracy: 0.8575\n",
      "Epoch: 34, Loss: 0.45983999967575073, Validation Accuracy: 0.859\n",
      "Epoch: 35, Loss: 0.4543580710887909, Validation Accuracy: 0.8611666666666666\n",
      "Epoch: 36, Loss: 0.44918379187583923, Validation Accuracy: 0.8625\n",
      "Epoch: 37, Loss: 0.4447593688964844, Validation Accuracy: 0.86225\n",
      "Epoch: 38, Loss: 0.44056734442710876, Validation Accuracy: 0.8645\n",
      "Epoch: 39, Loss: 0.4374769628047943, Validation Accuracy: 0.8631666666666666\n",
      "Epoch: 40, Loss: 0.43449947237968445, Validation Accuracy: 0.8643333333333333\n",
      "Epoch: 41, Loss: 0.4330524504184723, Validation Accuracy: 0.86475\n",
      "Epoch: 42, Loss: 0.431029736995697, Validation Accuracy: 0.8639166666666667\n",
      "Epoch: 43, Loss: 0.4313904345035553, Validation Accuracy: 0.8648333333333333\n",
      "Epoch: 44, Loss: 0.4299972653388977, Validation Accuracy: 0.86375\n",
      "Epoch: 45, Loss: 0.43154147267341614, Validation Accuracy: 0.8648333333333333\n",
      "Epoch: 46, Loss: 0.4296520948410034, Validation Accuracy: 0.864\n",
      "Epoch: 47, Loss: 0.43081963062286377, Validation Accuracy: 0.8658333333333333\n",
      "Epoch: 48, Loss: 0.4265293776988983, Validation Accuracy: 0.8651666666666666\n",
      "Epoch: 49, Loss: 0.42558780312538147, Validation Accuracy: 0.8685833333333334\n",
      "Epoch: 50, Loss: 0.41803279519081116, Validation Accuracy: 0.8688333333333333\n",
      "Epoch: 51, Loss: 0.4137442111968994, Validation Accuracy: 0.8740833333333333\n",
      "Epoch: 52, Loss: 0.4045846462249756, Validation Accuracy: 0.8745\n",
      "Epoch: 53, Loss: 0.3987489938735962, Validation Accuracy: 0.8804166666666666\n",
      "Epoch: 54, Loss: 0.3905530571937561, Validation Accuracy: 0.87925\n",
      "Epoch: 55, Loss: 0.38488736748695374, Validation Accuracy: 0.8839166666666667\n",
      "Epoch: 56, Loss: 0.3784095048904419, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 57, Loss: 0.37373098731040955, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 58, Loss: 0.36881861090660095, Validation Accuracy: 0.8864166666666666\n",
      "Epoch: 59, Loss: 0.3651200830936432, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 60, Loss: 0.3613815903663635, Validation Accuracy: 0.8885833333333333\n",
      "Epoch: 61, Loss: 0.35826942324638367, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 62, Loss: 0.35526615381240845, Validation Accuracy: 0.8905\n",
      "Epoch: 63, Loss: 0.3525870740413666, Validation Accuracy: 0.89275\n",
      "Epoch: 64, Loss: 0.34998661279678345, Validation Accuracy: 0.8923333333333333\n",
      "Epoch: 65, Loss: 0.3475779891014099, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 66, Loss: 0.34521928429603577, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 67, Loss: 0.34299325942993164, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 68, Loss: 0.340812087059021, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 69, Loss: 0.33873075246810913, Validation Accuracy: 0.8978333333333334\n",
      "Epoch: 70, Loss: 0.3367006182670593, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 71, Loss: 0.33473822474479675, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 72, Loss: 0.3328288495540619, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 73, Loss: 0.3309755325317383, Validation Accuracy: 0.90075\n",
      "Epoch: 74, Loss: 0.3291659355163574, Validation Accuracy: 0.9003333333333333\n",
      "Epoch: 75, Loss: 0.3274000585079193, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 76, Loss: 0.32565850019454956, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 77, Loss: 0.3239639699459076, Validation Accuracy: 0.9025\n",
      "Epoch: 78, Loss: 0.32230252027511597, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 79, Loss: 0.320675253868103, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 80, Loss: 0.31907740235328674, Validation Accuracy: 0.9035\n",
      "Epoch: 81, Loss: 0.3175101578235626, Validation Accuracy: 0.90425\n",
      "Epoch: 82, Loss: 0.3159702718257904, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 83, Loss: 0.3144594132900238, Validation Accuracy: 0.9055\n",
      "Epoch: 84, Loss: 0.31297767162323, Validation Accuracy: 0.90525\n",
      "Epoch: 85, Loss: 0.3115171492099762, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 86, Loss: 0.31007853150367737, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 87, Loss: 0.30866289138793945, Validation Accuracy: 0.9065\n",
      "Epoch: 88, Loss: 0.30727025866508484, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 89, Loss: 0.305901437997818, Validation Accuracy: 0.90725\n",
      "Epoch: 90, Loss: 0.3045520484447479, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 91, Loss: 0.30322226881980896, Validation Accuracy: 0.90775\n",
      "Epoch: 92, Loss: 0.3019130825996399, Validation Accuracy: 0.9075833333333333\n",
      "Epoch: 93, Loss: 0.30061817169189453, Validation Accuracy: 0.9081666666666667\n",
      "Epoch: 94, Loss: 0.29934054613113403, Validation Accuracy: 0.9084166666666667\n",
      "Epoch: 95, Loss: 0.2980824410915375, Validation Accuracy: 0.9091666666666667\n",
      "Epoch: 96, Loss: 0.2968410849571228, Validation Accuracy: 0.9093333333333333\n",
      "Epoch: 97, Loss: 0.29561516642570496, Validation Accuracy: 0.9103333333333333\n",
      "Epoch: 98, Loss: 0.2944071292877197, Validation Accuracy: 0.9103333333333333\n",
      "Epoch: 99, Loss: 0.29321548342704773, Validation Accuracy: 0.911\n",
      "Dataset 30\n",
      "Epoch: 0, Loss: 3.9281792640686035, Validation Accuracy: 0.19525\n",
      "Epoch: 1, Loss: 3.631211519241333, Validation Accuracy: 0.18066666666666667\n",
      "Epoch: 2, Loss: 3.387866973876953, Validation Accuracy: 0.17491666666666666\n",
      "Epoch: 3, Loss: 3.3986008167266846, Validation Accuracy: 0.2305\n",
      "Epoch: 4, Loss: 2.2830820083618164, Validation Accuracy: 0.26675\n",
      "Epoch: 5, Loss: 2.051790714263916, Validation Accuracy: 0.35\n",
      "Epoch: 6, Loss: 1.9006690979003906, Validation Accuracy: 0.39008333333333334\n",
      "Epoch: 7, Loss: 1.8124366998672485, Validation Accuracy: 0.414\n",
      "Epoch: 8, Loss: 1.729646921157837, Validation Accuracy: 0.43775\n",
      "Epoch: 9, Loss: 1.6496152877807617, Validation Accuracy: 0.46025\n",
      "Epoch: 10, Loss: 1.5739856958389282, Validation Accuracy: 0.4800833333333333\n",
      "Epoch: 11, Loss: 1.5014599561691284, Validation Accuracy: 0.5010833333333333\n",
      "Epoch: 12, Loss: 1.4310722351074219, Validation Accuracy: 0.5214166666666666\n",
      "Epoch: 13, Loss: 1.3630820512771606, Validation Accuracy: 0.5425\n",
      "Epoch: 14, Loss: 1.2978267669677734, Validation Accuracy: 0.5661666666666667\n",
      "Epoch: 15, Loss: 1.2362375259399414, Validation Accuracy: 0.5916666666666667\n",
      "Epoch: 16, Loss: 1.178523063659668, Validation Accuracy: 0.6176666666666667\n",
      "Epoch: 17, Loss: 1.124500036239624, Validation Accuracy: 0.6415\n",
      "Epoch: 18, Loss: 1.0744599103927612, Validation Accuracy: 0.6600833333333334\n",
      "Epoch: 19, Loss: 1.0285651683807373, Validation Accuracy: 0.672\n",
      "Epoch: 20, Loss: 0.9873291850090027, Validation Accuracy: 0.6771666666666667\n",
      "Epoch: 21, Loss: 0.9517977833747864, Validation Accuracy: 0.69075\n",
      "Epoch: 22, Loss: 0.9244248270988464, Validation Accuracy: 0.6838333333333333\n",
      "Epoch: 23, Loss: 0.9147167205810547, Validation Accuracy: 0.678\n",
      "Epoch: 24, Loss: 0.9412843585014343, Validation Accuracy: 0.6148333333333333\n",
      "Epoch: 25, Loss: 1.0792654752731323, Validation Accuracy: 0.5890833333333333\n",
      "Epoch: 26, Loss: 1.2005186080932617, Validation Accuracy: 0.5465\n",
      "Epoch: 27, Loss: 1.362890601158142, Validation Accuracy: 0.6968333333333333\n",
      "Epoch: 28, Loss: 0.8889845609664917, Validation Accuracy: 0.7310833333333333\n",
      "Epoch: 29, Loss: 0.7881317734718323, Validation Accuracy: 0.7518333333333334\n",
      "Epoch: 30, Loss: 0.7488204836845398, Validation Accuracy: 0.75975\n",
      "Epoch: 31, Loss: 0.7230099439620972, Validation Accuracy: 0.7685833333333333\n",
      "Epoch: 32, Loss: 0.7009317874908447, Validation Accuracy: 0.7729166666666667\n",
      "Epoch: 33, Loss: 0.6810785531997681, Validation Accuracy: 0.7808333333333334\n",
      "Epoch: 34, Loss: 0.6631091833114624, Validation Accuracy: 0.78675\n",
      "Epoch: 35, Loss: 0.6464840173721313, Validation Accuracy: 0.7935\n",
      "Epoch: 36, Loss: 0.6314794421195984, Validation Accuracy: 0.7963333333333333\n",
      "Epoch: 37, Loss: 0.6178426742553711, Validation Accuracy: 0.8040833333333334\n",
      "Epoch: 38, Loss: 0.6066047549247742, Validation Accuracy: 0.8021666666666667\n",
      "Epoch: 39, Loss: 0.5974648594856262, Validation Accuracy: 0.80875\n",
      "Epoch: 40, Loss: 0.594825267791748, Validation Accuracy: 0.8004166666666667\n",
      "Epoch: 41, Loss: 0.5957103967666626, Validation Accuracy: 0.79725\n",
      "Epoch: 42, Loss: 0.6200603246688843, Validation Accuracy: 0.7830833333333334\n",
      "Epoch: 43, Loss: 0.6358143091201782, Validation Accuracy: 0.7684166666666666\n",
      "Epoch: 44, Loss: 0.7021426558494568, Validation Accuracy: 0.7845833333333333\n",
      "Epoch: 45, Loss: 0.6432920098304749, Validation Accuracy: 0.7904166666666667\n",
      "Epoch: 46, Loss: 0.637561023235321, Validation Accuracy: 0.8161666666666667\n",
      "Epoch: 47, Loss: 0.5703150629997253, Validation Accuracy: 0.82875\n",
      "Epoch: 48, Loss: 0.5420222878456116, Validation Accuracy: 0.83625\n",
      "Epoch: 49, Loss: 0.5161293745040894, Validation Accuracy: 0.8460833333333333\n",
      "Epoch: 50, Loss: 0.5011726021766663, Validation Accuracy: 0.84775\n",
      "Epoch: 51, Loss: 0.48909661173820496, Validation Accuracy: 0.8521666666666666\n",
      "Epoch: 52, Loss: 0.4798352122306824, Validation Accuracy: 0.8531666666666666\n",
      "Epoch: 53, Loss: 0.4716147780418396, Validation Accuracy: 0.8574166666666667\n",
      "Epoch: 54, Loss: 0.4645701050758362, Validation Accuracy: 0.8565833333333334\n",
      "Epoch: 55, Loss: 0.4580601751804352, Validation Accuracy: 0.8600833333333333\n",
      "Epoch: 56, Loss: 0.4523290693759918, Validation Accuracy: 0.8595\n",
      "Epoch: 57, Loss: 0.44688528776168823, Validation Accuracy: 0.86375\n",
      "Epoch: 58, Loss: 0.44220852851867676, Validation Accuracy: 0.86325\n",
      "Epoch: 59, Loss: 0.4375593364238739, Validation Accuracy: 0.8654166666666666\n",
      "Epoch: 60, Loss: 0.43379878997802734, Validation Accuracy: 0.8660833333333333\n",
      "Epoch: 61, Loss: 0.4300207197666168, Validation Accuracy: 0.8664166666666666\n",
      "Epoch: 62, Loss: 0.42738208174705505, Validation Accuracy: 0.86825\n",
      "Epoch: 63, Loss: 0.4243408739566803, Validation Accuracy: 0.8675833333333334\n",
      "Epoch: 64, Loss: 0.4226765036582947, Validation Accuracy: 0.8695\n",
      "Epoch: 65, Loss: 0.42050474882125854, Validation Accuracy: 0.86725\n",
      "Epoch: 66, Loss: 0.41974520683288574, Validation Accuracy: 0.8699166666666667\n",
      "Epoch: 67, Loss: 0.41774508357048035, Validation Accuracy: 0.8674166666666666\n",
      "Epoch: 68, Loss: 0.4171326458454132, Validation Accuracy: 0.8695\n",
      "Epoch: 69, Loss: 0.41493672132492065, Validation Accuracy: 0.8684166666666666\n",
      "Epoch: 70, Loss: 0.4130629897117615, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 71, Loss: 0.40966978669166565, Validation Accuracy: 0.8706666666666667\n",
      "Epoch: 72, Loss: 0.40545299649238586, Validation Accuracy: 0.8735833333333334\n",
      "Epoch: 73, Loss: 0.40058568120002747, Validation Accuracy: 0.87425\n",
      "Epoch: 74, Loss: 0.39441853761672974, Validation Accuracy: 0.8775\n",
      "Epoch: 75, Loss: 0.38879281282424927, Validation Accuracy: 0.87975\n",
      "Epoch: 76, Loss: 0.38236844539642334, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 77, Loss: 0.37723812460899353, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 78, Loss: 0.37171679735183716, Validation Accuracy: 0.8850833333333333\n",
      "Epoch: 79, Loss: 0.3675397038459778, Validation Accuracy: 0.8873333333333333\n",
      "Epoch: 80, Loss: 0.3631085753440857, Validation Accuracy: 0.8871666666666667\n",
      "Epoch: 81, Loss: 0.3597104847431183, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 82, Loss: 0.3561762571334839, Validation Accuracy: 0.89\n",
      "Epoch: 83, Loss: 0.3532106578350067, Validation Accuracy: 0.89\n",
      "Epoch: 84, Loss: 0.3502524495124817, Validation Accuracy: 0.8914166666666666\n",
      "Epoch: 85, Loss: 0.3476521372795105, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 86, Loss: 0.34503796696662903, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 87, Loss: 0.342632532119751, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 88, Loss: 0.3402612805366516, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 89, Loss: 0.3379979729652405, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 90, Loss: 0.3358391523361206, Validation Accuracy: 0.89575\n",
      "Epoch: 91, Loss: 0.3337344825267792, Validation Accuracy: 0.89575\n",
      "Epoch: 92, Loss: 0.3317287266254425, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 93, Loss: 0.3297368288040161, Validation Accuracy: 0.8966666666666666\n",
      "Epoch: 94, Loss: 0.3278453052043915, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 95, Loss: 0.32597342133522034, Validation Accuracy: 0.89775\n",
      "Epoch: 96, Loss: 0.32418563961982727, Validation Accuracy: 0.8979166666666667\n",
      "Epoch: 97, Loss: 0.32241806387901306, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 98, Loss: 0.32070010900497437, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 99, Loss: 0.31901276111602783, Validation Accuracy: 0.9005833333333333\n",
      "Dataset 31\n",
      "Epoch: 0, Loss: 3.532336950302124, Validation Accuracy: 0.18283333333333332\n",
      "Epoch: 1, Loss: 2.3624935150146484, Validation Accuracy: 0.3164166666666667\n",
      "Epoch: 2, Loss: 1.916406273841858, Validation Accuracy: 0.4211666666666667\n",
      "Epoch: 3, Loss: 1.6554534435272217, Validation Accuracy: 0.4900833333333333\n",
      "Epoch: 4, Loss: 1.4805067777633667, Validation Accuracy: 0.5501666666666667\n",
      "Epoch: 5, Loss: 1.3433892726898193, Validation Accuracy: 0.5945\n",
      "Epoch: 6, Loss: 1.2207411527633667, Validation Accuracy: 0.634\n",
      "Epoch: 7, Loss: 1.1153737306594849, Validation Accuracy: 0.66725\n",
      "Epoch: 8, Loss: 1.0247100591659546, Validation Accuracy: 0.68225\n",
      "Epoch: 9, Loss: 0.9671580195426941, Validation Accuracy: 0.68375\n",
      "Epoch: 10, Loss: 0.963460385799408, Validation Accuracy: 0.6018333333333333\n",
      "Epoch: 11, Loss: 1.1264876127243042, Validation Accuracy: 0.5706666666666667\n",
      "Epoch: 12, Loss: 1.2638510465621948, Validation Accuracy: 0.6180833333333333\n",
      "Epoch: 13, Loss: 1.105649709701538, Validation Accuracy: 0.6984166666666667\n",
      "Epoch: 14, Loss: 0.8922042846679688, Validation Accuracy: 0.7400833333333333\n",
      "Epoch: 15, Loss: 0.7932223081588745, Validation Accuracy: 0.7323333333333333\n",
      "Epoch: 16, Loss: 0.8013172745704651, Validation Accuracy: 0.7381666666666666\n",
      "Epoch: 17, Loss: 0.8024505376815796, Validation Accuracy: 0.7145\n",
      "Epoch: 18, Loss: 0.814317524433136, Validation Accuracy: 0.76925\n",
      "Epoch: 19, Loss: 0.7079460620880127, Validation Accuracy: 0.7833333333333333\n",
      "Epoch: 20, Loss: 0.6507413983345032, Validation Accuracy: 0.8159166666666666\n",
      "Epoch: 21, Loss: 0.5898615121841431, Validation Accuracy: 0.82\n",
      "Epoch: 22, Loss: 0.5636741518974304, Validation Accuracy: 0.8324166666666667\n",
      "Epoch: 23, Loss: 0.5404878854751587, Validation Accuracy: 0.8330833333333333\n",
      "Epoch: 24, Loss: 0.5254825949668884, Validation Accuracy: 0.8404166666666667\n",
      "Epoch: 25, Loss: 0.5115893483161926, Validation Accuracy: 0.8419166666666666\n",
      "Epoch: 26, Loss: 0.5009412169456482, Validation Accuracy: 0.8461666666666666\n",
      "Epoch: 27, Loss: 0.49073487520217896, Validation Accuracy: 0.8484166666666667\n",
      "Epoch: 28, Loss: 0.4824203550815582, Validation Accuracy: 0.8516666666666667\n",
      "Epoch: 29, Loss: 0.47442516684532166, Validation Accuracy: 0.85275\n",
      "Epoch: 30, Loss: 0.46770527958869934, Validation Accuracy: 0.8559166666666667\n",
      "Epoch: 31, Loss: 0.461155503988266, Validation Accuracy: 0.8556666666666667\n",
      "Epoch: 32, Loss: 0.45565780997276306, Validation Accuracy: 0.8585\n",
      "Epoch: 33, Loss: 0.4501831829547882, Validation Accuracy: 0.8586666666666667\n",
      "Epoch: 34, Loss: 0.44533246755599976, Validation Accuracy: 0.8620833333333333\n",
      "Epoch: 35, Loss: 0.4405066668987274, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 36, Loss: 0.43599262833595276, Validation Accuracy: 0.86475\n",
      "Epoch: 37, Loss: 0.43139439821243286, Validation Accuracy: 0.86475\n",
      "Epoch: 38, Loss: 0.42680904269218445, Validation Accuracy: 0.8679166666666667\n",
      "Epoch: 39, Loss: 0.4220494329929352, Validation Accuracy: 0.8671666666666666\n",
      "Epoch: 40, Loss: 0.41718590259552, Validation Accuracy: 0.8706666666666667\n",
      "Epoch: 41, Loss: 0.41230833530426025, Validation Accuracy: 0.8715833333333334\n",
      "Epoch: 42, Loss: 0.4073018431663513, Validation Accuracy: 0.8729166666666667\n",
      "Epoch: 43, Loss: 0.40241459012031555, Validation Accuracy: 0.875\n",
      "Epoch: 44, Loss: 0.3976709246635437, Validation Accuracy: 0.8758333333333334\n",
      "Epoch: 45, Loss: 0.3930414915084839, Validation Accuracy: 0.8775\n",
      "Epoch: 46, Loss: 0.38856950402259827, Validation Accuracy: 0.8790833333333333\n",
      "Epoch: 47, Loss: 0.38443538546562195, Validation Accuracy: 0.88\n",
      "Epoch: 48, Loss: 0.38034167885780334, Validation Accuracy: 0.8814166666666666\n",
      "Epoch: 49, Loss: 0.37667346000671387, Validation Accuracy: 0.8824166666666666\n",
      "Epoch: 50, Loss: 0.37305331230163574, Validation Accuracy: 0.8839166666666667\n",
      "Epoch: 51, Loss: 0.36975041031837463, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 52, Loss: 0.3664320409297943, Validation Accuracy: 0.88725\n",
      "Epoch: 53, Loss: 0.36342358589172363, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 54, Loss: 0.3603966534137726, Validation Accuracy: 0.889\n",
      "Epoch: 55, Loss: 0.3575771152973175, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 56, Loss: 0.35483789443969727, Validation Accuracy: 0.891\n",
      "Epoch: 57, Loss: 0.352267861366272, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 58, Loss: 0.3497537076473236, Validation Accuracy: 0.8925\n",
      "Epoch: 59, Loss: 0.3473559021949768, Validation Accuracy: 0.8908333333333334\n",
      "Epoch: 60, Loss: 0.3450327217578888, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 61, Loss: 0.34279200434684753, Validation Accuracy: 0.8926666666666667\n",
      "Epoch: 62, Loss: 0.34062108397483826, Validation Accuracy: 0.8944166666666666\n",
      "Epoch: 63, Loss: 0.33850398659706116, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 64, Loss: 0.33644869923591614, Validation Accuracy: 0.89525\n",
      "Epoch: 65, Loss: 0.33443599939346313, Validation Accuracy: 0.8959166666666667\n",
      "Epoch: 66, Loss: 0.33248576521873474, Validation Accuracy: 0.896\n",
      "Epoch: 67, Loss: 0.3305686116218567, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 68, Loss: 0.32868465781211853, Validation Accuracy: 0.89675\n",
      "Epoch: 69, Loss: 0.3268386721611023, Validation Accuracy: 0.89725\n",
      "Epoch: 70, Loss: 0.3250389099121094, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 71, Loss: 0.32327231764793396, Validation Accuracy: 0.8988333333333334\n",
      "Epoch: 72, Loss: 0.32153046131134033, Validation Accuracy: 0.8986666666666666\n",
      "Epoch: 73, Loss: 0.3198319375514984, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 74, Loss: 0.3181825578212738, Validation Accuracy: 0.89975\n",
      "Epoch: 75, Loss: 0.31654873490333557, Validation Accuracy: 0.9008333333333334\n",
      "Epoch: 76, Loss: 0.3149639964103699, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 77, Loss: 0.31340429186820984, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 78, Loss: 0.31188276410102844, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 79, Loss: 0.3103773891925812, Validation Accuracy: 0.9034166666666666\n",
      "Epoch: 80, Loss: 0.3088979423046112, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 81, Loss: 0.307447224855423, Validation Accuracy: 0.9033333333333333\n",
      "Epoch: 82, Loss: 0.3060106337070465, Validation Accuracy: 0.9031666666666667\n",
      "Epoch: 83, Loss: 0.30461257696151733, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 84, Loss: 0.3032427728176117, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 85, Loss: 0.30188897252082825, Validation Accuracy: 0.904\n",
      "Epoch: 86, Loss: 0.300563246011734, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 87, Loss: 0.2992522716522217, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 88, Loss: 0.2979677617549896, Validation Accuracy: 0.9045\n",
      "Epoch: 89, Loss: 0.2966916859149933, Validation Accuracy: 0.9048333333333334\n",
      "Epoch: 90, Loss: 0.29543593525886536, Validation Accuracy: 0.9051666666666667\n",
      "Epoch: 91, Loss: 0.29420071840286255, Validation Accuracy: 0.9054166666666666\n",
      "Epoch: 92, Loss: 0.29298627376556396, Validation Accuracy: 0.9055833333333333\n",
      "Epoch: 93, Loss: 0.29177698493003845, Validation Accuracy: 0.906\n",
      "Epoch: 94, Loss: 0.29058927297592163, Validation Accuracy: 0.90625\n",
      "Epoch: 95, Loss: 0.28941237926483154, Validation Accuracy: 0.9063333333333333\n",
      "Epoch: 96, Loss: 0.2882556617259979, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 97, Loss: 0.2871110439300537, Validation Accuracy: 0.90675\n",
      "Epoch: 98, Loss: 0.2859891951084137, Validation Accuracy: 0.9073333333333333\n",
      "Epoch: 99, Loss: 0.2848754823207855, Validation Accuracy: 0.9071666666666667\n",
      "Dataset 32\n",
      "Epoch: 0, Loss: 3.3516063690185547, Validation Accuracy: 0.17991666666666667\n",
      "Epoch: 1, Loss: 3.651487350463867, Validation Accuracy: 0.21616666666666667\n",
      "Epoch: 2, Loss: 2.7936763763427734, Validation Accuracy: 0.36575\n",
      "Epoch: 3, Loss: 1.8443266153335571, Validation Accuracy: 0.4573333333333333\n",
      "Epoch: 4, Loss: 1.613078236579895, Validation Accuracy: 0.5070833333333333\n",
      "Epoch: 5, Loss: 1.4789901971817017, Validation Accuracy: 0.54525\n",
      "Epoch: 6, Loss: 1.3675612211227417, Validation Accuracy: 0.5834166666666667\n",
      "Epoch: 7, Loss: 1.2707151174545288, Validation Accuracy: 0.6083333333333333\n",
      "Epoch: 8, Loss: 1.187490701675415, Validation Accuracy: 0.6360833333333333\n",
      "Epoch: 9, Loss: 1.1165059804916382, Validation Accuracy: 0.652\n",
      "Epoch: 10, Loss: 1.056087851524353, Validation Accuracy: 0.6685\n",
      "Epoch: 11, Loss: 1.0047439336776733, Validation Accuracy: 0.68075\n",
      "Epoch: 12, Loss: 0.9600763320922852, Validation Accuracy: 0.6891666666666667\n",
      "Epoch: 13, Loss: 0.9231048226356506, Validation Accuracy: 0.6979166666666666\n",
      "Epoch: 14, Loss: 0.8919720649719238, Validation Accuracy: 0.7029166666666666\n",
      "Epoch: 15, Loss: 0.8806732296943665, Validation Accuracy: 0.7039166666666666\n",
      "Epoch: 16, Loss: 0.874946117401123, Validation Accuracy: 0.68025\n",
      "Epoch: 17, Loss: 0.9309287667274475, Validation Accuracy: 0.7080833333333333\n",
      "Epoch: 18, Loss: 0.8736799359321594, Validation Accuracy: 0.7013333333333334\n",
      "Epoch: 19, Loss: 0.8876469731330872, Validation Accuracy: 0.75\n",
      "Epoch: 20, Loss: 0.7652114033699036, Validation Accuracy: 0.7779166666666667\n",
      "Epoch: 21, Loss: 0.7092726230621338, Validation Accuracy: 0.7916666666666666\n",
      "Epoch: 22, Loss: 0.6587730050086975, Validation Accuracy: 0.80425\n",
      "Epoch: 23, Loss: 0.6350354552268982, Validation Accuracy: 0.8045833333333333\n",
      "Epoch: 24, Loss: 0.6218224167823792, Validation Accuracy: 0.8019166666666667\n",
      "Epoch: 25, Loss: 0.6296110153198242, Validation Accuracy: 0.7888333333333334\n",
      "Epoch: 26, Loss: 0.6512585282325745, Validation Accuracy: 0.773\n",
      "Epoch: 27, Loss: 0.6960421800613403, Validation Accuracy: 0.7475\n",
      "Epoch: 28, Loss: 0.7457054853439331, Validation Accuracy: 0.7491666666666666\n",
      "Epoch: 29, Loss: 0.7649675011634827, Validation Accuracy: 0.7600833333333333\n",
      "Epoch: 30, Loss: 0.7026690244674683, Validation Accuracy: 0.8053333333333333\n",
      "Epoch: 31, Loss: 0.6089569330215454, Validation Accuracy: 0.8301666666666667\n",
      "Epoch: 32, Loss: 0.5352868437767029, Validation Accuracy: 0.8520833333333333\n",
      "Epoch: 33, Loss: 0.49357128143310547, Validation Accuracy: 0.85575\n",
      "Epoch: 34, Loss: 0.4720155894756317, Validation Accuracy: 0.86325\n",
      "Epoch: 35, Loss: 0.458682119846344, Validation Accuracy: 0.86325\n",
      "Epoch: 36, Loss: 0.44907838106155396, Validation Accuracy: 0.868\n",
      "Epoch: 37, Loss: 0.44108206033706665, Validation Accuracy: 0.8691666666666666\n",
      "Epoch: 38, Loss: 0.4340837001800537, Validation Accuracy: 0.8714166666666666\n",
      "Epoch: 39, Loss: 0.4277627766132355, Validation Accuracy: 0.87325\n",
      "Epoch: 40, Loss: 0.42197197675704956, Validation Accuracy: 0.8745\n",
      "Epoch: 41, Loss: 0.41658833622932434, Validation Accuracy: 0.8771666666666667\n",
      "Epoch: 42, Loss: 0.4115493595600128, Validation Accuracy: 0.8785\n",
      "Epoch: 43, Loss: 0.40678671002388, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 44, Loss: 0.4022649824619293, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 45, Loss: 0.39796072244644165, Validation Accuracy: 0.8821666666666667\n",
      "Epoch: 46, Loss: 0.3938661217689514, Validation Accuracy: 0.8829166666666667\n",
      "Epoch: 47, Loss: 0.3899728059768677, Validation Accuracy: 0.8840833333333333\n",
      "Epoch: 48, Loss: 0.38624241948127747, Validation Accuracy: 0.8849166666666667\n",
      "Epoch: 49, Loss: 0.3826768398284912, Validation Accuracy: 0.886\n",
      "Epoch: 50, Loss: 0.3792513310909271, Validation Accuracy: 0.8868333333333334\n",
      "Epoch: 51, Loss: 0.3759533762931824, Validation Accuracy: 0.8879166666666667\n",
      "Epoch: 52, Loss: 0.37277474999427795, Validation Accuracy: 0.8890833333333333\n",
      "Epoch: 53, Loss: 0.36969882249832153, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 54, Loss: 0.3667270541191101, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 55, Loss: 0.3638536036014557, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 56, Loss: 0.3610779345035553, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 57, Loss: 0.3583908677101135, Validation Accuracy: 0.8943333333333333\n",
      "Epoch: 58, Loss: 0.3557814657688141, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 59, Loss: 0.3532494604587555, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 60, Loss: 0.3507871925830841, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 61, Loss: 0.3483988344669342, Validation Accuracy: 0.89675\n",
      "Epoch: 62, Loss: 0.34607598185539246, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 63, Loss: 0.34380868077278137, Validation Accuracy: 0.89825\n",
      "Epoch: 64, Loss: 0.34159716963768005, Validation Accuracy: 0.8986666666666666\n",
      "Epoch: 65, Loss: 0.3394373953342438, Validation Accuracy: 0.89975\n",
      "Epoch: 66, Loss: 0.3373328149318695, Validation Accuracy: 0.9\n",
      "Epoch: 67, Loss: 0.3352784216403961, Validation Accuracy: 0.9005\n",
      "Epoch: 68, Loss: 0.33327242732048035, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 69, Loss: 0.33131077885627747, Validation Accuracy: 0.9020833333333333\n",
      "Epoch: 70, Loss: 0.3293851315975189, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 71, Loss: 0.3275010585784912, Validation Accuracy: 0.903\n",
      "Epoch: 72, Loss: 0.32565754652023315, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 73, Loss: 0.3238545060157776, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 74, Loss: 0.32208451628685, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 75, Loss: 0.3203554153442383, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 76, Loss: 0.31866228580474854, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 77, Loss: 0.3169993460178375, Validation Accuracy: 0.90575\n",
      "Epoch: 78, Loss: 0.3153661787509918, Validation Accuracy: 0.906\n",
      "Epoch: 79, Loss: 0.31375741958618164, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 80, Loss: 0.31217896938323975, Validation Accuracy: 0.9071666666666667\n",
      "Epoch: 81, Loss: 0.3106287121772766, Validation Accuracy: 0.9074166666666666\n",
      "Epoch: 82, Loss: 0.3091011643409729, Validation Accuracy: 0.9075\n",
      "Epoch: 83, Loss: 0.3076007068157196, Validation Accuracy: 0.9085833333333333\n",
      "Epoch: 84, Loss: 0.306124210357666, Validation Accuracy: 0.9081666666666667\n",
      "Epoch: 85, Loss: 0.3046717345714569, Validation Accuracy: 0.90875\n",
      "Epoch: 86, Loss: 0.3032482862472534, Validation Accuracy: 0.90825\n",
      "Epoch: 87, Loss: 0.30184465646743774, Validation Accuracy: 0.90925\n",
      "Epoch: 88, Loss: 0.30046236515045166, Validation Accuracy: 0.9090833333333334\n",
      "Epoch: 89, Loss: 0.2991054356098175, Validation Accuracy: 0.9101666666666667\n",
      "Epoch: 90, Loss: 0.29777202010154724, Validation Accuracy: 0.9095\n",
      "Epoch: 91, Loss: 0.2964591383934021, Validation Accuracy: 0.9105\n",
      "Epoch: 92, Loss: 0.2951667308807373, Validation Accuracy: 0.9106666666666666\n",
      "Epoch: 93, Loss: 0.2938929498195648, Validation Accuracy: 0.9111666666666667\n",
      "Epoch: 94, Loss: 0.29263782501220703, Validation Accuracy: 0.9111666666666667\n",
      "Epoch: 95, Loss: 0.29140007495880127, Validation Accuracy: 0.9116666666666666\n",
      "Epoch: 96, Loss: 0.2901800274848938, Validation Accuracy: 0.91175\n",
      "Epoch: 97, Loss: 0.28897595405578613, Validation Accuracy: 0.912\n",
      "Epoch: 98, Loss: 0.287791907787323, Validation Accuracy: 0.9123333333333333\n",
      "Epoch: 99, Loss: 0.28662100434303284, Validation Accuracy: 0.9120833333333334\n",
      "Dataset 33\n",
      "Epoch: 0, Loss: 2.8454642295837402, Validation Accuracy: 0.13116666666666665\n",
      "Epoch: 1, Loss: 3.426344156265259, Validation Accuracy: 0.19375\n",
      "Epoch: 2, Loss: 5.051358699798584, Validation Accuracy: 0.15208333333333332\n",
      "Epoch: 3, Loss: 3.2340798377990723, Validation Accuracy: 0.24741666666666667\n",
      "Epoch: 4, Loss: 2.7087087631225586, Validation Accuracy: 0.27316666666666667\n",
      "Epoch: 5, Loss: 1.9857145547866821, Validation Accuracy: 0.36983333333333335\n",
      "Epoch: 6, Loss: 1.823732852935791, Validation Accuracy: 0.4166666666666667\n",
      "Epoch: 7, Loss: 1.7047921419143677, Validation Accuracy: 0.44816666666666666\n",
      "Epoch: 8, Loss: 1.6131631135940552, Validation Accuracy: 0.47991666666666666\n",
      "Epoch: 9, Loss: 1.5290732383728027, Validation Accuracy: 0.5128333333333334\n",
      "Epoch: 10, Loss: 1.4475822448730469, Validation Accuracy: 0.5435833333333333\n",
      "Epoch: 11, Loss: 1.3675525188446045, Validation Accuracy: 0.5735\n",
      "Epoch: 12, Loss: 1.2921117544174194, Validation Accuracy: 0.5985\n",
      "Epoch: 13, Loss: 1.223467230796814, Validation Accuracy: 0.6170833333333333\n",
      "Epoch: 14, Loss: 1.1613870859146118, Validation Accuracy: 0.6305833333333334\n",
      "Epoch: 15, Loss: 1.1049762964248657, Validation Accuracy: 0.6458333333333334\n",
      "Epoch: 16, Loss: 1.05324387550354, Validation Accuracy: 0.6639166666666667\n",
      "Epoch: 17, Loss: 1.0050877332687378, Validation Accuracy: 0.6790833333333334\n",
      "Epoch: 18, Loss: 0.9598193168640137, Validation Accuracy: 0.6975\n",
      "Epoch: 19, Loss: 0.9170079231262207, Validation Accuracy: 0.7148333333333333\n",
      "Epoch: 20, Loss: 0.8765103220939636, Validation Accuracy: 0.7328333333333333\n",
      "Epoch: 21, Loss: 0.8385999202728271, Validation Accuracy: 0.7496666666666667\n",
      "Epoch: 22, Loss: 0.8036909103393555, Validation Accuracy: 0.761\n",
      "Epoch: 23, Loss: 0.7725153565406799, Validation Accuracy: 0.7751666666666667\n",
      "Epoch: 24, Loss: 0.7467359900474548, Validation Accuracy: 0.7725833333333333\n",
      "Epoch: 25, Loss: 0.7303240299224854, Validation Accuracy: 0.7730833333333333\n",
      "Epoch: 26, Loss: 0.7371197938919067, Validation Accuracy: 0.7369166666666667\n",
      "Epoch: 27, Loss: 0.7872121334075928, Validation Accuracy: 0.6810833333333334\n",
      "Epoch: 28, Loss: 0.9499899744987488, Validation Accuracy: 0.6384166666666666\n",
      "Epoch: 29, Loss: 1.0430598258972168, Validation Accuracy: 0.6709166666666667\n",
      "Epoch: 30, Loss: 1.0013879537582397, Validation Accuracy: 0.7531666666666667\n",
      "Epoch: 31, Loss: 0.7333179712295532, Validation Accuracy: 0.81275\n",
      "Epoch: 32, Loss: 0.6250501871109009, Validation Accuracy: 0.81825\n",
      "Epoch: 33, Loss: 0.5935217142105103, Validation Accuracy: 0.8233333333333334\n",
      "Epoch: 34, Loss: 0.5772507190704346, Validation Accuracy: 0.8253333333333334\n",
      "Epoch: 35, Loss: 0.5630300641059875, Validation Accuracy: 0.8293333333333334\n",
      "Epoch: 36, Loss: 0.5535266399383545, Validation Accuracy: 0.82675\n",
      "Epoch: 37, Loss: 0.5462883114814758, Validation Accuracy: 0.83\n",
      "Epoch: 38, Loss: 0.5451039671897888, Validation Accuracy: 0.8205833333333333\n",
      "Epoch: 39, Loss: 0.5478897094726562, Validation Accuracy: 0.8179166666666666\n",
      "Epoch: 40, Loss: 0.5623034238815308, Validation Accuracy: 0.8026666666666666\n",
      "Epoch: 41, Loss: 0.5807415843009949, Validation Accuracy: 0.7968333333333333\n",
      "Epoch: 42, Loss: 0.6035856008529663, Validation Accuracy: 0.7879166666666667\n",
      "Epoch: 43, Loss: 0.6101585030555725, Validation Accuracy: 0.8010833333333334\n",
      "Epoch: 44, Loss: 0.5916316509246826, Validation Accuracy: 0.80975\n",
      "Epoch: 45, Loss: 0.5595090985298157, Validation Accuracy: 0.834\n",
      "Epoch: 46, Loss: 0.521604597568512, Validation Accuracy: 0.83875\n",
      "Epoch: 47, Loss: 0.49473562836647034, Validation Accuracy: 0.8531666666666666\n",
      "Epoch: 48, Loss: 0.4757535457611084, Validation Accuracy: 0.8526666666666667\n",
      "Epoch: 49, Loss: 0.4623722434043884, Validation Accuracy: 0.8609166666666667\n",
      "Epoch: 50, Loss: 0.4526579678058624, Validation Accuracy: 0.85925\n",
      "Epoch: 51, Loss: 0.4448324739933014, Validation Accuracy: 0.8653333333333333\n",
      "Epoch: 52, Loss: 0.43839260935783386, Validation Accuracy: 0.8640833333333333\n",
      "Epoch: 53, Loss: 0.4327133893966675, Validation Accuracy: 0.8688333333333333\n",
      "Epoch: 54, Loss: 0.4278193712234497, Validation Accuracy: 0.86725\n",
      "Epoch: 55, Loss: 0.4233153462409973, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 56, Loss: 0.41925525665283203, Validation Accuracy: 0.8704166666666666\n",
      "Epoch: 57, Loss: 0.41557201743125916, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 58, Loss: 0.41236889362335205, Validation Accuracy: 0.8718333333333333\n",
      "Epoch: 59, Loss: 0.4094860553741455, Validation Accuracy: 0.8743333333333333\n",
      "Epoch: 60, Loss: 0.40688231587409973, Validation Accuracy: 0.8724166666666666\n",
      "Epoch: 61, Loss: 0.40477365255355835, Validation Accuracy: 0.8760833333333333\n",
      "Epoch: 62, Loss: 0.40294620394706726, Validation Accuracy: 0.8735833333333334\n",
      "Epoch: 63, Loss: 0.40159788727760315, Validation Accuracy: 0.8763333333333333\n",
      "Epoch: 64, Loss: 0.400429904460907, Validation Accuracy: 0.8738333333333334\n",
      "Epoch: 65, Loss: 0.4000103771686554, Validation Accuracy: 0.876\n",
      "Epoch: 66, Loss: 0.3994722366333008, Validation Accuracy: 0.8733333333333333\n",
      "Epoch: 67, Loss: 0.39963001012802124, Validation Accuracy: 0.8759166666666667\n",
      "Epoch: 68, Loss: 0.39918971061706543, Validation Accuracy: 0.87375\n",
      "Epoch: 69, Loss: 0.3993503451347351, Validation Accuracy: 0.8765833333333334\n",
      "Epoch: 70, Loss: 0.398130863904953, Validation Accuracy: 0.87425\n",
      "Epoch: 71, Loss: 0.3970223665237427, Validation Accuracy: 0.8775833333333334\n",
      "Epoch: 72, Loss: 0.39416539669036865, Validation Accuracy: 0.87525\n",
      "Epoch: 73, Loss: 0.39098823070526123, Validation Accuracy: 0.8805833333333334\n",
      "Epoch: 74, Loss: 0.38636088371276855, Validation Accuracy: 0.878\n",
      "Epoch: 75, Loss: 0.3817947208881378, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 76, Loss: 0.3767450749874115, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 77, Loss: 0.3719826936721802, Validation Accuracy: 0.8874166666666666\n",
      "Epoch: 78, Loss: 0.3674582242965698, Validation Accuracy: 0.8840833333333333\n",
      "Epoch: 79, Loss: 0.36335232853889465, Validation Accuracy: 0.8896666666666667\n",
      "Epoch: 80, Loss: 0.3595269024372101, Validation Accuracy: 0.8879166666666667\n",
      "Epoch: 81, Loss: 0.35610848665237427, Validation Accuracy: 0.8904166666666666\n",
      "Epoch: 82, Loss: 0.3531879782676697, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 83, Loss: 0.3503713011741638, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 84, Loss: 0.34789490699768066, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 85, Loss: 0.34547269344329834, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 86, Loss: 0.3433528542518616, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 87, Loss: 0.34116730093955994, Validation Accuracy: 0.8945\n",
      "Epoch: 88, Loss: 0.3392207622528076, Validation Accuracy: 0.8954166666666666\n",
      "Epoch: 89, Loss: 0.33720678091049194, Validation Accuracy: 0.89575\n",
      "Epoch: 90, Loss: 0.33536890149116516, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 91, Loss: 0.3334917426109314, Validation Accuracy: 0.897\n",
      "Epoch: 92, Loss: 0.33174869418144226, Validation Accuracy: 0.89825\n",
      "Epoch: 93, Loss: 0.3299858868122101, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 94, Loss: 0.32836493849754333, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 95, Loss: 0.3267068564891815, Validation Accuracy: 0.8995\n",
      "Epoch: 96, Loss: 0.3251931667327881, Validation Accuracy: 0.8996666666666666\n",
      "Epoch: 97, Loss: 0.3236304819583893, Validation Accuracy: 0.90025\n",
      "Epoch: 98, Loss: 0.3221794664859772, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 99, Loss: 0.3206901550292969, Validation Accuracy: 0.9009166666666667\n",
      "Dataset 34\n",
      "Epoch: 0, Loss: 3.592707633972168, Validation Accuracy: 0.13008333333333333\n",
      "Epoch: 1, Loss: 3.9478557109832764, Validation Accuracy: 0.15966666666666668\n",
      "Epoch: 2, Loss: 2.7690258026123047, Validation Accuracy: 0.2735\n",
      "Epoch: 3, Loss: 2.257448673248291, Validation Accuracy: 0.3576666666666667\n",
      "Epoch: 4, Loss: 1.8570106029510498, Validation Accuracy: 0.4166666666666667\n",
      "Epoch: 5, Loss: 1.72223961353302, Validation Accuracy: 0.44766666666666666\n",
      "Epoch: 6, Loss: 1.6087830066680908, Validation Accuracy: 0.48675\n",
      "Epoch: 7, Loss: 1.5277032852172852, Validation Accuracy: 0.49191666666666667\n",
      "Epoch: 8, Loss: 1.4696135520935059, Validation Accuracy: 0.5416666666666666\n",
      "Epoch: 9, Loss: 1.4031915664672852, Validation Accuracy: 0.5483333333333333\n",
      "Epoch: 10, Loss: 1.337954044342041, Validation Accuracy: 0.6085833333333334\n",
      "Epoch: 11, Loss: 1.2053757905960083, Validation Accuracy: 0.6461666666666667\n",
      "Epoch: 12, Loss: 1.0881139039993286, Validation Accuracy: 0.6918333333333333\n",
      "Epoch: 13, Loss: 0.9810832738876343, Validation Accuracy: 0.7046666666666667\n",
      "Epoch: 14, Loss: 0.9146224856376648, Validation Accuracy: 0.73625\n",
      "Epoch: 15, Loss: 0.8520138263702393, Validation Accuracy: 0.7390833333333333\n",
      "Epoch: 16, Loss: 0.8099492788314819, Validation Accuracy: 0.7605833333333333\n",
      "Epoch: 17, Loss: 0.7705869078636169, Validation Accuracy: 0.7573333333333333\n",
      "Epoch: 18, Loss: 0.7456967830657959, Validation Accuracy: 0.7718333333333334\n",
      "Epoch: 19, Loss: 0.7229419946670532, Validation Accuracy: 0.768\n",
      "Epoch: 20, Loss: 0.705825686454773, Validation Accuracy: 0.7785\n",
      "Epoch: 21, Loss: 0.6932380199432373, Validation Accuracy: 0.7775833333333333\n",
      "Epoch: 22, Loss: 0.6709502339363098, Validation Accuracy: 0.7883333333333333\n",
      "Epoch: 23, Loss: 0.6590840220451355, Validation Accuracy: 0.79325\n",
      "Epoch: 24, Loss: 0.6333088278770447, Validation Accuracy: 0.799\n",
      "Epoch: 25, Loss: 0.6244887113571167, Validation Accuracy: 0.8049166666666666\n",
      "Epoch: 26, Loss: 0.603319525718689, Validation Accuracy: 0.8098333333333333\n",
      "Epoch: 27, Loss: 0.6000528931617737, Validation Accuracy: 0.8130833333333334\n",
      "Epoch: 28, Loss: 0.5814161896705627, Validation Accuracy: 0.8175833333333333\n",
      "Epoch: 29, Loss: 0.580837607383728, Validation Accuracy: 0.8238333333333333\n",
      "Epoch: 30, Loss: 0.5571966171264648, Validation Accuracy: 0.82975\n",
      "Epoch: 31, Loss: 0.5516132712364197, Validation Accuracy: 0.8359166666666666\n",
      "Epoch: 32, Loss: 0.5251258611679077, Validation Accuracy: 0.8433333333333334\n",
      "Epoch: 33, Loss: 0.514432430267334, Validation Accuracy: 0.8454166666666667\n",
      "Epoch: 34, Loss: 0.4931071400642395, Validation Accuracy: 0.8559166666666667\n",
      "Epoch: 35, Loss: 0.48214957118034363, Validation Accuracy: 0.8544166666666667\n",
      "Epoch: 36, Loss: 0.4677242040634155, Validation Accuracy: 0.8611666666666666\n",
      "Epoch: 37, Loss: 0.4584241807460785, Validation Accuracy: 0.8620833333333333\n",
      "Epoch: 38, Loss: 0.4484586715698242, Validation Accuracy: 0.866\n",
      "Epoch: 39, Loss: 0.44107380509376526, Validation Accuracy: 0.8665\n",
      "Epoch: 40, Loss: 0.43366989493370056, Validation Accuracy: 0.8696666666666667\n",
      "Epoch: 41, Loss: 0.4275089502334595, Validation Accuracy: 0.8700833333333333\n",
      "Epoch: 42, Loss: 0.4215553402900696, Validation Accuracy: 0.8725833333333334\n",
      "Epoch: 43, Loss: 0.416238933801651, Validation Accuracy: 0.873\n",
      "Epoch: 44, Loss: 0.411118745803833, Validation Accuracy: 0.8765\n",
      "Epoch: 45, Loss: 0.40636447072029114, Validation Accuracy: 0.8758333333333334\n",
      "Epoch: 46, Loss: 0.4018113315105438, Validation Accuracy: 0.8786666666666667\n",
      "Epoch: 47, Loss: 0.3974863588809967, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 48, Loss: 0.3933476209640503, Validation Accuracy: 0.8805\n",
      "Epoch: 49, Loss: 0.38939738273620605, Validation Accuracy: 0.8800833333333333\n",
      "Epoch: 50, Loss: 0.3855805993080139, Validation Accuracy: 0.88225\n",
      "Epoch: 51, Loss: 0.3819287121295929, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 52, Loss: 0.3784027099609375, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 53, Loss: 0.375016450881958, Validation Accuracy: 0.88525\n",
      "Epoch: 54, Loss: 0.3717403709888458, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 55, Loss: 0.3685888350009918, Validation Accuracy: 0.88675\n",
      "Epoch: 56, Loss: 0.3655520975589752, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 57, Loss: 0.3626250922679901, Validation Accuracy: 0.88875\n",
      "Epoch: 58, Loss: 0.3597770631313324, Validation Accuracy: 0.8905\n",
      "Epoch: 59, Loss: 0.3570353090763092, Validation Accuracy: 0.8905\n",
      "Epoch: 60, Loss: 0.3543705344200134, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 61, Loss: 0.35179319977760315, Validation Accuracy: 0.8925833333333333\n",
      "Epoch: 62, Loss: 0.34926846623420715, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 63, Loss: 0.34684738516807556, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 64, Loss: 0.3444754183292389, Validation Accuracy: 0.8945\n",
      "Epoch: 65, Loss: 0.34220072627067566, Validation Accuracy: 0.8953333333333333\n",
      "Epoch: 66, Loss: 0.3400043249130249, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 67, Loss: 0.33784720301628113, Validation Accuracy: 0.89675\n",
      "Epoch: 68, Loss: 0.33576250076293945, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 69, Loss: 0.333724707365036, Validation Accuracy: 0.898\n",
      "Epoch: 70, Loss: 0.3317537009716034, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 71, Loss: 0.3298376202583313, Validation Accuracy: 0.89825\n",
      "Epoch: 72, Loss: 0.32800495624542236, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 73, Loss: 0.3261892795562744, Validation Accuracy: 0.89925\n",
      "Epoch: 74, Loss: 0.3244469463825226, Validation Accuracy: 0.9001666666666667\n",
      "Epoch: 75, Loss: 0.322704941034317, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 76, Loss: 0.3210175037384033, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 77, Loss: 0.31937506794929504, Validation Accuracy: 0.90125\n",
      "Epoch: 78, Loss: 0.3176690340042114, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 79, Loss: 0.3160473108291626, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 80, Loss: 0.31436923146247864, Validation Accuracy: 0.9025833333333333\n",
      "Epoch: 81, Loss: 0.31275784969329834, Validation Accuracy: 0.9035\n",
      "Epoch: 82, Loss: 0.3110451400279999, Validation Accuracy: 0.90325\n",
      "Epoch: 83, Loss: 0.3094973564147949, Validation Accuracy: 0.905\n",
      "Epoch: 84, Loss: 0.30780360102653503, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 85, Loss: 0.3062451481819153, Validation Accuracy: 0.906\n",
      "Epoch: 86, Loss: 0.30456942319869995, Validation Accuracy: 0.9054166666666666\n",
      "Epoch: 87, Loss: 0.30307307839393616, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 88, Loss: 0.3014809191226959, Validation Accuracy: 0.9061666666666667\n",
      "Epoch: 89, Loss: 0.29998865723609924, Validation Accuracy: 0.9073333333333333\n",
      "Epoch: 90, Loss: 0.2984376847743988, Validation Accuracy: 0.907\n",
      "Epoch: 91, Loss: 0.2969529926776886, Validation Accuracy: 0.9083333333333333\n",
      "Epoch: 92, Loss: 0.29541999101638794, Validation Accuracy: 0.9076666666666666\n",
      "Epoch: 93, Loss: 0.2939755320549011, Validation Accuracy: 0.909\n",
      "Epoch: 94, Loss: 0.2924560308456421, Validation Accuracy: 0.9085833333333333\n",
      "Epoch: 95, Loss: 0.2909952998161316, Validation Accuracy: 0.9094166666666667\n",
      "Epoch: 96, Loss: 0.2894877791404724, Validation Accuracy: 0.9090833333333334\n",
      "Epoch: 97, Loss: 0.288082480430603, Validation Accuracy: 0.9098333333333334\n",
      "Epoch: 98, Loss: 0.2866271436214447, Validation Accuracy: 0.9100833333333334\n",
      "Epoch: 99, Loss: 0.285256564617157, Validation Accuracy: 0.9105833333333333\n",
      "Dataset 35\n",
      "Epoch: 0, Loss: 2.678032398223877, Validation Accuracy: 0.2615\n",
      "Epoch: 1, Loss: 2.113299608230591, Validation Accuracy: 0.39058333333333334\n",
      "Epoch: 2, Loss: 1.813245415687561, Validation Accuracy: 0.4195\n",
      "Epoch: 3, Loss: 1.7813303470611572, Validation Accuracy: 0.36491666666666667\n",
      "Epoch: 4, Loss: 1.7760534286499023, Validation Accuracy: 0.5533333333333333\n",
      "Epoch: 5, Loss: 1.3489679098129272, Validation Accuracy: 0.5848333333333333\n",
      "Epoch: 6, Loss: 1.2322410345077515, Validation Accuracy: 0.6124166666666667\n",
      "Epoch: 7, Loss: 1.1468262672424316, Validation Accuracy: 0.6466666666666666\n",
      "Epoch: 8, Loss: 1.0545533895492554, Validation Accuracy: 0.67225\n",
      "Epoch: 9, Loss: 0.9751459956169128, Validation Accuracy: 0.6938333333333333\n",
      "Epoch: 10, Loss: 0.9206346273422241, Validation Accuracy: 0.6904166666666667\n",
      "Epoch: 11, Loss: 0.9059931635856628, Validation Accuracy: 0.7096666666666667\n",
      "Epoch: 12, Loss: 0.8641762733459473, Validation Accuracy: 0.6833333333333333\n",
      "Epoch: 13, Loss: 0.9095873832702637, Validation Accuracy: 0.7230833333333333\n",
      "Epoch: 14, Loss: 0.8378015160560608, Validation Accuracy: 0.7088333333333333\n",
      "Epoch: 15, Loss: 0.8438190221786499, Validation Accuracy: 0.735\n",
      "Epoch: 16, Loss: 0.8015514612197876, Validation Accuracy: 0.7515\n",
      "Epoch: 17, Loss: 0.7522157430648804, Validation Accuracy: 0.7525\n",
      "Epoch: 18, Loss: 0.7497691512107849, Validation Accuracy: 0.75925\n",
      "Epoch: 19, Loss: 0.7143650650978088, Validation Accuracy: 0.7774166666666666\n",
      "Epoch: 20, Loss: 0.678888738155365, Validation Accuracy: 0.7793333333333333\n",
      "Epoch: 21, Loss: 0.6499648094177246, Validation Accuracy: 0.7930833333333334\n",
      "Epoch: 22, Loss: 0.6163759231567383, Validation Accuracy: 0.8044166666666667\n",
      "Epoch: 23, Loss: 0.5916483402252197, Validation Accuracy: 0.8095\n",
      "Epoch: 24, Loss: 0.5692301988601685, Validation Accuracy: 0.8195833333333333\n",
      "Epoch: 25, Loss: 0.5488948225975037, Validation Accuracy: 0.8225\n",
      "Epoch: 26, Loss: 0.5372363924980164, Validation Accuracy: 0.83\n",
      "Epoch: 27, Loss: 0.5236719846725464, Validation Accuracy: 0.8293333333333334\n",
      "Epoch: 28, Loss: 0.5182515978813171, Validation Accuracy: 0.83675\n",
      "Epoch: 29, Loss: 0.5080946087837219, Validation Accuracy: 0.8360833333333333\n",
      "Epoch: 30, Loss: 0.5038083791732788, Validation Accuracy: 0.84175\n",
      "Epoch: 31, Loss: 0.493734210729599, Validation Accuracy: 0.8414166666666667\n",
      "Epoch: 32, Loss: 0.4874824583530426, Validation Accuracy: 0.8486666666666667\n",
      "Epoch: 33, Loss: 0.4760209619998932, Validation Accuracy: 0.8491666666666666\n",
      "Epoch: 34, Loss: 0.4676834046840668, Validation Accuracy: 0.8555\n",
      "Epoch: 35, Loss: 0.45606428384780884, Validation Accuracy: 0.8576666666666667\n",
      "Epoch: 36, Loss: 0.4469142258167267, Validation Accuracy: 0.8625833333333334\n",
      "Epoch: 37, Loss: 0.4366917610168457, Validation Accuracy: 0.8655\n",
      "Epoch: 38, Loss: 0.42844030261039734, Validation Accuracy: 0.86725\n",
      "Epoch: 39, Loss: 0.4202059805393219, Validation Accuracy: 0.8725\n",
      "Epoch: 40, Loss: 0.41313135623931885, Validation Accuracy: 0.87225\n",
      "Epoch: 41, Loss: 0.40645742416381836, Validation Accuracy: 0.8754166666666666\n",
      "Epoch: 42, Loss: 0.4005364179611206, Validation Accuracy: 0.8759166666666667\n",
      "Epoch: 43, Loss: 0.3950977027416229, Validation Accuracy: 0.879\n",
      "Epoch: 44, Loss: 0.390003502368927, Validation Accuracy: 0.8795\n",
      "Epoch: 45, Loss: 0.38532015681266785, Validation Accuracy: 0.8815\n",
      "Epoch: 46, Loss: 0.380969762802124, Validation Accuracy: 0.8825833333333334\n",
      "Epoch: 47, Loss: 0.3768405616283417, Validation Accuracy: 0.8849166666666667\n",
      "Epoch: 48, Loss: 0.3729870915412903, Validation Accuracy: 0.885\n",
      "Epoch: 49, Loss: 0.36932116746902466, Validation Accuracy: 0.88625\n",
      "Epoch: 50, Loss: 0.3659125566482544, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 51, Loss: 0.3625381290912628, Validation Accuracy: 0.888\n",
      "Epoch: 52, Loss: 0.3593354821205139, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 53, Loss: 0.35626232624053955, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 54, Loss: 0.3532792925834656, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 55, Loss: 0.35046935081481934, Validation Accuracy: 0.89025\n",
      "Epoch: 56, Loss: 0.3476862907409668, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 57, Loss: 0.3450312912464142, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 58, Loss: 0.34241971373558044, Validation Accuracy: 0.8953333333333333\n",
      "Epoch: 59, Loss: 0.33990976214408875, Validation Accuracy: 0.8943333333333333\n",
      "Epoch: 60, Loss: 0.33744683861732483, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 61, Loss: 0.3351006805896759, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 62, Loss: 0.3327292799949646, Validation Accuracy: 0.898\n",
      "Epoch: 63, Loss: 0.33050626516342163, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 64, Loss: 0.3282506465911865, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 65, Loss: 0.3261743485927582, Validation Accuracy: 0.898\n",
      "Epoch: 66, Loss: 0.324022114276886, Validation Accuracy: 0.8999166666666667\n",
      "Epoch: 67, Loss: 0.3220546543598175, Validation Accuracy: 0.8995\n",
      "Epoch: 68, Loss: 0.3199847340583801, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 69, Loss: 0.318125456571579, Validation Accuracy: 0.9005\n",
      "Epoch: 70, Loss: 0.3161527216434479, Validation Accuracy: 0.902\n",
      "Epoch: 71, Loss: 0.3143365979194641, Validation Accuracy: 0.9016666666666666\n",
      "Epoch: 72, Loss: 0.3124164044857025, Validation Accuracy: 0.90325\n",
      "Epoch: 73, Loss: 0.31061843037605286, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 74, Loss: 0.3087782859802246, Validation Accuracy: 0.9044166666666666\n",
      "Epoch: 75, Loss: 0.3070251941680908, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 76, Loss: 0.3052537441253662, Validation Accuracy: 0.9055833333333333\n",
      "Epoch: 77, Loss: 0.3035604655742645, Validation Accuracy: 0.90525\n",
      "Epoch: 78, Loss: 0.30185022950172424, Validation Accuracy: 0.9064166666666666\n",
      "Epoch: 79, Loss: 0.3002137541770935, Validation Accuracy: 0.90625\n",
      "Epoch: 80, Loss: 0.2985646426677704, Validation Accuracy: 0.9076666666666666\n",
      "Epoch: 81, Loss: 0.2969616949558258, Validation Accuracy: 0.908\n",
      "Epoch: 82, Loss: 0.29536333680152893, Validation Accuracy: 0.90875\n",
      "Epoch: 83, Loss: 0.2938159108161926, Validation Accuracy: 0.9093333333333333\n",
      "Epoch: 84, Loss: 0.2922815680503845, Validation Accuracy: 0.9096666666666666\n",
      "Epoch: 85, Loss: 0.29079440236091614, Validation Accuracy: 0.9105\n",
      "Epoch: 86, Loss: 0.28931811451911926, Validation Accuracy: 0.9106666666666666\n",
      "Epoch: 87, Loss: 0.28788238763809204, Validation Accuracy: 0.9110833333333334\n",
      "Epoch: 88, Loss: 0.28646770119667053, Validation Accuracy: 0.9114166666666667\n",
      "Epoch: 89, Loss: 0.2850889563560486, Validation Accuracy: 0.912\n",
      "Epoch: 90, Loss: 0.2837374806404114, Validation Accuracy: 0.9128333333333334\n",
      "Epoch: 91, Loss: 0.28240904211997986, Validation Accuracy: 0.9125833333333333\n",
      "Epoch: 92, Loss: 0.28109002113342285, Validation Accuracy: 0.9145\n",
      "Epoch: 93, Loss: 0.2797950506210327, Validation Accuracy: 0.9135833333333333\n",
      "Epoch: 94, Loss: 0.27853694558143616, Validation Accuracy: 0.9153333333333333\n",
      "Epoch: 95, Loss: 0.27730488777160645, Validation Accuracy: 0.9146666666666666\n",
      "Epoch: 96, Loss: 0.27608177065849304, Validation Accuracy: 0.9161666666666667\n",
      "Epoch: 97, Loss: 0.2748885750770569, Validation Accuracy: 0.91575\n",
      "Epoch: 98, Loss: 0.2737119197845459, Validation Accuracy: 0.9163333333333333\n",
      "Epoch: 99, Loss: 0.2725600004196167, Validation Accuracy: 0.9164166666666667\n",
      "Dataset 36\n",
      "Epoch: 0, Loss: 3.3928608894348145, Validation Accuracy: 0.19466666666666665\n",
      "Epoch: 1, Loss: 2.666790246963501, Validation Accuracy: 0.19066666666666668\n",
      "Epoch: 2, Loss: 2.586681365966797, Validation Accuracy: 0.3615\n",
      "Epoch: 3, Loss: 1.8799986839294434, Validation Accuracy: 0.4280833333333333\n",
      "Epoch: 4, Loss: 1.6262255907058716, Validation Accuracy: 0.53025\n",
      "Epoch: 5, Loss: 1.4338856935501099, Validation Accuracy: 0.56375\n",
      "Epoch: 6, Loss: 1.322015404701233, Validation Accuracy: 0.5955833333333334\n",
      "Epoch: 7, Loss: 1.2331551313400269, Validation Accuracy: 0.61525\n",
      "Epoch: 8, Loss: 1.159116506576538, Validation Accuracy: 0.6375\n",
      "Epoch: 9, Loss: 1.096333384513855, Validation Accuracy: 0.648\n",
      "Epoch: 10, Loss: 1.043252944946289, Validation Accuracy: 0.6651666666666667\n",
      "Epoch: 11, Loss: 1.0015219449996948, Validation Accuracy: 0.66725\n",
      "Epoch: 12, Loss: 0.9710182547569275, Validation Accuracy: 0.6698333333333333\n",
      "Epoch: 13, Loss: 0.9652133584022522, Validation Accuracy: 0.6545\n",
      "Epoch: 14, Loss: 0.9693408012390137, Validation Accuracy: 0.6433333333333333\n",
      "Epoch: 15, Loss: 1.0030394792556763, Validation Accuracy: 0.6445833333333333\n",
      "Epoch: 16, Loss: 0.963582456111908, Validation Accuracy: 0.67175\n",
      "Epoch: 17, Loss: 0.9018235802650452, Validation Accuracy: 0.71075\n",
      "Epoch: 18, Loss: 0.807353675365448, Validation Accuracy: 0.73\n",
      "Epoch: 19, Loss: 0.7480831146240234, Validation Accuracy: 0.75425\n",
      "Epoch: 20, Loss: 0.7026561498641968, Validation Accuracy: 0.76275\n",
      "Epoch: 21, Loss: 0.6711232662200928, Validation Accuracy: 0.7751666666666667\n",
      "Epoch: 22, Loss: 0.6451693773269653, Validation Accuracy: 0.7783333333333333\n",
      "Epoch: 23, Loss: 0.6243526339530945, Validation Accuracy: 0.7895833333333333\n",
      "Epoch: 24, Loss: 0.6063215136528015, Validation Accuracy: 0.7916666666666666\n",
      "Epoch: 25, Loss: 0.5916327834129333, Validation Accuracy: 0.7989166666666667\n",
      "Epoch: 26, Loss: 0.5786358118057251, Validation Accuracy: 0.801\n",
      "Epoch: 27, Loss: 0.5693727135658264, Validation Accuracy: 0.8055\n",
      "Epoch: 28, Loss: 0.5624570250511169, Validation Accuracy: 0.8056666666666666\n",
      "Epoch: 29, Loss: 0.5596726536750793, Validation Accuracy: 0.807\n",
      "Epoch: 30, Loss: 0.5610029697418213, Validation Accuracy: 0.8036666666666666\n",
      "Epoch: 31, Loss: 0.5652964115142822, Validation Accuracy: 0.8013333333333333\n",
      "Epoch: 32, Loss: 0.5763118863105774, Validation Accuracy: 0.8021666666666667\n",
      "Epoch: 33, Loss: 0.5746549367904663, Validation Accuracy: 0.7978333333333333\n",
      "Epoch: 34, Loss: 0.5836859941482544, Validation Accuracy: 0.81075\n",
      "Epoch: 35, Loss: 0.5520808696746826, Validation Accuracy: 0.8095\n",
      "Epoch: 36, Loss: 0.5459088087081909, Validation Accuracy: 0.8278333333333333\n",
      "Epoch: 37, Loss: 0.5092136859893799, Validation Accuracy: 0.8249166666666666\n",
      "Epoch: 38, Loss: 0.5012676119804382, Validation Accuracy: 0.83425\n",
      "Epoch: 39, Loss: 0.4810284376144409, Validation Accuracy: 0.8353333333333334\n",
      "Epoch: 40, Loss: 0.47559860348701477, Validation Accuracy: 0.83975\n",
      "Epoch: 41, Loss: 0.46513503789901733, Validation Accuracy: 0.83975\n",
      "Epoch: 42, Loss: 0.46035417914390564, Validation Accuracy: 0.844\n",
      "Epoch: 43, Loss: 0.45368659496307373, Validation Accuracy: 0.8449166666666666\n",
      "Epoch: 44, Loss: 0.4474985897541046, Validation Accuracy: 0.8504166666666667\n",
      "Epoch: 45, Loss: 0.44174471497535706, Validation Accuracy: 0.849\n",
      "Epoch: 46, Loss: 0.43341004848480225, Validation Accuracy: 0.8558333333333333\n",
      "Epoch: 47, Loss: 0.42653965950012207, Validation Accuracy: 0.8558333333333333\n",
      "Epoch: 48, Loss: 0.4169491231441498, Validation Accuracy: 0.8618333333333333\n",
      "Epoch: 49, Loss: 0.40942302346229553, Validation Accuracy: 0.86175\n",
      "Epoch: 50, Loss: 0.400624543428421, Validation Accuracy: 0.8674166666666666\n",
      "Epoch: 51, Loss: 0.39372408390045166, Validation Accuracy: 0.8678333333333333\n",
      "Epoch: 52, Loss: 0.38675063848495483, Validation Accuracy: 0.874\n",
      "Epoch: 53, Loss: 0.38096269965171814, Validation Accuracy: 0.8718333333333333\n",
      "Epoch: 54, Loss: 0.3755006492137909, Validation Accuracy: 0.8770833333333333\n",
      "Epoch: 55, Loss: 0.3708195388317108, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 56, Loss: 0.36643466353416443, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 57, Loss: 0.36256083846092224, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 58, Loss: 0.35888001322746277, Validation Accuracy: 0.88175\n",
      "Epoch: 59, Loss: 0.35543832182884216, Validation Accuracy: 0.882\n",
      "Epoch: 60, Loss: 0.352225124835968, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 61, Loss: 0.3491615056991577, Validation Accuracy: 0.8851666666666667\n",
      "Epoch: 62, Loss: 0.34624990820884705, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 63, Loss: 0.34346210956573486, Validation Accuracy: 0.8866666666666667\n",
      "Epoch: 64, Loss: 0.3407922685146332, Validation Accuracy: 0.88775\n",
      "Epoch: 65, Loss: 0.3382202088832855, Validation Accuracy: 0.888\n",
      "Epoch: 66, Loss: 0.3357372581958771, Validation Accuracy: 0.8889166666666667\n",
      "Epoch: 67, Loss: 0.3333263397216797, Validation Accuracy: 0.8895\n",
      "Epoch: 68, Loss: 0.330974817276001, Validation Accuracy: 0.89\n",
      "Epoch: 69, Loss: 0.3286929726600647, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 70, Loss: 0.32647475600242615, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 71, Loss: 0.3243273198604584, Validation Accuracy: 0.89225\n",
      "Epoch: 72, Loss: 0.3222322463989258, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 73, Loss: 0.3202008605003357, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 74, Loss: 0.3182217478752136, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 75, Loss: 0.31629040837287903, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 76, Loss: 0.31440311670303345, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 77, Loss: 0.3125576674938202, Validation Accuracy: 0.89625\n",
      "Epoch: 78, Loss: 0.3107507526874542, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 79, Loss: 0.308983713388443, Validation Accuracy: 0.89725\n",
      "Epoch: 80, Loss: 0.30726388096809387, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 81, Loss: 0.3055824935436249, Validation Accuracy: 0.89825\n",
      "Epoch: 82, Loss: 0.30393338203430176, Validation Accuracy: 0.8985\n",
      "Epoch: 83, Loss: 0.3023151755332947, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 84, Loss: 0.30073216557502747, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 85, Loss: 0.2991771996021271, Validation Accuracy: 0.8996666666666666\n",
      "Epoch: 86, Loss: 0.29764851927757263, Validation Accuracy: 0.9003333333333333\n",
      "Epoch: 87, Loss: 0.29614731669425964, Validation Accuracy: 0.9008333333333334\n",
      "Epoch: 88, Loss: 0.2946746349334717, Validation Accuracy: 0.90125\n",
      "Epoch: 89, Loss: 0.29322975873947144, Validation Accuracy: 0.902\n",
      "Epoch: 90, Loss: 0.29180946946144104, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 91, Loss: 0.290415495634079, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 92, Loss: 0.28904569149017334, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 93, Loss: 0.2876965403556824, Validation Accuracy: 0.9046666666666666\n",
      "Epoch: 94, Loss: 0.28637221455574036, Validation Accuracy: 0.9046666666666666\n",
      "Epoch: 95, Loss: 0.285072386264801, Validation Accuracy: 0.9056666666666666\n",
      "Epoch: 96, Loss: 0.28379592299461365, Validation Accuracy: 0.9056666666666666\n",
      "Epoch: 97, Loss: 0.28253862261772156, Validation Accuracy: 0.9063333333333333\n",
      "Epoch: 98, Loss: 0.28130099177360535, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 99, Loss: 0.28008216619491577, Validation Accuracy: 0.9065833333333333\n",
      "Dataset 37\n",
      "Epoch: 0, Loss: 3.405500650405884, Validation Accuracy: 0.17416666666666666\n",
      "Epoch: 1, Loss: 3.7120440006256104, Validation Accuracy: 0.29541666666666666\n",
      "Epoch: 2, Loss: 1.948451042175293, Validation Accuracy: 0.4270833333333333\n",
      "Epoch: 3, Loss: 1.6992021799087524, Validation Accuracy: 0.49325\n",
      "Epoch: 4, Loss: 1.5326942205429077, Validation Accuracy: 0.53\n",
      "Epoch: 5, Loss: 1.3975099325180054, Validation Accuracy: 0.5770833333333333\n",
      "Epoch: 6, Loss: 1.2921589612960815, Validation Accuracy: 0.5995\n",
      "Epoch: 7, Loss: 1.2007322311401367, Validation Accuracy: 0.6281666666666667\n",
      "Epoch: 8, Loss: 1.1297516822814941, Validation Accuracy: 0.6409166666666667\n",
      "Epoch: 9, Loss: 1.0683751106262207, Validation Accuracy: 0.6515833333333333\n",
      "Epoch: 10, Loss: 1.0459309816360474, Validation Accuracy: 0.656\n",
      "Epoch: 11, Loss: 1.0138804912567139, Validation Accuracy: 0.64175\n",
      "Epoch: 12, Loss: 1.0407419204711914, Validation Accuracy: 0.6820833333333334\n",
      "Epoch: 13, Loss: 0.9266919493675232, Validation Accuracy: 0.6960833333333334\n",
      "Epoch: 14, Loss: 0.8877902030944824, Validation Accuracy: 0.73575\n",
      "Epoch: 15, Loss: 0.781821072101593, Validation Accuracy: 0.7570833333333333\n",
      "Epoch: 16, Loss: 0.7414134740829468, Validation Accuracy: 0.7648333333333334\n",
      "Epoch: 17, Loss: 0.6979496479034424, Validation Accuracy: 0.7804166666666666\n",
      "Epoch: 18, Loss: 0.6735833287239075, Validation Accuracy: 0.78025\n",
      "Epoch: 19, Loss: 0.6501038670539856, Validation Accuracy: 0.7940833333333334\n",
      "Epoch: 20, Loss: 0.6331422328948975, Validation Accuracy: 0.7908333333333334\n",
      "Epoch: 21, Loss: 0.6197238564491272, Validation Accuracy: 0.8031666666666667\n",
      "Epoch: 22, Loss: 0.6065931916236877, Validation Accuracy: 0.7976666666666666\n",
      "Epoch: 23, Loss: 0.6015603542327881, Validation Accuracy: 0.8051666666666667\n",
      "Epoch: 24, Loss: 0.5910805463790894, Validation Accuracy: 0.7969166666666667\n",
      "Epoch: 25, Loss: 0.5958490967750549, Validation Accuracy: 0.8048333333333333\n",
      "Epoch: 26, Loss: 0.5889220833778381, Validation Accuracy: 0.79175\n",
      "Epoch: 27, Loss: 0.5994239449501038, Validation Accuracy: 0.79875\n",
      "Epoch: 28, Loss: 0.5970674157142639, Validation Accuracy: 0.7883333333333333\n",
      "Epoch: 29, Loss: 0.6004157066345215, Validation Accuracy: 0.7943333333333333\n",
      "Epoch: 30, Loss: 0.6006490588188171, Validation Accuracy: 0.7956666666666666\n",
      "Epoch: 31, Loss: 0.583656370639801, Validation Accuracy: 0.8040833333333334\n",
      "Epoch: 32, Loss: 0.5733940601348877, Validation Accuracy: 0.812\n",
      "Epoch: 33, Loss: 0.5423828363418579, Validation Accuracy: 0.8221666666666667\n",
      "Epoch: 34, Loss: 0.5210024118423462, Validation Accuracy: 0.8363333333333334\n",
      "Epoch: 35, Loss: 0.49432772397994995, Validation Accuracy: 0.8399166666666666\n",
      "Epoch: 36, Loss: 0.475833535194397, Validation Accuracy: 0.8485833333333334\n",
      "Epoch: 37, Loss: 0.4598935544490814, Validation Accuracy: 0.8525\n",
      "Epoch: 38, Loss: 0.44774898886680603, Validation Accuracy: 0.8579166666666667\n",
      "Epoch: 39, Loss: 0.4380919635295868, Validation Accuracy: 0.86025\n",
      "Epoch: 40, Loss: 0.42990782856941223, Validation Accuracy: 0.8638333333333333\n",
      "Epoch: 41, Loss: 0.42298364639282227, Validation Accuracy: 0.8649166666666667\n",
      "Epoch: 42, Loss: 0.4168233573436737, Validation Accuracy: 0.8681666666666666\n",
      "Epoch: 43, Loss: 0.41114041209220886, Validation Accuracy: 0.8686666666666667\n",
      "Epoch: 44, Loss: 0.4059630036354065, Validation Accuracy: 0.87025\n",
      "Epoch: 45, Loss: 0.4009973406791687, Validation Accuracy: 0.8708333333333333\n",
      "Epoch: 46, Loss: 0.396383136510849, Validation Accuracy: 0.8735833333333334\n",
      "Epoch: 47, Loss: 0.3919515907764435, Validation Accuracy: 0.8740833333333333\n",
      "Epoch: 48, Loss: 0.3877224624156952, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 49, Loss: 0.3837082087993622, Validation Accuracy: 0.8761666666666666\n",
      "Epoch: 50, Loss: 0.3798145651817322, Validation Accuracy: 0.8795833333333334\n",
      "Epoch: 51, Loss: 0.37611693143844604, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 52, Loss: 0.37253594398498535, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 53, Loss: 0.36908969283103943, Validation Accuracy: 0.8813333333333333\n",
      "Epoch: 54, Loss: 0.36574292182922363, Validation Accuracy: 0.88425\n",
      "Epoch: 55, Loss: 0.36250853538513184, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 56, Loss: 0.3593798875808716, Validation Accuracy: 0.88575\n",
      "Epoch: 57, Loss: 0.3563595712184906, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 58, Loss: 0.3534087836742401, Validation Accuracy: 0.88725\n",
      "Epoch: 59, Loss: 0.35055437684059143, Validation Accuracy: 0.88775\n",
      "Epoch: 60, Loss: 0.34777817130088806, Validation Accuracy: 0.8895\n",
      "Epoch: 61, Loss: 0.3450862169265747, Validation Accuracy: 0.8886666666666667\n",
      "Epoch: 62, Loss: 0.3424641191959381, Validation Accuracy: 0.8915\n",
      "Epoch: 63, Loss: 0.3399043083190918, Validation Accuracy: 0.88975\n",
      "Epoch: 64, Loss: 0.337401807308197, Validation Accuracy: 0.8926666666666667\n",
      "Epoch: 65, Loss: 0.3349711000919342, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 66, Loss: 0.3326033353805542, Validation Accuracy: 0.8939166666666667\n",
      "Epoch: 67, Loss: 0.3303002417087555, Validation Accuracy: 0.8925\n",
      "Epoch: 68, Loss: 0.3280259370803833, Validation Accuracy: 0.8945\n",
      "Epoch: 69, Loss: 0.3258252441883087, Validation Accuracy: 0.89375\n",
      "Epoch: 70, Loss: 0.32366928458213806, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 71, Loss: 0.3215397894382477, Validation Accuracy: 0.89475\n",
      "Epoch: 72, Loss: 0.3194672763347626, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 73, Loss: 0.31743818521499634, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 74, Loss: 0.315452516078949, Validation Accuracy: 0.89775\n",
      "Epoch: 75, Loss: 0.3135019540786743, Validation Accuracy: 0.8966666666666666\n",
      "Epoch: 76, Loss: 0.31160199642181396, Validation Accuracy: 0.8983333333333333\n",
      "Epoch: 77, Loss: 0.30973729491233826, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 78, Loss: 0.30791276693344116, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 79, Loss: 0.3060911297798157, Validation Accuracy: 0.899\n",
      "Epoch: 80, Loss: 0.30432695150375366, Validation Accuracy: 0.89975\n",
      "Epoch: 81, Loss: 0.3025698661804199, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 82, Loss: 0.30085858702659607, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 83, Loss: 0.2991648018360138, Validation Accuracy: 0.9001666666666667\n",
      "Epoch: 84, Loss: 0.2975173592567444, Validation Accuracy: 0.9016666666666666\n",
      "Epoch: 85, Loss: 0.2959039807319641, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 86, Loss: 0.2943328022956848, Validation Accuracy: 0.9023333333333333\n",
      "Epoch: 87, Loss: 0.29278764128685, Validation Accuracy: 0.9015\n",
      "Epoch: 88, Loss: 0.29126864671707153, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 89, Loss: 0.2897738218307495, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 90, Loss: 0.28829607367515564, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 91, Loss: 0.2868558466434479, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 92, Loss: 0.28543198108673096, Validation Accuracy: 0.904\n",
      "Epoch: 93, Loss: 0.2840324342250824, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 94, Loss: 0.2826499044895172, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 95, Loss: 0.28127869963645935, Validation Accuracy: 0.9046666666666666\n",
      "Epoch: 96, Loss: 0.2799369692802429, Validation Accuracy: 0.9059166666666667\n",
      "Epoch: 97, Loss: 0.2786138653755188, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 98, Loss: 0.2773195505142212, Validation Accuracy: 0.9064166666666666\n",
      "Epoch: 99, Loss: 0.2760452628135681, Validation Accuracy: 0.9058333333333334\n",
      "Dataset 38\n",
      "Epoch: 0, Loss: 3.7474489212036133, Validation Accuracy: 0.11741666666666667\n",
      "Epoch: 1, Loss: 3.842010736465454, Validation Accuracy: 0.2625\n",
      "Epoch: 2, Loss: 2.355604648590088, Validation Accuracy: 0.3169166666666667\n",
      "Epoch: 3, Loss: 2.0773849487304688, Validation Accuracy: 0.25383333333333336\n",
      "Epoch: 4, Loss: 2.3013765811920166, Validation Accuracy: 0.16133333333333333\n",
      "Epoch: 5, Loss: 3.7828359603881836, Validation Accuracy: 0.18641666666666667\n",
      "Epoch: 6, Loss: 2.2140095233917236, Validation Accuracy: 0.2916666666666667\n",
      "Epoch: 7, Loss: 1.9961689710617065, Validation Accuracy: 0.39258333333333334\n",
      "Epoch: 8, Loss: 1.8582383394241333, Validation Accuracy: 0.41925\n",
      "Epoch: 9, Loss: 1.7624717950820923, Validation Accuracy: 0.4355833333333333\n",
      "Epoch: 10, Loss: 1.6945940256118774, Validation Accuracy: 0.4535\n",
      "Epoch: 11, Loss: 1.6335244178771973, Validation Accuracy: 0.4661666666666667\n",
      "Epoch: 12, Loss: 1.5761539936065674, Validation Accuracy: 0.48191666666666666\n",
      "Epoch: 13, Loss: 1.5210411548614502, Validation Accuracy: 0.4955833333333333\n",
      "Epoch: 14, Loss: 1.4672070741653442, Validation Accuracy: 0.5128333333333334\n",
      "Epoch: 15, Loss: 1.4142470359802246, Validation Accuracy: 0.5306666666666666\n",
      "Epoch: 16, Loss: 1.3614795207977295, Validation Accuracy: 0.5483333333333333\n",
      "Epoch: 17, Loss: 1.3088663816452026, Validation Accuracy: 0.5660833333333334\n",
      "Epoch: 18, Loss: 1.2562382221221924, Validation Accuracy: 0.5895833333333333\n",
      "Epoch: 19, Loss: 1.2036340236663818, Validation Accuracy: 0.6035\n",
      "Epoch: 20, Loss: 1.1510746479034424, Validation Accuracy: 0.6378333333333334\n",
      "Epoch: 21, Loss: 1.0989346504211426, Validation Accuracy: 0.6595833333333333\n",
      "Epoch: 22, Loss: 1.0469279289245605, Validation Accuracy: 0.69275\n",
      "Epoch: 23, Loss: 0.9966030120849609, Validation Accuracy: 0.7106666666666667\n",
      "Epoch: 24, Loss: 0.9484036564826965, Validation Accuracy: 0.7298333333333333\n",
      "Epoch: 25, Loss: 0.9074479937553406, Validation Accuracy: 0.7244166666666667\n",
      "Epoch: 26, Loss: 0.8755426406860352, Validation Accuracy: 0.7270833333333333\n",
      "Epoch: 27, Loss: 0.8658204078674316, Validation Accuracy: 0.7099166666666666\n",
      "Epoch: 28, Loss: 0.8640826940536499, Validation Accuracy: 0.6998333333333333\n",
      "Epoch: 29, Loss: 0.8901017308235168, Validation Accuracy: 0.7048333333333333\n",
      "Epoch: 30, Loss: 0.8615006804466248, Validation Accuracy: 0.7091666666666666\n",
      "Epoch: 31, Loss: 0.841888427734375, Validation Accuracy: 0.7380833333333333\n",
      "Epoch: 32, Loss: 0.7721027731895447, Validation Accuracy: 0.74575\n",
      "Epoch: 33, Loss: 0.7577028870582581, Validation Accuracy: 0.7480833333333333\n",
      "Epoch: 34, Loss: 0.736272394657135, Validation Accuracy: 0.741\n",
      "Epoch: 35, Loss: 0.7646010518074036, Validation Accuracy: 0.72825\n",
      "Epoch: 36, Loss: 0.7642176747322083, Validation Accuracy: 0.7350833333333333\n",
      "Epoch: 37, Loss: 0.7755051255226135, Validation Accuracy: 0.7418333333333333\n",
      "Epoch: 38, Loss: 0.7350084781646729, Validation Accuracy: 0.7821666666666667\n",
      "Epoch: 39, Loss: 0.6519490480422974, Validation Accuracy: 0.8075\n",
      "Epoch: 40, Loss: 0.5927228927612305, Validation Accuracy: 0.8185\n",
      "Epoch: 41, Loss: 0.5572869181632996, Validation Accuracy: 0.8271666666666667\n",
      "Epoch: 42, Loss: 0.536807119846344, Validation Accuracy: 0.83025\n",
      "Epoch: 43, Loss: 0.5237177014350891, Validation Accuracy: 0.8335\n",
      "Epoch: 44, Loss: 0.5128146409988403, Validation Accuracy: 0.83625\n",
      "Epoch: 45, Loss: 0.5037642121315002, Validation Accuracy: 0.8385833333333333\n",
      "Epoch: 46, Loss: 0.4954914152622223, Validation Accuracy: 0.8419166666666666\n",
      "Epoch: 47, Loss: 0.48829159140586853, Validation Accuracy: 0.8434166666666667\n",
      "Epoch: 48, Loss: 0.4817779064178467, Validation Accuracy: 0.8453333333333334\n",
      "Epoch: 49, Loss: 0.47607824206352234, Validation Accuracy: 0.8473333333333334\n",
      "Epoch: 50, Loss: 0.471214234828949, Validation Accuracy: 0.8475833333333334\n",
      "Epoch: 51, Loss: 0.46720650792121887, Validation Accuracy: 0.8488333333333333\n",
      "Epoch: 52, Loss: 0.4643801748752594, Validation Accuracy: 0.8491666666666666\n",
      "Epoch: 53, Loss: 0.4623147249221802, Validation Accuracy: 0.8491666666666666\n",
      "Epoch: 54, Loss: 0.46228519082069397, Validation Accuracy: 0.8485833333333334\n",
      "Epoch: 55, Loss: 0.46233218908309937, Validation Accuracy: 0.8451666666666666\n",
      "Epoch: 56, Loss: 0.46591606736183167, Validation Accuracy: 0.8451666666666666\n",
      "Epoch: 57, Loss: 0.4673939645290375, Validation Accuracy: 0.8420833333333333\n",
      "Epoch: 58, Loss: 0.4737900495529175, Validation Accuracy: 0.8415833333333333\n",
      "Epoch: 59, Loss: 0.4722638428211212, Validation Accuracy: 0.8395833333333333\n",
      "Epoch: 60, Loss: 0.4769499897956848, Validation Accuracy: 0.843\n",
      "Epoch: 61, Loss: 0.4666385054588318, Validation Accuracy: 0.8448333333333333\n",
      "Epoch: 62, Loss: 0.4630555510520935, Validation Accuracy: 0.85175\n",
      "Epoch: 63, Loss: 0.44564396142959595, Validation Accuracy: 0.8576666666666667\n",
      "Epoch: 64, Loss: 0.4359041452407837, Validation Accuracy: 0.8626666666666667\n",
      "Epoch: 65, Loss: 0.42079466581344604, Validation Accuracy: 0.8694166666666666\n",
      "Epoch: 66, Loss: 0.4121139645576477, Validation Accuracy: 0.8718333333333333\n",
      "Epoch: 67, Loss: 0.40277355909347534, Validation Accuracy: 0.8754166666666666\n",
      "Epoch: 68, Loss: 0.39675599336624146, Validation Accuracy: 0.87725\n",
      "Epoch: 69, Loss: 0.3908707797527313, Validation Accuracy: 0.8795\n",
      "Epoch: 70, Loss: 0.38638269901275635, Validation Accuracy: 0.8805833333333334\n",
      "Epoch: 71, Loss: 0.3822229504585266, Validation Accuracy: 0.8824166666666666\n",
      "Epoch: 72, Loss: 0.37857645750045776, Validation Accuracy: 0.8841666666666667\n",
      "Epoch: 73, Loss: 0.3751605153083801, Validation Accuracy: 0.8845833333333334\n",
      "Epoch: 74, Loss: 0.37200927734375, Validation Accuracy: 0.8864166666666666\n",
      "Epoch: 75, Loss: 0.3689895570278168, Validation Accuracy: 0.8859166666666667\n",
      "Epoch: 76, Loss: 0.3661743998527527, Validation Accuracy: 0.888\n",
      "Epoch: 77, Loss: 0.3634134829044342, Validation Accuracy: 0.8876666666666667\n",
      "Epoch: 78, Loss: 0.3608253598213196, Validation Accuracy: 0.88975\n",
      "Epoch: 79, Loss: 0.3582780063152313, Validation Accuracy: 0.8896666666666667\n",
      "Epoch: 80, Loss: 0.35585489869117737, Validation Accuracy: 0.89125\n",
      "Epoch: 81, Loss: 0.3534573018550873, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 82, Loss: 0.3511647582054138, Validation Accuracy: 0.8925833333333333\n",
      "Epoch: 83, Loss: 0.34890103340148926, Validation Accuracy: 0.8925833333333333\n",
      "Epoch: 84, Loss: 0.3467145562171936, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 85, Loss: 0.34459158778190613, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 86, Loss: 0.3425193130970001, Validation Accuracy: 0.89475\n",
      "Epoch: 87, Loss: 0.34046944975852966, Validation Accuracy: 0.8954166666666666\n",
      "Epoch: 88, Loss: 0.3384837806224823, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 89, Loss: 0.33652031421661377, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 90, Loss: 0.33461788296699524, Validation Accuracy: 0.8963333333333333\n",
      "Epoch: 91, Loss: 0.3327431380748749, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 92, Loss: 0.33092159032821655, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 93, Loss: 0.32911935448646545, Validation Accuracy: 0.8986666666666666\n",
      "Epoch: 94, Loss: 0.3273480534553528, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 95, Loss: 0.32560503482818604, Validation Accuracy: 0.9\n",
      "Epoch: 96, Loss: 0.32390135526657104, Validation Accuracy: 0.89875\n",
      "Epoch: 97, Loss: 0.3221989870071411, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 98, Loss: 0.32053524255752563, Validation Accuracy: 0.9\n",
      "Epoch: 99, Loss: 0.3188803791999817, Validation Accuracy: 0.902\n",
      "Dataset 39\n",
      "Epoch: 0, Loss: 3.449162721633911, Validation Accuracy: 0.1335\n",
      "Epoch: 1, Loss: 3.348282814025879, Validation Accuracy: 0.19075\n",
      "Epoch: 2, Loss: 3.465637683868408, Validation Accuracy: 0.2375\n",
      "Epoch: 3, Loss: 2.4466161727905273, Validation Accuracy: 0.33025\n",
      "Epoch: 4, Loss: 2.1147520542144775, Validation Accuracy: 0.31808333333333333\n",
      "Epoch: 5, Loss: 1.9306931495666504, Validation Accuracy: 0.4370833333333333\n",
      "Epoch: 6, Loss: 1.711431860923767, Validation Accuracy: 0.47941666666666666\n",
      "Epoch: 7, Loss: 1.5766831636428833, Validation Accuracy: 0.5025833333333334\n",
      "Epoch: 8, Loss: 1.4756269454956055, Validation Accuracy: 0.5205833333333333\n",
      "Epoch: 9, Loss: 1.3953373432159424, Validation Accuracy: 0.5439166666666667\n",
      "Epoch: 10, Loss: 1.3177603483200073, Validation Accuracy: 0.5784166666666667\n",
      "Epoch: 11, Loss: 1.2400033473968506, Validation Accuracy: 0.6100833333333333\n",
      "Epoch: 12, Loss: 1.1629620790481567, Validation Accuracy: 0.6409166666666667\n",
      "Epoch: 13, Loss: 1.0880423784255981, Validation Accuracy: 0.6686666666666666\n",
      "Epoch: 14, Loss: 1.017185926437378, Validation Accuracy: 0.69325\n",
      "Epoch: 15, Loss: 0.9520686864852905, Validation Accuracy: 0.7164166666666667\n",
      "Epoch: 16, Loss: 0.8944900631904602, Validation Accuracy: 0.7341666666666666\n",
      "Epoch: 17, Loss: 0.8455114960670471, Validation Accuracy: 0.7449166666666667\n",
      "Epoch: 18, Loss: 0.8044270277023315, Validation Accuracy: 0.755\n",
      "Epoch: 19, Loss: 0.7693093419075012, Validation Accuracy: 0.7660833333333333\n",
      "Epoch: 20, Loss: 0.7387152314186096, Validation Accuracy: 0.7738333333333334\n",
      "Epoch: 21, Loss: 0.7118008732795715, Validation Accuracy: 0.7801666666666667\n",
      "Epoch: 22, Loss: 0.687930166721344, Validation Accuracy: 0.7899166666666667\n",
      "Epoch: 23, Loss: 0.6667718291282654, Validation Accuracy: 0.7936666666666666\n",
      "Epoch: 24, Loss: 0.6485633254051208, Validation Accuracy: 0.79975\n",
      "Epoch: 25, Loss: 0.6350935697555542, Validation Accuracy: 0.7965833333333333\n",
      "Epoch: 26, Loss: 0.6289645433425903, Validation Accuracy: 0.79475\n",
      "Epoch: 27, Loss: 0.643777072429657, Validation Accuracy: 0.77325\n",
      "Epoch: 28, Loss: 0.6848461031913757, Validation Accuracy: 0.7195833333333334\n",
      "Epoch: 29, Loss: 0.8455082178115845, Validation Accuracy: 0.7005833333333333\n",
      "Epoch: 30, Loss: 0.8699021935462952, Validation Accuracy: 0.6915\n",
      "Epoch: 31, Loss: 0.9666158556938171, Validation Accuracy: 0.8061666666666667\n",
      "Epoch: 32, Loss: 0.619356095790863, Validation Accuracy: 0.8264166666666667\n",
      "Epoch: 33, Loss: 0.5604449510574341, Validation Accuracy: 0.8335\n",
      "Epoch: 34, Loss: 0.5397352576255798, Validation Accuracy: 0.8343333333333334\n",
      "Epoch: 35, Loss: 0.5279807448387146, Validation Accuracy: 0.8400833333333333\n",
      "Epoch: 36, Loss: 0.5186395049095154, Validation Accuracy: 0.8405\n",
      "Epoch: 37, Loss: 0.5102869272232056, Validation Accuracy: 0.84375\n",
      "Epoch: 38, Loss: 0.5041036605834961, Validation Accuracy: 0.84425\n",
      "Epoch: 39, Loss: 0.49738213419914246, Validation Accuracy: 0.846\n",
      "Epoch: 40, Loss: 0.4931027889251709, Validation Accuracy: 0.8469166666666667\n",
      "Epoch: 41, Loss: 0.48729023337364197, Validation Accuracy: 0.8483333333333334\n",
      "Epoch: 42, Loss: 0.4845007658004761, Validation Accuracy: 0.8506666666666667\n",
      "Epoch: 43, Loss: 0.4785063862800598, Validation Accuracy: 0.8494166666666667\n",
      "Epoch: 44, Loss: 0.47568896412849426, Validation Accuracy: 0.8531666666666666\n",
      "Epoch: 45, Loss: 0.46881774067878723, Validation Accuracy: 0.85375\n",
      "Epoch: 46, Loss: 0.46520185470581055, Validation Accuracy: 0.8565\n",
      "Epoch: 47, Loss: 0.4574211537837982, Validation Accuracy: 0.8578333333333333\n",
      "Epoch: 48, Loss: 0.452831506729126, Validation Accuracy: 0.8608333333333333\n",
      "Epoch: 49, Loss: 0.4448072016239166, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 50, Loss: 0.43943318724632263, Validation Accuracy: 0.86525\n",
      "Epoch: 51, Loss: 0.4323248565196991, Validation Accuracy: 0.8674166666666666\n",
      "Epoch: 52, Loss: 0.42704519629478455, Validation Accuracy: 0.8695833333333334\n",
      "Epoch: 53, Loss: 0.4210546910762787, Validation Accuracy: 0.8704166666666666\n",
      "Epoch: 54, Loss: 0.4163200557231903, Validation Accuracy: 0.8729166666666667\n",
      "Epoch: 55, Loss: 0.41128620505332947, Validation Accuracy: 0.87425\n",
      "Epoch: 56, Loss: 0.40709349513053894, Validation Accuracy: 0.8751666666666666\n",
      "Epoch: 57, Loss: 0.40288016200065613, Validation Accuracy: 0.877\n",
      "Epoch: 58, Loss: 0.39917391538619995, Validation Accuracy: 0.8776666666666667\n",
      "Epoch: 59, Loss: 0.39543598890304565, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 60, Loss: 0.39206722378730774, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 61, Loss: 0.38873499631881714, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 62, Loss: 0.3856339156627655, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 63, Loss: 0.38258281350135803, Validation Accuracy: 0.884\n",
      "Epoch: 64, Loss: 0.37972989678382874, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 65, Loss: 0.37691980600357056, Validation Accuracy: 0.88625\n",
      "Epoch: 66, Loss: 0.37422817945480347, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 67, Loss: 0.37160196900367737, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 68, Loss: 0.3690722584724426, Validation Accuracy: 0.88725\n",
      "Epoch: 69, Loss: 0.3666223883628845, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 70, Loss: 0.3642309904098511, Validation Accuracy: 0.8890833333333333\n",
      "Epoch: 71, Loss: 0.3618960678577423, Validation Accuracy: 0.89075\n",
      "Epoch: 72, Loss: 0.35962793231010437, Validation Accuracy: 0.89125\n",
      "Epoch: 73, Loss: 0.3574056327342987, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 74, Loss: 0.355237752199173, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 75, Loss: 0.3531167507171631, Validation Accuracy: 0.89325\n",
      "Epoch: 76, Loss: 0.35104215145111084, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 77, Loss: 0.349005788564682, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 78, Loss: 0.34700310230255127, Validation Accuracy: 0.8944166666666666\n",
      "Epoch: 79, Loss: 0.3450496792793274, Validation Accuracy: 0.8953333333333333\n",
      "Epoch: 80, Loss: 0.34313175082206726, Validation Accuracy: 0.895\n",
      "Epoch: 81, Loss: 0.3412553369998932, Validation Accuracy: 0.8965\n",
      "Epoch: 82, Loss: 0.33940908312797546, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 83, Loss: 0.33759841322898865, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 84, Loss: 0.3358246684074402, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 85, Loss: 0.3340797424316406, Validation Accuracy: 0.898\n",
      "Epoch: 86, Loss: 0.33236435055732727, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 87, Loss: 0.3306892514228821, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 88, Loss: 0.3290315866470337, Validation Accuracy: 0.898\n",
      "Epoch: 89, Loss: 0.32741522789001465, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 90, Loss: 0.3258141577243805, Validation Accuracy: 0.8985\n",
      "Epoch: 91, Loss: 0.32425597310066223, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 92, Loss: 0.32271260023117065, Validation Accuracy: 0.899\n",
      "Epoch: 93, Loss: 0.3212052881717682, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 94, Loss: 0.3197101652622223, Validation Accuracy: 0.89975\n",
      "Epoch: 95, Loss: 0.3182516396045685, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 96, Loss: 0.31681156158447266, Validation Accuracy: 0.9\n",
      "Epoch: 97, Loss: 0.315403550863266, Validation Accuracy: 0.90275\n",
      "Epoch: 98, Loss: 0.31401586532592773, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 99, Loss: 0.3126767873764038, Validation Accuracy: 0.90375\n",
      "Dataset 40\n",
      "Epoch: 0, Loss: 3.860346794128418, Validation Accuracy: 0.22558333333333333\n",
      "Epoch: 1, Loss: 2.780909776687622, Validation Accuracy: 0.2215\n",
      "Epoch: 2, Loss: 2.664137601852417, Validation Accuracy: 0.22041666666666668\n",
      "Epoch: 3, Loss: 2.1668078899383545, Validation Accuracy: 0.32508333333333334\n",
      "Epoch: 4, Loss: 1.8994871377944946, Validation Accuracy: 0.37275\n",
      "Epoch: 5, Loss: 1.7837648391723633, Validation Accuracy: 0.41183333333333333\n",
      "Epoch: 6, Loss: 1.6794955730438232, Validation Accuracy: 0.4505\n",
      "Epoch: 7, Loss: 1.5694490671157837, Validation Accuracy: 0.5018333333333334\n",
      "Epoch: 8, Loss: 1.4546126127243042, Validation Accuracy: 0.5475\n",
      "Epoch: 9, Loss: 1.3460007905960083, Validation Accuracy: 0.58175\n",
      "Epoch: 10, Loss: 1.2514694929122925, Validation Accuracy: 0.6078333333333333\n",
      "Epoch: 11, Loss: 1.169710636138916, Validation Accuracy: 0.6310833333333333\n",
      "Epoch: 12, Loss: 1.0963438749313354, Validation Accuracy: 0.6506666666666666\n",
      "Epoch: 13, Loss: 1.0290138721466064, Validation Accuracy: 0.6709166666666667\n",
      "Epoch: 14, Loss: 0.9662127494812012, Validation Accuracy: 0.6915833333333333\n",
      "Epoch: 15, Loss: 0.907556414604187, Validation Accuracy: 0.713\n",
      "Epoch: 16, Loss: 0.8536588549613953, Validation Accuracy: 0.73075\n",
      "Epoch: 17, Loss: 0.8065217137336731, Validation Accuracy: 0.7465\n",
      "Epoch: 18, Loss: 0.7668953537940979, Validation Accuracy: 0.755\n",
      "Epoch: 19, Loss: 0.7347587943077087, Validation Accuracy: 0.7679166666666667\n",
      "Epoch: 20, Loss: 0.711142361164093, Validation Accuracy: 0.7628333333333334\n",
      "Epoch: 21, Loss: 0.7001957297325134, Validation Accuracy: 0.7543333333333333\n",
      "Epoch: 22, Loss: 0.7263355851173401, Validation Accuracy: 0.7183333333333334\n",
      "Epoch: 23, Loss: 0.8092117309570312, Validation Accuracy: 0.63575\n",
      "Epoch: 24, Loss: 1.062020182609558, Validation Accuracy: 0.6555833333333333\n",
      "Epoch: 25, Loss: 1.034317135810852, Validation Accuracy: 0.6700833333333334\n",
      "Epoch: 26, Loss: 0.9251630306243896, Validation Accuracy: 0.7835833333333333\n",
      "Epoch: 27, Loss: 0.6675589084625244, Validation Accuracy: 0.7948333333333333\n",
      "Epoch: 28, Loss: 0.615899920463562, Validation Accuracy: 0.81475\n",
      "Epoch: 29, Loss: 0.5919601917266846, Validation Accuracy: 0.8101666666666667\n",
      "Epoch: 30, Loss: 0.5781043171882629, Validation Accuracy: 0.822\n",
      "Epoch: 31, Loss: 0.5652291178703308, Validation Accuracy: 0.8186666666666667\n",
      "Epoch: 32, Loss: 0.5526735186576843, Validation Accuracy: 0.8249166666666666\n",
      "Epoch: 33, Loss: 0.5443036556243896, Validation Accuracy: 0.8263333333333334\n",
      "Epoch: 34, Loss: 0.5310516953468323, Validation Accuracy: 0.8311666666666667\n",
      "Epoch: 35, Loss: 0.525302529335022, Validation Accuracy: 0.8333333333333334\n",
      "Epoch: 36, Loss: 0.5110775232315063, Validation Accuracy: 0.8359166666666666\n",
      "Epoch: 37, Loss: 0.5064106583595276, Validation Accuracy: 0.8401666666666666\n",
      "Epoch: 38, Loss: 0.4928533434867859, Validation Accuracy: 0.8429166666666666\n",
      "Epoch: 39, Loss: 0.4881458282470703, Validation Accuracy: 0.8465\n",
      "Epoch: 40, Loss: 0.4767548441886902, Validation Accuracy: 0.8484166666666667\n",
      "Epoch: 41, Loss: 0.4718553125858307, Validation Accuracy: 0.851\n",
      "Epoch: 42, Loss: 0.463081955909729, Validation Accuracy: 0.8523333333333334\n",
      "Epoch: 43, Loss: 0.4576368033885956, Validation Accuracy: 0.85375\n",
      "Epoch: 44, Loss: 0.4510730803012848, Validation Accuracy: 0.8566666666666667\n",
      "Epoch: 45, Loss: 0.44509416818618774, Validation Accuracy: 0.8581666666666666\n",
      "Epoch: 46, Loss: 0.43983617424964905, Validation Accuracy: 0.8608333333333333\n",
      "Epoch: 47, Loss: 0.4337996542453766, Validation Accuracy: 0.8609166666666667\n",
      "Epoch: 48, Loss: 0.4293351173400879, Validation Accuracy: 0.86475\n",
      "Epoch: 49, Loss: 0.4233913719654083, Validation Accuracy: 0.8654166666666666\n",
      "Epoch: 50, Loss: 0.4191769063472748, Validation Accuracy: 0.8681666666666666\n",
      "Epoch: 51, Loss: 0.4134979248046875, Validation Accuracy: 0.86975\n",
      "Epoch: 52, Loss: 0.4093225598335266, Validation Accuracy: 0.8709166666666667\n",
      "Epoch: 53, Loss: 0.4039471745491028, Validation Accuracy: 0.87275\n",
      "Epoch: 54, Loss: 0.3997698128223419, Validation Accuracy: 0.875\n",
      "Epoch: 55, Loss: 0.39488840103149414, Validation Accuracy: 0.8751666666666666\n",
      "Epoch: 56, Loss: 0.3907966613769531, Validation Accuracy: 0.8779166666666667\n",
      "Epoch: 57, Loss: 0.3862912952899933, Validation Accuracy: 0.878\n",
      "Epoch: 58, Loss: 0.3824883997440338, Validation Accuracy: 0.8805833333333334\n",
      "Epoch: 59, Loss: 0.3783639669418335, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 60, Loss: 0.3748057782649994, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 61, Loss: 0.3710430860519409, Validation Accuracy: 0.8825\n",
      "Epoch: 62, Loss: 0.36765149235725403, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 63, Loss: 0.3642435371875763, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 64, Loss: 0.36108678579330444, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 65, Loss: 0.3579701781272888, Validation Accuracy: 0.88725\n",
      "Epoch: 66, Loss: 0.35502922534942627, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 67, Loss: 0.35213321447372437, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 68, Loss: 0.3493766784667969, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 69, Loss: 0.346701443195343, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 70, Loss: 0.3441277742385864, Validation Accuracy: 0.891\n",
      "Epoch: 71, Loss: 0.3416178524494171, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 72, Loss: 0.3391997516155243, Validation Accuracy: 0.893\n",
      "Epoch: 73, Loss: 0.3368167281150818, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 74, Loss: 0.3345395028591156, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 75, Loss: 0.3322897255420685, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 76, Loss: 0.3301056921482086, Validation Accuracy: 0.896\n",
      "Epoch: 77, Loss: 0.32796144485473633, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 78, Loss: 0.3258782923221588, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 79, Loss: 0.32385358214378357, Validation Accuracy: 0.89925\n",
      "Epoch: 80, Loss: 0.3218667209148407, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 81, Loss: 0.31993287801742554, Validation Accuracy: 0.9\n",
      "Epoch: 82, Loss: 0.3180314302444458, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 83, Loss: 0.3161843717098236, Validation Accuracy: 0.90125\n",
      "Epoch: 84, Loss: 0.31436967849731445, Validation Accuracy: 0.9005\n",
      "Epoch: 85, Loss: 0.3125947117805481, Validation Accuracy: 0.9020833333333333\n",
      "Epoch: 86, Loss: 0.31084856390953064, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 87, Loss: 0.30914220213890076, Validation Accuracy: 0.90325\n",
      "Epoch: 88, Loss: 0.30745506286621094, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 89, Loss: 0.30580443143844604, Validation Accuracy: 0.9041666666666667\n",
      "Epoch: 90, Loss: 0.30417975783348083, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 91, Loss: 0.3025861382484436, Validation Accuracy: 0.9051666666666667\n",
      "Epoch: 92, Loss: 0.3010205924510956, Validation Accuracy: 0.9055\n",
      "Epoch: 93, Loss: 0.29948490858078003, Validation Accuracy: 0.9063333333333333\n",
      "Epoch: 94, Loss: 0.2979748845100403, Validation Accuracy: 0.9063333333333333\n",
      "Epoch: 95, Loss: 0.29649215936660767, Validation Accuracy: 0.907\n",
      "Epoch: 96, Loss: 0.29503655433654785, Validation Accuracy: 0.9076666666666666\n",
      "Epoch: 97, Loss: 0.29360824823379517, Validation Accuracy: 0.9085833333333333\n",
      "Epoch: 98, Loss: 0.2922057807445526, Validation Accuracy: 0.9085\n",
      "Epoch: 99, Loss: 0.29082274436950684, Validation Accuracy: 0.9094166666666667\n",
      "Dataset 41\n",
      "Epoch: 0, Loss: 3.285492181777954, Validation Accuracy: 0.2265\n",
      "Epoch: 1, Loss: 2.570498466491699, Validation Accuracy: 0.1985\n",
      "Epoch: 2, Loss: 2.2776947021484375, Validation Accuracy: 0.36641666666666667\n",
      "Epoch: 3, Loss: 1.841585636138916, Validation Accuracy: 0.5080833333333333\n",
      "Epoch: 4, Loss: 1.4065296649932861, Validation Accuracy: 0.563\n",
      "Epoch: 5, Loss: 1.2584336996078491, Validation Accuracy: 0.5934166666666667\n",
      "Epoch: 6, Loss: 1.1721514463424683, Validation Accuracy: 0.5668333333333333\n",
      "Epoch: 7, Loss: 1.2213962078094482, Validation Accuracy: 0.5083333333333333\n",
      "Epoch: 8, Loss: 1.4500421285629272, Validation Accuracy: 0.5289166666666667\n",
      "Epoch: 9, Loss: 1.3433103561401367, Validation Accuracy: 0.6745\n",
      "Epoch: 10, Loss: 0.9819417595863342, Validation Accuracy: 0.70775\n",
      "Epoch: 11, Loss: 0.8901891112327576, Validation Accuracy: 0.73925\n",
      "Epoch: 12, Loss: 0.8032965660095215, Validation Accuracy: 0.7426666666666667\n",
      "Epoch: 13, Loss: 0.7743127346038818, Validation Accuracy: 0.7545833333333334\n",
      "Epoch: 14, Loss: 0.7380841374397278, Validation Accuracy: 0.7520833333333333\n",
      "Epoch: 15, Loss: 0.7400104403495789, Validation Accuracy: 0.7591666666666667\n",
      "Epoch: 16, Loss: 0.7117518186569214, Validation Accuracy: 0.7513333333333333\n",
      "Epoch: 17, Loss: 0.7292280197143555, Validation Accuracy: 0.7645\n",
      "Epoch: 18, Loss: 0.6882912516593933, Validation Accuracy: 0.7604166666666666\n",
      "Epoch: 19, Loss: 0.6913009285926819, Validation Accuracy: 0.7738333333333334\n",
      "Epoch: 20, Loss: 0.6607070565223694, Validation Accuracy: 0.771\n",
      "Epoch: 21, Loss: 0.6548741459846497, Validation Accuracy: 0.7675\n",
      "Epoch: 22, Loss: 0.6672748327255249, Validation Accuracy: 0.7733333333333333\n",
      "Epoch: 23, Loss: 0.6452010273933411, Validation Accuracy: 0.7705\n",
      "Epoch: 24, Loss: 0.6549253463745117, Validation Accuracy: 0.7918333333333333\n",
      "Epoch: 25, Loss: 0.593087375164032, Validation Accuracy: 0.80475\n",
      "Epoch: 26, Loss: 0.5682647824287415, Validation Accuracy: 0.8229166666666666\n",
      "Epoch: 27, Loss: 0.5240548253059387, Validation Accuracy: 0.8325833333333333\n",
      "Epoch: 28, Loss: 0.5022907853126526, Validation Accuracy: 0.8413333333333334\n",
      "Epoch: 29, Loss: 0.4831288158893585, Validation Accuracy: 0.8459166666666667\n",
      "Epoch: 30, Loss: 0.46989455819129944, Validation Accuracy: 0.8485833333333334\n",
      "Epoch: 31, Loss: 0.45932695269584656, Validation Accuracy: 0.8518333333333333\n",
      "Epoch: 32, Loss: 0.45048654079437256, Validation Accuracy: 0.8534166666666667\n",
      "Epoch: 33, Loss: 0.4428420960903168, Validation Accuracy: 0.8566666666666667\n",
      "Epoch: 34, Loss: 0.4360494315624237, Validation Accuracy: 0.8583333333333333\n",
      "Epoch: 35, Loss: 0.42987072467803955, Validation Accuracy: 0.8620833333333333\n",
      "Epoch: 36, Loss: 0.42414408922195435, Validation Accuracy: 0.86275\n",
      "Epoch: 37, Loss: 0.41885700821876526, Validation Accuracy: 0.8656666666666667\n",
      "Epoch: 38, Loss: 0.4138146936893463, Validation Accuracy: 0.8665833333333334\n",
      "Epoch: 39, Loss: 0.4091051518917084, Validation Accuracy: 0.8695\n",
      "Epoch: 40, Loss: 0.40457674860954285, Validation Accuracy: 0.8696666666666667\n",
      "Epoch: 41, Loss: 0.4003083109855652, Validation Accuracy: 0.8720833333333333\n",
      "Epoch: 42, Loss: 0.3962167203426361, Validation Accuracy: 0.8725\n",
      "Epoch: 43, Loss: 0.3922971189022064, Validation Accuracy: 0.8749166666666667\n",
      "Epoch: 44, Loss: 0.38852542638778687, Validation Accuracy: 0.8756666666666667\n",
      "Epoch: 45, Loss: 0.38489213585853577, Validation Accuracy: 0.8765\n",
      "Epoch: 46, Loss: 0.3814007639884949, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 47, Loss: 0.37803006172180176, Validation Accuracy: 0.87875\n",
      "Epoch: 48, Loss: 0.37479346990585327, Validation Accuracy: 0.8799166666666667\n",
      "Epoch: 49, Loss: 0.3716548979282379, Validation Accuracy: 0.8804166666666666\n",
      "Epoch: 50, Loss: 0.3686180114746094, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 51, Loss: 0.3656793236732483, Validation Accuracy: 0.8824166666666666\n",
      "Epoch: 52, Loss: 0.36281704902648926, Validation Accuracy: 0.884\n",
      "Epoch: 53, Loss: 0.36003679037094116, Validation Accuracy: 0.8845\n",
      "Epoch: 54, Loss: 0.3573458790779114, Validation Accuracy: 0.88625\n",
      "Epoch: 55, Loss: 0.3547321856021881, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 56, Loss: 0.3521660268306732, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 57, Loss: 0.34966787695884705, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 58, Loss: 0.3472379446029663, Validation Accuracy: 0.88825\n",
      "Epoch: 59, Loss: 0.3448743522167206, Validation Accuracy: 0.88825\n",
      "Epoch: 60, Loss: 0.3425547778606415, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 61, Loss: 0.3402763605117798, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 62, Loss: 0.33807075023651123, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 63, Loss: 0.33591464161872864, Validation Accuracy: 0.89025\n",
      "Epoch: 64, Loss: 0.3338009715080261, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 65, Loss: 0.33173906803131104, Validation Accuracy: 0.891\n",
      "Epoch: 66, Loss: 0.3297061622142792, Validation Accuracy: 0.8925833333333333\n",
      "Epoch: 67, Loss: 0.32772332429885864, Validation Accuracy: 0.89225\n",
      "Epoch: 68, Loss: 0.325774610042572, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 69, Loss: 0.3238973915576935, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 70, Loss: 0.32202333211898804, Validation Accuracy: 0.8939166666666667\n",
      "Epoch: 71, Loss: 0.3202022314071655, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 72, Loss: 0.31840917468070984, Validation Accuracy: 0.8951666666666667\n",
      "Epoch: 73, Loss: 0.31663182377815247, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 74, Loss: 0.3148980140686035, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 75, Loss: 0.3131830394268036, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 76, Loss: 0.31151115894317627, Validation Accuracy: 0.8971666666666667\n",
      "Epoch: 77, Loss: 0.30985715985298157, Validation Accuracy: 0.89725\n",
      "Epoch: 78, Loss: 0.30822405219078064, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 79, Loss: 0.3066149353981018, Validation Accuracy: 0.8985\n",
      "Epoch: 80, Loss: 0.30502790212631226, Validation Accuracy: 0.899\n",
      "Epoch: 81, Loss: 0.3034929037094116, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 82, Loss: 0.3019556999206543, Validation Accuracy: 0.9\n",
      "Epoch: 83, Loss: 0.30048203468322754, Validation Accuracy: 0.9005\n",
      "Epoch: 84, Loss: 0.29896679520606995, Validation Accuracy: 0.90025\n",
      "Epoch: 85, Loss: 0.2975296974182129, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 86, Loss: 0.2960823178291321, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 87, Loss: 0.29469171166419983, Validation Accuracy: 0.90225\n",
      "Epoch: 88, Loss: 0.2932787239551544, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 89, Loss: 0.2919165790081024, Validation Accuracy: 0.903\n",
      "Epoch: 90, Loss: 0.290546715259552, Validation Accuracy: 0.9028333333333334\n",
      "Epoch: 91, Loss: 0.2892080545425415, Validation Accuracy: 0.9035\n",
      "Epoch: 92, Loss: 0.28789177536964417, Validation Accuracy: 0.90325\n",
      "Epoch: 93, Loss: 0.28657251596450806, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 94, Loss: 0.28530052304267883, Validation Accuracy: 0.90375\n",
      "Epoch: 95, Loss: 0.2840180993080139, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 96, Loss: 0.28277111053466797, Validation Accuracy: 0.9045\n",
      "Epoch: 97, Loss: 0.2815278172492981, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 98, Loss: 0.2803109288215637, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 99, Loss: 0.27909183502197266, Validation Accuracy: 0.9059166666666667\n",
      "Dataset 42\n",
      "Epoch: 0, Loss: 3.287851333618164, Validation Accuracy: 0.18925\n",
      "Epoch: 1, Loss: 2.447913885116577, Validation Accuracy: 0.31216666666666665\n",
      "Epoch: 2, Loss: 1.9560199975967407, Validation Accuracy: 0.38816666666666666\n",
      "Epoch: 3, Loss: 1.7678017616271973, Validation Accuracy: 0.43175\n",
      "Epoch: 4, Loss: 1.6199313402175903, Validation Accuracy: 0.47908333333333336\n",
      "Epoch: 5, Loss: 1.4910060167312622, Validation Accuracy: 0.5079166666666667\n",
      "Epoch: 6, Loss: 1.3976168632507324, Validation Accuracy: 0.5323333333333333\n",
      "Epoch: 7, Loss: 1.3495038747787476, Validation Accuracy: 0.48083333333333333\n",
      "Epoch: 8, Loss: 1.446051001548767, Validation Accuracy: 0.5585833333333333\n",
      "Epoch: 9, Loss: 1.3270888328552246, Validation Accuracy: 0.5656666666666667\n",
      "Epoch: 10, Loss: 1.2568145990371704, Validation Accuracy: 0.6620833333333334\n",
      "Epoch: 11, Loss: 1.0134793519973755, Validation Accuracy: 0.684\n",
      "Epoch: 12, Loss: 0.9444676041603088, Validation Accuracy: 0.6846666666666666\n",
      "Epoch: 13, Loss: 0.9209634065628052, Validation Accuracy: 0.675\n",
      "Epoch: 14, Loss: 0.9614182710647583, Validation Accuracy: 0.67575\n",
      "Epoch: 15, Loss: 0.9438050389289856, Validation Accuracy: 0.6675833333333333\n",
      "Epoch: 16, Loss: 0.9580498933792114, Validation Accuracy: 0.6783333333333333\n",
      "Epoch: 17, Loss: 0.9375684261322021, Validation Accuracy: 0.7305\n",
      "Epoch: 18, Loss: 0.7945865988731384, Validation Accuracy: 0.74775\n",
      "Epoch: 19, Loss: 0.7279139161109924, Validation Accuracy: 0.7776666666666666\n",
      "Epoch: 20, Loss: 0.6557298302650452, Validation Accuracy: 0.7868333333333334\n",
      "Epoch: 21, Loss: 0.6321537494659424, Validation Accuracy: 0.7910833333333334\n",
      "Epoch: 22, Loss: 0.6144125461578369, Validation Accuracy: 0.78925\n",
      "Epoch: 23, Loss: 0.6149474382400513, Validation Accuracy: 0.7880833333333334\n",
      "Epoch: 24, Loss: 0.6120027899742126, Validation Accuracy: 0.7748333333333334\n",
      "Epoch: 25, Loss: 0.6433283090591431, Validation Accuracy: 0.779\n",
      "Epoch: 26, Loss: 0.6318286657333374, Validation Accuracy: 0.7645\n",
      "Epoch: 27, Loss: 0.6749662756919861, Validation Accuracy: 0.79275\n",
      "Epoch: 28, Loss: 0.596627950668335, Validation Accuracy: 0.7979166666666667\n",
      "Epoch: 29, Loss: 0.5843779444694519, Validation Accuracy: 0.8223333333333334\n",
      "Epoch: 30, Loss: 0.5253419280052185, Validation Accuracy: 0.83025\n",
      "Epoch: 31, Loss: 0.5076188445091248, Validation Accuracy: 0.8394166666666667\n",
      "Epoch: 32, Loss: 0.48570355772972107, Validation Accuracy: 0.8454166666666667\n",
      "Epoch: 33, Loss: 0.4746301770210266, Validation Accuracy: 0.8484166666666667\n",
      "Epoch: 34, Loss: 0.46403735876083374, Validation Accuracy: 0.8516666666666667\n",
      "Epoch: 35, Loss: 0.4561450183391571, Validation Accuracy: 0.8535\n",
      "Epoch: 36, Loss: 0.449195921421051, Validation Accuracy: 0.85725\n",
      "Epoch: 37, Loss: 0.4435539245605469, Validation Accuracy: 0.85625\n",
      "Epoch: 38, Loss: 0.438865065574646, Validation Accuracy: 0.85975\n",
      "Epoch: 39, Loss: 0.43601977825164795, Validation Accuracy: 0.85725\n",
      "Epoch: 40, Loss: 0.435078501701355, Validation Accuracy: 0.85725\n",
      "Epoch: 41, Loss: 0.4384215772151947, Validation Accuracy: 0.8536666666666667\n",
      "Epoch: 42, Loss: 0.44591525197029114, Validation Accuracy: 0.8420833333333333\n",
      "Epoch: 43, Loss: 0.4657128155231476, Validation Accuracy: 0.8330833333333333\n",
      "Epoch: 44, Loss: 0.4929995536804199, Validation Accuracy: 0.8089166666666666\n",
      "Epoch: 45, Loss: 0.5489837527275085, Validation Accuracy: 0.7998333333333333\n",
      "Epoch: 46, Loss: 0.5852361917495728, Validation Accuracy: 0.7813333333333333\n",
      "Epoch: 47, Loss: 0.6294939517974854, Validation Accuracy: 0.8118333333333333\n",
      "Epoch: 48, Loss: 0.5552418828010559, Validation Accuracy: 0.8343333333333334\n",
      "Epoch: 49, Loss: 0.48574918508529663, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 50, Loss: 0.42487549781799316, Validation Accuracy: 0.874\n",
      "Epoch: 51, Loss: 0.3981470465660095, Validation Accuracy: 0.8764166666666666\n",
      "Epoch: 52, Loss: 0.38614290952682495, Validation Accuracy: 0.8804166666666666\n",
      "Epoch: 53, Loss: 0.3793894350528717, Validation Accuracy: 0.8805\n",
      "Epoch: 54, Loss: 0.3745374083518982, Validation Accuracy: 0.8825833333333334\n",
      "Epoch: 55, Loss: 0.3704545795917511, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 56, Loss: 0.3668348491191864, Validation Accuracy: 0.8845833333333334\n",
      "Epoch: 57, Loss: 0.36349397897720337, Validation Accuracy: 0.885\n",
      "Epoch: 58, Loss: 0.36035454273223877, Validation Accuracy: 0.8859166666666667\n",
      "Epoch: 59, Loss: 0.35737255215644836, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 60, Loss: 0.35452964901924133, Validation Accuracy: 0.8881666666666667\n",
      "Epoch: 61, Loss: 0.35179850459098816, Validation Accuracy: 0.8890833333333333\n",
      "Epoch: 62, Loss: 0.34916743636131287, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 63, Loss: 0.3466309905052185, Validation Accuracy: 0.8905\n",
      "Epoch: 64, Loss: 0.34416788816452026, Validation Accuracy: 0.8916666666666667\n",
      "Epoch: 65, Loss: 0.3417803943157196, Validation Accuracy: 0.8923333333333333\n",
      "Epoch: 66, Loss: 0.3394682705402374, Validation Accuracy: 0.893\n",
      "Epoch: 67, Loss: 0.33721843361854553, Validation Accuracy: 0.8935\n",
      "Epoch: 68, Loss: 0.3350231647491455, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 69, Loss: 0.3328821063041687, Validation Accuracy: 0.89425\n",
      "Epoch: 70, Loss: 0.3308025598526001, Validation Accuracy: 0.895\n",
      "Epoch: 71, Loss: 0.32877591252326965, Validation Accuracy: 0.8954166666666666\n",
      "Epoch: 72, Loss: 0.3267950117588043, Validation Accuracy: 0.89575\n",
      "Epoch: 73, Loss: 0.3248596489429474, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 74, Loss: 0.32296639680862427, Validation Accuracy: 0.897\n",
      "Epoch: 75, Loss: 0.32111242413520813, Validation Accuracy: 0.8979166666666667\n",
      "Epoch: 76, Loss: 0.3192989230155945, Validation Accuracy: 0.8985833333333333\n",
      "Epoch: 77, Loss: 0.3175220489501953, Validation Accuracy: 0.8991666666666667\n",
      "Epoch: 78, Loss: 0.31578096747398376, Validation Accuracy: 0.8998333333333334\n",
      "Epoch: 79, Loss: 0.31407907605171204, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 80, Loss: 0.3124084770679474, Validation Accuracy: 0.901\n",
      "Epoch: 81, Loss: 0.3107711970806122, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 82, Loss: 0.30916354060173035, Validation Accuracy: 0.9020833333333333\n",
      "Epoch: 83, Loss: 0.3075867295265198, Validation Accuracy: 0.9025\n",
      "Epoch: 84, Loss: 0.3060355484485626, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 85, Loss: 0.3045101761817932, Validation Accuracy: 0.9034166666666666\n",
      "Epoch: 86, Loss: 0.30301132798194885, Validation Accuracy: 0.9039166666666667\n",
      "Epoch: 87, Loss: 0.301541805267334, Validation Accuracy: 0.9044166666666666\n",
      "Epoch: 88, Loss: 0.30009642243385315, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 89, Loss: 0.2986755073070526, Validation Accuracy: 0.9048333333333334\n",
      "Epoch: 90, Loss: 0.29727476835250854, Validation Accuracy: 0.905\n",
      "Epoch: 91, Loss: 0.29589492082595825, Validation Accuracy: 0.9055833333333333\n",
      "Epoch: 92, Loss: 0.29453620314598083, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 93, Loss: 0.29319652915000916, Validation Accuracy: 0.9065\n",
      "Epoch: 94, Loss: 0.29187482595443726, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 95, Loss: 0.2905723750591278, Validation Accuracy: 0.9069166666666667\n",
      "Epoch: 96, Loss: 0.2892896234989166, Validation Accuracy: 0.9073333333333333\n",
      "Epoch: 97, Loss: 0.28802308440208435, Validation Accuracy: 0.90775\n",
      "Epoch: 98, Loss: 0.28677141666412354, Validation Accuracy: 0.9085833333333333\n",
      "Epoch: 99, Loss: 0.2855355143547058, Validation Accuracy: 0.909\n",
      "Dataset 43\n",
      "Epoch: 0, Loss: 3.685883045196533, Validation Accuracy: 0.12575\n",
      "Epoch: 1, Loss: 3.3417561054229736, Validation Accuracy: 0.17583333333333334\n",
      "Epoch: 2, Loss: 2.75815486907959, Validation Accuracy: 0.22125\n",
      "Epoch: 3, Loss: 2.4852845668792725, Validation Accuracy: 0.31808333333333333\n",
      "Epoch: 4, Loss: 1.9661062955856323, Validation Accuracy: 0.44283333333333336\n",
      "Epoch: 5, Loss: 1.7004867792129517, Validation Accuracy: 0.49666666666666665\n",
      "Epoch: 6, Loss: 1.517750859260559, Validation Accuracy: 0.5425833333333333\n",
      "Epoch: 7, Loss: 1.3772412538528442, Validation Accuracy: 0.5835833333333333\n",
      "Epoch: 8, Loss: 1.2579425573349, Validation Accuracy: 0.61675\n",
      "Epoch: 9, Loss: 1.1498764753341675, Validation Accuracy: 0.6544166666666666\n",
      "Epoch: 10, Loss: 1.0582705736160278, Validation Accuracy: 0.67175\n",
      "Epoch: 11, Loss: 0.9800272583961487, Validation Accuracy: 0.69975\n",
      "Epoch: 12, Loss: 0.9251592755317688, Validation Accuracy: 0.7014166666666667\n",
      "Epoch: 13, Loss: 0.8811615109443665, Validation Accuracy: 0.70425\n",
      "Epoch: 14, Loss: 0.8833540081977844, Validation Accuracy: 0.7016666666666667\n",
      "Epoch: 15, Loss: 0.8737888336181641, Validation Accuracy: 0.6824166666666667\n",
      "Epoch: 16, Loss: 0.9179126620292664, Validation Accuracy: 0.7056666666666667\n",
      "Epoch: 17, Loss: 0.8606501221656799, Validation Accuracy: 0.7414166666666666\n",
      "Epoch: 18, Loss: 0.7700828313827515, Validation Accuracy: 0.7725\n",
      "Epoch: 19, Loss: 0.6905482411384583, Validation Accuracy: 0.7915\n",
      "Epoch: 20, Loss: 0.6395497918128967, Validation Accuracy: 0.8039166666666666\n",
      "Epoch: 21, Loss: 0.6073726415634155, Validation Accuracy: 0.80925\n",
      "Epoch: 22, Loss: 0.5847981572151184, Validation Accuracy: 0.8175833333333333\n",
      "Epoch: 23, Loss: 0.5666437745094299, Validation Accuracy: 0.82175\n",
      "Epoch: 24, Loss: 0.5514798164367676, Validation Accuracy: 0.8251666666666667\n",
      "Epoch: 25, Loss: 0.5380030274391174, Validation Accuracy: 0.8299166666666666\n",
      "Epoch: 26, Loss: 0.5263873934745789, Validation Accuracy: 0.8335\n",
      "Epoch: 27, Loss: 0.5156704187393188, Validation Accuracy: 0.8373333333333334\n",
      "Epoch: 28, Loss: 0.5065957903862, Validation Accuracy: 0.83775\n",
      "Epoch: 29, Loss: 0.49825939536094666, Validation Accuracy: 0.842\n",
      "Epoch: 30, Loss: 0.4917082190513611, Validation Accuracy: 0.8411666666666666\n",
      "Epoch: 31, Loss: 0.48580917716026306, Validation Accuracy: 0.84375\n",
      "Epoch: 32, Loss: 0.481527715921402, Validation Accuracy: 0.8418333333333333\n",
      "Epoch: 33, Loss: 0.4775642454624176, Validation Accuracy: 0.8434166666666667\n",
      "Epoch: 34, Loss: 0.4752444326877594, Validation Accuracy: 0.8421666666666666\n",
      "Epoch: 35, Loss: 0.4716522991657257, Validation Accuracy: 0.84475\n",
      "Epoch: 36, Loss: 0.4683345556259155, Validation Accuracy: 0.84575\n",
      "Epoch: 37, Loss: 0.4624255299568176, Validation Accuracy: 0.8484166666666667\n",
      "Epoch: 38, Loss: 0.4560794532299042, Validation Accuracy: 0.85275\n",
      "Epoch: 39, Loss: 0.4471152722835541, Validation Accuracy: 0.8560833333333333\n",
      "Epoch: 40, Loss: 0.4383946657180786, Validation Accuracy: 0.86025\n",
      "Epoch: 41, Loss: 0.4287561774253845, Validation Accuracy: 0.8639166666666667\n",
      "Epoch: 42, Loss: 0.4203053116798401, Validation Accuracy: 0.8674166666666666\n",
      "Epoch: 43, Loss: 0.41196146607398987, Validation Accuracy: 0.8705\n",
      "Epoch: 44, Loss: 0.4045675992965698, Validation Accuracy: 0.8736666666666667\n",
      "Epoch: 45, Loss: 0.3976292312145233, Validation Accuracy: 0.8760833333333333\n",
      "Epoch: 46, Loss: 0.3915916681289673, Validation Accuracy: 0.87775\n",
      "Epoch: 47, Loss: 0.3858514130115509, Validation Accuracy: 0.87875\n",
      "Epoch: 48, Loss: 0.38076329231262207, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 49, Loss: 0.3759460151195526, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 50, Loss: 0.37155359983444214, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 51, Loss: 0.36730408668518066, Validation Accuracy: 0.8839166666666667\n",
      "Epoch: 52, Loss: 0.36343148350715637, Validation Accuracy: 0.8873333333333333\n",
      "Epoch: 53, Loss: 0.35966411232948303, Validation Accuracy: 0.88675\n",
      "Epoch: 54, Loss: 0.3561544120311737, Validation Accuracy: 0.8900833333333333\n",
      "Epoch: 55, Loss: 0.35273751616477966, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 56, Loss: 0.34957945346832275, Validation Accuracy: 0.89225\n",
      "Epoch: 57, Loss: 0.3464587330818176, Validation Accuracy: 0.89125\n",
      "Epoch: 58, Loss: 0.3435332775115967, Validation Accuracy: 0.89425\n",
      "Epoch: 59, Loss: 0.3406224846839905, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 60, Loss: 0.3378722071647644, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 61, Loss: 0.3351219594478607, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 62, Loss: 0.33251509070396423, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 63, Loss: 0.32996565103530884, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 64, Loss: 0.32752493023872375, Validation Accuracy: 0.89775\n",
      "Epoch: 65, Loss: 0.3250894248485565, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 66, Loss: 0.3227790594100952, Validation Accuracy: 0.8996666666666666\n",
      "Epoch: 67, Loss: 0.320483535528183, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 68, Loss: 0.31823861598968506, Validation Accuracy: 0.901\n",
      "Epoch: 69, Loss: 0.31606462597846985, Validation Accuracy: 0.9\n",
      "Epoch: 70, Loss: 0.31388965249061584, Validation Accuracy: 0.90225\n",
      "Epoch: 71, Loss: 0.3117618262767792, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 72, Loss: 0.30970409512519836, Validation Accuracy: 0.9033333333333333\n",
      "Epoch: 73, Loss: 0.30767694115638733, Validation Accuracy: 0.90225\n",
      "Epoch: 74, Loss: 0.3056899905204773, Validation Accuracy: 0.9039166666666667\n",
      "Epoch: 75, Loss: 0.3037523925304413, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 76, Loss: 0.30186009407043457, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 77, Loss: 0.30002331733703613, Validation Accuracy: 0.9046666666666666\n",
      "Epoch: 78, Loss: 0.2982274889945984, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 79, Loss: 0.2964878976345062, Validation Accuracy: 0.9055\n",
      "Epoch: 80, Loss: 0.2947731614112854, Validation Accuracy: 0.9073333333333333\n",
      "Epoch: 81, Loss: 0.2930922508239746, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 82, Loss: 0.2914271354675293, Validation Accuracy: 0.9083333333333333\n",
      "Epoch: 83, Loss: 0.28981897234916687, Validation Accuracy: 0.9075833333333333\n",
      "Epoch: 84, Loss: 0.2882172763347626, Validation Accuracy: 0.9093333333333333\n",
      "Epoch: 85, Loss: 0.2866514027118683, Validation Accuracy: 0.9086666666666666\n",
      "Epoch: 86, Loss: 0.285117506980896, Validation Accuracy: 0.9106666666666666\n",
      "Epoch: 87, Loss: 0.2836066484451294, Validation Accuracy: 0.9093333333333333\n",
      "Epoch: 88, Loss: 0.28213414549827576, Validation Accuracy: 0.9114166666666667\n",
      "Epoch: 89, Loss: 0.2806891202926636, Validation Accuracy: 0.9100833333333334\n",
      "Epoch: 90, Loss: 0.2792646586894989, Validation Accuracy: 0.9120833333333334\n",
      "Epoch: 91, Loss: 0.2778695523738861, Validation Accuracy: 0.9113333333333333\n",
      "Epoch: 92, Loss: 0.27649378776550293, Validation Accuracy: 0.9125833333333333\n",
      "Epoch: 93, Loss: 0.27513912320137024, Validation Accuracy: 0.9125\n",
      "Epoch: 94, Loss: 0.27380427718162537, Validation Accuracy: 0.91325\n",
      "Epoch: 95, Loss: 0.27250340580940247, Validation Accuracy: 0.9135\n",
      "Epoch: 96, Loss: 0.2712247669696808, Validation Accuracy: 0.91375\n",
      "Epoch: 97, Loss: 0.269970178604126, Validation Accuracy: 0.9145\n",
      "Epoch: 98, Loss: 0.2687172591686249, Validation Accuracy: 0.9145\n",
      "Epoch: 99, Loss: 0.2675025165081024, Validation Accuracy: 0.9153333333333333\n",
      "Dataset 44\n",
      "Epoch: 0, Loss: 3.5099856853485107, Validation Accuracy: 0.15266666666666667\n",
      "Epoch: 1, Loss: 2.8746604919433594, Validation Accuracy: 0.16241666666666665\n",
      "Epoch: 2, Loss: 2.781177520751953, Validation Accuracy: 0.22333333333333333\n",
      "Epoch: 3, Loss: 2.4264352321624756, Validation Accuracy: 0.19033333333333333\n",
      "Epoch: 4, Loss: 2.5250935554504395, Validation Accuracy: 0.29591666666666666\n",
      "Epoch: 5, Loss: 1.9442081451416016, Validation Accuracy: 0.37816666666666665\n",
      "Epoch: 6, Loss: 1.7767293453216553, Validation Accuracy: 0.44958333333333333\n",
      "Epoch: 7, Loss: 1.6398684978485107, Validation Accuracy: 0.49725\n",
      "Epoch: 8, Loss: 1.5147180557250977, Validation Accuracy: 0.54475\n",
      "Epoch: 9, Loss: 1.3944311141967773, Validation Accuracy: 0.5803333333333334\n",
      "Epoch: 10, Loss: 1.2835159301757812, Validation Accuracy: 0.6123333333333333\n",
      "Epoch: 11, Loss: 1.1843156814575195, Validation Accuracy: 0.6398333333333334\n",
      "Epoch: 12, Loss: 1.0979646444320679, Validation Accuracy: 0.6680833333333334\n",
      "Epoch: 13, Loss: 1.0240397453308105, Validation Accuracy: 0.68575\n",
      "Epoch: 14, Loss: 0.9623770117759705, Validation Accuracy: 0.70025\n",
      "Epoch: 15, Loss: 0.9229878187179565, Validation Accuracy: 0.6903333333333334\n",
      "Epoch: 16, Loss: 0.9289278984069824, Validation Accuracy: 0.6113333333333333\n",
      "Epoch: 17, Loss: 1.1305456161499023, Validation Accuracy: 0.6013333333333334\n",
      "Epoch: 18, Loss: 1.1430879831314087, Validation Accuracy: 0.57825\n",
      "Epoch: 19, Loss: 1.24986732006073, Validation Accuracy: 0.6645833333333333\n",
      "Epoch: 20, Loss: 0.9719349145889282, Validation Accuracy: 0.72325\n",
      "Epoch: 21, Loss: 0.8164812922477722, Validation Accuracy: 0.7431666666666666\n",
      "Epoch: 22, Loss: 0.7841880917549133, Validation Accuracy: 0.7275833333333334\n",
      "Epoch: 23, Loss: 0.8021450042724609, Validation Accuracy: 0.694\n",
      "Epoch: 24, Loss: 0.8740477561950684, Validation Accuracy: 0.6854166666666667\n",
      "Epoch: 25, Loss: 0.8915320038795471, Validation Accuracy: 0.72875\n",
      "Epoch: 26, Loss: 0.7715663909912109, Validation Accuracy: 0.7675833333333333\n",
      "Epoch: 27, Loss: 0.681222677230835, Validation Accuracy: 0.79775\n",
      "Epoch: 28, Loss: 0.6217169761657715, Validation Accuracy: 0.814\n",
      "Epoch: 29, Loss: 0.5834352374076843, Validation Accuracy: 0.8209166666666666\n",
      "Epoch: 30, Loss: 0.5606759190559387, Validation Accuracy: 0.8289166666666666\n",
      "Epoch: 31, Loss: 0.5422924757003784, Validation Accuracy: 0.8326666666666667\n",
      "Epoch: 32, Loss: 0.5288704037666321, Validation Accuracy: 0.83675\n",
      "Epoch: 33, Loss: 0.5167647004127502, Validation Accuracy: 0.8391666666666666\n",
      "Epoch: 34, Loss: 0.5071711540222168, Validation Accuracy: 0.8403333333333334\n",
      "Epoch: 35, Loss: 0.49809274077415466, Validation Accuracy: 0.84325\n",
      "Epoch: 36, Loss: 0.49103596806526184, Validation Accuracy: 0.8435833333333334\n",
      "Epoch: 37, Loss: 0.4843002259731293, Validation Accuracy: 0.8464166666666667\n",
      "Epoch: 38, Loss: 0.4798995852470398, Validation Accuracy: 0.8459166666666667\n",
      "Epoch: 39, Loss: 0.475169837474823, Validation Accuracy: 0.8475833333333334\n",
      "Epoch: 40, Loss: 0.47329476475715637, Validation Accuracy: 0.8465833333333334\n",
      "Epoch: 41, Loss: 0.4698822498321533, Validation Accuracy: 0.8479166666666667\n",
      "Epoch: 42, Loss: 0.4695889949798584, Validation Accuracy: 0.8475833333333334\n",
      "Epoch: 43, Loss: 0.46599698066711426, Validation Accuracy: 0.84775\n",
      "Epoch: 44, Loss: 0.4657531678676605, Validation Accuracy: 0.84825\n",
      "Epoch: 45, Loss: 0.4600643813610077, Validation Accuracy: 0.8509166666666667\n",
      "Epoch: 46, Loss: 0.45691683888435364, Validation Accuracy: 0.8515833333333334\n",
      "Epoch: 47, Loss: 0.4480348229408264, Validation Accuracy: 0.8564166666666667\n",
      "Epoch: 48, Loss: 0.4415372312068939, Validation Accuracy: 0.8573333333333333\n",
      "Epoch: 49, Loss: 0.43091219663619995, Validation Accuracy: 0.865\n",
      "Epoch: 50, Loss: 0.42280247807502747, Validation Accuracy: 0.8658333333333333\n",
      "Epoch: 51, Loss: 0.41294705867767334, Validation Accuracy: 0.87025\n",
      "Epoch: 52, Loss: 0.4054858386516571, Validation Accuracy: 0.8726666666666667\n",
      "Epoch: 53, Loss: 0.39775317907333374, Validation Accuracy: 0.87375\n",
      "Epoch: 54, Loss: 0.3917196989059448, Validation Accuracy: 0.8776666666666667\n",
      "Epoch: 55, Loss: 0.3860543966293335, Validation Accuracy: 0.878\n",
      "Epoch: 56, Loss: 0.38120612502098083, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 57, Loss: 0.3768560290336609, Validation Accuracy: 0.8818333333333334\n",
      "Epoch: 58, Loss: 0.3728688061237335, Validation Accuracy: 0.8835\n",
      "Epoch: 59, Loss: 0.3691563010215759, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 60, Loss: 0.36575639247894287, Validation Accuracy: 0.8854166666666666\n",
      "Epoch: 61, Loss: 0.36251315474510193, Validation Accuracy: 0.8865\n",
      "Epoch: 62, Loss: 0.35947081446647644, Validation Accuracy: 0.8874166666666666\n",
      "Epoch: 63, Loss: 0.35653549432754517, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 64, Loss: 0.3537723124027252, Validation Accuracy: 0.889\n",
      "Epoch: 65, Loss: 0.3510773479938507, Validation Accuracy: 0.8895\n",
      "Epoch: 66, Loss: 0.3484969139099121, Validation Accuracy: 0.8899166666666667\n",
      "Epoch: 67, Loss: 0.34597253799438477, Validation Accuracy: 0.892\n",
      "Epoch: 68, Loss: 0.3435387909412384, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 69, Loss: 0.3411637842655182, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 70, Loss: 0.33887362480163574, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 71, Loss: 0.3366360068321228, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 72, Loss: 0.3344961106777191, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 73, Loss: 0.33237773180007935, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 74, Loss: 0.3303312063217163, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 75, Loss: 0.3283478319644928, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 76, Loss: 0.32638031244277954, Validation Accuracy: 0.8983333333333333\n",
      "Epoch: 77, Loss: 0.3244834244251251, Validation Accuracy: 0.89825\n",
      "Epoch: 78, Loss: 0.3226107060909271, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 79, Loss: 0.3207850158214569, Validation Accuracy: 0.8998333333333334\n",
      "Epoch: 80, Loss: 0.3190022110939026, Validation Accuracy: 0.90075\n",
      "Epoch: 81, Loss: 0.31725507974624634, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 82, Loss: 0.3155282437801361, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 83, Loss: 0.31382110714912415, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 84, Loss: 0.3121541738510132, Validation Accuracy: 0.902\n",
      "Epoch: 85, Loss: 0.3105032444000244, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 86, Loss: 0.30893033742904663, Validation Accuracy: 0.9025833333333333\n",
      "Epoch: 87, Loss: 0.3073507249355316, Validation Accuracy: 0.9025833333333333\n",
      "Epoch: 88, Loss: 0.3058284521102905, Validation Accuracy: 0.9035\n",
      "Epoch: 89, Loss: 0.30429142713546753, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 90, Loss: 0.3028264045715332, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 91, Loss: 0.3013416826725006, Validation Accuracy: 0.9044166666666666\n",
      "Epoch: 92, Loss: 0.2999211251735687, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 93, Loss: 0.29850292205810547, Validation Accuracy: 0.9056666666666666\n",
      "Epoch: 94, Loss: 0.29712316393852234, Validation Accuracy: 0.906\n",
      "Epoch: 95, Loss: 0.29574280977249146, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 96, Loss: 0.29439908266067505, Validation Accuracy: 0.90625\n",
      "Epoch: 97, Loss: 0.2930613160133362, Validation Accuracy: 0.9075833333333333\n",
      "Epoch: 98, Loss: 0.2917577028274536, Validation Accuracy: 0.90675\n",
      "Epoch: 99, Loss: 0.29043686389923096, Validation Accuracy: 0.90825\n",
      "Dataset 45\n",
      "Epoch: 0, Loss: 3.448411226272583, Validation Accuracy: 0.173\n",
      "Epoch: 1, Loss: 2.498305559158325, Validation Accuracy: 0.20691666666666667\n",
      "Epoch: 2, Loss: 2.389970302581787, Validation Accuracy: 0.24516666666666667\n",
      "Epoch: 3, Loss: 2.2126519680023193, Validation Accuracy: 0.2865\n",
      "Epoch: 4, Loss: 2.0085268020629883, Validation Accuracy: 0.3899166666666667\n",
      "Epoch: 5, Loss: 1.7476330995559692, Validation Accuracy: 0.5120833333333333\n",
      "Epoch: 6, Loss: 1.537207841873169, Validation Accuracy: 0.5474166666666667\n",
      "Epoch: 7, Loss: 1.4151700735092163, Validation Accuracy: 0.5840833333333333\n",
      "Epoch: 8, Loss: 1.3030599355697632, Validation Accuracy: 0.6218333333333333\n",
      "Epoch: 9, Loss: 1.1942462921142578, Validation Accuracy: 0.65375\n",
      "Epoch: 10, Loss: 1.0919890403747559, Validation Accuracy: 0.6851666666666667\n",
      "Epoch: 11, Loss: 1.0002667903900146, Validation Accuracy: 0.7053333333333334\n",
      "Epoch: 12, Loss: 0.9206603765487671, Validation Accuracy: 0.7281666666666666\n",
      "Epoch: 13, Loss: 0.8536087870597839, Validation Accuracy: 0.7463333333333333\n",
      "Epoch: 14, Loss: 0.7979984283447266, Validation Accuracy: 0.76075\n",
      "Epoch: 15, Loss: 0.7542912364006042, Validation Accuracy: 0.7611666666666667\n",
      "Epoch: 16, Loss: 0.7354753613471985, Validation Accuracy: 0.7110833333333333\n",
      "Epoch: 17, Loss: 0.8308334946632385, Validation Accuracy: 0.5083333333333333\n",
      "Epoch: 18, Loss: 1.486029028892517, Validation Accuracy: 0.49825\n",
      "Epoch: 19, Loss: 1.6001944541931152, Validation Accuracy: 0.5789166666666666\n",
      "Epoch: 20, Loss: 1.238356590270996, Validation Accuracy: 0.6506666666666666\n",
      "Epoch: 21, Loss: 1.030635118484497, Validation Accuracy: 0.6999166666666666\n",
      "Epoch: 22, Loss: 0.8984767198562622, Validation Accuracy: 0.7388333333333333\n",
      "Epoch: 23, Loss: 0.7886571288108826, Validation Accuracy: 0.77425\n",
      "Epoch: 24, Loss: 0.7028455138206482, Validation Accuracy: 0.7988333333333333\n",
      "Epoch: 25, Loss: 0.6430174112319946, Validation Accuracy: 0.8143333333333334\n",
      "Epoch: 26, Loss: 0.6034018397331238, Validation Accuracy: 0.8208333333333333\n",
      "Epoch: 27, Loss: 0.5750057697296143, Validation Accuracy: 0.8279166666666666\n",
      "Epoch: 28, Loss: 0.553449809551239, Validation Accuracy: 0.8313333333333334\n",
      "Epoch: 29, Loss: 0.5361846685409546, Validation Accuracy: 0.8356666666666667\n",
      "Epoch: 30, Loss: 0.5217626690864563, Validation Accuracy: 0.8384166666666667\n",
      "Epoch: 31, Loss: 0.5093448758125305, Validation Accuracy: 0.8424166666666667\n",
      "Epoch: 32, Loss: 0.4984436333179474, Validation Accuracy: 0.8455833333333334\n",
      "Epoch: 33, Loss: 0.48864254355430603, Validation Accuracy: 0.8480833333333333\n",
      "Epoch: 34, Loss: 0.47977039217948914, Validation Accuracy: 0.8518333333333333\n",
      "Epoch: 35, Loss: 0.47170382738113403, Validation Accuracy: 0.8543333333333333\n",
      "Epoch: 36, Loss: 0.46428537368774414, Validation Accuracy: 0.857\n",
      "Epoch: 37, Loss: 0.4574240744113922, Validation Accuracy: 0.8590833333333333\n",
      "Epoch: 38, Loss: 0.4510257840156555, Validation Accuracy: 0.86175\n",
      "Epoch: 39, Loss: 0.44502124190330505, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 40, Loss: 0.43935564160346985, Validation Accuracy: 0.8654166666666666\n",
      "Epoch: 41, Loss: 0.43398457765579224, Validation Accuracy: 0.8670833333333333\n",
      "Epoch: 42, Loss: 0.42888757586479187, Validation Accuracy: 0.8685833333333334\n",
      "Epoch: 43, Loss: 0.42403843998908997, Validation Accuracy: 0.8694166666666666\n",
      "Epoch: 44, Loss: 0.4194081723690033, Validation Accuracy: 0.87075\n",
      "Epoch: 45, Loss: 0.41496312618255615, Validation Accuracy: 0.87225\n",
      "Epoch: 46, Loss: 0.41068509221076965, Validation Accuracy: 0.8735\n",
      "Epoch: 47, Loss: 0.40656623244285583, Validation Accuracy: 0.8749166666666667\n",
      "Epoch: 48, Loss: 0.40261009335517883, Validation Accuracy: 0.8759166666666667\n",
      "Epoch: 49, Loss: 0.3987993896007538, Validation Accuracy: 0.8764166666666666\n",
      "Epoch: 50, Loss: 0.3951180875301361, Validation Accuracy: 0.8780833333333333\n",
      "Epoch: 51, Loss: 0.3915652930736542, Validation Accuracy: 0.87825\n",
      "Epoch: 52, Loss: 0.3881320655345917, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 53, Loss: 0.38482901453971863, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 54, Loss: 0.38163647055625916, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 55, Loss: 0.3785383701324463, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 56, Loss: 0.3755227327346802, Validation Accuracy: 0.883\n",
      "Epoch: 57, Loss: 0.3725954294204712, Validation Accuracy: 0.88375\n",
      "Epoch: 58, Loss: 0.36975574493408203, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 59, Loss: 0.36700639128685, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 60, Loss: 0.364340215921402, Validation Accuracy: 0.8866666666666667\n",
      "Epoch: 61, Loss: 0.36174166202545166, Validation Accuracy: 0.8875\n",
      "Epoch: 62, Loss: 0.35919904708862305, Validation Accuracy: 0.88875\n",
      "Epoch: 63, Loss: 0.35671743750572205, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 64, Loss: 0.3542986512184143, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 65, Loss: 0.351936399936676, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 66, Loss: 0.3496270477771759, Validation Accuracy: 0.893\n",
      "Epoch: 67, Loss: 0.3473711311817169, Validation Accuracy: 0.89325\n",
      "Epoch: 68, Loss: 0.34517186880111694, Validation Accuracy: 0.894\n",
      "Epoch: 69, Loss: 0.3430185616016388, Validation Accuracy: 0.89475\n",
      "Epoch: 70, Loss: 0.3409111797809601, Validation Accuracy: 0.8955\n",
      "Epoch: 71, Loss: 0.3388499617576599, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 72, Loss: 0.3368285596370697, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 73, Loss: 0.33485642075538635, Validation Accuracy: 0.8975\n",
      "Epoch: 74, Loss: 0.3329327702522278, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 75, Loss: 0.33104920387268066, Validation Accuracy: 0.8985\n",
      "Epoch: 76, Loss: 0.3291977345943451, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 77, Loss: 0.32738155126571655, Validation Accuracy: 0.89925\n",
      "Epoch: 78, Loss: 0.32560086250305176, Validation Accuracy: 0.90025\n",
      "Epoch: 79, Loss: 0.32385340332984924, Validation Accuracy: 0.9005\n",
      "Epoch: 80, Loss: 0.32213839888572693, Validation Accuracy: 0.90075\n",
      "Epoch: 81, Loss: 0.3204515874385834, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 82, Loss: 0.31879594922065735, Validation Accuracy: 0.9015\n",
      "Epoch: 83, Loss: 0.3171677589416504, Validation Accuracy: 0.902\n",
      "Epoch: 84, Loss: 0.31556522846221924, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 85, Loss: 0.31398653984069824, Validation Accuracy: 0.9026666666666666\n",
      "Epoch: 86, Loss: 0.3124350905418396, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 87, Loss: 0.31090256571769714, Validation Accuracy: 0.90375\n",
      "Epoch: 88, Loss: 0.3093918263912201, Validation Accuracy: 0.904\n",
      "Epoch: 89, Loss: 0.30790477991104126, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 90, Loss: 0.3064413070678711, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 91, Loss: 0.30500200390815735, Validation Accuracy: 0.9056666666666666\n",
      "Epoch: 92, Loss: 0.30358782410621643, Validation Accuracy: 0.9061666666666667\n",
      "Epoch: 93, Loss: 0.3021966218948364, Validation Accuracy: 0.9065\n",
      "Epoch: 94, Loss: 0.30082303285598755, Validation Accuracy: 0.9069166666666667\n",
      "Epoch: 95, Loss: 0.29947176575660706, Validation Accuracy: 0.9078333333333334\n",
      "Epoch: 96, Loss: 0.29813992977142334, Validation Accuracy: 0.9078333333333334\n",
      "Epoch: 97, Loss: 0.29683104157447815, Validation Accuracy: 0.9080833333333334\n",
      "Epoch: 98, Loss: 0.2955418527126312, Validation Accuracy: 0.9085\n",
      "Epoch: 99, Loss: 0.29426994919776917, Validation Accuracy: 0.9089166666666667\n",
      "Dataset 46\n",
      "Epoch: 0, Loss: 4.1503119468688965, Validation Accuracy: 0.18358333333333332\n",
      "Epoch: 1, Loss: 3.0727620124816895, Validation Accuracy: 0.3001666666666667\n",
      "Epoch: 2, Loss: 1.9803564548492432, Validation Accuracy: 0.4205833333333333\n",
      "Epoch: 3, Loss: 1.7312182188034058, Validation Accuracy: 0.4886666666666667\n",
      "Epoch: 4, Loss: 1.5456863641738892, Validation Accuracy: 0.5419166666666667\n",
      "Epoch: 5, Loss: 1.4118345975875854, Validation Accuracy: 0.5586666666666666\n",
      "Epoch: 6, Loss: 1.3117200136184692, Validation Accuracy: 0.5704166666666667\n",
      "Epoch: 7, Loss: 1.2819703817367554, Validation Accuracy: 0.5659166666666666\n",
      "Epoch: 8, Loss: 1.2676929235458374, Validation Accuracy: 0.5446666666666666\n",
      "Epoch: 9, Loss: 1.308064579963684, Validation Accuracy: 0.6040833333333333\n",
      "Epoch: 10, Loss: 1.1577495336532593, Validation Accuracy: 0.6711666666666667\n",
      "Epoch: 11, Loss: 1.005704402923584, Validation Accuracy: 0.7095\n",
      "Epoch: 12, Loss: 0.8968569040298462, Validation Accuracy: 0.7311666666666666\n",
      "Epoch: 13, Loss: 0.8313506841659546, Validation Accuracy: 0.7460833333333333\n",
      "Epoch: 14, Loss: 0.7834935188293457, Validation Accuracy: 0.7549166666666667\n",
      "Epoch: 15, Loss: 0.7494153380393982, Validation Accuracy: 0.7641666666666667\n",
      "Epoch: 16, Loss: 0.720302402973175, Validation Accuracy: 0.7654166666666666\n",
      "Epoch: 17, Loss: 0.7028539180755615, Validation Accuracy: 0.7728333333333334\n",
      "Epoch: 18, Loss: 0.6891254186630249, Validation Accuracy: 0.7643333333333333\n",
      "Epoch: 19, Loss: 0.6932026147842407, Validation Accuracy: 0.76425\n",
      "Epoch: 20, Loss: 0.6950026154518127, Validation Accuracy: 0.7495833333333334\n",
      "Epoch: 21, Loss: 0.7180036902427673, Validation Accuracy: 0.7596666666666667\n",
      "Epoch: 22, Loss: 0.7003903985023499, Validation Accuracy: 0.7641666666666667\n",
      "Epoch: 23, Loss: 0.6883166432380676, Validation Accuracy: 0.7909166666666667\n",
      "Epoch: 24, Loss: 0.6266164183616638, Validation Accuracy: 0.8094166666666667\n",
      "Epoch: 25, Loss: 0.5863308310508728, Validation Accuracy: 0.8265833333333333\n",
      "Epoch: 26, Loss: 0.5482276678085327, Validation Accuracy: 0.8335\n",
      "Epoch: 27, Loss: 0.5276269912719727, Validation Accuracy: 0.8405833333333333\n",
      "Epoch: 28, Loss: 0.5107318758964539, Validation Accuracy: 0.8400833333333333\n",
      "Epoch: 29, Loss: 0.49851369857788086, Validation Accuracy: 0.848\n",
      "Epoch: 30, Loss: 0.48769688606262207, Validation Accuracy: 0.8479166666666667\n",
      "Epoch: 31, Loss: 0.47841718792915344, Validation Accuracy: 0.85225\n",
      "Epoch: 32, Loss: 0.4699098765850067, Validation Accuracy: 0.8525833333333334\n",
      "Epoch: 33, Loss: 0.4622262716293335, Validation Accuracy: 0.8566666666666667\n",
      "Epoch: 34, Loss: 0.45506030321121216, Validation Accuracy: 0.8574166666666667\n",
      "Epoch: 35, Loss: 0.4484691619873047, Validation Accuracy: 0.8613333333333333\n",
      "Epoch: 36, Loss: 0.44229012727737427, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 37, Loss: 0.43662121891975403, Validation Accuracy: 0.8661666666666666\n",
      "Epoch: 38, Loss: 0.43129292130470276, Validation Accuracy: 0.8655\n",
      "Epoch: 39, Loss: 0.4264239966869354, Validation Accuracy: 0.8676666666666667\n",
      "Epoch: 40, Loss: 0.42192843556404114, Validation Accuracy: 0.8675833333333334\n",
      "Epoch: 41, Loss: 0.4179837703704834, Validation Accuracy: 0.8695\n",
      "Epoch: 42, Loss: 0.41455647349357605, Validation Accuracy: 0.8679166666666667\n",
      "Epoch: 43, Loss: 0.41206979751586914, Validation Accuracy: 0.8715\n",
      "Epoch: 44, Loss: 0.41018277406692505, Validation Accuracy: 0.8680833333333333\n",
      "Epoch: 45, Loss: 0.41004523634910583, Validation Accuracy: 0.8713333333333333\n",
      "Epoch: 46, Loss: 0.4111548364162445, Validation Accuracy: 0.86575\n",
      "Epoch: 47, Loss: 0.414863646030426, Validation Accuracy: 0.86725\n",
      "Epoch: 48, Loss: 0.4218032658100128, Validation Accuracy: 0.8608333333333333\n",
      "Epoch: 49, Loss: 0.4306248426437378, Validation Accuracy: 0.8595833333333334\n",
      "Epoch: 50, Loss: 0.44403275847435, Validation Accuracy: 0.8520833333333333\n",
      "Epoch: 51, Loss: 0.45098620653152466, Validation Accuracy: 0.8539166666666667\n",
      "Epoch: 52, Loss: 0.4597547650337219, Validation Accuracy: 0.85475\n",
      "Epoch: 53, Loss: 0.4457889795303345, Validation Accuracy: 0.86375\n",
      "Epoch: 54, Loss: 0.4335731267929077, Validation Accuracy: 0.87025\n",
      "Epoch: 55, Loss: 0.40541398525238037, Validation Accuracy: 0.87875\n",
      "Epoch: 56, Loss: 0.38865819573402405, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 57, Loss: 0.37313130497932434, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 58, Loss: 0.36459484696388245, Validation Accuracy: 0.88775\n",
      "Epoch: 59, Loss: 0.3582264482975006, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 60, Loss: 0.3538854122161865, Validation Accuracy: 0.8903333333333333\n",
      "Epoch: 61, Loss: 0.35029900074005127, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 62, Loss: 0.34726274013519287, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 63, Loss: 0.3445185422897339, Validation Accuracy: 0.8929166666666667\n",
      "Epoch: 64, Loss: 0.34196528792381287, Validation Accuracy: 0.89325\n",
      "Epoch: 65, Loss: 0.3395630717277527, Validation Accuracy: 0.8936666666666667\n",
      "Epoch: 66, Loss: 0.3372651934623718, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 67, Loss: 0.3350540101528168, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 68, Loss: 0.3329113721847534, Validation Accuracy: 0.8961666666666667\n",
      "Epoch: 69, Loss: 0.33083513379096985, Validation Accuracy: 0.8963333333333333\n",
      "Epoch: 70, Loss: 0.32881346344947815, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 71, Loss: 0.32684001326560974, Validation Accuracy: 0.8978333333333334\n",
      "Epoch: 72, Loss: 0.324910044670105, Validation Accuracy: 0.899\n",
      "Epoch: 73, Loss: 0.32302525639533997, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 74, Loss: 0.3211787939071655, Validation Accuracy: 0.8998333333333334\n",
      "Epoch: 75, Loss: 0.3193694055080414, Validation Accuracy: 0.901\n",
      "Epoch: 76, Loss: 0.31759360432624817, Validation Accuracy: 0.90125\n",
      "Epoch: 77, Loss: 0.3158496916294098, Validation Accuracy: 0.9015\n",
      "Epoch: 78, Loss: 0.31413939595222473, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 79, Loss: 0.31245970726013184, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 80, Loss: 0.3108113408088684, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 81, Loss: 0.30919110774993896, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 82, Loss: 0.30759841203689575, Validation Accuracy: 0.9041666666666667\n",
      "Epoch: 83, Loss: 0.3060344159603119, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 84, Loss: 0.3044971823692322, Validation Accuracy: 0.9051666666666667\n",
      "Epoch: 85, Loss: 0.30298590660095215, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 86, Loss: 0.30150118470191956, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 87, Loss: 0.30004361271858215, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 88, Loss: 0.29860907793045044, Validation Accuracy: 0.9059166666666667\n",
      "Epoch: 89, Loss: 0.29719898104667664, Validation Accuracy: 0.90675\n",
      "Epoch: 90, Loss: 0.29581335186958313, Validation Accuracy: 0.907\n",
      "Epoch: 91, Loss: 0.29444605112075806, Validation Accuracy: 0.9075\n",
      "Epoch: 92, Loss: 0.2930958569049835, Validation Accuracy: 0.90775\n",
      "Epoch: 93, Loss: 0.29176631569862366, Validation Accuracy: 0.9086666666666666\n",
      "Epoch: 94, Loss: 0.29045966267585754, Validation Accuracy: 0.9088333333333334\n",
      "Epoch: 95, Loss: 0.28917407989501953, Validation Accuracy: 0.9090833333333334\n",
      "Epoch: 96, Loss: 0.2879084646701813, Validation Accuracy: 0.9090833333333334\n",
      "Epoch: 97, Loss: 0.2866610884666443, Validation Accuracy: 0.9094166666666667\n",
      "Epoch: 98, Loss: 0.28542932868003845, Validation Accuracy: 0.9099166666666667\n",
      "Epoch: 99, Loss: 0.2842138707637787, Validation Accuracy: 0.9104166666666667\n",
      "Dataset 47\n",
      "Epoch: 0, Loss: 3.2319397926330566, Validation Accuracy: 0.1675\n",
      "Epoch: 1, Loss: 3.48874568939209, Validation Accuracy: 0.2509166666666667\n",
      "Epoch: 2, Loss: 2.4017202854156494, Validation Accuracy: 0.23025\n",
      "Epoch: 3, Loss: 2.4815123081207275, Validation Accuracy: 0.24225\n",
      "Epoch: 4, Loss: 2.1505868434906006, Validation Accuracy: 0.35275\n",
      "Epoch: 5, Loss: 1.8312089443206787, Validation Accuracy: 0.494\n",
      "Epoch: 6, Loss: 1.5662992000579834, Validation Accuracy: 0.5825833333333333\n",
      "Epoch: 7, Loss: 1.3193293809890747, Validation Accuracy: 0.6309166666666667\n",
      "Epoch: 8, Loss: 1.165569543838501, Validation Accuracy: 0.6629166666666667\n",
      "Epoch: 9, Loss: 1.0635133981704712, Validation Accuracy: 0.6879166666666666\n",
      "Epoch: 10, Loss: 0.9796701669692993, Validation Accuracy: 0.7115\n",
      "Epoch: 11, Loss: 0.9087145328521729, Validation Accuracy: 0.7271666666666666\n",
      "Epoch: 12, Loss: 0.8486105799674988, Validation Accuracy: 0.7426666666666667\n",
      "Epoch: 13, Loss: 0.800091564655304, Validation Accuracy: 0.7505\n",
      "Epoch: 14, Loss: 0.7663522362709045, Validation Accuracy: 0.75075\n",
      "Epoch: 15, Loss: 0.7568327784538269, Validation Accuracy: 0.73075\n",
      "Epoch: 16, Loss: 0.7901583909988403, Validation Accuracy: 0.6900833333333334\n",
      "Epoch: 17, Loss: 0.8734824061393738, Validation Accuracy: 0.6715\n",
      "Epoch: 18, Loss: 0.9899961948394775, Validation Accuracy: 0.6955\n",
      "Epoch: 19, Loss: 0.8427663445472717, Validation Accuracy: 0.7745\n",
      "Epoch: 20, Loss: 0.6913340091705322, Validation Accuracy: 0.8094166666666667\n",
      "Epoch: 21, Loss: 0.5914257168769836, Validation Accuracy: 0.8189166666666666\n",
      "Epoch: 22, Loss: 0.5634959936141968, Validation Accuracy: 0.82375\n",
      "Epoch: 23, Loss: 0.546064019203186, Validation Accuracy: 0.8268333333333333\n",
      "Epoch: 24, Loss: 0.532589852809906, Validation Accuracy: 0.82975\n",
      "Epoch: 25, Loss: 0.5213508009910583, Validation Accuracy: 0.8330833333333333\n",
      "Epoch: 26, Loss: 0.5122461915016174, Validation Accuracy: 0.8315833333333333\n",
      "Epoch: 27, Loss: 0.5055286288261414, Validation Accuracy: 0.83575\n",
      "Epoch: 28, Loss: 0.5023288130760193, Validation Accuracy: 0.8281666666666667\n",
      "Epoch: 29, Loss: 0.5042093396186829, Validation Accuracy: 0.8270833333333333\n",
      "Epoch: 30, Loss: 0.5143226981163025, Validation Accuracy: 0.8128333333333333\n",
      "Epoch: 31, Loss: 0.5347176790237427, Validation Accuracy: 0.80225\n",
      "Epoch: 32, Loss: 0.5654251575469971, Validation Accuracy: 0.7861666666666667\n",
      "Epoch: 33, Loss: 0.5919308066368103, Validation Accuracy: 0.7890833333333334\n",
      "Epoch: 34, Loss: 0.5972134470939636, Validation Accuracy: 0.7973333333333333\n",
      "Epoch: 35, Loss: 0.5592758655548096, Validation Accuracy: 0.8259166666666666\n",
      "Epoch: 36, Loss: 0.5111386179924011, Validation Accuracy: 0.8365\n",
      "Epoch: 37, Loss: 0.4709780216217041, Validation Accuracy: 0.8571666666666666\n",
      "Epoch: 38, Loss: 0.44722020626068115, Validation Accuracy: 0.85425\n",
      "Epoch: 39, Loss: 0.43325984477996826, Validation Accuracy: 0.86275\n",
      "Epoch: 40, Loss: 0.4241231381893158, Validation Accuracy: 0.86\n",
      "Epoch: 41, Loss: 0.4172276556491852, Validation Accuracy: 0.86475\n",
      "Epoch: 42, Loss: 0.4115540683269501, Validation Accuracy: 0.8655833333333334\n",
      "Epoch: 43, Loss: 0.40658003091812134, Validation Accuracy: 0.8679166666666667\n",
      "Epoch: 44, Loss: 0.40203791856765747, Validation Accuracy: 0.8689166666666667\n",
      "Epoch: 45, Loss: 0.3978390693664551, Validation Accuracy: 0.8701666666666666\n",
      "Epoch: 46, Loss: 0.39385685324668884, Validation Accuracy: 0.8709166666666667\n",
      "Epoch: 47, Loss: 0.3900754451751709, Validation Accuracy: 0.8736666666666667\n",
      "Epoch: 48, Loss: 0.3864403963088989, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 49, Loss: 0.38295915722846985, Validation Accuracy: 0.87625\n",
      "Epoch: 50, Loss: 0.37960806488990784, Validation Accuracy: 0.8760833333333333\n",
      "Epoch: 51, Loss: 0.3763674795627594, Validation Accuracy: 0.8780833333333333\n",
      "Epoch: 52, Loss: 0.3732355833053589, Validation Accuracy: 0.878\n",
      "Epoch: 53, Loss: 0.3701936900615692, Validation Accuracy: 0.8799166666666667\n",
      "Epoch: 54, Loss: 0.36724451184272766, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 55, Loss: 0.3643791079521179, Validation Accuracy: 0.8815\n",
      "Epoch: 56, Loss: 0.361595094203949, Validation Accuracy: 0.88125\n",
      "Epoch: 57, Loss: 0.3588874936103821, Validation Accuracy: 0.8829166666666667\n",
      "Epoch: 58, Loss: 0.35624930262565613, Validation Accuracy: 0.88325\n",
      "Epoch: 59, Loss: 0.3536776602268219, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 60, Loss: 0.35117435455322266, Validation Accuracy: 0.885\n",
      "Epoch: 61, Loss: 0.34873342514038086, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 62, Loss: 0.3463519811630249, Validation Accuracy: 0.8866666666666667\n",
      "Epoch: 63, Loss: 0.3440271317958832, Validation Accuracy: 0.8885\n",
      "Epoch: 64, Loss: 0.341759592294693, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 65, Loss: 0.3395404517650604, Validation Accuracy: 0.8903333333333333\n",
      "Epoch: 66, Loss: 0.33736878633499146, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 67, Loss: 0.33524537086486816, Validation Accuracy: 0.89125\n",
      "Epoch: 68, Loss: 0.33316510915756226, Validation Accuracy: 0.8916666666666667\n",
      "Epoch: 69, Loss: 0.3311324119567871, Validation Accuracy: 0.8925\n",
      "Epoch: 70, Loss: 0.329140841960907, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 71, Loss: 0.32719099521636963, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 72, Loss: 0.3252853453159332, Validation Accuracy: 0.894\n",
      "Epoch: 73, Loss: 0.32341501116752625, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 74, Loss: 0.3215879797935486, Validation Accuracy: 0.89575\n",
      "Epoch: 75, Loss: 0.3197971284389496, Validation Accuracy: 0.89675\n",
      "Epoch: 76, Loss: 0.31803804636001587, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 77, Loss: 0.31630954146385193, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 78, Loss: 0.31461426615715027, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 79, Loss: 0.312954843044281, Validation Accuracy: 0.89875\n",
      "Epoch: 80, Loss: 0.3113252520561218, Validation Accuracy: 0.89875\n",
      "Epoch: 81, Loss: 0.3097269535064697, Validation Accuracy: 0.89975\n",
      "Epoch: 82, Loss: 0.3081565201282501, Validation Accuracy: 0.9003333333333333\n",
      "Epoch: 83, Loss: 0.3066113591194153, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 84, Loss: 0.3050870895385742, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 85, Loss: 0.3035913407802582, Validation Accuracy: 0.9020833333333333\n",
      "Epoch: 86, Loss: 0.30212241411209106, Validation Accuracy: 0.9025833333333333\n",
      "Epoch: 87, Loss: 0.30067989230155945, Validation Accuracy: 0.9026666666666666\n",
      "Epoch: 88, Loss: 0.29925450682640076, Validation Accuracy: 0.9034166666666666\n",
      "Epoch: 89, Loss: 0.2978496849536896, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 90, Loss: 0.29646891355514526, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 91, Loss: 0.29510822892189026, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 92, Loss: 0.2937672436237335, Validation Accuracy: 0.905\n",
      "Epoch: 93, Loss: 0.29244670271873474, Validation Accuracy: 0.9055833333333333\n",
      "Epoch: 94, Loss: 0.29114505648612976, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 95, Loss: 0.28986257314682007, Validation Accuracy: 0.9061666666666667\n",
      "Epoch: 96, Loss: 0.28860384225845337, Validation Accuracy: 0.9064166666666666\n",
      "Epoch: 97, Loss: 0.28736525774002075, Validation Accuracy: 0.907\n",
      "Epoch: 98, Loss: 0.28614717721939087, Validation Accuracy: 0.907\n",
      "Epoch: 99, Loss: 0.28494465351104736, Validation Accuracy: 0.9075\n",
      "Dataset 48\n",
      "Epoch: 0, Loss: 3.6761727333068848, Validation Accuracy: 0.18541666666666667\n",
      "Epoch: 1, Loss: 3.261293649673462, Validation Accuracy: 0.24083333333333334\n",
      "Epoch: 2, Loss: 3.561598539352417, Validation Accuracy: 0.27416666666666667\n",
      "Epoch: 3, Loss: 2.2625114917755127, Validation Accuracy: 0.35183333333333333\n",
      "Epoch: 4, Loss: 1.8200416564941406, Validation Accuracy: 0.42083333333333334\n",
      "Epoch: 5, Loss: 1.6746629476547241, Validation Accuracy: 0.4673333333333333\n",
      "Epoch: 6, Loss: 1.5822352170944214, Validation Accuracy: 0.5035\n",
      "Epoch: 7, Loss: 1.5004459619522095, Validation Accuracy: 0.5466666666666666\n",
      "Epoch: 8, Loss: 1.4235268831253052, Validation Accuracy: 0.5775\n",
      "Epoch: 9, Loss: 1.3506914377212524, Validation Accuracy: 0.5959166666666667\n",
      "Epoch: 10, Loss: 1.2898727655410767, Validation Accuracy: 0.61325\n",
      "Epoch: 11, Loss: 1.2419968843460083, Validation Accuracy: 0.5965833333333334\n",
      "Epoch: 12, Loss: 1.2395330667495728, Validation Accuracy: 0.6031666666666666\n",
      "Epoch: 13, Loss: 1.215235710144043, Validation Accuracy: 0.586\n",
      "Epoch: 14, Loss: 1.2348425388336182, Validation Accuracy: 0.6634166666666667\n",
      "Epoch: 15, Loss: 1.0480376482009888, Validation Accuracy: 0.7023333333333334\n",
      "Epoch: 16, Loss: 0.9637201428413391, Validation Accuracy: 0.7270833333333333\n",
      "Epoch: 17, Loss: 0.8834277987480164, Validation Accuracy: 0.7395\n",
      "Epoch: 18, Loss: 0.8387049436569214, Validation Accuracy: 0.7520833333333333\n",
      "Epoch: 19, Loss: 0.7953898906707764, Validation Accuracy: 0.761\n",
      "Epoch: 20, Loss: 0.7649028897285461, Validation Accuracy: 0.76925\n",
      "Epoch: 21, Loss: 0.7340611815452576, Validation Accuracy: 0.7729166666666667\n",
      "Epoch: 22, Loss: 0.7123472690582275, Validation Accuracy: 0.7804166666666666\n",
      "Epoch: 23, Loss: 0.6914243698120117, Validation Accuracy: 0.7783333333333333\n",
      "Epoch: 24, Loss: 0.6843804717063904, Validation Accuracy: 0.78\n",
      "Epoch: 25, Loss: 0.6822372674942017, Validation Accuracy: 0.762\n",
      "Epoch: 26, Loss: 0.7192560434341431, Validation Accuracy: 0.7591666666666667\n",
      "Epoch: 27, Loss: 0.7431048154830933, Validation Accuracy: 0.7155\n",
      "Epoch: 28, Loss: 0.8391792178153992, Validation Accuracy: 0.7645\n",
      "Epoch: 29, Loss: 0.7237422466278076, Validation Accuracy: 0.7765833333333333\n",
      "Epoch: 30, Loss: 0.6798639893531799, Validation Accuracy: 0.813\n",
      "Epoch: 31, Loss: 0.5892207026481628, Validation Accuracy: 0.8225833333333333\n",
      "Epoch: 32, Loss: 0.5599580407142639, Validation Accuracy: 0.8316666666666667\n",
      "Epoch: 33, Loss: 0.5405066609382629, Validation Accuracy: 0.8351666666666666\n",
      "Epoch: 34, Loss: 0.5271767973899841, Validation Accuracy: 0.8384166666666667\n",
      "Epoch: 35, Loss: 0.5159502625465393, Validation Accuracy: 0.8418333333333333\n",
      "Epoch: 36, Loss: 0.5061116218566895, Validation Accuracy: 0.8441666666666666\n",
      "Epoch: 37, Loss: 0.49720174074172974, Validation Accuracy: 0.847\n",
      "Epoch: 38, Loss: 0.4890448749065399, Validation Accuracy: 0.8493333333333334\n",
      "Epoch: 39, Loss: 0.4814699590206146, Validation Accuracy: 0.8514166666666667\n",
      "Epoch: 40, Loss: 0.4743881821632385, Validation Accuracy: 0.8530833333333333\n",
      "Epoch: 41, Loss: 0.4677877128124237, Validation Accuracy: 0.8555833333333334\n",
      "Epoch: 42, Loss: 0.4616367220878601, Validation Accuracy: 0.8565\n",
      "Epoch: 43, Loss: 0.45588135719299316, Validation Accuracy: 0.85925\n",
      "Epoch: 44, Loss: 0.4505214989185333, Validation Accuracy: 0.85925\n",
      "Epoch: 45, Loss: 0.4455762803554535, Validation Accuracy: 0.863\n",
      "Epoch: 46, Loss: 0.4410720765590668, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 47, Loss: 0.4370068907737732, Validation Accuracy: 0.86525\n",
      "Epoch: 48, Loss: 0.43346232175827026, Validation Accuracy: 0.8643333333333333\n",
      "Epoch: 49, Loss: 0.43045690655708313, Validation Accuracy: 0.86775\n",
      "Epoch: 50, Loss: 0.42810505628585815, Validation Accuracy: 0.86525\n",
      "Epoch: 51, Loss: 0.42650189995765686, Validation Accuracy: 0.8668333333333333\n",
      "Epoch: 52, Loss: 0.4258313477039337, Validation Accuracy: 0.8650833333333333\n",
      "Epoch: 53, Loss: 0.4257749021053314, Validation Accuracy: 0.86425\n",
      "Epoch: 54, Loss: 0.4271388053894043, Validation Accuracy: 0.8615\n",
      "Epoch: 55, Loss: 0.4281446635723114, Validation Accuracy: 0.86275\n",
      "Epoch: 56, Loss: 0.43129047751426697, Validation Accuracy: 0.8595\n",
      "Epoch: 57, Loss: 0.4312072694301605, Validation Accuracy: 0.861\n",
      "Epoch: 58, Loss: 0.4334228038787842, Validation Accuracy: 0.8598333333333333\n",
      "Epoch: 59, Loss: 0.4292583465576172, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 60, Loss: 0.4267755448818207, Validation Accuracy: 0.865\n",
      "Epoch: 61, Loss: 0.4169028699398041, Validation Accuracy: 0.8700833333333333\n",
      "Epoch: 62, Loss: 0.40965813398361206, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 63, Loss: 0.3979957699775696, Validation Accuracy: 0.8764166666666666\n",
      "Epoch: 64, Loss: 0.3896544277667999, Validation Accuracy: 0.878\n",
      "Epoch: 65, Loss: 0.3809088170528412, Validation Accuracy: 0.88225\n",
      "Epoch: 66, Loss: 0.3748709261417389, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 67, Loss: 0.3690970540046692, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 68, Loss: 0.36489757895469666, Validation Accuracy: 0.8868333333333334\n",
      "Epoch: 69, Loss: 0.3609202802181244, Validation Accuracy: 0.8889166666666667\n",
      "Epoch: 70, Loss: 0.35767099261283875, Validation Accuracy: 0.8881666666666667\n",
      "Epoch: 71, Loss: 0.3545382022857666, Validation Accuracy: 0.891\n",
      "Epoch: 72, Loss: 0.3517652451992035, Validation Accuracy: 0.8908333333333334\n",
      "Epoch: 73, Loss: 0.3491207957267761, Validation Accuracy: 0.8925833333333333\n",
      "Epoch: 74, Loss: 0.34668394923210144, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 75, Loss: 0.34433120489120483, Validation Accuracy: 0.8939166666666667\n",
      "Epoch: 76, Loss: 0.34211182594299316, Validation Accuracy: 0.894\n",
      "Epoch: 77, Loss: 0.33994999527931213, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 78, Loss: 0.3378749489784241, Validation Accuracy: 0.8953333333333333\n",
      "Epoch: 79, Loss: 0.3358461856842041, Validation Accuracy: 0.8966666666666666\n",
      "Epoch: 80, Loss: 0.3338729739189148, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 81, Loss: 0.33194059133529663, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 82, Loss: 0.3300620913505554, Validation Accuracy: 0.8971666666666667\n",
      "Epoch: 83, Loss: 0.3282337188720703, Validation Accuracy: 0.8983333333333333\n",
      "Epoch: 84, Loss: 0.3264428675174713, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 85, Loss: 0.3246871531009674, Validation Accuracy: 0.899\n",
      "Epoch: 86, Loss: 0.32297083735466003, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 87, Loss: 0.3212846517562866, Validation Accuracy: 0.8998333333333334\n",
      "Epoch: 88, Loss: 0.3196336030960083, Validation Accuracy: 0.90075\n",
      "Epoch: 89, Loss: 0.3180214464664459, Validation Accuracy: 0.9005833333333333\n",
      "Epoch: 90, Loss: 0.31644102931022644, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 91, Loss: 0.3148898482322693, Validation Accuracy: 0.90125\n",
      "Epoch: 92, Loss: 0.3133693337440491, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 93, Loss: 0.31187736988067627, Validation Accuracy: 0.9025\n",
      "Epoch: 94, Loss: 0.31040796637535095, Validation Accuracy: 0.9028333333333334\n",
      "Epoch: 95, Loss: 0.30896544456481934, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 96, Loss: 0.3075486123561859, Validation Accuracy: 0.90375\n",
      "Epoch: 97, Loss: 0.3061557412147522, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 98, Loss: 0.3047846555709839, Validation Accuracy: 0.9048333333333334\n",
      "Epoch: 99, Loss: 0.3034321963787079, Validation Accuracy: 0.9054166666666666\n",
      "Dataset 49\n",
      "Epoch: 0, Loss: 4.662681579589844, Validation Accuracy: 0.11075\n",
      "Epoch: 1, Loss: 5.126007556915283, Validation Accuracy: 0.09416666666666666\n",
      "Epoch: 2, Loss: 3.4910085201263428, Validation Accuracy: 0.16733333333333333\n",
      "Epoch: 3, Loss: 2.8780345916748047, Validation Accuracy: 0.26258333333333334\n",
      "Epoch: 4, Loss: 2.042728900909424, Validation Accuracy: 0.35991666666666666\n",
      "Epoch: 5, Loss: 1.8338186740875244, Validation Accuracy: 0.42791666666666667\n",
      "Epoch: 6, Loss: 1.7102469205856323, Validation Accuracy: 0.4745\n",
      "Epoch: 7, Loss: 1.601716160774231, Validation Accuracy: 0.5114166666666666\n",
      "Epoch: 8, Loss: 1.505795955657959, Validation Accuracy: 0.5399166666666667\n",
      "Epoch: 9, Loss: 1.4226837158203125, Validation Accuracy: 0.55875\n",
      "Epoch: 10, Loss: 1.3508280515670776, Validation Accuracy: 0.5743333333333334\n",
      "Epoch: 11, Loss: 1.2882328033447266, Validation Accuracy: 0.591\n",
      "Epoch: 12, Loss: 1.2322781085968018, Validation Accuracy: 0.60475\n",
      "Epoch: 13, Loss: 1.180685043334961, Validation Accuracy: 0.6205\n",
      "Epoch: 14, Loss: 1.1317458152770996, Validation Accuracy: 0.636\n",
      "Epoch: 15, Loss: 1.0847606658935547, Validation Accuracy: 0.6506666666666666\n",
      "Epoch: 16, Loss: 1.0392990112304688, Validation Accuracy: 0.6679166666666667\n",
      "Epoch: 17, Loss: 0.9953740239143372, Validation Accuracy: 0.6848333333333333\n",
      "Epoch: 18, Loss: 0.9531136155128479, Validation Accuracy: 0.69875\n",
      "Epoch: 19, Loss: 0.9140104055404663, Validation Accuracy: 0.7075\n",
      "Epoch: 20, Loss: 0.8822328448295593, Validation Accuracy: 0.7100833333333333\n",
      "Epoch: 21, Loss: 0.8723722100257874, Validation Accuracy: 0.6855\n",
      "Epoch: 22, Loss: 0.9268041253089905, Validation Accuracy: 0.6206666666666667\n",
      "Epoch: 23, Loss: 1.1091221570968628, Validation Accuracy: 0.5859166666666666\n",
      "Epoch: 24, Loss: 1.1917245388031006, Validation Accuracy: 0.6589166666666667\n",
      "Epoch: 25, Loss: 0.9848082065582275, Validation Accuracy: 0.7668333333333334\n",
      "Epoch: 26, Loss: 0.7512015104293823, Validation Accuracy: 0.7816666666666666\n",
      "Epoch: 27, Loss: 0.6966724395751953, Validation Accuracy: 0.788\n",
      "Epoch: 28, Loss: 0.6659202575683594, Validation Accuracy: 0.7935\n",
      "Epoch: 29, Loss: 0.6418549418449402, Validation Accuracy: 0.8000833333333334\n",
      "Epoch: 30, Loss: 0.622133731842041, Validation Accuracy: 0.8050833333333334\n",
      "Epoch: 31, Loss: 0.604902982711792, Validation Accuracy: 0.81\n",
      "Epoch: 32, Loss: 0.5900792479515076, Validation Accuracy: 0.8125833333333333\n",
      "Epoch: 33, Loss: 0.5767920613288879, Validation Accuracy: 0.8171666666666667\n",
      "Epoch: 34, Loss: 0.5654879808425903, Validation Accuracy: 0.8183333333333334\n",
      "Epoch: 35, Loss: 0.5553061366081238, Validation Accuracy: 0.8224166666666667\n",
      "Epoch: 36, Loss: 0.5474172234535217, Validation Accuracy: 0.8238333333333333\n",
      "Epoch: 37, Loss: 0.5404183864593506, Validation Accuracy: 0.8255833333333333\n",
      "Epoch: 38, Loss: 0.5374308228492737, Validation Accuracy: 0.8240833333333333\n",
      "Epoch: 39, Loss: 0.5348441004753113, Validation Accuracy: 0.823\n",
      "Epoch: 40, Loss: 0.5412304401397705, Validation Accuracy: 0.8175\n",
      "Epoch: 41, Loss: 0.5442842245101929, Validation Accuracy: 0.81275\n",
      "Epoch: 42, Loss: 0.5663090348243713, Validation Accuracy: 0.8049166666666666\n",
      "Epoch: 43, Loss: 0.5704032182693481, Validation Accuracy: 0.7963333333333333\n",
      "Epoch: 44, Loss: 0.6030781269073486, Validation Accuracy: 0.8016666666666666\n",
      "Epoch: 45, Loss: 0.581451416015625, Validation Accuracy: 0.8021666666666667\n",
      "Epoch: 46, Loss: 0.5871750712394714, Validation Accuracy: 0.8191666666666667\n",
      "Epoch: 47, Loss: 0.5353159308433533, Validation Accuracy: 0.8309166666666666\n",
      "Epoch: 48, Loss: 0.5167276859283447, Validation Accuracy: 0.84175\n",
      "Epoch: 49, Loss: 0.4813861846923828, Validation Accuracy: 0.8495833333333334\n",
      "Epoch: 50, Loss: 0.46770524978637695, Validation Accuracy: 0.8524166666666667\n",
      "Epoch: 51, Loss: 0.45311298966407776, Validation Accuracy: 0.85675\n",
      "Epoch: 52, Loss: 0.4451485276222229, Validation Accuracy: 0.86\n",
      "Epoch: 53, Loss: 0.4375884234905243, Validation Accuracy: 0.86075\n",
      "Epoch: 54, Loss: 0.43196550011634827, Validation Accuracy: 0.8635\n",
      "Epoch: 55, Loss: 0.4268149435520172, Validation Accuracy: 0.8644166666666667\n",
      "Epoch: 56, Loss: 0.4222768247127533, Validation Accuracy: 0.8669166666666667\n",
      "Epoch: 57, Loss: 0.4179784655570984, Validation Accuracy: 0.8670833333333333\n",
      "Epoch: 58, Loss: 0.41403108835220337, Validation Accuracy: 0.8691666666666666\n",
      "Epoch: 59, Loss: 0.41022008657455444, Validation Accuracy: 0.8699166666666667\n",
      "Epoch: 60, Loss: 0.4066358506679535, Validation Accuracy: 0.87175\n",
      "Epoch: 61, Loss: 0.40318554639816284, Validation Accuracy: 0.8716666666666667\n",
      "Epoch: 62, Loss: 0.3998886048793793, Validation Accuracy: 0.8736666666666667\n",
      "Epoch: 63, Loss: 0.3966904580593109, Validation Accuracy: 0.87375\n",
      "Epoch: 64, Loss: 0.3935944139957428, Validation Accuracy: 0.87575\n",
      "Epoch: 65, Loss: 0.39057767391204834, Validation Accuracy: 0.8756666666666667\n",
      "Epoch: 66, Loss: 0.3876523971557617, Validation Accuracy: 0.87725\n",
      "Epoch: 67, Loss: 0.38480260968208313, Validation Accuracy: 0.8774166666666666\n",
      "Epoch: 68, Loss: 0.38203978538513184, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 69, Loss: 0.37934842705726624, Validation Accuracy: 0.8794166666666666\n",
      "Epoch: 70, Loss: 0.3767315745353699, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 71, Loss: 0.37417522072792053, Validation Accuracy: 0.8810833333333333\n",
      "Epoch: 72, Loss: 0.37168189883232117, Validation Accuracy: 0.88225\n",
      "Epoch: 73, Loss: 0.3692426085472107, Validation Accuracy: 0.8825\n",
      "Epoch: 74, Loss: 0.36686331033706665, Validation Accuracy: 0.8840833333333333\n",
      "Epoch: 75, Loss: 0.3645342290401459, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 76, Loss: 0.3622652590274811, Validation Accuracy: 0.8855\n",
      "Epoch: 77, Loss: 0.36004579067230225, Validation Accuracy: 0.8850833333333333\n",
      "Epoch: 78, Loss: 0.3578692674636841, Validation Accuracy: 0.8871666666666667\n",
      "Epoch: 79, Loss: 0.3557499051094055, Validation Accuracy: 0.8864166666666666\n",
      "Epoch: 80, Loss: 0.3536699712276459, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 81, Loss: 0.3516400456428528, Validation Accuracy: 0.8876666666666667\n",
      "Epoch: 82, Loss: 0.3496493995189667, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 83, Loss: 0.34770044684410095, Validation Accuracy: 0.8895\n",
      "Epoch: 84, Loss: 0.3457854092121124, Validation Accuracy: 0.8900833333333333\n",
      "Epoch: 85, Loss: 0.34391528367996216, Validation Accuracy: 0.89075\n",
      "Epoch: 86, Loss: 0.34208357334136963, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 87, Loss: 0.34028345346450806, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 88, Loss: 0.33851274847984314, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 89, Loss: 0.33678701519966125, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 90, Loss: 0.3350951075553894, Validation Accuracy: 0.893\n",
      "Epoch: 91, Loss: 0.33344167470932007, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 92, Loss: 0.3318118751049042, Validation Accuracy: 0.8943333333333333\n",
      "Epoch: 93, Loss: 0.330208957195282, Validation Accuracy: 0.8945\n",
      "Epoch: 94, Loss: 0.32863110303878784, Validation Accuracy: 0.8954166666666666\n",
      "Epoch: 95, Loss: 0.32707712054252625, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 96, Loss: 0.32553720474243164, Validation Accuracy: 0.8966666666666666\n",
      "Epoch: 97, Loss: 0.3240375816822052, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 98, Loss: 0.3225467801094055, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 99, Loss: 0.3210819661617279, Validation Accuracy: 0.8976666666666666\n",
      "Dataset 50\n",
      "Epoch: 0, Loss: 3.46193528175354, Validation Accuracy: 0.20125\n",
      "Epoch: 1, Loss: 2.4617300033569336, Validation Accuracy: 0.278\n",
      "Epoch: 2, Loss: 2.033381462097168, Validation Accuracy: 0.3834166666666667\n",
      "Epoch: 3, Loss: 1.7974315881729126, Validation Accuracy: 0.36533333333333334\n",
      "Epoch: 4, Loss: 1.7507145404815674, Validation Accuracy: 0.4995\n",
      "Epoch: 5, Loss: 1.5047246217727661, Validation Accuracy: 0.48433333333333334\n",
      "Epoch: 6, Loss: 1.4766497611999512, Validation Accuracy: 0.51375\n",
      "Epoch: 7, Loss: 1.4076173305511475, Validation Accuracy: 0.53925\n",
      "Epoch: 8, Loss: 1.3226081132888794, Validation Accuracy: 0.5381666666666667\n",
      "Epoch: 9, Loss: 1.3276151418685913, Validation Accuracy: 0.62125\n",
      "Epoch: 10, Loss: 1.1145631074905396, Validation Accuracy: 0.6505833333333333\n",
      "Epoch: 11, Loss: 1.0594621896743774, Validation Accuracy: 0.6798333333333333\n",
      "Epoch: 12, Loss: 0.9579964280128479, Validation Accuracy: 0.70175\n",
      "Epoch: 13, Loss: 0.9195395708084106, Validation Accuracy: 0.7149166666666666\n",
      "Epoch: 14, Loss: 0.8554906249046326, Validation Accuracy: 0.7258333333333333\n",
      "Epoch: 15, Loss: 0.8329958319664001, Validation Accuracy: 0.7230833333333333\n",
      "Epoch: 16, Loss: 0.8271523714065552, Validation Accuracy: 0.6826666666666666\n",
      "Epoch: 17, Loss: 0.9307464957237244, Validation Accuracy: 0.6384166666666666\n",
      "Epoch: 18, Loss: 1.0326077938079834, Validation Accuracy: 0.62875\n",
      "Epoch: 19, Loss: 1.0794155597686768, Validation Accuracy: 0.6965\n",
      "Epoch: 20, Loss: 0.8706770539283752, Validation Accuracy: 0.7819166666666667\n",
      "Epoch: 21, Loss: 0.6691232919692993, Validation Accuracy: 0.8071666666666667\n",
      "Epoch: 22, Loss: 0.6178901195526123, Validation Accuracy: 0.81175\n",
      "Epoch: 23, Loss: 0.5868001580238342, Validation Accuracy: 0.8200833333333334\n",
      "Epoch: 24, Loss: 0.56642085313797, Validation Accuracy: 0.8218333333333333\n",
      "Epoch: 25, Loss: 0.549910306930542, Validation Accuracy: 0.82875\n",
      "Epoch: 26, Loss: 0.5362416505813599, Validation Accuracy: 0.8301666666666667\n",
      "Epoch: 27, Loss: 0.524157702922821, Validation Accuracy: 0.8351666666666666\n",
      "Epoch: 28, Loss: 0.5132952332496643, Validation Accuracy: 0.8365833333333333\n",
      "Epoch: 29, Loss: 0.5033513903617859, Validation Accuracy: 0.8403333333333334\n",
      "Epoch: 30, Loss: 0.49419718980789185, Validation Accuracy: 0.8423333333333334\n",
      "Epoch: 31, Loss: 0.48569437861442566, Validation Accuracy: 0.8439166666666666\n",
      "Epoch: 32, Loss: 0.4777798354625702, Validation Accuracy: 0.8463333333333334\n",
      "Epoch: 33, Loss: 0.4703606069087982, Validation Accuracy: 0.8491666666666666\n",
      "Epoch: 34, Loss: 0.46338391304016113, Validation Accuracy: 0.8504166666666667\n",
      "Epoch: 35, Loss: 0.4567890763282776, Validation Accuracy: 0.8524166666666667\n",
      "Epoch: 36, Loss: 0.45055171847343445, Validation Accuracy: 0.8535833333333334\n",
      "Epoch: 37, Loss: 0.44466695189476013, Validation Accuracy: 0.8550833333333333\n",
      "Epoch: 38, Loss: 0.4390832483768463, Validation Accuracy: 0.8566666666666667\n",
      "Epoch: 39, Loss: 0.43376174569129944, Validation Accuracy: 0.8578333333333333\n",
      "Epoch: 40, Loss: 0.42868462204933167, Validation Accuracy: 0.8595\n",
      "Epoch: 41, Loss: 0.42385315895080566, Validation Accuracy: 0.8606666666666667\n",
      "Epoch: 42, Loss: 0.4192301034927368, Validation Accuracy: 0.8631666666666666\n",
      "Epoch: 43, Loss: 0.41483598947525024, Validation Accuracy: 0.86375\n",
      "Epoch: 44, Loss: 0.4106162190437317, Validation Accuracy: 0.86575\n",
      "Epoch: 45, Loss: 0.40657180547714233, Validation Accuracy: 0.8664166666666666\n",
      "Epoch: 46, Loss: 0.40270471572875977, Validation Accuracy: 0.867\n",
      "Epoch: 47, Loss: 0.39902999997138977, Validation Accuracy: 0.86925\n",
      "Epoch: 48, Loss: 0.3955283463001251, Validation Accuracy: 0.869\n",
      "Epoch: 49, Loss: 0.39220231771469116, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 50, Loss: 0.3890632688999176, Validation Accuracy: 0.871\n",
      "Epoch: 51, Loss: 0.3860737979412079, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 52, Loss: 0.38322713971138, Validation Accuracy: 0.8731666666666666\n",
      "Epoch: 53, Loss: 0.3806641697883606, Validation Accuracy: 0.875\n",
      "Epoch: 54, Loss: 0.3781333863735199, Validation Accuracy: 0.8743333333333333\n",
      "Epoch: 55, Loss: 0.3759676516056061, Validation Accuracy: 0.8773333333333333\n",
      "Epoch: 56, Loss: 0.3737635612487793, Validation Accuracy: 0.8756666666666667\n",
      "Epoch: 57, Loss: 0.37190425395965576, Validation Accuracy: 0.8788333333333334\n",
      "Epoch: 58, Loss: 0.36983492970466614, Validation Accuracy: 0.8775\n",
      "Epoch: 59, Loss: 0.3683798015117645, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 60, Loss: 0.3663727939128876, Validation Accuracy: 0.8786666666666667\n",
      "Epoch: 61, Loss: 0.3651381731033325, Validation Accuracy: 0.882\n",
      "Epoch: 62, Loss: 0.36280325055122375, Validation Accuracy: 0.881\n",
      "Epoch: 63, Loss: 0.3616354167461395, Validation Accuracy: 0.8834166666666666\n",
      "Epoch: 64, Loss: 0.35891231894493103, Validation Accuracy: 0.8818333333333334\n",
      "Epoch: 65, Loss: 0.3576081097126007, Validation Accuracy: 0.8845833333333334\n",
      "Epoch: 66, Loss: 0.3545641601085663, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 67, Loss: 0.35301053524017334, Validation Accuracy: 0.886\n",
      "Epoch: 68, Loss: 0.34967267513275146, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 69, Loss: 0.3478180468082428, Validation Accuracy: 0.88775\n",
      "Epoch: 70, Loss: 0.3443860709667206, Validation Accuracy: 0.8868333333333334\n",
      "Epoch: 71, Loss: 0.3423895537853241, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 72, Loss: 0.3390492796897888, Validation Accuracy: 0.88875\n",
      "Epoch: 73, Loss: 0.33681750297546387, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 74, Loss: 0.33381256461143494, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 75, Loss: 0.33162352442741394, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 76, Loss: 0.3289598524570465, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 77, Loss: 0.3268592655658722, Validation Accuracy: 0.894\n",
      "Epoch: 78, Loss: 0.32449060678482056, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 79, Loss: 0.322521835565567, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 80, Loss: 0.32041260600090027, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 81, Loss: 0.3185909688472748, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 82, Loss: 0.31669148802757263, Validation Accuracy: 0.896\n",
      "Epoch: 83, Loss: 0.31499093770980835, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 84, Loss: 0.3132559061050415, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 85, Loss: 0.3116343021392822, Validation Accuracy: 0.89925\n",
      "Epoch: 86, Loss: 0.31002384424209595, Validation Accuracy: 0.8985833333333333\n",
      "Epoch: 87, Loss: 0.3084994852542877, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 88, Loss: 0.3069685995578766, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 89, Loss: 0.30550146102905273, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 90, Loss: 0.30403223633766174, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 91, Loss: 0.30261674523353577, Validation Accuracy: 0.9025833333333333\n",
      "Epoch: 92, Loss: 0.30121341347694397, Validation Accuracy: 0.902\n",
      "Epoch: 93, Loss: 0.29984453320503235, Validation Accuracy: 0.9034166666666666\n",
      "Epoch: 94, Loss: 0.29849955439567566, Validation Accuracy: 0.9026666666666666\n",
      "Epoch: 95, Loss: 0.29718437790870667, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 96, Loss: 0.29588332772254944, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 97, Loss: 0.29460492730140686, Validation Accuracy: 0.90475\n",
      "Epoch: 98, Loss: 0.2933449447154999, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 99, Loss: 0.2921101450920105, Validation Accuracy: 0.9056666666666666\n",
      "Dataset 51\n",
      "Epoch: 0, Loss: 4.620650291442871, Validation Accuracy: 0.17258333333333334\n",
      "Epoch: 1, Loss: 4.28217077255249, Validation Accuracy: 0.21975\n",
      "Epoch: 2, Loss: 2.1513776779174805, Validation Accuracy: 0.32233333333333336\n",
      "Epoch: 3, Loss: 1.9460004568099976, Validation Accuracy: 0.378\n",
      "Epoch: 4, Loss: 1.8186297416687012, Validation Accuracy: 0.43016666666666664\n",
      "Epoch: 5, Loss: 1.7047311067581177, Validation Accuracy: 0.4721666666666667\n",
      "Epoch: 6, Loss: 1.5913130044937134, Validation Accuracy: 0.5065833333333334\n",
      "Epoch: 7, Loss: 1.4823591709136963, Validation Accuracy: 0.5323333333333333\n",
      "Epoch: 8, Loss: 1.3870946168899536, Validation Accuracy: 0.5530833333333334\n",
      "Epoch: 9, Loss: 1.3058940172195435, Validation Accuracy: 0.5821666666666667\n",
      "Epoch: 10, Loss: 1.2342607975006104, Validation Accuracy: 0.6045833333333334\n",
      "Epoch: 11, Loss: 1.1698524951934814, Validation Accuracy: 0.6250833333333333\n",
      "Epoch: 12, Loss: 1.11203932762146, Validation Accuracy: 0.6448333333333334\n",
      "Epoch: 13, Loss: 1.0594942569732666, Validation Accuracy: 0.6644166666666667\n",
      "Epoch: 14, Loss: 1.012401819229126, Validation Accuracy: 0.6775\n",
      "Epoch: 15, Loss: 0.9701733589172363, Validation Accuracy: 0.688\n",
      "Epoch: 16, Loss: 0.937748372554779, Validation Accuracy: 0.6926666666666667\n",
      "Epoch: 17, Loss: 0.9182960391044617, Validation Accuracy: 0.6735\n",
      "Epoch: 18, Loss: 0.9529768228530884, Validation Accuracy: 0.6161666666666666\n",
      "Epoch: 19, Loss: 1.0869371891021729, Validation Accuracy: 0.5276666666666666\n",
      "Epoch: 20, Loss: 1.391182780265808, Validation Accuracy: 0.47375\n",
      "Epoch: 21, Loss: 1.6323808431625366, Validation Accuracy: 0.61675\n",
      "Epoch: 22, Loss: 1.0708988904953003, Validation Accuracy: 0.7244166666666667\n",
      "Epoch: 23, Loss: 0.8572937846183777, Validation Accuracy: 0.7444166666666666\n",
      "Epoch: 24, Loss: 0.7921180725097656, Validation Accuracy: 0.7653333333333333\n",
      "Epoch: 25, Loss: 0.7310407757759094, Validation Accuracy: 0.7776666666666666\n",
      "Epoch: 26, Loss: 0.6968461871147156, Validation Accuracy: 0.7815\n",
      "Epoch: 27, Loss: 0.6716983914375305, Validation Accuracy: 0.7903333333333333\n",
      "Epoch: 28, Loss: 0.6513532996177673, Validation Accuracy: 0.794\n",
      "Epoch: 29, Loss: 0.6339958310127258, Validation Accuracy: 0.79975\n",
      "Epoch: 30, Loss: 0.6186123490333557, Validation Accuracy: 0.8025833333333333\n",
      "Epoch: 31, Loss: 0.6047430634498596, Validation Accuracy: 0.8070833333333334\n",
      "Epoch: 32, Loss: 0.5921018123626709, Validation Accuracy: 0.80875\n",
      "Epoch: 33, Loss: 0.5804532766342163, Validation Accuracy: 0.8126666666666666\n",
      "Epoch: 34, Loss: 0.5696751475334167, Validation Accuracy: 0.8149166666666666\n",
      "Epoch: 35, Loss: 0.559638261795044, Validation Accuracy: 0.8178333333333333\n",
      "Epoch: 36, Loss: 0.5502110123634338, Validation Accuracy: 0.82\n",
      "Epoch: 37, Loss: 0.5413343906402588, Validation Accuracy: 0.82275\n",
      "Epoch: 38, Loss: 0.5329486131668091, Validation Accuracy: 0.8253333333333334\n",
      "Epoch: 39, Loss: 0.5250084400177002, Validation Accuracy: 0.82825\n",
      "Epoch: 40, Loss: 0.5174788236618042, Validation Accuracy: 0.8305\n",
      "Epoch: 41, Loss: 0.5103320479393005, Validation Accuracy: 0.8323333333333334\n",
      "Epoch: 42, Loss: 0.5035145878791809, Validation Accuracy: 0.8344166666666667\n",
      "Epoch: 43, Loss: 0.4969962537288666, Validation Accuracy: 0.8354166666666667\n",
      "Epoch: 44, Loss: 0.49076053500175476, Validation Accuracy: 0.8384166666666667\n",
      "Epoch: 45, Loss: 0.4847876727581024, Validation Accuracy: 0.839\n",
      "Epoch: 46, Loss: 0.47906675934791565, Validation Accuracy: 0.8411666666666666\n",
      "Epoch: 47, Loss: 0.47357800602912903, Validation Accuracy: 0.8431666666666666\n",
      "Epoch: 48, Loss: 0.46828779578208923, Validation Accuracy: 0.84425\n",
      "Epoch: 49, Loss: 0.4631851315498352, Validation Accuracy: 0.846\n",
      "Epoch: 50, Loss: 0.45827019214630127, Validation Accuracy: 0.8466666666666667\n",
      "Epoch: 51, Loss: 0.4535312354564667, Validation Accuracy: 0.8481666666666666\n",
      "Epoch: 52, Loss: 0.4489525258541107, Validation Accuracy: 0.8496666666666667\n",
      "Epoch: 53, Loss: 0.44450247287750244, Validation Accuracy: 0.85025\n",
      "Epoch: 54, Loss: 0.4401867687702179, Validation Accuracy: 0.8525833333333334\n",
      "Epoch: 55, Loss: 0.4360013008117676, Validation Accuracy: 0.8531666666666666\n",
      "Epoch: 56, Loss: 0.43194815516471863, Validation Accuracy: 0.8545833333333334\n",
      "Epoch: 57, Loss: 0.42801690101623535, Validation Accuracy: 0.8558333333333333\n",
      "Epoch: 58, Loss: 0.4242095649242401, Validation Accuracy: 0.85725\n",
      "Epoch: 59, Loss: 0.4205159842967987, Validation Accuracy: 0.8585\n",
      "Epoch: 60, Loss: 0.41692447662353516, Validation Accuracy: 0.8595\n",
      "Epoch: 61, Loss: 0.41345083713531494, Validation Accuracy: 0.86125\n",
      "Epoch: 62, Loss: 0.41007038950920105, Validation Accuracy: 0.86175\n",
      "Epoch: 63, Loss: 0.40677347779273987, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 64, Loss: 0.4035560190677643, Validation Accuracy: 0.8643333333333333\n",
      "Epoch: 65, Loss: 0.4004204571247101, Validation Accuracy: 0.8653333333333333\n",
      "Epoch: 66, Loss: 0.3973660469055176, Validation Accuracy: 0.8660833333333333\n",
      "Epoch: 67, Loss: 0.39438846707344055, Validation Accuracy: 0.8663333333333333\n",
      "Epoch: 68, Loss: 0.3914828300476074, Validation Accuracy: 0.868\n",
      "Epoch: 69, Loss: 0.38863664865493774, Validation Accuracy: 0.8685\n",
      "Epoch: 70, Loss: 0.3858568072319031, Validation Accuracy: 0.8695\n",
      "Epoch: 71, Loss: 0.38313716650009155, Validation Accuracy: 0.87025\n",
      "Epoch: 72, Loss: 0.3804779350757599, Validation Accuracy: 0.87175\n",
      "Epoch: 73, Loss: 0.3778809905052185, Validation Accuracy: 0.8721666666666666\n",
      "Epoch: 74, Loss: 0.3753463625907898, Validation Accuracy: 0.8745\n",
      "Epoch: 75, Loss: 0.37286901473999023, Validation Accuracy: 0.8743333333333333\n",
      "Epoch: 76, Loss: 0.37044385075569153, Validation Accuracy: 0.8755833333333334\n",
      "Epoch: 77, Loss: 0.3680588901042938, Validation Accuracy: 0.8760833333333333\n",
      "Epoch: 78, Loss: 0.3657296597957611, Validation Accuracy: 0.8773333333333333\n",
      "Epoch: 79, Loss: 0.36344578862190247, Validation Accuracy: 0.878\n",
      "Epoch: 80, Loss: 0.36121195554733276, Validation Accuracy: 0.8790833333333333\n",
      "Epoch: 81, Loss: 0.3590135872364044, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 82, Loss: 0.3568609654903412, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 83, Loss: 0.35474711656570435, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 84, Loss: 0.3526662588119507, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 85, Loss: 0.3506236970424652, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 86, Loss: 0.3486121892929077, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 87, Loss: 0.3466382324695587, Validation Accuracy: 0.8849166666666667\n",
      "Epoch: 88, Loss: 0.34471777081489563, Validation Accuracy: 0.88525\n",
      "Epoch: 89, Loss: 0.3428220748901367, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 90, Loss: 0.3409590721130371, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 91, Loss: 0.33913591504096985, Validation Accuracy: 0.8875\n",
      "Epoch: 92, Loss: 0.3373456299304962, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 93, Loss: 0.3355892300605774, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 94, Loss: 0.33386531472206116, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 95, Loss: 0.3321658670902252, Validation Accuracy: 0.88975\n",
      "Epoch: 96, Loss: 0.330491304397583, Validation Accuracy: 0.89025\n",
      "Epoch: 97, Loss: 0.32884523272514343, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 98, Loss: 0.3272249698638916, Validation Accuracy: 0.89125\n",
      "Epoch: 99, Loss: 0.3256336450576782, Validation Accuracy: 0.8919166666666667\n",
      "Dataset 52\n",
      "Epoch: 0, Loss: 3.4413983821868896, Validation Accuracy: 0.1705\n",
      "Epoch: 1, Loss: 3.4794833660125732, Validation Accuracy: 0.20133333333333334\n",
      "Epoch: 2, Loss: 2.745007276535034, Validation Accuracy: 0.2673333333333333\n",
      "Epoch: 3, Loss: 2.3059263229370117, Validation Accuracy: 0.34658333333333335\n",
      "Epoch: 4, Loss: 1.887457013130188, Validation Accuracy: 0.46608333333333335\n",
      "Epoch: 5, Loss: 1.6440900564193726, Validation Accuracy: 0.49275\n",
      "Epoch: 6, Loss: 1.5205594301223755, Validation Accuracy: 0.5211666666666667\n",
      "Epoch: 7, Loss: 1.4321684837341309, Validation Accuracy: 0.5345833333333333\n",
      "Epoch: 8, Loss: 1.3519381284713745, Validation Accuracy: 0.56525\n",
      "Epoch: 9, Loss: 1.2947380542755127, Validation Accuracy: 0.5695\n",
      "Epoch: 10, Loss: 1.2414480447769165, Validation Accuracy: 0.5959166666666667\n",
      "Epoch: 11, Loss: 1.2115871906280518, Validation Accuracy: 0.5931666666666666\n",
      "Epoch: 12, Loss: 1.1704407930374146, Validation Accuracy: 0.5988333333333333\n",
      "Epoch: 13, Loss: 1.1630247831344604, Validation Accuracy: 0.6175833333333334\n",
      "Epoch: 14, Loss: 1.0768624544143677, Validation Accuracy: 0.6496666666666666\n",
      "Epoch: 15, Loss: 1.023987889289856, Validation Accuracy: 0.67375\n",
      "Epoch: 16, Loss: 0.9118245244026184, Validation Accuracy: 0.7204166666666667\n",
      "Epoch: 17, Loss: 0.8471196889877319, Validation Accuracy: 0.7320833333333333\n",
      "Epoch: 18, Loss: 0.7809628248214722, Validation Accuracy: 0.75675\n",
      "Epoch: 19, Loss: 0.7374745011329651, Validation Accuracy: 0.768\n",
      "Epoch: 20, Loss: 0.6980306506156921, Validation Accuracy: 0.78\n",
      "Epoch: 21, Loss: 0.6681219339370728, Validation Accuracy: 0.7889166666666667\n",
      "Epoch: 22, Loss: 0.6416326761245728, Validation Accuracy: 0.797\n",
      "Epoch: 23, Loss: 0.6201393008232117, Validation Accuracy: 0.8024166666666667\n",
      "Epoch: 24, Loss: 0.6010314226150513, Validation Accuracy: 0.8079166666666666\n",
      "Epoch: 25, Loss: 0.5857186317443848, Validation Accuracy: 0.8099166666666666\n",
      "Epoch: 26, Loss: 0.572818398475647, Validation Accuracy: 0.8131666666666667\n",
      "Epoch: 27, Loss: 0.5649265050888062, Validation Accuracy: 0.8105\n",
      "Epoch: 28, Loss: 0.5616693496704102, Validation Accuracy: 0.8095833333333333\n",
      "Epoch: 29, Loss: 0.5709503889083862, Validation Accuracy: 0.79975\n",
      "Epoch: 30, Loss: 0.5870172381401062, Validation Accuracy: 0.7876666666666666\n",
      "Epoch: 31, Loss: 0.6333582997322083, Validation Accuracy: 0.7688333333333334\n",
      "Epoch: 32, Loss: 0.6595339179039001, Validation Accuracy: 0.77075\n",
      "Epoch: 33, Loss: 0.6921893954277039, Validation Accuracy: 0.7833333333333333\n",
      "Epoch: 34, Loss: 0.6214055418968201, Validation Accuracy: 0.8214166666666667\n",
      "Epoch: 35, Loss: 0.5482274889945984, Validation Accuracy: 0.8416666666666667\n",
      "Epoch: 36, Loss: 0.49335595965385437, Validation Accuracy: 0.8481666666666666\n",
      "Epoch: 37, Loss: 0.46980640292167664, Validation Accuracy: 0.8528333333333333\n",
      "Epoch: 38, Loss: 0.4574589729309082, Validation Accuracy: 0.85425\n",
      "Epoch: 39, Loss: 0.44858938455581665, Validation Accuracy: 0.8581666666666666\n",
      "Epoch: 40, Loss: 0.4414878189563751, Validation Accuracy: 0.8584166666666667\n",
      "Epoch: 41, Loss: 0.43506306409835815, Validation Accuracy: 0.8624166666666667\n",
      "Epoch: 42, Loss: 0.4293224811553955, Validation Accuracy: 0.8628333333333333\n",
      "Epoch: 43, Loss: 0.4239378571510315, Validation Accuracy: 0.8661666666666666\n",
      "Epoch: 44, Loss: 0.41893893480300903, Validation Accuracy: 0.8658333333333333\n",
      "Epoch: 45, Loss: 0.41416361927986145, Validation Accuracy: 0.86975\n",
      "Epoch: 46, Loss: 0.4096502959728241, Validation Accuracy: 0.8695833333333334\n",
      "Epoch: 47, Loss: 0.4053536653518677, Validation Accuracy: 0.87175\n",
      "Epoch: 48, Loss: 0.40129825472831726, Validation Accuracy: 0.87225\n",
      "Epoch: 49, Loss: 0.3974100649356842, Validation Accuracy: 0.8750833333333333\n",
      "Epoch: 50, Loss: 0.3936828672885895, Validation Accuracy: 0.8750833333333333\n",
      "Epoch: 51, Loss: 0.3901010751724243, Validation Accuracy: 0.8774166666666666\n",
      "Epoch: 52, Loss: 0.3866921067237854, Validation Accuracy: 0.87775\n",
      "Epoch: 53, Loss: 0.38340622186660767, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 54, Loss: 0.3802737593650818, Validation Accuracy: 0.8804166666666666\n",
      "Epoch: 55, Loss: 0.3772417902946472, Validation Accuracy: 0.8824166666666666\n",
      "Epoch: 56, Loss: 0.3743078112602234, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 57, Loss: 0.3714851140975952, Validation Accuracy: 0.884\n",
      "Epoch: 58, Loss: 0.36874353885650635, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 59, Loss: 0.3660835921764374, Validation Accuracy: 0.8856666666666667\n",
      "Epoch: 60, Loss: 0.3635132908821106, Validation Accuracy: 0.8849166666666667\n",
      "Epoch: 61, Loss: 0.36100804805755615, Validation Accuracy: 0.887\n",
      "Epoch: 62, Loss: 0.35857683420181274, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 63, Loss: 0.35621312260627747, Validation Accuracy: 0.8883333333333333\n",
      "Epoch: 64, Loss: 0.3539182245731354, Validation Accuracy: 0.88875\n",
      "Epoch: 65, Loss: 0.35169658064842224, Validation Accuracy: 0.8895\n",
      "Epoch: 66, Loss: 0.34951725602149963, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 67, Loss: 0.34739911556243896, Validation Accuracy: 0.89075\n",
      "Epoch: 68, Loss: 0.3453340232372284, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 69, Loss: 0.34331920742988586, Validation Accuracy: 0.89275\n",
      "Epoch: 70, Loss: 0.34135517477989197, Validation Accuracy: 0.8929166666666667\n",
      "Epoch: 71, Loss: 0.33944547176361084, Validation Accuracy: 0.89375\n",
      "Epoch: 72, Loss: 0.33758535981178284, Validation Accuracy: 0.8935833333333333\n",
      "Epoch: 73, Loss: 0.3357648551464081, Validation Accuracy: 0.8954166666666666\n",
      "Epoch: 74, Loss: 0.3339847922325134, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 75, Loss: 0.3322402536869049, Validation Accuracy: 0.89625\n",
      "Epoch: 76, Loss: 0.330536812543869, Validation Accuracy: 0.8965\n",
      "Epoch: 77, Loss: 0.328858882188797, Validation Accuracy: 0.8975\n",
      "Epoch: 78, Loss: 0.32721656560897827, Validation Accuracy: 0.8978333333333334\n",
      "Epoch: 79, Loss: 0.3256075382232666, Validation Accuracy: 0.8988333333333334\n",
      "Epoch: 80, Loss: 0.32402363419532776, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 81, Loss: 0.32247185707092285, Validation Accuracy: 0.9000833333333333\n",
      "Epoch: 82, Loss: 0.32094404101371765, Validation Accuracy: 0.9001666666666667\n",
      "Epoch: 83, Loss: 0.31944721937179565, Validation Accuracy: 0.9015\n",
      "Epoch: 84, Loss: 0.3179795444011688, Validation Accuracy: 0.9015\n",
      "Epoch: 85, Loss: 0.31653493642807007, Validation Accuracy: 0.9025833333333333\n",
      "Epoch: 86, Loss: 0.31512224674224854, Validation Accuracy: 0.90275\n",
      "Epoch: 87, Loss: 0.31373462080955505, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 88, Loss: 0.31237393617630005, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 89, Loss: 0.311033695936203, Validation Accuracy: 0.9046666666666666\n",
      "Epoch: 90, Loss: 0.30971217155456543, Validation Accuracy: 0.9045\n",
      "Epoch: 91, Loss: 0.3084116578102112, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 92, Loss: 0.3071329891681671, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 93, Loss: 0.3058788776397705, Validation Accuracy: 0.9059166666666667\n",
      "Epoch: 94, Loss: 0.30464407801628113, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 95, Loss: 0.30343112349510193, Validation Accuracy: 0.9069166666666667\n",
      "Epoch: 96, Loss: 0.3022362291812897, Validation Accuracy: 0.9066666666666666\n",
      "Epoch: 97, Loss: 0.30105721950531006, Validation Accuracy: 0.9075833333333333\n",
      "Epoch: 98, Loss: 0.2998984456062317, Validation Accuracy: 0.9078333333333334\n",
      "Epoch: 99, Loss: 0.29875487089157104, Validation Accuracy: 0.9085833333333333\n",
      "Dataset 53\n",
      "Epoch: 0, Loss: 4.0691680908203125, Validation Accuracy: 0.10675\n",
      "Epoch: 1, Loss: 4.895866870880127, Validation Accuracy: 0.1385\n",
      "Epoch: 2, Loss: 3.8075389862060547, Validation Accuracy: 0.17541666666666667\n",
      "Epoch: 3, Loss: 4.574567794799805, Validation Accuracy: 0.17791666666666667\n",
      "Epoch: 4, Loss: 2.173304796218872, Validation Accuracy: 0.24266666666666667\n",
      "Epoch: 5, Loss: 2.0730438232421875, Validation Accuracy: 0.29775\n",
      "Epoch: 6, Loss: 1.947906732559204, Validation Accuracy: 0.32708333333333334\n",
      "Epoch: 7, Loss: 1.8584201335906982, Validation Accuracy: 0.3576666666666667\n",
      "Epoch: 8, Loss: 1.792260766029358, Validation Accuracy: 0.3948333333333333\n",
      "Epoch: 9, Loss: 1.7292102575302124, Validation Accuracy: 0.43525\n",
      "Epoch: 10, Loss: 1.6635469198226929, Validation Accuracy: 0.47658333333333336\n",
      "Epoch: 11, Loss: 1.592045545578003, Validation Accuracy: 0.5151666666666667\n",
      "Epoch: 12, Loss: 1.5129950046539307, Validation Accuracy: 0.54875\n",
      "Epoch: 13, Loss: 1.4247760772705078, Validation Accuracy: 0.573\n",
      "Epoch: 14, Loss: 1.3300775289535522, Validation Accuracy: 0.5956666666666667\n",
      "Epoch: 15, Loss: 1.2365713119506836, Validation Accuracy: 0.62175\n",
      "Epoch: 16, Loss: 1.1522363424301147, Validation Accuracy: 0.6444166666666666\n",
      "Epoch: 17, Loss: 1.0789189338684082, Validation Accuracy: 0.6663333333333333\n",
      "Epoch: 18, Loss: 1.0158231258392334, Validation Accuracy: 0.6829166666666666\n",
      "Epoch: 19, Loss: 0.9605712890625, Validation Accuracy: 0.70225\n",
      "Epoch: 20, Loss: 0.9118455648422241, Validation Accuracy: 0.7158333333333333\n",
      "Epoch: 21, Loss: 0.8689552545547485, Validation Accuracy: 0.72825\n",
      "Epoch: 22, Loss: 0.8319129347801208, Validation Accuracy: 0.7355833333333334\n",
      "Epoch: 23, Loss: 0.8038490414619446, Validation Accuracy: 0.73775\n",
      "Epoch: 24, Loss: 0.7948225736618042, Validation Accuracy: 0.7155\n",
      "Epoch: 25, Loss: 0.8406544327735901, Validation Accuracy: 0.639\n",
      "Epoch: 26, Loss: 1.0219801664352417, Validation Accuracy: 0.538\n",
      "Epoch: 27, Loss: 1.3587003946304321, Validation Accuracy: 0.48975\n",
      "Epoch: 28, Loss: 1.5737909078598022, Validation Accuracy: 0.6343333333333333\n",
      "Epoch: 29, Loss: 1.0405157804489136, Validation Accuracy: 0.7099166666666666\n",
      "Epoch: 30, Loss: 0.9394651651382446, Validation Accuracy: 0.7480833333333333\n",
      "Epoch: 31, Loss: 0.7615392208099365, Validation Accuracy: 0.7924166666666667\n",
      "Epoch: 32, Loss: 0.6805835962295532, Validation Accuracy: 0.7998333333333333\n",
      "Epoch: 33, Loss: 0.6287578344345093, Validation Accuracy: 0.8076666666666666\n",
      "Epoch: 34, Loss: 0.6035856008529663, Validation Accuracy: 0.8120833333333334\n",
      "Epoch: 35, Loss: 0.5849964022636414, Validation Accuracy: 0.8165833333333333\n",
      "Epoch: 36, Loss: 0.5701645612716675, Validation Accuracy: 0.8204166666666667\n",
      "Epoch: 37, Loss: 0.5573224425315857, Validation Accuracy: 0.8235\n",
      "Epoch: 38, Loss: 0.5459242463111877, Validation Accuracy: 0.8275\n",
      "Epoch: 39, Loss: 0.5356082916259766, Validation Accuracy: 0.83025\n",
      "Epoch: 40, Loss: 0.5261641144752502, Validation Accuracy: 0.8330833333333333\n",
      "Epoch: 41, Loss: 0.517424464225769, Validation Accuracy: 0.8350833333333333\n",
      "Epoch: 42, Loss: 0.5093227624893188, Validation Accuracy: 0.8375\n",
      "Epoch: 43, Loss: 0.5017982721328735, Validation Accuracy: 0.8396666666666667\n",
      "Epoch: 44, Loss: 0.4947583079338074, Validation Accuracy: 0.8415\n",
      "Epoch: 45, Loss: 0.48819783329963684, Validation Accuracy: 0.8425\n",
      "Epoch: 46, Loss: 0.48205485939979553, Validation Accuracy: 0.8455833333333334\n",
      "Epoch: 47, Loss: 0.47623324394226074, Validation Accuracy: 0.8459166666666667\n",
      "Epoch: 48, Loss: 0.4708130359649658, Validation Accuracy: 0.84775\n",
      "Epoch: 49, Loss: 0.46573179960250854, Validation Accuracy: 0.84875\n",
      "Epoch: 50, Loss: 0.4610832631587982, Validation Accuracy: 0.85075\n",
      "Epoch: 51, Loss: 0.4567417502403259, Validation Accuracy: 0.8516666666666667\n",
      "Epoch: 52, Loss: 0.45297905802726746, Validation Accuracy: 0.8529166666666667\n",
      "Epoch: 53, Loss: 0.4497336447238922, Validation Accuracy: 0.8519166666666667\n",
      "Epoch: 54, Loss: 0.4476723372936249, Validation Accuracy: 0.8540833333333333\n",
      "Epoch: 55, Loss: 0.4463755190372467, Validation Accuracy: 0.84975\n",
      "Epoch: 56, Loss: 0.44750455021858215, Validation Accuracy: 0.8534166666666667\n",
      "Epoch: 57, Loss: 0.4499715268611908, Validation Accuracy: 0.8445\n",
      "Epoch: 58, Loss: 0.456586629152298, Validation Accuracy: 0.8475\n",
      "Epoch: 59, Loss: 0.46483707427978516, Validation Accuracy: 0.8356666666666667\n",
      "Epoch: 60, Loss: 0.4805673062801361, Validation Accuracy: 0.8388333333333333\n",
      "Epoch: 61, Loss: 0.49128735065460205, Validation Accuracy: 0.82325\n",
      "Epoch: 62, Loss: 0.5085545182228088, Validation Accuracy: 0.8331666666666667\n",
      "Epoch: 63, Loss: 0.5032563805580139, Validation Accuracy: 0.8253333333333334\n",
      "Epoch: 64, Loss: 0.4986896216869354, Validation Accuracy: 0.8461666666666666\n",
      "Epoch: 65, Loss: 0.4699232876300812, Validation Accuracy: 0.84825\n",
      "Epoch: 66, Loss: 0.44896581768989563, Validation Accuracy: 0.86125\n",
      "Epoch: 67, Loss: 0.42667314410209656, Validation Accuracy: 0.8629166666666667\n",
      "Epoch: 68, Loss: 0.4138926863670349, Validation Accuracy: 0.8694166666666666\n",
      "Epoch: 69, Loss: 0.4042838513851166, Validation Accuracy: 0.869\n",
      "Epoch: 70, Loss: 0.39797818660736084, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 71, Loss: 0.39309221506118774, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 72, Loss: 0.38915568590164185, Validation Accuracy: 0.8753333333333333\n",
      "Epoch: 73, Loss: 0.38573092222213745, Validation Accuracy: 0.8748333333333334\n",
      "Epoch: 74, Loss: 0.3827378749847412, Validation Accuracy: 0.8769166666666667\n",
      "Epoch: 75, Loss: 0.3799271583557129, Validation Accuracy: 0.8765833333333334\n",
      "Epoch: 76, Loss: 0.377329021692276, Validation Accuracy: 0.8783333333333333\n",
      "Epoch: 77, Loss: 0.37487590312957764, Validation Accuracy: 0.8780833333333333\n",
      "Epoch: 78, Loss: 0.3725201487541199, Validation Accuracy: 0.8805\n",
      "Epoch: 79, Loss: 0.37027111649513245, Validation Accuracy: 0.8801666666666667\n",
      "Epoch: 80, Loss: 0.3681281805038452, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 81, Loss: 0.36604049801826477, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 82, Loss: 0.3640175759792328, Validation Accuracy: 0.8834166666666666\n",
      "Epoch: 83, Loss: 0.3620460629463196, Validation Accuracy: 0.8825833333333334\n",
      "Epoch: 84, Loss: 0.36014488339424133, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 85, Loss: 0.35827088356018066, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 86, Loss: 0.3564445674419403, Validation Accuracy: 0.88575\n",
      "Epoch: 87, Loss: 0.3546505570411682, Validation Accuracy: 0.8855833333333333\n",
      "Epoch: 88, Loss: 0.35289448499679565, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 89, Loss: 0.35118794441223145, Validation Accuracy: 0.8871666666666667\n",
      "Epoch: 90, Loss: 0.3495125472545624, Validation Accuracy: 0.88775\n",
      "Epoch: 91, Loss: 0.3478820025920868, Validation Accuracy: 0.88825\n",
      "Epoch: 92, Loss: 0.34627285599708557, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 93, Loss: 0.34471896290779114, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 94, Loss: 0.3431777358055115, Validation Accuracy: 0.8896666666666667\n",
      "Epoch: 95, Loss: 0.3416825234889984, Validation Accuracy: 0.8904166666666666\n",
      "Epoch: 96, Loss: 0.340217262506485, Validation Accuracy: 0.89\n",
      "Epoch: 97, Loss: 0.33878007531166077, Validation Accuracy: 0.8914166666666666\n",
      "Epoch: 98, Loss: 0.3373856842517853, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 99, Loss: 0.3360438644886017, Validation Accuracy: 0.8921666666666667\n",
      "Dataset 54\n",
      "Epoch: 0, Loss: 3.1982614994049072, Validation Accuracy: 0.17916666666666667\n",
      "Epoch: 1, Loss: 2.3629419803619385, Validation Accuracy: 0.30933333333333335\n",
      "Epoch: 2, Loss: 1.9386435747146606, Validation Accuracy: 0.377\n",
      "Epoch: 3, Loss: 1.8503608703613281, Validation Accuracy: 0.43975\n",
      "Epoch: 4, Loss: 1.6251193284988403, Validation Accuracy: 0.5365\n",
      "Epoch: 5, Loss: 1.3953245878219604, Validation Accuracy: 0.6033333333333334\n",
      "Epoch: 6, Loss: 1.234649658203125, Validation Accuracy: 0.6338333333333334\n",
      "Epoch: 7, Loss: 1.1221601963043213, Validation Accuracy: 0.6605\n",
      "Epoch: 8, Loss: 1.0363819599151611, Validation Accuracy: 0.6695833333333333\n",
      "Epoch: 9, Loss: 0.9812307357788086, Validation Accuracy: 0.67825\n",
      "Epoch: 10, Loss: 0.9643269777297974, Validation Accuracy: 0.6538333333333334\n",
      "Epoch: 11, Loss: 1.0027111768722534, Validation Accuracy: 0.589\n",
      "Epoch: 12, Loss: 1.1834263801574707, Validation Accuracy: 0.651\n",
      "Epoch: 13, Loss: 1.0002645254135132, Validation Accuracy: 0.68425\n",
      "Epoch: 14, Loss: 0.9075719118118286, Validation Accuracy: 0.7245833333333334\n",
      "Epoch: 15, Loss: 0.8037067651748657, Validation Accuracy: 0.7220833333333333\n",
      "Epoch: 16, Loss: 0.7937132120132446, Validation Accuracy: 0.7335833333333334\n",
      "Epoch: 17, Loss: 0.7719632983207703, Validation Accuracy: 0.7348333333333333\n",
      "Epoch: 18, Loss: 0.7548856735229492, Validation Accuracy: 0.75625\n",
      "Epoch: 19, Loss: 0.7155734300613403, Validation Accuracy: 0.7665\n",
      "Epoch: 20, Loss: 0.677820086479187, Validation Accuracy: 0.7885833333333333\n",
      "Epoch: 21, Loss: 0.6323915719985962, Validation Accuracy: 0.7988333333333333\n",
      "Epoch: 22, Loss: 0.6004334688186646, Validation Accuracy: 0.8128333333333333\n",
      "Epoch: 23, Loss: 0.5713488459587097, Validation Accuracy: 0.8161666666666667\n",
      "Epoch: 24, Loss: 0.5530104041099548, Validation Accuracy: 0.8251666666666667\n",
      "Epoch: 25, Loss: 0.5366355180740356, Validation Accuracy: 0.8261666666666667\n",
      "Epoch: 26, Loss: 0.5249789357185364, Validation Accuracy: 0.8339166666666666\n",
      "Epoch: 27, Loss: 0.5138795375823975, Validation Accuracy: 0.8334166666666667\n",
      "Epoch: 28, Loss: 0.5051895380020142, Validation Accuracy: 0.8376666666666667\n",
      "Epoch: 29, Loss: 0.49693143367767334, Validation Accuracy: 0.8371666666666666\n",
      "Epoch: 30, Loss: 0.49001064896583557, Validation Accuracy: 0.8406666666666667\n",
      "Epoch: 31, Loss: 0.48407161235809326, Validation Accuracy: 0.8429166666666666\n",
      "Epoch: 32, Loss: 0.478244423866272, Validation Accuracy: 0.8451666666666666\n",
      "Epoch: 33, Loss: 0.4740113914012909, Validation Accuracy: 0.8455\n",
      "Epoch: 34, Loss: 0.469003289937973, Validation Accuracy: 0.8478333333333333\n",
      "Epoch: 35, Loss: 0.46634191274642944, Validation Accuracy: 0.84825\n",
      "Epoch: 36, Loss: 0.4617386758327484, Validation Accuracy: 0.8505833333333334\n",
      "Epoch: 37, Loss: 0.4599015414714813, Validation Accuracy: 0.85\n",
      "Epoch: 38, Loss: 0.4547733664512634, Validation Accuracy: 0.85325\n",
      "Epoch: 39, Loss: 0.45294052362442017, Validation Accuracy: 0.8541666666666666\n",
      "Epoch: 40, Loss: 0.4466565251350403, Validation Accuracy: 0.8563333333333333\n",
      "Epoch: 41, Loss: 0.4440002739429474, Validation Accuracy: 0.85825\n",
      "Epoch: 42, Loss: 0.43658533692359924, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 43, Loss: 0.4327232241630554, Validation Accuracy: 0.862\n",
      "Epoch: 44, Loss: 0.4252970814704895, Validation Accuracy: 0.8658333333333333\n",
      "Epoch: 45, Loss: 0.4207074046134949, Validation Accuracy: 0.8669166666666667\n",
      "Epoch: 46, Loss: 0.4138014614582062, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 47, Loss: 0.4089883267879486, Validation Accuracy: 0.8719166666666667\n",
      "Epoch: 48, Loss: 0.4030209183692932, Validation Accuracy: 0.87525\n",
      "Epoch: 49, Loss: 0.3984915316104889, Validation Accuracy: 0.8766666666666667\n",
      "Epoch: 50, Loss: 0.39350855350494385, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 51, Loss: 0.38947582244873047, Validation Accuracy: 0.8799166666666667\n",
      "Epoch: 52, Loss: 0.38514474034309387, Validation Accuracy: 0.88225\n",
      "Epoch: 53, Loss: 0.3815681040287018, Validation Accuracy: 0.8825833333333334\n",
      "Epoch: 54, Loss: 0.37782809138298035, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 55, Loss: 0.3745746314525604, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 56, Loss: 0.3712758421897888, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 57, Loss: 0.36833101511001587, Validation Accuracy: 0.8859166666666667\n",
      "Epoch: 58, Loss: 0.36536532640457153, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 59, Loss: 0.36267098784446716, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 60, Loss: 0.3599890172481537, Validation Accuracy: 0.8890833333333333\n",
      "Epoch: 61, Loss: 0.3575030565261841, Validation Accuracy: 0.8885\n",
      "Epoch: 62, Loss: 0.35494714975357056, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 63, Loss: 0.35265296697616577, Validation Accuracy: 0.8900833333333333\n",
      "Epoch: 64, Loss: 0.3502618372440338, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 65, Loss: 0.34808915853500366, Validation Accuracy: 0.8915\n",
      "Epoch: 66, Loss: 0.345844566822052, Validation Accuracy: 0.89375\n",
      "Epoch: 67, Loss: 0.3437729477882385, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 68, Loss: 0.3416765034198761, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 69, Loss: 0.3397105634212494, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 70, Loss: 0.3377313017845154, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 71, Loss: 0.335879385471344, Validation Accuracy: 0.89525\n",
      "Epoch: 72, Loss: 0.33403530716896057, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 73, Loss: 0.332239031791687, Validation Accuracy: 0.8961666666666667\n",
      "Epoch: 74, Loss: 0.33046507835388184, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 75, Loss: 0.3287511169910431, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 76, Loss: 0.32704150676727295, Validation Accuracy: 0.89825\n",
      "Epoch: 77, Loss: 0.32541388273239136, Validation Accuracy: 0.8991666666666667\n",
      "Epoch: 78, Loss: 0.32374921441078186, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 79, Loss: 0.3221535086631775, Validation Accuracy: 0.8999166666666667\n",
      "Epoch: 80, Loss: 0.3205462396144867, Validation Accuracy: 0.9005\n",
      "Epoch: 81, Loss: 0.31898894906044006, Validation Accuracy: 0.901\n",
      "Epoch: 82, Loss: 0.3174552917480469, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 83, Loss: 0.3159717619419098, Validation Accuracy: 0.9016666666666666\n",
      "Epoch: 84, Loss: 0.3145222067832947, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 85, Loss: 0.3130851089954376, Validation Accuracy: 0.90225\n",
      "Epoch: 86, Loss: 0.3116675913333893, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 87, Loss: 0.31029319763183594, Validation Accuracy: 0.903\n",
      "Epoch: 88, Loss: 0.30891773104667664, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 89, Loss: 0.3075941503047943, Validation Accuracy: 0.9039166666666667\n",
      "Epoch: 90, Loss: 0.3062673509120941, Validation Accuracy: 0.9046666666666666\n",
      "Epoch: 91, Loss: 0.30501002073287964, Validation Accuracy: 0.9048333333333334\n",
      "Epoch: 92, Loss: 0.3037075102329254, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 93, Loss: 0.3024987578392029, Validation Accuracy: 0.9055\n",
      "Epoch: 94, Loss: 0.3012434244155884, Validation Accuracy: 0.9064166666666666\n",
      "Epoch: 95, Loss: 0.3000729978084564, Validation Accuracy: 0.9066666666666666\n",
      "Epoch: 96, Loss: 0.2988629639148712, Validation Accuracy: 0.9071666666666667\n",
      "Epoch: 97, Loss: 0.29771849513053894, Validation Accuracy: 0.90725\n",
      "Epoch: 98, Loss: 0.29656094312667847, Validation Accuracy: 0.9075\n",
      "Epoch: 99, Loss: 0.2954333424568176, Validation Accuracy: 0.90775\n",
      "Dataset 55\n",
      "Epoch: 0, Loss: 3.351426124572754, Validation Accuracy: 0.18633333333333332\n",
      "Epoch: 1, Loss: 2.3015010356903076, Validation Accuracy: 0.28225\n",
      "Epoch: 2, Loss: 2.0069754123687744, Validation Accuracy: 0.35991666666666666\n",
      "Epoch: 3, Loss: 1.7665283679962158, Validation Accuracy: 0.4330833333333333\n",
      "Epoch: 4, Loss: 1.6550835371017456, Validation Accuracy: 0.3825\n",
      "Epoch: 5, Loss: 1.6704312562942505, Validation Accuracy: 0.48191666666666666\n",
      "Epoch: 6, Loss: 1.520304799079895, Validation Accuracy: 0.47441666666666665\n",
      "Epoch: 7, Loss: 1.5057035684585571, Validation Accuracy: 0.48641666666666666\n",
      "Epoch: 8, Loss: 1.4498883485794067, Validation Accuracy: 0.5501666666666667\n",
      "Epoch: 9, Loss: 1.3588083982467651, Validation Accuracy: 0.6168333333333333\n",
      "Epoch: 10, Loss: 1.1055676937103271, Validation Accuracy: 0.6650833333333334\n",
      "Epoch: 11, Loss: 1.012447714805603, Validation Accuracy: 0.659\n",
      "Epoch: 12, Loss: 0.9702599048614502, Validation Accuracy: 0.6551666666666667\n",
      "Epoch: 13, Loss: 0.9853485226631165, Validation Accuracy: 0.6168333333333333\n",
      "Epoch: 14, Loss: 1.0604902505874634, Validation Accuracy: 0.6375\n",
      "Epoch: 15, Loss: 1.017664909362793, Validation Accuracy: 0.7038333333333333\n",
      "Epoch: 16, Loss: 0.8723547458648682, Validation Accuracy: 0.7255\n",
      "Epoch: 17, Loss: 0.8034186959266663, Validation Accuracy: 0.73375\n",
      "Epoch: 18, Loss: 0.7962765097618103, Validation Accuracy: 0.73775\n",
      "Epoch: 19, Loss: 0.7715543508529663, Validation Accuracy: 0.7419166666666667\n",
      "Epoch: 20, Loss: 0.7726357579231262, Validation Accuracy: 0.7663333333333333\n",
      "Epoch: 21, Loss: 0.6888815760612488, Validation Accuracy: 0.78875\n",
      "Epoch: 22, Loss: 0.6432931423187256, Validation Accuracy: 0.8014166666666667\n",
      "Epoch: 23, Loss: 0.5941132307052612, Validation Accuracy: 0.8144166666666667\n",
      "Epoch: 24, Loss: 0.5653617978096008, Validation Accuracy: 0.8195833333333333\n",
      "Epoch: 25, Loss: 0.5449392199516296, Validation Accuracy: 0.8265833333333333\n",
      "Epoch: 26, Loss: 0.5291736125946045, Validation Accuracy: 0.8285\n",
      "Epoch: 27, Loss: 0.5172257423400879, Validation Accuracy: 0.8341666666666666\n",
      "Epoch: 28, Loss: 0.5063787698745728, Validation Accuracy: 0.8365833333333333\n",
      "Epoch: 29, Loss: 0.49755412340164185, Validation Accuracy: 0.839\n",
      "Epoch: 30, Loss: 0.4892663061618805, Validation Accuracy: 0.8421666666666666\n",
      "Epoch: 31, Loss: 0.4823561906814575, Validation Accuracy: 0.844\n",
      "Epoch: 32, Loss: 0.47598156332969666, Validation Accuracy: 0.8448333333333333\n",
      "Epoch: 33, Loss: 0.4708019196987152, Validation Accuracy: 0.8478333333333333\n",
      "Epoch: 34, Loss: 0.4661206901073456, Validation Accuracy: 0.8496666666666667\n",
      "Epoch: 35, Loss: 0.46265172958374023, Validation Accuracy: 0.85\n",
      "Epoch: 36, Loss: 0.4598422050476074, Validation Accuracy: 0.8510833333333333\n",
      "Epoch: 37, Loss: 0.4584246873855591, Validation Accuracy: 0.8508333333333333\n",
      "Epoch: 38, Loss: 0.45742887258529663, Validation Accuracy: 0.8514166666666667\n",
      "Epoch: 39, Loss: 0.4577820897102356, Validation Accuracy: 0.849\n",
      "Epoch: 40, Loss: 0.4568400979042053, Validation Accuracy: 0.8526666666666667\n",
      "Epoch: 41, Loss: 0.45674237608909607, Validation Accuracy: 0.8499166666666667\n",
      "Epoch: 42, Loss: 0.4527674615383148, Validation Accuracy: 0.8551666666666666\n",
      "Epoch: 43, Loss: 0.44903111457824707, Validation Accuracy: 0.8555833333333334\n",
      "Epoch: 44, Loss: 0.4402155876159668, Validation Accuracy: 0.8625833333333334\n",
      "Epoch: 45, Loss: 0.4332151710987091, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 46, Loss: 0.4225020706653595, Validation Accuracy: 0.8690833333333333\n",
      "Epoch: 47, Loss: 0.4148211181163788, Validation Accuracy: 0.8680833333333333\n",
      "Epoch: 48, Loss: 0.40569207072257996, Validation Accuracy: 0.87475\n",
      "Epoch: 49, Loss: 0.39936473965644836, Validation Accuracy: 0.8731666666666666\n",
      "Epoch: 50, Loss: 0.3926212191581726, Validation Accuracy: 0.87775\n",
      "Epoch: 51, Loss: 0.38768574595451355, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 52, Loss: 0.3828050196170807, Validation Accuracy: 0.881\n",
      "Epoch: 53, Loss: 0.37884700298309326, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 54, Loss: 0.37497252225875854, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 55, Loss: 0.3716232478618622, Validation Accuracy: 0.8831666666666667\n",
      "Epoch: 56, Loss: 0.3683178722858429, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 57, Loss: 0.3653532862663269, Validation Accuracy: 0.88525\n",
      "Epoch: 58, Loss: 0.3624798059463501, Validation Accuracy: 0.8875\n",
      "Epoch: 59, Loss: 0.35985803604125977, Validation Accuracy: 0.88725\n",
      "Epoch: 60, Loss: 0.35719358921051025, Validation Accuracy: 0.88925\n",
      "Epoch: 61, Loss: 0.35479602217674255, Validation Accuracy: 0.8881666666666667\n",
      "Epoch: 62, Loss: 0.3524223268032074, Validation Accuracy: 0.891\n",
      "Epoch: 63, Loss: 0.3502132296562195, Validation Accuracy: 0.8900833333333333\n",
      "Epoch: 64, Loss: 0.34803593158721924, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 65, Loss: 0.3460344970226288, Validation Accuracy: 0.8914166666666666\n",
      "Epoch: 66, Loss: 0.34405404329299927, Validation Accuracy: 0.894\n",
      "Epoch: 67, Loss: 0.3423037827014923, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 68, Loss: 0.3405105769634247, Validation Accuracy: 0.895\n",
      "Epoch: 69, Loss: 0.33900851011276245, Validation Accuracy: 0.8925\n",
      "Epoch: 70, Loss: 0.3373863399028778, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 71, Loss: 0.33612167835235596, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 72, Loss: 0.33463212847709656, Validation Accuracy: 0.897\n",
      "Epoch: 73, Loss: 0.3335212469100952, Validation Accuracy: 0.89425\n",
      "Epoch: 74, Loss: 0.3322029709815979, Validation Accuracy: 0.89775\n",
      "Epoch: 75, Loss: 0.33127641677856445, Validation Accuracy: 0.8953333333333333\n",
      "Epoch: 76, Loss: 0.329956978559494, Validation Accuracy: 0.8991666666666667\n",
      "Epoch: 77, Loss: 0.3292385935783386, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 78, Loss: 0.3278904855251312, Validation Accuracy: 0.8996666666666666\n",
      "Epoch: 79, Loss: 0.327169805765152, Validation Accuracy: 0.8970833333333333\n",
      "Epoch: 80, Loss: 0.32578086853027344, Validation Accuracy: 0.89975\n",
      "Epoch: 81, Loss: 0.3250716030597687, Validation Accuracy: 0.89775\n",
      "Epoch: 82, Loss: 0.32351794838905334, Validation Accuracy: 0.9\n",
      "Epoch: 83, Loss: 0.32288920879364014, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 84, Loss: 0.32113441824913025, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 85, Loss: 0.320394903421402, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 86, Loss: 0.3182380497455597, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 87, Loss: 0.31725218892097473, Validation Accuracy: 0.9001666666666667\n",
      "Epoch: 88, Loss: 0.3148629665374756, Validation Accuracy: 0.903\n",
      "Epoch: 89, Loss: 0.31366854906082153, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 90, Loss: 0.3112315535545349, Validation Accuracy: 0.9041666666666667\n",
      "Epoch: 91, Loss: 0.3098847270011902, Validation Accuracy: 0.9028333333333334\n",
      "Epoch: 92, Loss: 0.3075810670852661, Validation Accuracy: 0.9055\n",
      "Epoch: 93, Loss: 0.3061690628528595, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 94, Loss: 0.3039168417453766, Validation Accuracy: 0.90675\n",
      "Epoch: 95, Loss: 0.3025214672088623, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 96, Loss: 0.30042263865470886, Validation Accuracy: 0.90775\n",
      "Epoch: 97, Loss: 0.2990829348564148, Validation Accuracy: 0.9055\n",
      "Epoch: 98, Loss: 0.2971883714199066, Validation Accuracy: 0.909\n",
      "Epoch: 99, Loss: 0.2958885133266449, Validation Accuracy: 0.9063333333333333\n",
      "Dataset 56\n",
      "Epoch: 0, Loss: 4.083859920501709, Validation Accuracy: 0.14241666666666666\n",
      "Epoch: 1, Loss: 3.302111864089966, Validation Accuracy: 0.19575\n",
      "Epoch: 2, Loss: 2.6443493366241455, Validation Accuracy: 0.243\n",
      "Epoch: 3, Loss: 2.040966749191284, Validation Accuracy: 0.3348333333333333\n",
      "Epoch: 4, Loss: 1.8635227680206299, Validation Accuracy: 0.39366666666666666\n",
      "Epoch: 5, Loss: 1.7354042530059814, Validation Accuracy: 0.4345\n",
      "Epoch: 6, Loss: 1.613795280456543, Validation Accuracy: 0.48291666666666666\n",
      "Epoch: 7, Loss: 1.488826036453247, Validation Accuracy: 0.5248333333333334\n",
      "Epoch: 8, Loss: 1.3729549646377563, Validation Accuracy: 0.5664166666666667\n",
      "Epoch: 9, Loss: 1.2696075439453125, Validation Accuracy: 0.5993333333333334\n",
      "Epoch: 10, Loss: 1.1786483526229858, Validation Accuracy: 0.6291666666666667\n",
      "Epoch: 11, Loss: 1.1000841856002808, Validation Accuracy: 0.6525\n",
      "Epoch: 12, Loss: 1.0342875719070435, Validation Accuracy: 0.6729166666666667\n",
      "Epoch: 13, Loss: 0.9814832210540771, Validation Accuracy: 0.6815\n",
      "Epoch: 14, Loss: 0.949249267578125, Validation Accuracy: 0.6646666666666666\n",
      "Epoch: 15, Loss: 0.9803948402404785, Validation Accuracy: 0.5880833333333333\n",
      "Epoch: 16, Loss: 1.1856135129928589, Validation Accuracy: 0.44525\n",
      "Epoch: 17, Loss: 1.9246082305908203, Validation Accuracy: 0.5584166666666667\n",
      "Epoch: 18, Loss: 1.2491053342819214, Validation Accuracy: 0.6590833333333334\n",
      "Epoch: 19, Loss: 0.9486987590789795, Validation Accuracy: 0.7025\n",
      "Epoch: 20, Loss: 0.8449552655220032, Validation Accuracy: 0.7421666666666666\n",
      "Epoch: 21, Loss: 0.7936340570449829, Validation Accuracy: 0.7300833333333333\n",
      "Epoch: 22, Loss: 0.7724917531013489, Validation Accuracy: 0.7459166666666667\n",
      "Epoch: 23, Loss: 0.7582845687866211, Validation Accuracy: 0.7203333333333334\n",
      "Epoch: 24, Loss: 0.7781290411949158, Validation Accuracy: 0.72925\n",
      "Epoch: 25, Loss: 0.7735913991928101, Validation Accuracy: 0.7065833333333333\n",
      "Epoch: 26, Loss: 0.7944984436035156, Validation Accuracy: 0.7354166666666667\n",
      "Epoch: 27, Loss: 0.7387628555297852, Validation Accuracy: 0.7363333333333333\n",
      "Epoch: 28, Loss: 0.7091928720474243, Validation Accuracy: 0.7733333333333333\n",
      "Epoch: 29, Loss: 0.6562833189964294, Validation Accuracy: 0.7758333333333334\n",
      "Epoch: 30, Loss: 0.6319552659988403, Validation Accuracy: 0.7970833333333334\n",
      "Epoch: 31, Loss: 0.6036480665206909, Validation Accuracy: 0.7961666666666667\n",
      "Epoch: 32, Loss: 0.5881527662277222, Validation Accuracy: 0.8101666666666667\n",
      "Epoch: 33, Loss: 0.5715940594673157, Validation Accuracy: 0.8063333333333333\n",
      "Epoch: 34, Loss: 0.5604334473609924, Validation Accuracy: 0.81675\n",
      "Epoch: 35, Loss: 0.5493870973587036, Validation Accuracy: 0.8139166666666666\n",
      "Epoch: 36, Loss: 0.5412312746047974, Validation Accuracy: 0.8215833333333333\n",
      "Epoch: 37, Loss: 0.5331905484199524, Validation Accuracy: 0.8185\n",
      "Epoch: 38, Loss: 0.5265326499938965, Validation Accuracy: 0.824\n",
      "Epoch: 39, Loss: 0.5204720497131348, Validation Accuracy: 0.8221666666666667\n",
      "Epoch: 40, Loss: 0.5145306587219238, Validation Accuracy: 0.827\n",
      "Epoch: 41, Loss: 0.5090786218643188, Validation Accuracy: 0.8275833333333333\n",
      "Epoch: 42, Loss: 0.502612292766571, Validation Accuracy: 0.832\n",
      "Epoch: 43, Loss: 0.49625492095947266, Validation Accuracy: 0.8341666666666666\n",
      "Epoch: 44, Loss: 0.48845919966697693, Validation Accuracy: 0.8370833333333333\n",
      "Epoch: 45, Loss: 0.4809906482696533, Validation Accuracy: 0.84075\n",
      "Epoch: 46, Loss: 0.4720514714717865, Validation Accuracy: 0.8444166666666667\n",
      "Epoch: 47, Loss: 0.46371781826019287, Validation Accuracy: 0.8501666666666666\n",
      "Epoch: 48, Loss: 0.45462045073509216, Validation Accuracy: 0.8514166666666667\n",
      "Epoch: 49, Loss: 0.44675981998443604, Validation Accuracy: 0.8566666666666667\n",
      "Epoch: 50, Loss: 0.4383845925331116, Validation Accuracy: 0.8571666666666666\n",
      "Epoch: 51, Loss: 0.4309404194355011, Validation Accuracy: 0.8629166666666667\n",
      "Epoch: 52, Loss: 0.42364704608917236, Validation Accuracy: 0.86375\n",
      "Epoch: 53, Loss: 0.41713330149650574, Validation Accuracy: 0.8674166666666666\n",
      "Epoch: 54, Loss: 0.4109194874763489, Validation Accuracy: 0.8675833333333334\n",
      "Epoch: 55, Loss: 0.40520960092544556, Validation Accuracy: 0.8708333333333333\n",
      "Epoch: 56, Loss: 0.399937242269516, Validation Accuracy: 0.8715\n",
      "Epoch: 57, Loss: 0.3950347602367401, Validation Accuracy: 0.8755833333333334\n",
      "Epoch: 58, Loss: 0.3904450237751007, Validation Accuracy: 0.8750833333333333\n",
      "Epoch: 59, Loss: 0.3861827850341797, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 60, Loss: 0.38214200735092163, Validation Accuracy: 0.8775\n",
      "Epoch: 61, Loss: 0.3783814609050751, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 62, Loss: 0.3748416304588318, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 63, Loss: 0.3713952600955963, Validation Accuracy: 0.8830833333333333\n",
      "Epoch: 64, Loss: 0.3681294322013855, Validation Accuracy: 0.8829166666666667\n",
      "Epoch: 65, Loss: 0.36509090662002563, Validation Accuracy: 0.8855833333333333\n",
      "Epoch: 66, Loss: 0.36210131645202637, Validation Accuracy: 0.8846666666666667\n",
      "Epoch: 67, Loss: 0.35928142070770264, Validation Accuracy: 0.887\n",
      "Epoch: 68, Loss: 0.3564777076244354, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 69, Loss: 0.3538288176059723, Validation Accuracy: 0.88925\n",
      "Epoch: 70, Loss: 0.35118043422698975, Validation Accuracy: 0.88925\n",
      "Epoch: 71, Loss: 0.34869128465652466, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 72, Loss: 0.346248984336853, Validation Accuracy: 0.89125\n",
      "Epoch: 73, Loss: 0.343900591135025, Validation Accuracy: 0.89225\n",
      "Epoch: 74, Loss: 0.34160709381103516, Validation Accuracy: 0.8926666666666667\n",
      "Epoch: 75, Loss: 0.33941328525543213, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 76, Loss: 0.3372364640235901, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 77, Loss: 0.33513152599334717, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 78, Loss: 0.33306387066841125, Validation Accuracy: 0.89475\n",
      "Epoch: 79, Loss: 0.3310737907886505, Validation Accuracy: 0.8954166666666666\n",
      "Epoch: 80, Loss: 0.3291114270687103, Validation Accuracy: 0.896\n",
      "Epoch: 81, Loss: 0.3272191882133484, Validation Accuracy: 0.8965\n",
      "Epoch: 82, Loss: 0.3253265619277954, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 83, Loss: 0.3234967589378357, Validation Accuracy: 0.89775\n",
      "Epoch: 84, Loss: 0.32169991731643677, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 85, Loss: 0.31993791460990906, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 86, Loss: 0.3182133138179779, Validation Accuracy: 0.8985\n",
      "Epoch: 87, Loss: 0.3165210783481598, Validation Accuracy: 0.90025\n",
      "Epoch: 88, Loss: 0.3148987591266632, Validation Accuracy: 0.9\n",
      "Epoch: 89, Loss: 0.31328222155570984, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 90, Loss: 0.31172463297843933, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 91, Loss: 0.31014811992645264, Validation Accuracy: 0.902\n",
      "Epoch: 92, Loss: 0.30863967537879944, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 93, Loss: 0.307135671377182, Validation Accuracy: 0.9025833333333333\n",
      "Epoch: 94, Loss: 0.30566832423210144, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 95, Loss: 0.3042106628417969, Validation Accuracy: 0.9035\n",
      "Epoch: 96, Loss: 0.30277711153030396, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 97, Loss: 0.3013632297515869, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 98, Loss: 0.29997357726097107, Validation Accuracy: 0.90375\n",
      "Epoch: 99, Loss: 0.29861435294151306, Validation Accuracy: 0.90475\n",
      "Dataset 57\n",
      "Epoch: 0, Loss: 4.090553283691406, Validation Accuracy: 0.12741666666666668\n",
      "Epoch: 1, Loss: 3.027082920074463, Validation Accuracy: 0.204\n",
      "Epoch: 2, Loss: 2.9934935569763184, Validation Accuracy: 0.21708333333333332\n",
      "Epoch: 3, Loss: 2.2412683963775635, Validation Accuracy: 0.2891666666666667\n",
      "Epoch: 4, Loss: 1.9578585624694824, Validation Accuracy: 0.31825\n",
      "Epoch: 5, Loss: 1.878308892250061, Validation Accuracy: 0.34725\n",
      "Epoch: 6, Loss: 1.807875156402588, Validation Accuracy: 0.37583333333333335\n",
      "Epoch: 7, Loss: 1.7351465225219727, Validation Accuracy: 0.4076666666666667\n",
      "Epoch: 8, Loss: 1.6570889949798584, Validation Accuracy: 0.44166666666666665\n",
      "Epoch: 9, Loss: 1.574877142906189, Validation Accuracy: 0.4845\n",
      "Epoch: 10, Loss: 1.491167664527893, Validation Accuracy: 0.5263333333333333\n",
      "Epoch: 11, Loss: 1.407760739326477, Validation Accuracy: 0.5693333333333334\n",
      "Epoch: 12, Loss: 1.323702096939087, Validation Accuracy: 0.6075\n",
      "Epoch: 13, Loss: 1.239338994026184, Validation Accuracy: 0.6411666666666667\n",
      "Epoch: 14, Loss: 1.1564528942108154, Validation Accuracy: 0.6695833333333333\n",
      "Epoch: 15, Loss: 1.0770900249481201, Validation Accuracy: 0.6908333333333333\n",
      "Epoch: 16, Loss: 1.0054441690444946, Validation Accuracy: 0.7024166666666667\n",
      "Epoch: 17, Loss: 0.9510545134544373, Validation Accuracy: 0.69875\n",
      "Epoch: 18, Loss: 0.9377970099449158, Validation Accuracy: 0.6250833333333333\n",
      "Epoch: 19, Loss: 1.0751597881317139, Validation Accuracy: 0.4969166666666667\n",
      "Epoch: 20, Loss: 1.5453884601593018, Validation Accuracy: 0.44408333333333333\n",
      "Epoch: 21, Loss: 1.7800770998001099, Validation Accuracy: 0.52325\n",
      "Epoch: 22, Loss: 1.3796557188034058, Validation Accuracy: 0.6334166666666666\n",
      "Epoch: 23, Loss: 1.1081479787826538, Validation Accuracy: 0.7035\n",
      "Epoch: 24, Loss: 0.9378114342689514, Validation Accuracy: 0.7403333333333333\n",
      "Epoch: 25, Loss: 0.8016257882118225, Validation Accuracy: 0.7705833333333333\n",
      "Epoch: 26, Loss: 0.7348929047584534, Validation Accuracy: 0.7758333333333334\n",
      "Epoch: 27, Loss: 0.6910784244537354, Validation Accuracy: 0.7876666666666666\n",
      "Epoch: 28, Loss: 0.6634518504142761, Validation Accuracy: 0.79275\n",
      "Epoch: 29, Loss: 0.6401650309562683, Validation Accuracy: 0.79925\n",
      "Epoch: 30, Loss: 0.6230154633522034, Validation Accuracy: 0.8039166666666666\n",
      "Epoch: 31, Loss: 0.6070011854171753, Validation Accuracy: 0.80775\n",
      "Epoch: 32, Loss: 0.5943865776062012, Validation Accuracy: 0.81125\n",
      "Epoch: 33, Loss: 0.5821148753166199, Validation Accuracy: 0.8143333333333334\n",
      "Epoch: 34, Loss: 0.5721604228019714, Validation Accuracy: 0.8174166666666667\n",
      "Epoch: 35, Loss: 0.5618955492973328, Validation Accuracy: 0.8219166666666666\n",
      "Epoch: 36, Loss: 0.5536231398582458, Validation Accuracy: 0.8239166666666666\n",
      "Epoch: 37, Loss: 0.5446701049804688, Validation Accuracy: 0.8275\n",
      "Epoch: 38, Loss: 0.537560760974884, Validation Accuracy: 0.8293333333333334\n",
      "Epoch: 39, Loss: 0.5292552709579468, Validation Accuracy: 0.8330833333333333\n",
      "Epoch: 40, Loss: 0.5228449702262878, Validation Accuracy: 0.8353333333333334\n",
      "Epoch: 41, Loss: 0.5150279402732849, Validation Accuracy: 0.8384166666666667\n",
      "Epoch: 42, Loss: 0.5092300772666931, Validation Accuracy: 0.8396666666666667\n",
      "Epoch: 43, Loss: 0.5019107460975647, Validation Accuracy: 0.84275\n",
      "Epoch: 44, Loss: 0.49640902876853943, Validation Accuracy: 0.844\n",
      "Epoch: 45, Loss: 0.48944273591041565, Validation Accuracy: 0.8478333333333333\n",
      "Epoch: 46, Loss: 0.48416027426719666, Validation Accuracy: 0.8475833333333334\n",
      "Epoch: 47, Loss: 0.4775126874446869, Validation Accuracy: 0.8510833333333333\n",
      "Epoch: 48, Loss: 0.4722924828529358, Validation Accuracy: 0.8516666666666667\n",
      "Epoch: 49, Loss: 0.46605944633483887, Validation Accuracy: 0.85625\n",
      "Epoch: 50, Loss: 0.46100151538848877, Validation Accuracy: 0.8554166666666667\n",
      "Epoch: 51, Loss: 0.45531773567199707, Validation Accuracy: 0.8583333333333333\n",
      "Epoch: 52, Loss: 0.45054715871810913, Validation Accuracy: 0.8589166666666667\n",
      "Epoch: 53, Loss: 0.4454100728034973, Validation Accuracy: 0.861\n",
      "Epoch: 54, Loss: 0.44089868664741516, Validation Accuracy: 0.8620833333333333\n",
      "Epoch: 55, Loss: 0.43618693947792053, Validation Accuracy: 0.86425\n",
      "Epoch: 56, Loss: 0.4319509267807007, Validation Accuracy: 0.8649166666666667\n",
      "Epoch: 57, Loss: 0.4275975227355957, Validation Accuracy: 0.8674166666666666\n",
      "Epoch: 58, Loss: 0.42363688349723816, Validation Accuracy: 0.86825\n",
      "Epoch: 59, Loss: 0.41966816782951355, Validation Accuracy: 0.8705833333333334\n",
      "Epoch: 60, Loss: 0.41596636176109314, Validation Accuracy: 0.8714166666666666\n",
      "Epoch: 61, Loss: 0.41229361295700073, Validation Accuracy: 0.87275\n",
      "Epoch: 62, Loss: 0.4088752567768097, Validation Accuracy: 0.8740833333333333\n",
      "Epoch: 63, Loss: 0.405530720949173, Validation Accuracy: 0.87475\n",
      "Epoch: 64, Loss: 0.4023129343986511, Validation Accuracy: 0.8761666666666666\n",
      "Epoch: 65, Loss: 0.39924609661102295, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 66, Loss: 0.39628201723098755, Validation Accuracy: 0.879\n",
      "Epoch: 67, Loss: 0.3934754729270935, Validation Accuracy: 0.8785\n",
      "Epoch: 68, Loss: 0.3906891942024231, Validation Accuracy: 0.8799166666666667\n",
      "Epoch: 69, Loss: 0.3881998658180237, Validation Accuracy: 0.88\n",
      "Epoch: 70, Loss: 0.3856477737426758, Validation Accuracy: 0.881\n",
      "Epoch: 71, Loss: 0.38339152932167053, Validation Accuracy: 0.8813333333333333\n",
      "Epoch: 72, Loss: 0.3810581564903259, Validation Accuracy: 0.88275\n",
      "Epoch: 73, Loss: 0.379132479429245, Validation Accuracy: 0.8824166666666666\n",
      "Epoch: 74, Loss: 0.37696346640586853, Validation Accuracy: 0.8834166666666666\n",
      "Epoch: 75, Loss: 0.37522831559181213, Validation Accuracy: 0.8834166666666666\n",
      "Epoch: 76, Loss: 0.3732396364212036, Validation Accuracy: 0.88375\n",
      "Epoch: 77, Loss: 0.37175607681274414, Validation Accuracy: 0.88375\n",
      "Epoch: 78, Loss: 0.36983516812324524, Validation Accuracy: 0.8851666666666667\n",
      "Epoch: 79, Loss: 0.36851468682289124, Validation Accuracy: 0.8845\n",
      "Epoch: 80, Loss: 0.3666507601737976, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 81, Loss: 0.3654750883579254, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 82, Loss: 0.3633544147014618, Validation Accuracy: 0.887\n",
      "Epoch: 83, Loss: 0.36203333735466003, Validation Accuracy: 0.88625\n",
      "Epoch: 84, Loss: 0.35974180698394775, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 85, Loss: 0.35806307196617126, Validation Accuracy: 0.8875\n",
      "Epoch: 86, Loss: 0.35554513335227966, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 87, Loss: 0.3536997139453888, Validation Accuracy: 0.8890833333333333\n",
      "Epoch: 88, Loss: 0.35107046365737915, Validation Accuracy: 0.8905\n",
      "Epoch: 89, Loss: 0.3490159511566162, Validation Accuracy: 0.8908333333333334\n",
      "Epoch: 90, Loss: 0.34646570682525635, Validation Accuracy: 0.89275\n",
      "Epoch: 91, Loss: 0.3441835641860962, Validation Accuracy: 0.89225\n",
      "Epoch: 92, Loss: 0.3416704535484314, Validation Accuracy: 0.8943333333333333\n",
      "Epoch: 93, Loss: 0.33937326073646545, Validation Accuracy: 0.8935\n",
      "Epoch: 94, Loss: 0.33697378635406494, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 95, Loss: 0.3347625136375427, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 96, Loss: 0.3325529396533966, Validation Accuracy: 0.8971666666666667\n",
      "Epoch: 97, Loss: 0.33044275641441345, Validation Accuracy: 0.8966666666666666\n",
      "Epoch: 98, Loss: 0.3284202218055725, Validation Accuracy: 0.89875\n",
      "Epoch: 99, Loss: 0.32646432518959045, Validation Accuracy: 0.898\n",
      "Dataset 58\n",
      "Epoch: 0, Loss: 3.419326066970825, Validation Accuracy: 0.17691666666666667\n",
      "Epoch: 1, Loss: 4.076190948486328, Validation Accuracy: 0.1815\n",
      "Epoch: 2, Loss: 4.629415512084961, Validation Accuracy: 0.12508333333333332\n",
      "Epoch: 3, Loss: 2.2816967964172363, Validation Accuracy: 0.25916666666666666\n",
      "Epoch: 4, Loss: 2.0699453353881836, Validation Accuracy: 0.33216666666666667\n",
      "Epoch: 5, Loss: 1.9370977878570557, Validation Accuracy: 0.39891666666666664\n",
      "Epoch: 6, Loss: 1.8069287538528442, Validation Accuracy: 0.4340833333333333\n",
      "Epoch: 7, Loss: 1.699729323387146, Validation Accuracy: 0.46375\n",
      "Epoch: 8, Loss: 1.6034008264541626, Validation Accuracy: 0.4890833333333333\n",
      "Epoch: 9, Loss: 1.5134241580963135, Validation Accuracy: 0.5170833333333333\n",
      "Epoch: 10, Loss: 1.4323097467422485, Validation Accuracy: 0.5274166666666666\n",
      "Epoch: 11, Loss: 1.3720858097076416, Validation Accuracy: 0.5161666666666667\n",
      "Epoch: 12, Loss: 1.381909966468811, Validation Accuracy: 0.45766666666666667\n",
      "Epoch: 13, Loss: 1.5370500087738037, Validation Accuracy: 0.3535\n",
      "Epoch: 14, Loss: 1.823603630065918, Validation Accuracy: 0.5219166666666667\n",
      "Epoch: 15, Loss: 1.3918696641921997, Validation Accuracy: 0.65525\n",
      "Epoch: 16, Loss: 1.1456482410430908, Validation Accuracy: 0.6579166666666667\n",
      "Epoch: 17, Loss: 1.0751934051513672, Validation Accuracy: 0.6768333333333333\n",
      "Epoch: 18, Loss: 1.0204657316207886, Validation Accuracy: 0.6868333333333333\n",
      "Epoch: 19, Loss: 0.9746296405792236, Validation Accuracy: 0.7038333333333333\n",
      "Epoch: 20, Loss: 0.9365708827972412, Validation Accuracy: 0.70425\n",
      "Epoch: 21, Loss: 0.9077680110931396, Validation Accuracy: 0.7134166666666667\n",
      "Epoch: 22, Loss: 0.8972544074058533, Validation Accuracy: 0.6778333333333333\n",
      "Epoch: 23, Loss: 0.9287120699882507, Validation Accuracy: 0.6093333333333333\n",
      "Epoch: 24, Loss: 1.1038084030151367, Validation Accuracy: 0.4846666666666667\n",
      "Epoch: 25, Loss: 1.4603829383850098, Validation Accuracy: 0.42783333333333334\n",
      "Epoch: 26, Loss: 1.620579719543457, Validation Accuracy: 0.62175\n",
      "Epoch: 27, Loss: 1.0793850421905518, Validation Accuracy: 0.7389166666666667\n",
      "Epoch: 28, Loss: 0.8530154824256897, Validation Accuracy: 0.7590833333333333\n",
      "Epoch: 29, Loss: 0.7998387813568115, Validation Accuracy: 0.765\n",
      "Epoch: 30, Loss: 0.7685502171516418, Validation Accuracy: 0.7729166666666667\n",
      "Epoch: 31, Loss: 0.7449930906295776, Validation Accuracy: 0.773\n",
      "Epoch: 32, Loss: 0.7291616201400757, Validation Accuracy: 0.7774166666666666\n",
      "Epoch: 33, Loss: 0.7171913981437683, Validation Accuracy: 0.7735\n",
      "Epoch: 34, Loss: 0.7158385515213013, Validation Accuracy: 0.76925\n",
      "Epoch: 35, Loss: 0.7200499773025513, Validation Accuracy: 0.75525\n",
      "Epoch: 36, Loss: 0.7437924742698669, Validation Accuracy: 0.74825\n",
      "Epoch: 37, Loss: 0.7639138102531433, Validation Accuracy: 0.7258333333333333\n",
      "Epoch: 38, Loss: 0.8006411194801331, Validation Accuracy: 0.7446666666666667\n",
      "Epoch: 39, Loss: 0.7764975428581238, Validation Accuracy: 0.7488333333333334\n",
      "Epoch: 40, Loss: 0.7461451888084412, Validation Accuracy: 0.7848333333333334\n",
      "Epoch: 41, Loss: 0.6711298227310181, Validation Accuracy: 0.799\n",
      "Epoch: 42, Loss: 0.6263070106506348, Validation Accuracy: 0.8171666666666667\n",
      "Epoch: 43, Loss: 0.5939075946807861, Validation Accuracy: 0.8211666666666667\n",
      "Epoch: 44, Loss: 0.5746795535087585, Validation Accuracy: 0.8285\n",
      "Epoch: 45, Loss: 0.5607025027275085, Validation Accuracy: 0.83\n",
      "Epoch: 46, Loss: 0.5496508479118347, Validation Accuracy: 0.83225\n",
      "Epoch: 47, Loss: 0.5401328206062317, Validation Accuracy: 0.8369166666666666\n",
      "Epoch: 48, Loss: 0.5317338705062866, Validation Accuracy: 0.838\n",
      "Epoch: 49, Loss: 0.5241100192070007, Validation Accuracy: 0.8425\n",
      "Epoch: 50, Loss: 0.517071545124054, Validation Accuracy: 0.84375\n",
      "Epoch: 51, Loss: 0.5104773640632629, Validation Accuracy: 0.8460833333333333\n",
      "Epoch: 52, Loss: 0.5043264627456665, Validation Accuracy: 0.847\n",
      "Epoch: 53, Loss: 0.4985150694847107, Validation Accuracy: 0.85075\n",
      "Epoch: 54, Loss: 0.4932052791118622, Validation Accuracy: 0.8513333333333334\n",
      "Epoch: 55, Loss: 0.488167405128479, Validation Accuracy: 0.8538333333333333\n",
      "Epoch: 56, Loss: 0.4837818741798401, Validation Accuracy: 0.8535833333333334\n",
      "Epoch: 57, Loss: 0.47972404956817627, Validation Accuracy: 0.85425\n",
      "Epoch: 58, Loss: 0.47669997811317444, Validation Accuracy: 0.85625\n",
      "Epoch: 59, Loss: 0.47417184710502625, Validation Accuracy: 0.8559166666666667\n",
      "Epoch: 60, Loss: 0.4738398492336273, Validation Accuracy: 0.8534166666666667\n",
      "Epoch: 61, Loss: 0.4741467237472534, Validation Accuracy: 0.8538333333333333\n",
      "Epoch: 62, Loss: 0.480072557926178, Validation Accuracy: 0.8480833333333333\n",
      "Epoch: 63, Loss: 0.4856272041797638, Validation Accuracy: 0.8446666666666667\n",
      "Epoch: 64, Loss: 0.504903256893158, Validation Accuracy: 0.8360833333333333\n",
      "Epoch: 65, Loss: 0.5168206095695496, Validation Accuracy: 0.8245\n",
      "Epoch: 66, Loss: 0.5592659115791321, Validation Accuracy: 0.81425\n",
      "Epoch: 67, Loss: 0.5615872144699097, Validation Accuracy: 0.80475\n",
      "Epoch: 68, Loss: 0.6109422445297241, Validation Accuracy: 0.8188333333333333\n",
      "Epoch: 69, Loss: 0.555036187171936, Validation Accuracy: 0.82675\n",
      "Epoch: 70, Loss: 0.5526154637336731, Validation Accuracy: 0.851\n",
      "Epoch: 71, Loss: 0.4815920889377594, Validation Accuracy: 0.85975\n",
      "Epoch: 72, Loss: 0.46017009019851685, Validation Accuracy: 0.8685\n",
      "Epoch: 73, Loss: 0.4339272379875183, Validation Accuracy: 0.8719166666666667\n",
      "Epoch: 74, Loss: 0.424003005027771, Validation Accuracy: 0.8759166666666667\n",
      "Epoch: 75, Loss: 0.4159906804561615, Validation Accuracy: 0.87875\n",
      "Epoch: 76, Loss: 0.4110681116580963, Validation Accuracy: 0.8799166666666667\n",
      "Epoch: 77, Loss: 0.40674421191215515, Validation Accuracy: 0.8815\n",
      "Epoch: 78, Loss: 0.4031967222690582, Validation Accuracy: 0.8821666666666667\n",
      "Epoch: 79, Loss: 0.39988353848457336, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 80, Loss: 0.3968285620212555, Validation Accuracy: 0.8841666666666667\n",
      "Epoch: 81, Loss: 0.39391085505485535, Validation Accuracy: 0.8851666666666667\n",
      "Epoch: 82, Loss: 0.3911316692829132, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 83, Loss: 0.3884522318840027, Validation Accuracy: 0.8871666666666667\n",
      "Epoch: 84, Loss: 0.3858568072319031, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 85, Loss: 0.3833397924900055, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 86, Loss: 0.38089311122894287, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 87, Loss: 0.3785122036933899, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 88, Loss: 0.37619587779045105, Validation Accuracy: 0.8915\n",
      "Epoch: 89, Loss: 0.3739338517189026, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 90, Loss: 0.37172406911849976, Validation Accuracy: 0.8923333333333333\n",
      "Epoch: 91, Loss: 0.3695635199546814, Validation Accuracy: 0.8929166666666667\n",
      "Epoch: 92, Loss: 0.3674449324607849, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 93, Loss: 0.36536523699760437, Validation Accuracy: 0.894\n",
      "Epoch: 94, Loss: 0.3633268177509308, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 95, Loss: 0.36132609844207764, Validation Accuracy: 0.895\n",
      "Epoch: 96, Loss: 0.35936394333839417, Validation Accuracy: 0.8954166666666666\n",
      "Epoch: 97, Loss: 0.35743746161460876, Validation Accuracy: 0.896\n",
      "Epoch: 98, Loss: 0.3555442988872528, Validation Accuracy: 0.89675\n",
      "Epoch: 99, Loss: 0.35368725657463074, Validation Accuracy: 0.89725\n",
      "Dataset 59\n",
      "Epoch: 0, Loss: 3.781195878982544, Validation Accuracy: 0.16108333333333333\n",
      "Epoch: 1, Loss: 4.181751728057861, Validation Accuracy: 0.194\n",
      "Epoch: 2, Loss: 2.635284900665283, Validation Accuracy: 0.3159166666666667\n",
      "Epoch: 3, Loss: 2.0209367275238037, Validation Accuracy: 0.34308333333333335\n",
      "Epoch: 4, Loss: 1.8651357889175415, Validation Accuracy: 0.45066666666666666\n",
      "Epoch: 5, Loss: 1.665608286857605, Validation Accuracy: 0.4974166666666667\n",
      "Epoch: 6, Loss: 1.544608235359192, Validation Accuracy: 0.5375\n",
      "Epoch: 7, Loss: 1.4331263303756714, Validation Accuracy: 0.5788333333333333\n",
      "Epoch: 8, Loss: 1.3218801021575928, Validation Accuracy: 0.6193333333333333\n",
      "Epoch: 9, Loss: 1.2125850915908813, Validation Accuracy: 0.6514166666666666\n",
      "Epoch: 10, Loss: 1.1111958026885986, Validation Accuracy: 0.6798333333333333\n",
      "Epoch: 11, Loss: 1.0243278741836548, Validation Accuracy: 0.70275\n",
      "Epoch: 12, Loss: 0.9514833092689514, Validation Accuracy: 0.7215833333333334\n",
      "Epoch: 13, Loss: 0.8907977938652039, Validation Accuracy: 0.7339166666666667\n",
      "Epoch: 14, Loss: 0.8419227004051208, Validation Accuracy: 0.7380833333333333\n",
      "Epoch: 15, Loss: 0.8102978467941284, Validation Accuracy: 0.73025\n",
      "Epoch: 16, Loss: 0.8344006538391113, Validation Accuracy: 0.6650833333333334\n",
      "Epoch: 17, Loss: 0.9757315516471863, Validation Accuracy: 0.519\n",
      "Epoch: 18, Loss: 1.4939244985580444, Validation Accuracy: 0.46825\n",
      "Epoch: 19, Loss: 1.726209282875061, Validation Accuracy: 0.5409166666666667\n",
      "Epoch: 20, Loss: 1.3079166412353516, Validation Accuracy: 0.6690833333333334\n",
      "Epoch: 21, Loss: 0.9540742039680481, Validation Accuracy: 0.749\n",
      "Epoch: 22, Loss: 0.7869033813476562, Validation Accuracy: 0.7885\n",
      "Epoch: 23, Loss: 0.7058030366897583, Validation Accuracy: 0.79775\n",
      "Epoch: 24, Loss: 0.661057710647583, Validation Accuracy: 0.8055833333333333\n",
      "Epoch: 25, Loss: 0.6302816867828369, Validation Accuracy: 0.812\n",
      "Epoch: 26, Loss: 0.6061124801635742, Validation Accuracy: 0.8176666666666667\n",
      "Epoch: 27, Loss: 0.5860087275505066, Validation Accuracy: 0.8226666666666667\n",
      "Epoch: 28, Loss: 0.5689148902893066, Validation Accuracy: 0.8255\n",
      "Epoch: 29, Loss: 0.5541560053825378, Validation Accuracy: 0.8291666666666667\n",
      "Epoch: 30, Loss: 0.5412640571594238, Validation Accuracy: 0.8326666666666667\n",
      "Epoch: 31, Loss: 0.5298199653625488, Validation Accuracy: 0.8360833333333333\n",
      "Epoch: 32, Loss: 0.519567608833313, Validation Accuracy: 0.837\n",
      "Epoch: 33, Loss: 0.5102921724319458, Validation Accuracy: 0.8410833333333333\n",
      "Epoch: 34, Loss: 0.5018231868743896, Validation Accuracy: 0.8415\n",
      "Epoch: 35, Loss: 0.4940853416919708, Validation Accuracy: 0.8445\n",
      "Epoch: 36, Loss: 0.4870375692844391, Validation Accuracy: 0.84475\n",
      "Epoch: 37, Loss: 0.4807491898536682, Validation Accuracy: 0.84825\n",
      "Epoch: 38, Loss: 0.4752838611602783, Validation Accuracy: 0.8463333333333334\n",
      "Epoch: 39, Loss: 0.4712539613246918, Validation Accuracy: 0.8503333333333334\n",
      "Epoch: 40, Loss: 0.4685366749763489, Validation Accuracy: 0.8466666666666667\n",
      "Epoch: 41, Loss: 0.46922990679740906, Validation Accuracy: 0.8488333333333333\n",
      "Epoch: 42, Loss: 0.4732325077056885, Validation Accuracy: 0.8395833333333333\n",
      "Epoch: 43, Loss: 0.48660287261009216, Validation Accuracy: 0.83425\n",
      "Epoch: 44, Loss: 0.5055572390556335, Validation Accuracy: 0.81725\n",
      "Epoch: 45, Loss: 0.5449264645576477, Validation Accuracy: 0.8076666666666666\n",
      "Epoch: 46, Loss: 0.5744309425354004, Validation Accuracy: 0.79225\n",
      "Epoch: 47, Loss: 0.6138404607772827, Validation Accuracy: 0.8054166666666667\n",
      "Epoch: 48, Loss: 0.5751532912254333, Validation Accuracy: 0.8206666666666667\n",
      "Epoch: 49, Loss: 0.5305623412132263, Validation Accuracy: 0.8451666666666666\n",
      "Epoch: 50, Loss: 0.4773874580860138, Validation Accuracy: 0.8555\n",
      "Epoch: 51, Loss: 0.44505709409713745, Validation Accuracy: 0.8625\n",
      "Epoch: 52, Loss: 0.4266054630279541, Validation Accuracy: 0.865\n",
      "Epoch: 53, Loss: 0.41623303294181824, Validation Accuracy: 0.8688333333333333\n",
      "Epoch: 54, Loss: 0.40922245383262634, Validation Accuracy: 0.8695833333333334\n",
      "Epoch: 55, Loss: 0.40406355261802673, Validation Accuracy: 0.8713333333333333\n",
      "Epoch: 56, Loss: 0.3996996581554413, Validation Accuracy: 0.8715833333333334\n",
      "Epoch: 57, Loss: 0.3959067761898041, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 58, Loss: 0.3924379050731659, Validation Accuracy: 0.8733333333333333\n",
      "Epoch: 59, Loss: 0.3892115354537964, Validation Accuracy: 0.8756666666666667\n",
      "Epoch: 60, Loss: 0.38615182042121887, Validation Accuracy: 0.8748333333333334\n",
      "Epoch: 61, Loss: 0.38325726985931396, Validation Accuracy: 0.8765\n",
      "Epoch: 62, Loss: 0.3804747462272644, Validation Accuracy: 0.8769166666666667\n",
      "Epoch: 63, Loss: 0.3778190016746521, Validation Accuracy: 0.8780833333333333\n",
      "Epoch: 64, Loss: 0.37523847818374634, Validation Accuracy: 0.8783333333333333\n",
      "Epoch: 65, Loss: 0.3727429509162903, Validation Accuracy: 0.87975\n",
      "Epoch: 66, Loss: 0.37030985951423645, Validation Accuracy: 0.8800833333333333\n",
      "Epoch: 67, Loss: 0.3679425120353699, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 68, Loss: 0.36564111709594727, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 69, Loss: 0.3634010851383209, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 70, Loss: 0.361214816570282, Validation Accuracy: 0.883\n",
      "Epoch: 71, Loss: 0.3590784966945648, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 72, Loss: 0.35699406266212463, Validation Accuracy: 0.8846666666666667\n",
      "Epoch: 73, Loss: 0.35495275259017944, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 74, Loss: 0.35295984148979187, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 75, Loss: 0.35100629925727844, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 76, Loss: 0.34909874200820923, Validation Accuracy: 0.8868333333333334\n",
      "Epoch: 77, Loss: 0.34723037481307983, Validation Accuracy: 0.88725\n",
      "Epoch: 78, Loss: 0.34539973735809326, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 79, Loss: 0.3436087667942047, Validation Accuracy: 0.8881666666666667\n",
      "Epoch: 80, Loss: 0.3418548107147217, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 81, Loss: 0.34013307094573975, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 82, Loss: 0.3384418785572052, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 83, Loss: 0.33678609132766724, Validation Accuracy: 0.89075\n",
      "Epoch: 84, Loss: 0.33516037464141846, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 85, Loss: 0.33356523513793945, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 86, Loss: 0.33199721574783325, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 87, Loss: 0.3304454982280731, Validation Accuracy: 0.8925\n",
      "Epoch: 88, Loss: 0.3289216160774231, Validation Accuracy: 0.8936666666666667\n",
      "Epoch: 89, Loss: 0.32741954922676086, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 90, Loss: 0.3259442150592804, Validation Accuracy: 0.89425\n",
      "Epoch: 91, Loss: 0.3244905471801758, Validation Accuracy: 0.89425\n",
      "Epoch: 92, Loss: 0.32305270433425903, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 93, Loss: 0.32164859771728516, Validation Accuracy: 0.8955\n",
      "Epoch: 94, Loss: 0.32025226950645447, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 95, Loss: 0.31888291239738464, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 96, Loss: 0.3175325393676758, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 97, Loss: 0.31620147824287415, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 98, Loss: 0.3148829936981201, Validation Accuracy: 0.8975\n",
      "Epoch: 99, Loss: 0.3135782480239868, Validation Accuracy: 0.898\n",
      "Dataset 60\n",
      "Epoch: 0, Loss: 3.0053043365478516, Validation Accuracy: 0.19416666666666665\n",
      "Epoch: 1, Loss: 2.9321300983428955, Validation Accuracy: 0.11491666666666667\n",
      "Epoch: 2, Loss: 3.640592098236084, Validation Accuracy: 0.23808333333333334\n",
      "Epoch: 3, Loss: 2.455552339553833, Validation Accuracy: 0.3739166666666667\n",
      "Epoch: 4, Loss: 1.7787307500839233, Validation Accuracy: 0.43191666666666667\n",
      "Epoch: 5, Loss: 1.60368013381958, Validation Accuracy: 0.48841666666666667\n",
      "Epoch: 6, Loss: 1.457148790359497, Validation Accuracy: 0.5286666666666666\n",
      "Epoch: 7, Loss: 1.3403265476226807, Validation Accuracy: 0.5675\n",
      "Epoch: 8, Loss: 1.241985559463501, Validation Accuracy: 0.5954166666666667\n",
      "Epoch: 9, Loss: 1.1583068370819092, Validation Accuracy: 0.6196666666666667\n",
      "Epoch: 10, Loss: 1.087181568145752, Validation Accuracy: 0.6374166666666666\n",
      "Epoch: 11, Loss: 1.02626371383667, Validation Accuracy: 0.6550833333333334\n",
      "Epoch: 12, Loss: 0.9733705520629883, Validation Accuracy: 0.6721666666666667\n",
      "Epoch: 13, Loss: 0.9265559911727905, Validation Accuracy: 0.68675\n",
      "Epoch: 14, Loss: 0.8847206830978394, Validation Accuracy: 0.7018333333333333\n",
      "Epoch: 15, Loss: 0.8472120761871338, Validation Accuracy: 0.71225\n",
      "Epoch: 16, Loss: 0.8140261173248291, Validation Accuracy: 0.7261666666666666\n",
      "Epoch: 17, Loss: 0.7859649062156677, Validation Accuracy: 0.7275833333333334\n",
      "Epoch: 18, Loss: 0.7679451704025269, Validation Accuracy: 0.73575\n",
      "Epoch: 19, Loss: 0.7702525854110718, Validation Accuracy: 0.6865\n",
      "Epoch: 20, Loss: 0.84670490026474, Validation Accuracy: 0.6749166666666667\n",
      "Epoch: 21, Loss: 0.9307671189308167, Validation Accuracy: 0.56075\n",
      "Epoch: 22, Loss: 1.194798469543457, Validation Accuracy: 0.6771666666666667\n",
      "Epoch: 23, Loss: 0.9045025110244751, Validation Accuracy: 0.7490833333333333\n",
      "Epoch: 24, Loss: 0.7271281480789185, Validation Accuracy: 0.7835833333333333\n",
      "Epoch: 25, Loss: 0.6567456722259521, Validation Accuracy: 0.7920833333333334\n",
      "Epoch: 26, Loss: 0.6283227205276489, Validation Accuracy: 0.7990833333333334\n",
      "Epoch: 27, Loss: 0.6093739867210388, Validation Accuracy: 0.80275\n",
      "Epoch: 28, Loss: 0.5943648815155029, Validation Accuracy: 0.80925\n",
      "Epoch: 29, Loss: 0.581284761428833, Validation Accuracy: 0.81\n",
      "Epoch: 30, Loss: 0.5697031021118164, Validation Accuracy: 0.81525\n",
      "Epoch: 31, Loss: 0.5590145587921143, Validation Accuracy: 0.8181666666666667\n",
      "Epoch: 32, Loss: 0.5492408275604248, Validation Accuracy: 0.8229166666666666\n",
      "Epoch: 33, Loss: 0.5400740504264832, Validation Accuracy: 0.8249166666666666\n",
      "Epoch: 34, Loss: 0.5315693616867065, Validation Accuracy: 0.8285\n",
      "Epoch: 35, Loss: 0.5234660506248474, Validation Accuracy: 0.8299166666666666\n",
      "Epoch: 36, Loss: 0.5158767104148865, Validation Accuracy: 0.8328333333333333\n",
      "Epoch: 37, Loss: 0.5085878968238831, Validation Accuracy: 0.8350833333333333\n",
      "Epoch: 38, Loss: 0.5017898678779602, Validation Accuracy: 0.8388333333333333\n",
      "Epoch: 39, Loss: 0.4952481687068939, Validation Accuracy: 0.8395833333333333\n",
      "Epoch: 40, Loss: 0.48930200934410095, Validation Accuracy: 0.84425\n",
      "Epoch: 41, Loss: 0.48340994119644165, Validation Accuracy: 0.8441666666666666\n",
      "Epoch: 42, Loss: 0.47819656133651733, Validation Accuracy: 0.8468333333333333\n",
      "Epoch: 43, Loss: 0.47286996245384216, Validation Accuracy: 0.8485\n",
      "Epoch: 44, Loss: 0.46843522787094116, Validation Accuracy: 0.8503333333333334\n",
      "Epoch: 45, Loss: 0.4636177122592926, Validation Accuracy: 0.8520833333333333\n",
      "Epoch: 46, Loss: 0.4598759710788727, Validation Accuracy: 0.8529166666666667\n",
      "Epoch: 47, Loss: 0.45554789900779724, Validation Accuracy: 0.8545833333333334\n",
      "Epoch: 48, Loss: 0.45254072546958923, Validation Accuracy: 0.8554166666666667\n",
      "Epoch: 49, Loss: 0.4486304223537445, Validation Accuracy: 0.8569166666666667\n",
      "Epoch: 50, Loss: 0.44633349776268005, Validation Accuracy: 0.8576666666666667\n",
      "Epoch: 51, Loss: 0.44266679883003235, Validation Accuracy: 0.858\n",
      "Epoch: 52, Loss: 0.44099050760269165, Validation Accuracy: 0.8600833333333333\n",
      "Epoch: 53, Loss: 0.43707650899887085, Validation Accuracy: 0.8596666666666667\n",
      "Epoch: 54, Loss: 0.4358111023902893, Validation Accuracy: 0.8621666666666666\n",
      "Epoch: 55, Loss: 0.4313296675682068, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 56, Loss: 0.43002116680145264, Validation Accuracy: 0.8645\n",
      "Epoch: 57, Loss: 0.4249037802219391, Validation Accuracy: 0.86325\n",
      "Epoch: 58, Loss: 0.42320582270622253, Validation Accuracy: 0.867\n",
      "Epoch: 59, Loss: 0.41740843653678894, Validation Accuracy: 0.8666666666666667\n",
      "Epoch: 60, Loss: 0.4149930775165558, Validation Accuracy: 0.8703333333333333\n",
      "Epoch: 61, Loss: 0.40909749269485474, Validation Accuracy: 0.8695833333333334\n",
      "Epoch: 62, Loss: 0.4060349464416504, Validation Accuracy: 0.87225\n",
      "Epoch: 63, Loss: 0.4005463719367981, Validation Accuracy: 0.87325\n",
      "Epoch: 64, Loss: 0.3970668613910675, Validation Accuracy: 0.8753333333333333\n",
      "Epoch: 65, Loss: 0.3921600878238678, Validation Accuracy: 0.8773333333333333\n",
      "Epoch: 66, Loss: 0.3886972665786743, Validation Accuracy: 0.8780833333333333\n",
      "Epoch: 67, Loss: 0.38449767231941223, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 68, Loss: 0.38130664825439453, Validation Accuracy: 0.8805833333333334\n",
      "Epoch: 69, Loss: 0.3778096139431, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 70, Loss: 0.37488335371017456, Validation Accuracy: 0.8825\n",
      "Epoch: 71, Loss: 0.3718951940536499, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 72, Loss: 0.36925336718559265, Validation Accuracy: 0.8839166666666667\n",
      "Epoch: 73, Loss: 0.36661937832832336, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 74, Loss: 0.36420777440071106, Validation Accuracy: 0.8856666666666667\n",
      "Epoch: 75, Loss: 0.36181965470314026, Validation Accuracy: 0.8868333333333334\n",
      "Epoch: 76, Loss: 0.3595881760120392, Validation Accuracy: 0.88725\n",
      "Epoch: 77, Loss: 0.3573942482471466, Validation Accuracy: 0.8886666666666667\n",
      "Epoch: 78, Loss: 0.35530588030815125, Validation Accuracy: 0.8885\n",
      "Epoch: 79, Loss: 0.3532749116420746, Validation Accuracy: 0.8896666666666667\n",
      "Epoch: 80, Loss: 0.35130733251571655, Validation Accuracy: 0.8896666666666667\n",
      "Epoch: 81, Loss: 0.3493778109550476, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 82, Loss: 0.34750184416770935, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 83, Loss: 0.34567496180534363, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 84, Loss: 0.3438817262649536, Validation Accuracy: 0.8925833333333333\n",
      "Epoch: 85, Loss: 0.3421292006969452, Validation Accuracy: 0.893\n",
      "Epoch: 86, Loss: 0.34041571617126465, Validation Accuracy: 0.8943333333333333\n",
      "Epoch: 87, Loss: 0.33873045444488525, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 88, Loss: 0.33708029985427856, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 89, Loss: 0.3354620635509491, Validation Accuracy: 0.89575\n",
      "Epoch: 90, Loss: 0.3338777422904968, Validation Accuracy: 0.897\n",
      "Epoch: 91, Loss: 0.33231982588768005, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 92, Loss: 0.33079397678375244, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 93, Loss: 0.3292938768863678, Validation Accuracy: 0.8979166666666667\n",
      "Epoch: 94, Loss: 0.32781925797462463, Validation Accuracy: 0.89825\n",
      "Epoch: 95, Loss: 0.3263683021068573, Validation Accuracy: 0.8985\n",
      "Epoch: 96, Loss: 0.324939101934433, Validation Accuracy: 0.8988333333333334\n",
      "Epoch: 97, Loss: 0.32352906465530396, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 98, Loss: 0.3221360445022583, Validation Accuracy: 0.8991666666666667\n",
      "Epoch: 99, Loss: 0.32076457142829895, Validation Accuracy: 0.89975\n",
      "Dataset 61\n",
      "Epoch: 0, Loss: 3.833470106124878, Validation Accuracy: 0.15991666666666668\n",
      "Epoch: 1, Loss: 3.235663414001465, Validation Accuracy: 0.1535\n",
      "Epoch: 2, Loss: 2.8648922443389893, Validation Accuracy: 0.2659166666666667\n",
      "Epoch: 3, Loss: 2.2428550720214844, Validation Accuracy: 0.33891666666666664\n",
      "Epoch: 4, Loss: 1.8561897277832031, Validation Accuracy: 0.42083333333333334\n",
      "Epoch: 5, Loss: 1.6698791980743408, Validation Accuracy: 0.466\n",
      "Epoch: 6, Loss: 1.5461434125900269, Validation Accuracy: 0.514\n",
      "Epoch: 7, Loss: 1.4189269542694092, Validation Accuracy: 0.55975\n",
      "Epoch: 8, Loss: 1.2972021102905273, Validation Accuracy: 0.598\n",
      "Epoch: 9, Loss: 1.188876986503601, Validation Accuracy: 0.62425\n",
      "Epoch: 10, Loss: 1.0963890552520752, Validation Accuracy: 0.6530833333333333\n",
      "Epoch: 11, Loss: 1.018015742301941, Validation Accuracy: 0.67275\n",
      "Epoch: 12, Loss: 0.9531806111335754, Validation Accuracy: 0.6911666666666667\n",
      "Epoch: 13, Loss: 0.9025415778160095, Validation Accuracy: 0.6980833333333333\n",
      "Epoch: 14, Loss: 0.8706440329551697, Validation Accuracy: 0.69425\n",
      "Epoch: 15, Loss: 0.8833395838737488, Validation Accuracy: 0.6675833333333333\n",
      "Epoch: 16, Loss: 0.9705529808998108, Validation Accuracy: 0.5754166666666667\n",
      "Epoch: 17, Loss: 1.2993450164794922, Validation Accuracy: 0.6905833333333333\n",
      "Epoch: 18, Loss: 0.8904237747192383, Validation Accuracy: 0.7288333333333333\n",
      "Epoch: 19, Loss: 0.7850127816200256, Validation Accuracy: 0.7525833333333334\n",
      "Epoch: 20, Loss: 0.7259002923965454, Validation Accuracy: 0.7641666666666667\n",
      "Epoch: 21, Loss: 0.6944295763969421, Validation Accuracy: 0.7725\n",
      "Epoch: 22, Loss: 0.6713593006134033, Validation Accuracy: 0.7769166666666667\n",
      "Epoch: 23, Loss: 0.653307318687439, Validation Accuracy: 0.7833333333333333\n",
      "Epoch: 24, Loss: 0.6403365135192871, Validation Accuracy: 0.786\n",
      "Epoch: 25, Loss: 0.6298246383666992, Validation Accuracy: 0.7878333333333334\n",
      "Epoch: 26, Loss: 0.6268165111541748, Validation Accuracy: 0.7851666666666667\n",
      "Epoch: 27, Loss: 0.6227526664733887, Validation Accuracy: 0.7865\n",
      "Epoch: 28, Loss: 0.6315211653709412, Validation Accuracy: 0.7834166666666667\n",
      "Epoch: 29, Loss: 0.6282781958580017, Validation Accuracy: 0.7841666666666667\n",
      "Epoch: 30, Loss: 0.641423761844635, Validation Accuracy: 0.7850833333333334\n",
      "Epoch: 31, Loss: 0.6211618781089783, Validation Accuracy: 0.79325\n",
      "Epoch: 32, Loss: 0.6169346570968628, Validation Accuracy: 0.8019166666666667\n",
      "Epoch: 33, Loss: 0.5807387232780457, Validation Accuracy: 0.813\n",
      "Epoch: 34, Loss: 0.5628310441970825, Validation Accuracy: 0.8204166666666667\n",
      "Epoch: 35, Loss: 0.5358272790908813, Validation Accuracy: 0.828\n",
      "Epoch: 36, Loss: 0.5215595960617065, Validation Accuracy: 0.8316666666666667\n",
      "Epoch: 37, Loss: 0.5064518451690674, Validation Accuracy: 0.8366666666666667\n",
      "Epoch: 38, Loss: 0.4968319535255432, Validation Accuracy: 0.8389166666666666\n",
      "Epoch: 39, Loss: 0.48768892884254456, Validation Accuracy: 0.84275\n",
      "Epoch: 40, Loss: 0.48056912422180176, Validation Accuracy: 0.844\n",
      "Epoch: 41, Loss: 0.4739803373813629, Validation Accuracy: 0.8468333333333333\n",
      "Epoch: 42, Loss: 0.4682173728942871, Validation Accuracy: 0.8471666666666666\n",
      "Epoch: 43, Loss: 0.4627169966697693, Validation Accuracy: 0.8506666666666667\n",
      "Epoch: 44, Loss: 0.45777982473373413, Validation Accuracy: 0.84975\n",
      "Epoch: 45, Loss: 0.453011155128479, Validation Accuracy: 0.8533333333333334\n",
      "Epoch: 46, Loss: 0.44856688380241394, Validation Accuracy: 0.8521666666666666\n",
      "Epoch: 47, Loss: 0.44432568550109863, Validation Accuracy: 0.8558333333333333\n",
      "Epoch: 48, Loss: 0.4401249289512634, Validation Accuracy: 0.8545\n",
      "Epoch: 49, Loss: 0.43627235293388367, Validation Accuracy: 0.85875\n",
      "Epoch: 50, Loss: 0.43242090940475464, Validation Accuracy: 0.8565833333333334\n",
      "Epoch: 51, Loss: 0.42884671688079834, Validation Accuracy: 0.8605\n",
      "Epoch: 52, Loss: 0.42530378699302673, Validation Accuracy: 0.8588333333333333\n",
      "Epoch: 53, Loss: 0.42201411724090576, Validation Accuracy: 0.8625\n",
      "Epoch: 54, Loss: 0.4186774492263794, Validation Accuracy: 0.86075\n",
      "Epoch: 55, Loss: 0.4155590832233429, Validation Accuracy: 0.865\n",
      "Epoch: 56, Loss: 0.41248607635498047, Validation Accuracy: 0.863\n",
      "Epoch: 57, Loss: 0.4096180498600006, Validation Accuracy: 0.8674166666666666\n",
      "Epoch: 58, Loss: 0.40681588649749756, Validation Accuracy: 0.8648333333333333\n",
      "Epoch: 59, Loss: 0.404070645570755, Validation Accuracy: 0.86875\n",
      "Epoch: 60, Loss: 0.401387482881546, Validation Accuracy: 0.8663333333333333\n",
      "Epoch: 61, Loss: 0.3987751603126526, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 62, Loss: 0.396270215511322, Validation Accuracy: 0.868\n",
      "Epoch: 63, Loss: 0.3937775194644928, Validation Accuracy: 0.8726666666666667\n",
      "Epoch: 64, Loss: 0.39141133427619934, Validation Accuracy: 0.8695\n",
      "Epoch: 65, Loss: 0.3890969157218933, Validation Accuracy: 0.8733333333333333\n",
      "Epoch: 66, Loss: 0.386809766292572, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 67, Loss: 0.38466987013816833, Validation Accuracy: 0.8740833333333333\n",
      "Epoch: 68, Loss: 0.3825111985206604, Validation Accuracy: 0.872\n",
      "Epoch: 69, Loss: 0.3804898262023926, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 70, Loss: 0.37852582335472107, Validation Accuracy: 0.8729166666666667\n",
      "Epoch: 71, Loss: 0.3765588700771332, Validation Accuracy: 0.8755833333333334\n",
      "Epoch: 72, Loss: 0.374727338552475, Validation Accuracy: 0.8745833333333334\n",
      "Epoch: 73, Loss: 0.3728659152984619, Validation Accuracy: 0.8765833333333334\n",
      "Epoch: 74, Loss: 0.37106388807296753, Validation Accuracy: 0.8756666666666667\n",
      "Epoch: 75, Loss: 0.36923274397850037, Validation Accuracy: 0.8775\n",
      "Epoch: 76, Loss: 0.36757344007492065, Validation Accuracy: 0.8766666666666667\n",
      "Epoch: 77, Loss: 0.3657282590866089, Validation Accuracy: 0.8785\n",
      "Epoch: 78, Loss: 0.36410626769065857, Validation Accuracy: 0.878\n",
      "Epoch: 79, Loss: 0.36229532957077026, Validation Accuracy: 0.8794166666666666\n",
      "Epoch: 80, Loss: 0.3607002794742584, Validation Accuracy: 0.8788333333333334\n",
      "Epoch: 81, Loss: 0.3589257299900055, Validation Accuracy: 0.8814166666666666\n",
      "Epoch: 82, Loss: 0.3573271632194519, Validation Accuracy: 0.88\n",
      "Epoch: 83, Loss: 0.3555351197719574, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 84, Loss: 0.3539174497127533, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 85, Loss: 0.3521503508090973, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 86, Loss: 0.350563108921051, Validation Accuracy: 0.8815\n",
      "Epoch: 87, Loss: 0.34878280758857727, Validation Accuracy: 0.8840833333333333\n",
      "Epoch: 88, Loss: 0.34719306230545044, Validation Accuracy: 0.8823333333333333\n",
      "Epoch: 89, Loss: 0.3454512059688568, Validation Accuracy: 0.8855833333333333\n",
      "Epoch: 90, Loss: 0.34385138750076294, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 91, Loss: 0.3421226739883423, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 92, Loss: 0.34056785702705383, Validation Accuracy: 0.88525\n",
      "Epoch: 93, Loss: 0.3388776183128357, Validation Accuracy: 0.88725\n",
      "Epoch: 94, Loss: 0.33741235733032227, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 95, Loss: 0.3357750475406647, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 96, Loss: 0.3343273997306824, Validation Accuracy: 0.8873333333333333\n",
      "Epoch: 97, Loss: 0.33272650837898254, Validation Accuracy: 0.889\n",
      "Epoch: 98, Loss: 0.3312853276729584, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 99, Loss: 0.32971835136413574, Validation Accuracy: 0.89025\n",
      "Dataset 62\n",
      "Epoch: 0, Loss: 3.4160547256469727, Validation Accuracy: 0.14483333333333334\n",
      "Epoch: 1, Loss: 2.627063035964966, Validation Accuracy: 0.18133333333333335\n",
      "Epoch: 2, Loss: 2.62461256980896, Validation Accuracy: 0.22766666666666666\n",
      "Epoch: 3, Loss: 2.236182451248169, Validation Accuracy: 0.3175\n",
      "Epoch: 4, Loss: 1.92951500415802, Validation Accuracy: 0.4230833333333333\n",
      "Epoch: 5, Loss: 1.6717774868011475, Validation Accuracy: 0.4985833333333333\n",
      "Epoch: 6, Loss: 1.5245683193206787, Validation Accuracy: 0.53825\n",
      "Epoch: 7, Loss: 1.4056833982467651, Validation Accuracy: 0.5741666666666667\n",
      "Epoch: 8, Loss: 1.3003056049346924, Validation Accuracy: 0.6033333333333334\n",
      "Epoch: 9, Loss: 1.2094781398773193, Validation Accuracy: 0.6324166666666666\n",
      "Epoch: 10, Loss: 1.130570411682129, Validation Accuracy: 0.6506666666666666\n",
      "Epoch: 11, Loss: 1.0607718229293823, Validation Accuracy: 0.67775\n",
      "Epoch: 12, Loss: 1.0008467435836792, Validation Accuracy: 0.6819166666666666\n",
      "Epoch: 13, Loss: 0.9523709416389465, Validation Accuracy: 0.6954166666666667\n",
      "Epoch: 14, Loss: 0.9264838695526123, Validation Accuracy: 0.6795833333333333\n",
      "Epoch: 15, Loss: 0.9169377684593201, Validation Accuracy: 0.6740833333333334\n",
      "Epoch: 16, Loss: 0.9621561765670776, Validation Accuracy: 0.6710833333333334\n",
      "Epoch: 17, Loss: 0.9237984418869019, Validation Accuracy: 0.6789166666666666\n",
      "Epoch: 18, Loss: 0.9311402440071106, Validation Accuracy: 0.7295\n",
      "Epoch: 19, Loss: 0.7861194014549255, Validation Accuracy: 0.7470833333333333\n",
      "Epoch: 20, Loss: 0.7566924691200256, Validation Accuracy: 0.7638333333333334\n",
      "Epoch: 21, Loss: 0.7107934355735779, Validation Accuracy: 0.7708333333333334\n",
      "Epoch: 22, Loss: 0.6926107406616211, Validation Accuracy: 0.77925\n",
      "Epoch: 23, Loss: 0.6682812571525574, Validation Accuracy: 0.7823333333333333\n",
      "Epoch: 24, Loss: 0.6561475992202759, Validation Accuracy: 0.78675\n",
      "Epoch: 25, Loss: 0.6424404978752136, Validation Accuracy: 0.7871666666666667\n",
      "Epoch: 26, Loss: 0.6370782256126404, Validation Accuracy: 0.7891666666666667\n",
      "Epoch: 27, Loss: 0.6311413049697876, Validation Accuracy: 0.7885833333333333\n",
      "Epoch: 28, Loss: 0.6305227875709534, Validation Accuracy: 0.7878333333333334\n",
      "Epoch: 29, Loss: 0.627665638923645, Validation Accuracy: 0.7885\n",
      "Epoch: 30, Loss: 0.6234311461448669, Validation Accuracy: 0.7915833333333333\n",
      "Epoch: 31, Loss: 0.6155827045440674, Validation Accuracy: 0.79875\n",
      "Epoch: 32, Loss: 0.5993843078613281, Validation Accuracy: 0.80225\n",
      "Epoch: 33, Loss: 0.5843900442123413, Validation Accuracy: 0.81425\n",
      "Epoch: 34, Loss: 0.5606579780578613, Validation Accuracy: 0.8194166666666667\n",
      "Epoch: 35, Loss: 0.5444672107696533, Validation Accuracy: 0.8285\n",
      "Epoch: 36, Loss: 0.524114727973938, Validation Accuracy: 0.8331666666666667\n",
      "Epoch: 37, Loss: 0.5113947987556458, Validation Accuracy: 0.8393333333333334\n",
      "Epoch: 38, Loss: 0.4973110854625702, Validation Accuracy: 0.8414166666666667\n",
      "Epoch: 39, Loss: 0.48775243759155273, Validation Accuracy: 0.8458333333333333\n",
      "Epoch: 40, Loss: 0.4777595102787018, Validation Accuracy: 0.8476666666666667\n",
      "Epoch: 41, Loss: 0.4701542258262634, Validation Accuracy: 0.85125\n",
      "Epoch: 42, Loss: 0.46240943670272827, Validation Accuracy: 0.8518333333333333\n",
      "Epoch: 43, Loss: 0.4559565484523773, Validation Accuracy: 0.8555833333333334\n",
      "Epoch: 44, Loss: 0.44949203729629517, Validation Accuracy: 0.8561666666666666\n",
      "Epoch: 45, Loss: 0.4438875615596771, Validation Accuracy: 0.8595\n",
      "Epoch: 46, Loss: 0.4383007884025574, Validation Accuracy: 0.8599166666666667\n",
      "Epoch: 47, Loss: 0.4332514703273773, Validation Accuracy: 0.8623333333333333\n",
      "Epoch: 48, Loss: 0.42828673124313354, Validation Accuracy: 0.8629166666666667\n",
      "Epoch: 49, Loss: 0.4237186014652252, Validation Accuracy: 0.8643333333333333\n",
      "Epoch: 50, Loss: 0.4192451536655426, Validation Accuracy: 0.86575\n",
      "Epoch: 51, Loss: 0.41506409645080566, Validation Accuracy: 0.8668333333333333\n",
      "Epoch: 52, Loss: 0.41096362471580505, Validation Accuracy: 0.8681666666666666\n",
      "Epoch: 53, Loss: 0.40712764859199524, Validation Accuracy: 0.86875\n",
      "Epoch: 54, Loss: 0.4033658504486084, Validation Accuracy: 0.87\n",
      "Epoch: 55, Loss: 0.3998343050479889, Validation Accuracy: 0.8696666666666667\n",
      "Epoch: 56, Loss: 0.3963075876235962, Validation Accuracy: 0.87225\n",
      "Epoch: 57, Loss: 0.39299046993255615, Validation Accuracy: 0.873\n",
      "Epoch: 58, Loss: 0.38970303535461426, Validation Accuracy: 0.8745833333333334\n",
      "Epoch: 59, Loss: 0.3866005837917328, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 60, Loss: 0.38352227210998535, Validation Accuracy: 0.8755833333333334\n",
      "Epoch: 61, Loss: 0.3805766701698303, Validation Accuracy: 0.8761666666666666\n",
      "Epoch: 62, Loss: 0.3777073919773102, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 63, Loss: 0.3749566674232483, Validation Accuracy: 0.8775\n",
      "Epoch: 64, Loss: 0.3722812831401825, Validation Accuracy: 0.8783333333333333\n",
      "Epoch: 65, Loss: 0.3697119951248169, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 66, Loss: 0.36715397238731384, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 67, Loss: 0.36473003029823303, Validation Accuracy: 0.88125\n",
      "Epoch: 68, Loss: 0.3622923195362091, Validation Accuracy: 0.8805833333333334\n",
      "Epoch: 69, Loss: 0.36000871658325195, Validation Accuracy: 0.8823333333333333\n",
      "Epoch: 70, Loss: 0.3576345145702362, Validation Accuracy: 0.881\n",
      "Epoch: 71, Loss: 0.3554418981075287, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 72, Loss: 0.35317811369895935, Validation Accuracy: 0.8830833333333333\n",
      "Epoch: 73, Loss: 0.3511102795600891, Validation Accuracy: 0.885\n",
      "Epoch: 74, Loss: 0.3489384651184082, Validation Accuracy: 0.8845833333333334\n",
      "Epoch: 75, Loss: 0.34696313738822937, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 76, Loss: 0.34486523270606995, Validation Accuracy: 0.886\n",
      "Epoch: 77, Loss: 0.3429540991783142, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 78, Loss: 0.34093067049980164, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 79, Loss: 0.3390468657016754, Validation Accuracy: 0.8890833333333333\n",
      "Epoch: 80, Loss: 0.3371241092681885, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 81, Loss: 0.3353344202041626, Validation Accuracy: 0.8899166666666667\n",
      "Epoch: 82, Loss: 0.33349066972732544, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 83, Loss: 0.33178967237472534, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 84, Loss: 0.3300139904022217, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 85, Loss: 0.3283674716949463, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 86, Loss: 0.3266555964946747, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 87, Loss: 0.32509806752204895, Validation Accuracy: 0.8925\n",
      "Epoch: 88, Loss: 0.3234131336212158, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 89, Loss: 0.32189956307411194, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 90, Loss: 0.3202759027481079, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 91, Loss: 0.31879323720932007, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 92, Loss: 0.3172271251678467, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 93, Loss: 0.31579089164733887, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 94, Loss: 0.3142906427383423, Validation Accuracy: 0.89675\n",
      "Epoch: 95, Loss: 0.31292107701301575, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 96, Loss: 0.31147313117980957, Validation Accuracy: 0.8975\n",
      "Epoch: 97, Loss: 0.31012997031211853, Validation Accuracy: 0.897\n",
      "Epoch: 98, Loss: 0.30872461199760437, Validation Accuracy: 0.8985\n",
      "Epoch: 99, Loss: 0.3073962330818176, Validation Accuracy: 0.8974166666666666\n",
      "Dataset 63\n",
      "Epoch: 0, Loss: 3.4160537719726562, Validation Accuracy: 0.21883333333333332\n",
      "Epoch: 1, Loss: 2.4727580547332764, Validation Accuracy: 0.27758333333333335\n",
      "Epoch: 2, Loss: 2.3106555938720703, Validation Accuracy: 0.34833333333333333\n",
      "Epoch: 3, Loss: 1.868327260017395, Validation Accuracy: 0.39366666666666666\n",
      "Epoch: 4, Loss: 1.759003758430481, Validation Accuracy: 0.44775\n",
      "Epoch: 5, Loss: 1.58015775680542, Validation Accuracy: 0.5198333333333334\n",
      "Epoch: 6, Loss: 1.4123526811599731, Validation Accuracy: 0.5746666666666667\n",
      "Epoch: 7, Loss: 1.267224669456482, Validation Accuracy: 0.62225\n",
      "Epoch: 8, Loss: 1.142651915550232, Validation Accuracy: 0.6581666666666667\n",
      "Epoch: 9, Loss: 1.0426052808761597, Validation Accuracy: 0.6775833333333333\n",
      "Epoch: 10, Loss: 0.9679273962974548, Validation Accuracy: 0.70075\n",
      "Epoch: 11, Loss: 0.9100724458694458, Validation Accuracy: 0.7068333333333333\n",
      "Epoch: 12, Loss: 0.8708382248878479, Validation Accuracy: 0.7146666666666667\n",
      "Epoch: 13, Loss: 0.8559961915016174, Validation Accuracy: 0.6985\n",
      "Epoch: 14, Loss: 0.8710721731185913, Validation Accuracy: 0.66175\n",
      "Epoch: 15, Loss: 0.9679605960845947, Validation Accuracy: 0.6744166666666667\n",
      "Epoch: 16, Loss: 0.95217365026474, Validation Accuracy: 0.66175\n",
      "Epoch: 17, Loss: 0.9571155309677124, Validation Accuracy: 0.7425\n",
      "Epoch: 18, Loss: 0.7812308073043823, Validation Accuracy: 0.7578333333333334\n",
      "Epoch: 19, Loss: 0.724554181098938, Validation Accuracy: 0.7774166666666666\n",
      "Epoch: 20, Loss: 0.6820858716964722, Validation Accuracy: 0.7821666666666667\n",
      "Epoch: 21, Loss: 0.6575700044631958, Validation Accuracy: 0.7920833333333334\n",
      "Epoch: 22, Loss: 0.641541600227356, Validation Accuracy: 0.7903333333333333\n",
      "Epoch: 23, Loss: 0.6308104991912842, Validation Accuracy: 0.79575\n",
      "Epoch: 24, Loss: 0.6254559755325317, Validation Accuracy: 0.7910833333333334\n",
      "Epoch: 25, Loss: 0.625449001789093, Validation Accuracy: 0.791\n",
      "Epoch: 26, Loss: 0.6284281611442566, Validation Accuracy: 0.7851666666666667\n",
      "Epoch: 27, Loss: 0.6337069869041443, Validation Accuracy: 0.7855\n",
      "Epoch: 28, Loss: 0.6382680535316467, Validation Accuracy: 0.78575\n",
      "Epoch: 29, Loss: 0.630667507648468, Validation Accuracy: 0.7910833333333334\n",
      "Epoch: 30, Loss: 0.6231282353401184, Validation Accuracy: 0.8003333333333333\n",
      "Epoch: 31, Loss: 0.5941128134727478, Validation Accuracy: 0.8061666666666667\n",
      "Epoch: 32, Loss: 0.576253354549408, Validation Accuracy: 0.8181666666666667\n",
      "Epoch: 33, Loss: 0.5481797456741333, Validation Accuracy: 0.8226666666666667\n",
      "Epoch: 34, Loss: 0.5325061678886414, Validation Accuracy: 0.8300833333333333\n",
      "Epoch: 35, Loss: 0.5149899125099182, Validation Accuracy: 0.8346666666666667\n",
      "Epoch: 36, Loss: 0.5032782554626465, Validation Accuracy: 0.83975\n",
      "Epoch: 37, Loss: 0.49269548058509827, Validation Accuracy: 0.8425\n",
      "Epoch: 38, Loss: 0.4841088354587555, Validation Accuracy: 0.8469166666666667\n",
      "Epoch: 39, Loss: 0.47674238681793213, Validation Accuracy: 0.847\n",
      "Epoch: 40, Loss: 0.46969738602638245, Validation Accuracy: 0.853\n",
      "Epoch: 41, Loss: 0.46373963356018066, Validation Accuracy: 0.8515\n",
      "Epoch: 42, Loss: 0.4576636552810669, Validation Accuracy: 0.856\n",
      "Epoch: 43, Loss: 0.4525390565395355, Validation Accuracy: 0.8553333333333333\n",
      "Epoch: 44, Loss: 0.44716519117355347, Validation Accuracy: 0.8590833333333333\n",
      "Epoch: 45, Loss: 0.4426327049732208, Validation Accuracy: 0.8581666666666666\n",
      "Epoch: 46, Loss: 0.4378845691680908, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 47, Loss: 0.4337826073169708, Validation Accuracy: 0.8608333333333333\n",
      "Epoch: 48, Loss: 0.42957690358161926, Validation Accuracy: 0.8646666666666667\n",
      "Epoch: 49, Loss: 0.4259166121482849, Validation Accuracy: 0.86375\n",
      "Epoch: 50, Loss: 0.42206403613090515, Validation Accuracy: 0.8665\n",
      "Epoch: 51, Loss: 0.418641597032547, Validation Accuracy: 0.8655833333333334\n",
      "Epoch: 52, Loss: 0.4150868356227875, Validation Accuracy: 0.86775\n",
      "Epoch: 53, Loss: 0.41193315386772156, Validation Accuracy: 0.8675833333333334\n",
      "Epoch: 54, Loss: 0.40860483050346375, Validation Accuracy: 0.8691666666666666\n",
      "Epoch: 55, Loss: 0.40564340353012085, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 56, Loss: 0.4025520086288452, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 57, Loss: 0.39979857206344604, Validation Accuracy: 0.8709166666666667\n",
      "Epoch: 58, Loss: 0.3968370854854584, Validation Accuracy: 0.8729166666666667\n",
      "Epoch: 59, Loss: 0.39426881074905396, Validation Accuracy: 0.8725833333333334\n",
      "Epoch: 60, Loss: 0.39155521988868713, Validation Accuracy: 0.8748333333333334\n",
      "Epoch: 61, Loss: 0.38907748460769653, Validation Accuracy: 0.8745\n",
      "Epoch: 62, Loss: 0.38655248284339905, Validation Accuracy: 0.8765\n",
      "Epoch: 63, Loss: 0.3841395974159241, Validation Accuracy: 0.8765833333333334\n",
      "Epoch: 64, Loss: 0.3817281424999237, Validation Accuracy: 0.8783333333333333\n",
      "Epoch: 65, Loss: 0.3794572651386261, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 66, Loss: 0.3771415948867798, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 67, Loss: 0.3749327063560486, Validation Accuracy: 0.8805\n",
      "Epoch: 68, Loss: 0.3726580739021301, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 69, Loss: 0.37051546573638916, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 70, Loss: 0.3683094382286072, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 71, Loss: 0.3661905825138092, Validation Accuracy: 0.8831666666666667\n",
      "Epoch: 72, Loss: 0.364077627658844, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 73, Loss: 0.36204907298088074, Validation Accuracy: 0.8845833333333334\n",
      "Epoch: 74, Loss: 0.3600318133831024, Validation Accuracy: 0.88525\n",
      "Epoch: 75, Loss: 0.35808899998664856, Validation Accuracy: 0.8855833333333333\n",
      "Epoch: 76, Loss: 0.3561328053474426, Validation Accuracy: 0.8866666666666667\n",
      "Epoch: 77, Loss: 0.3542793095111847, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 78, Loss: 0.35237225890159607, Validation Accuracy: 0.888\n",
      "Epoch: 79, Loss: 0.35058850049972534, Validation Accuracy: 0.8881666666666667\n",
      "Epoch: 80, Loss: 0.348733514547348, Validation Accuracy: 0.8890833333333333\n",
      "Epoch: 81, Loss: 0.34702059626579285, Validation Accuracy: 0.8895\n",
      "Epoch: 82, Loss: 0.3452315628528595, Validation Accuracy: 0.89025\n",
      "Epoch: 83, Loss: 0.34356993436813354, Validation Accuracy: 0.89025\n",
      "Epoch: 84, Loss: 0.3418632447719574, Validation Accuracy: 0.8915\n",
      "Epoch: 85, Loss: 0.34026309847831726, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 86, Loss: 0.33862927556037903, Validation Accuracy: 0.89225\n",
      "Epoch: 87, Loss: 0.33707624673843384, Validation Accuracy: 0.89275\n",
      "Epoch: 88, Loss: 0.33551493287086487, Validation Accuracy: 0.8935\n",
      "Epoch: 89, Loss: 0.33402007818222046, Validation Accuracy: 0.8936666666666667\n",
      "Epoch: 90, Loss: 0.33251404762268066, Validation Accuracy: 0.8945\n",
      "Epoch: 91, Loss: 0.33106887340545654, Validation Accuracy: 0.8944166666666666\n",
      "Epoch: 92, Loss: 0.32963046431541443, Validation Accuracy: 0.8951666666666667\n",
      "Epoch: 93, Loss: 0.3282407522201538, Validation Accuracy: 0.89575\n",
      "Epoch: 94, Loss: 0.32685044407844543, Validation Accuracy: 0.8963333333333333\n",
      "Epoch: 95, Loss: 0.3255029022693634, Validation Accuracy: 0.8963333333333333\n",
      "Epoch: 96, Loss: 0.3241572380065918, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 97, Loss: 0.32284021377563477, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 98, Loss: 0.3215273320674896, Validation Accuracy: 0.8979166666666667\n",
      "Epoch: 99, Loss: 0.3202451467514038, Validation Accuracy: 0.8980833333333333\n",
      "Dataset 64\n",
      "Epoch: 0, Loss: 3.6857569217681885, Validation Accuracy: 0.16041666666666668\n",
      "Epoch: 1, Loss: 3.153562545776367, Validation Accuracy: 0.1935\n",
      "Epoch: 2, Loss: 2.896406650543213, Validation Accuracy: 0.2911666666666667\n",
      "Epoch: 3, Loss: 2.0098791122436523, Validation Accuracy: 0.34125\n",
      "Epoch: 4, Loss: 1.8510758876800537, Validation Accuracy: 0.38466666666666666\n",
      "Epoch: 5, Loss: 1.75407874584198, Validation Accuracy: 0.41241666666666665\n",
      "Epoch: 6, Loss: 1.6815260648727417, Validation Accuracy: 0.44325\n",
      "Epoch: 7, Loss: 1.6219537258148193, Validation Accuracy: 0.4518333333333333\n",
      "Epoch: 8, Loss: 1.5750205516815186, Validation Accuracy: 0.47141666666666665\n",
      "Epoch: 9, Loss: 1.551737666130066, Validation Accuracy: 0.47825\n",
      "Epoch: 10, Loss: 1.5032765865325928, Validation Accuracy: 0.47633333333333333\n",
      "Epoch: 11, Loss: 1.5061341524124146, Validation Accuracy: 0.5198333333333334\n",
      "Epoch: 12, Loss: 1.3900296688079834, Validation Accuracy: 0.5324166666666666\n",
      "Epoch: 13, Loss: 1.3424930572509766, Validation Accuracy: 0.5548333333333333\n",
      "Epoch: 14, Loss: 1.272729754447937, Validation Accuracy: 0.5698333333333333\n",
      "Epoch: 15, Loss: 1.2285770177841187, Validation Accuracy: 0.5845\n",
      "Epoch: 16, Loss: 1.1781686544418335, Validation Accuracy: 0.60175\n",
      "Epoch: 17, Loss: 1.137196660041809, Validation Accuracy: 0.6185\n",
      "Epoch: 18, Loss: 1.092607855796814, Validation Accuracy: 0.6393333333333333\n",
      "Epoch: 19, Loss: 1.0541648864746094, Validation Accuracy: 0.6505\n",
      "Epoch: 20, Loss: 1.0122548341751099, Validation Accuracy: 0.675\n",
      "Epoch: 21, Loss: 0.9774839878082275, Validation Accuracy: 0.67625\n",
      "Epoch: 22, Loss: 0.9392442107200623, Validation Accuracy: 0.70075\n",
      "Epoch: 23, Loss: 0.9103714227676392, Validation Accuracy: 0.6975\n",
      "Epoch: 24, Loss: 0.8776267766952515, Validation Accuracy: 0.7195\n",
      "Epoch: 25, Loss: 0.8563140630722046, Validation Accuracy: 0.7131666666666666\n",
      "Epoch: 26, Loss: 0.8285324573516846, Validation Accuracy: 0.73175\n",
      "Epoch: 27, Loss: 0.8111472129821777, Validation Accuracy: 0.7276666666666667\n",
      "Epoch: 28, Loss: 0.7829698324203491, Validation Accuracy: 0.7446666666666667\n",
      "Epoch: 29, Loss: 0.7619999051094055, Validation Accuracy: 0.7500833333333333\n",
      "Epoch: 30, Loss: 0.7295089364051819, Validation Accuracy: 0.7640833333333333\n",
      "Epoch: 31, Loss: 0.701042652130127, Validation Accuracy: 0.7715833333333333\n",
      "Epoch: 32, Loss: 0.6704165935516357, Validation Accuracy: 0.7829166666666667\n",
      "Epoch: 33, Loss: 0.644875705242157, Validation Accuracy: 0.7926666666666666\n",
      "Epoch: 34, Loss: 0.6224851012229919, Validation Accuracy: 0.797\n",
      "Epoch: 35, Loss: 0.604573667049408, Validation Accuracy: 0.8038333333333333\n",
      "Epoch: 36, Loss: 0.5889310836791992, Validation Accuracy: 0.8066666666666666\n",
      "Epoch: 37, Loss: 0.5757190585136414, Validation Accuracy: 0.813\n",
      "Epoch: 38, Loss: 0.5635713934898376, Validation Accuracy: 0.815\n",
      "Epoch: 39, Loss: 0.5528945922851562, Validation Accuracy: 0.8210833333333334\n",
      "Epoch: 40, Loss: 0.5427226424217224, Validation Accuracy: 0.82275\n",
      "Epoch: 41, Loss: 0.5336309671401978, Validation Accuracy: 0.8264166666666667\n",
      "Epoch: 42, Loss: 0.5250654816627502, Validation Accuracy: 0.8290833333333333\n",
      "Epoch: 43, Loss: 0.5174408555030823, Validation Accuracy: 0.831\n",
      "Epoch: 44, Loss: 0.5104181170463562, Validation Accuracy: 0.8340833333333333\n",
      "Epoch: 45, Loss: 0.5045010447502136, Validation Accuracy: 0.8345833333333333\n",
      "Epoch: 46, Loss: 0.4991125166416168, Validation Accuracy: 0.83925\n",
      "Epoch: 47, Loss: 0.49522334337234497, Validation Accuracy: 0.8355\n",
      "Epoch: 48, Loss: 0.4924652576446533, Validation Accuracy: 0.8383333333333334\n",
      "Epoch: 49, Loss: 0.49162667989730835, Validation Accuracy: 0.8350833333333333\n",
      "Epoch: 50, Loss: 0.4916086792945862, Validation Accuracy: 0.8365\n",
      "Epoch: 51, Loss: 0.49471256136894226, Validation Accuracy: 0.8298333333333333\n",
      "Epoch: 52, Loss: 0.498162180185318, Validation Accuracy: 0.8288333333333333\n",
      "Epoch: 53, Loss: 0.5058915019035339, Validation Accuracy: 0.8258333333333333\n",
      "Epoch: 54, Loss: 0.5082522034645081, Validation Accuracy: 0.8253333333333334\n",
      "Epoch: 55, Loss: 0.514340341091156, Validation Accuracy: 0.82575\n",
      "Epoch: 56, Loss: 0.5072150826454163, Validation Accuracy: 0.8294166666666667\n",
      "Epoch: 57, Loss: 0.5029600262641907, Validation Accuracy: 0.8348333333333333\n",
      "Epoch: 58, Loss: 0.48354658484458923, Validation Accuracy: 0.844\n",
      "Epoch: 59, Loss: 0.4704141318798065, Validation Accuracy: 0.8481666666666666\n",
      "Epoch: 60, Loss: 0.4513518810272217, Validation Accuracy: 0.8560833333333333\n",
      "Epoch: 61, Loss: 0.43910038471221924, Validation Accuracy: 0.8596666666666667\n",
      "Epoch: 62, Loss: 0.4271634817123413, Validation Accuracy: 0.8659166666666667\n",
      "Epoch: 63, Loss: 0.4187369644641876, Validation Accuracy: 0.8659166666666667\n",
      "Epoch: 64, Loss: 0.4116035997867584, Validation Accuracy: 0.8696666666666667\n",
      "Epoch: 65, Loss: 0.4059749245643616, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 66, Loss: 0.4010629951953888, Validation Accuracy: 0.87275\n",
      "Epoch: 67, Loss: 0.3967847228050232, Validation Accuracy: 0.87275\n",
      "Epoch: 68, Loss: 0.3928793668746948, Validation Accuracy: 0.8753333333333333\n",
      "Epoch: 69, Loss: 0.3893645405769348, Validation Accuracy: 0.875\n",
      "Epoch: 70, Loss: 0.3860415816307068, Validation Accuracy: 0.8776666666666667\n",
      "Epoch: 71, Loss: 0.38293465971946716, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 72, Loss: 0.3799397051334381, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 73, Loss: 0.37714025378227234, Validation Accuracy: 0.87975\n",
      "Epoch: 74, Loss: 0.37437742948532104, Validation Accuracy: 0.8810833333333333\n",
      "Epoch: 75, Loss: 0.3717775046825409, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 76, Loss: 0.3692198097705841, Validation Accuracy: 0.8825\n",
      "Epoch: 77, Loss: 0.36678189039230347, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 78, Loss: 0.36435216665267944, Validation Accuracy: 0.8843333333333333\n",
      "Epoch: 79, Loss: 0.36205485463142395, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 80, Loss: 0.35976725816726685, Validation Accuracy: 0.886\n",
      "Epoch: 81, Loss: 0.35755953192710876, Validation Accuracy: 0.88525\n",
      "Epoch: 82, Loss: 0.3554084002971649, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 83, Loss: 0.35330286622047424, Validation Accuracy: 0.8865\n",
      "Epoch: 84, Loss: 0.3512820899486542, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 85, Loss: 0.34927546977996826, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 86, Loss: 0.34734150767326355, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 87, Loss: 0.34541991353034973, Validation Accuracy: 0.88925\n",
      "Epoch: 88, Loss: 0.34355098009109497, Validation Accuracy: 0.8905\n",
      "Epoch: 89, Loss: 0.3417087495326996, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 90, Loss: 0.3399171829223633, Validation Accuracy: 0.8915\n",
      "Epoch: 91, Loss: 0.33818286657333374, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 92, Loss: 0.33647963404655457, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 93, Loss: 0.33482837677001953, Validation Accuracy: 0.8929166666666667\n",
      "Epoch: 94, Loss: 0.33318978548049927, Validation Accuracy: 0.8935\n",
      "Epoch: 95, Loss: 0.33159756660461426, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 96, Loss: 0.33002108335494995, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 97, Loss: 0.3285129964351654, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 98, Loss: 0.32698094844818115, Validation Accuracy: 0.8961666666666667\n",
      "Epoch: 99, Loss: 0.32553815841674805, Validation Accuracy: 0.8948333333333334\n",
      "Dataset 65\n",
      "Epoch: 0, Loss: 3.0713765621185303, Validation Accuracy: 0.16833333333333333\n",
      "Epoch: 1, Loss: 2.439533233642578, Validation Accuracy: 0.19508333333333333\n",
      "Epoch: 2, Loss: 2.8193562030792236, Validation Accuracy: 0.24425\n",
      "Epoch: 3, Loss: 2.1095449924468994, Validation Accuracy: 0.31925\n",
      "Epoch: 4, Loss: 1.940865397453308, Validation Accuracy: 0.3565833333333333\n",
      "Epoch: 5, Loss: 1.7918754816055298, Validation Accuracy: 0.5008333333333334\n",
      "Epoch: 6, Loss: 1.4894293546676636, Validation Accuracy: 0.5433333333333333\n",
      "Epoch: 7, Loss: 1.349674940109253, Validation Accuracy: 0.58425\n",
      "Epoch: 8, Loss: 1.23555588722229, Validation Accuracy: 0.60925\n",
      "Epoch: 9, Loss: 1.156099557876587, Validation Accuracy: 0.6211666666666666\n",
      "Epoch: 10, Loss: 1.102304458618164, Validation Accuracy: 0.62325\n",
      "Epoch: 11, Loss: 1.1051334142684937, Validation Accuracy: 0.5611666666666667\n",
      "Epoch: 12, Loss: 1.1970003843307495, Validation Accuracy: 0.57125\n",
      "Epoch: 13, Loss: 1.2002671957015991, Validation Accuracy: 0.5725833333333333\n",
      "Epoch: 14, Loss: 1.1794990301132202, Validation Accuracy: 0.7105833333333333\n",
      "Epoch: 15, Loss: 0.8832842707633972, Validation Accuracy: 0.7469166666666667\n",
      "Epoch: 16, Loss: 0.8011457324028015, Validation Accuracy: 0.7606666666666667\n",
      "Epoch: 17, Loss: 0.7540566325187683, Validation Accuracy: 0.7715\n",
      "Epoch: 18, Loss: 0.7186093926429749, Validation Accuracy: 0.77925\n",
      "Epoch: 19, Loss: 0.6897339820861816, Validation Accuracy: 0.79125\n",
      "Epoch: 20, Loss: 0.664708137512207, Validation Accuracy: 0.7918333333333333\n",
      "Epoch: 21, Loss: 0.6467291116714478, Validation Accuracy: 0.7995\n",
      "Epoch: 22, Loss: 0.6311227679252625, Validation Accuracy: 0.7929166666666667\n",
      "Epoch: 23, Loss: 0.6304055452346802, Validation Accuracy: 0.7915833333333333\n",
      "Epoch: 24, Loss: 0.6347482800483704, Validation Accuracy: 0.7756666666666666\n",
      "Epoch: 25, Loss: 0.6659004092216492, Validation Accuracy: 0.7621666666666667\n",
      "Epoch: 26, Loss: 0.7018276453018188, Validation Accuracy: 0.759\n",
      "Epoch: 27, Loss: 0.6973754167556763, Validation Accuracy: 0.7686666666666667\n",
      "Epoch: 28, Loss: 0.6801877021789551, Validation Accuracy: 0.7955\n",
      "Epoch: 29, Loss: 0.5986471176147461, Validation Accuracy: 0.8185\n",
      "Epoch: 30, Loss: 0.5571585893630981, Validation Accuracy: 0.83125\n",
      "Epoch: 31, Loss: 0.5245171189308167, Validation Accuracy: 0.83725\n",
      "Epoch: 32, Loss: 0.505487322807312, Validation Accuracy: 0.8444166666666667\n",
      "Epoch: 33, Loss: 0.4924289584159851, Validation Accuracy: 0.8455\n",
      "Epoch: 34, Loss: 0.48244625329971313, Validation Accuracy: 0.85025\n",
      "Epoch: 35, Loss: 0.4743088483810425, Validation Accuracy: 0.849\n",
      "Epoch: 36, Loss: 0.46735095977783203, Validation Accuracy: 0.8540833333333333\n",
      "Epoch: 37, Loss: 0.46086129546165466, Validation Accuracy: 0.8521666666666666\n",
      "Epoch: 38, Loss: 0.4552402198314667, Validation Accuracy: 0.8575833333333334\n",
      "Epoch: 39, Loss: 0.4495845437049866, Validation Accuracy: 0.8553333333333333\n",
      "Epoch: 40, Loss: 0.44476115703582764, Validation Accuracy: 0.8603333333333333\n",
      "Epoch: 41, Loss: 0.43979841470718384, Validation Accuracy: 0.85775\n",
      "Epoch: 42, Loss: 0.4354398250579834, Validation Accuracy: 0.862\n",
      "Epoch: 43, Loss: 0.4309099018573761, Validation Accuracy: 0.8608333333333333\n",
      "Epoch: 44, Loss: 0.4269814193248749, Validation Accuracy: 0.8648333333333333\n",
      "Epoch: 45, Loss: 0.4227065145969391, Validation Accuracy: 0.8624166666666667\n",
      "Epoch: 46, Loss: 0.4190237522125244, Validation Accuracy: 0.8673333333333333\n",
      "Epoch: 47, Loss: 0.41489478945732117, Validation Accuracy: 0.8645833333333334\n",
      "Epoch: 48, Loss: 0.4113874137401581, Validation Accuracy: 0.8696666666666667\n",
      "Epoch: 49, Loss: 0.40746650099754333, Validation Accuracy: 0.8663333333333333\n",
      "Epoch: 50, Loss: 0.40415453910827637, Validation Accuracy: 0.87125\n",
      "Epoch: 51, Loss: 0.40026456117630005, Validation Accuracy: 0.86875\n",
      "Epoch: 52, Loss: 0.3970108926296234, Validation Accuracy: 0.873\n",
      "Epoch: 53, Loss: 0.3931087553501129, Validation Accuracy: 0.8713333333333333\n",
      "Epoch: 54, Loss: 0.3899781107902527, Validation Accuracy: 0.87475\n",
      "Epoch: 55, Loss: 0.3861904442310333, Validation Accuracy: 0.8735833333333334\n",
      "Epoch: 56, Loss: 0.3830898106098175, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 57, Loss: 0.3794330656528473, Validation Accuracy: 0.8755\n",
      "Epoch: 58, Loss: 0.37642139196395874, Validation Accuracy: 0.8795833333333334\n",
      "Epoch: 59, Loss: 0.37305834889411926, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 60, Loss: 0.3702789843082428, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 61, Loss: 0.3671939969062805, Validation Accuracy: 0.87975\n",
      "Epoch: 62, Loss: 0.3645329177379608, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 63, Loss: 0.3617488145828247, Validation Accuracy: 0.88075\n",
      "Epoch: 64, Loss: 0.35930681228637695, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 65, Loss: 0.35673433542251587, Validation Accuracy: 0.8824166666666666\n",
      "Epoch: 66, Loss: 0.3543865978717804, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 67, Loss: 0.35200703144073486, Validation Accuracy: 0.88425\n",
      "Epoch: 68, Loss: 0.3497675359249115, Validation Accuracy: 0.8868333333333334\n",
      "Epoch: 69, Loss: 0.34751710295677185, Validation Accuracy: 0.88575\n",
      "Epoch: 70, Loss: 0.3453933596611023, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 71, Loss: 0.34329208731651306, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 72, Loss: 0.3413124978542328, Validation Accuracy: 0.8886666666666667\n",
      "Epoch: 73, Loss: 0.3393227159976959, Validation Accuracy: 0.8886666666666667\n",
      "Epoch: 74, Loss: 0.3374330699443817, Validation Accuracy: 0.89025\n",
      "Epoch: 75, Loss: 0.3355291187763214, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 76, Loss: 0.3337164521217346, Validation Accuracy: 0.8913333333333333\n",
      "Epoch: 77, Loss: 0.33190402388572693, Validation Accuracy: 0.8914166666666666\n",
      "Epoch: 78, Loss: 0.3301353454589844, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 79, Loss: 0.3283841609954834, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 80, Loss: 0.3266960084438324, Validation Accuracy: 0.8935833333333333\n",
      "Epoch: 81, Loss: 0.325018048286438, Validation Accuracy: 0.8936666666666667\n",
      "Epoch: 82, Loss: 0.32339656352996826, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 83, Loss: 0.32180511951446533, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 84, Loss: 0.32024186849594116, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 85, Loss: 0.3187197744846344, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 86, Loss: 0.3172178864479065, Validation Accuracy: 0.8965\n",
      "Epoch: 87, Loss: 0.31574881076812744, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 88, Loss: 0.31430768966674805, Validation Accuracy: 0.89725\n",
      "Epoch: 89, Loss: 0.31289252638816833, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 90, Loss: 0.31150248646736145, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 91, Loss: 0.31013223528862, Validation Accuracy: 0.8986666666666666\n",
      "Epoch: 92, Loss: 0.30878719687461853, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 93, Loss: 0.30746325850486755, Validation Accuracy: 0.89975\n",
      "Epoch: 94, Loss: 0.30615949630737305, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 95, Loss: 0.3048712909221649, Validation Accuracy: 0.90025\n",
      "Epoch: 96, Loss: 0.303600549697876, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 97, Loss: 0.3023509383201599, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 98, Loss: 0.30111998319625854, Validation Accuracy: 0.9015\n",
      "Epoch: 99, Loss: 0.2999071478843689, Validation Accuracy: 0.90225\n",
      "Dataset 66\n",
      "Epoch: 0, Loss: 3.5414373874664307, Validation Accuracy: 0.14533333333333334\n",
      "Epoch: 1, Loss: 3.043104410171509, Validation Accuracy: 0.2613333333333333\n",
      "Epoch: 2, Loss: 2.3725993633270264, Validation Accuracy: 0.2813333333333333\n",
      "Epoch: 3, Loss: 2.2991368770599365, Validation Accuracy: 0.31716666666666665\n",
      "Epoch: 4, Loss: 1.9824330806732178, Validation Accuracy: 0.41783333333333333\n",
      "Epoch: 5, Loss: 1.679373860359192, Validation Accuracy: 0.47975\n",
      "Epoch: 6, Loss: 1.5540450811386108, Validation Accuracy: 0.5158333333333334\n",
      "Epoch: 7, Loss: 1.4517511129379272, Validation Accuracy: 0.5429166666666667\n",
      "Epoch: 8, Loss: 1.3639302253723145, Validation Accuracy: 0.56725\n",
      "Epoch: 9, Loss: 1.2876285314559937, Validation Accuracy: 0.587\n",
      "Epoch: 10, Loss: 1.219990611076355, Validation Accuracy: 0.60475\n",
      "Epoch: 11, Loss: 1.1588644981384277, Validation Accuracy: 0.6245833333333334\n",
      "Epoch: 12, Loss: 1.102439522743225, Validation Accuracy: 0.6416666666666667\n",
      "Epoch: 13, Loss: 1.0490405559539795, Validation Accuracy: 0.6615833333333333\n",
      "Epoch: 14, Loss: 0.9982108473777771, Validation Accuracy: 0.6795833333333333\n",
      "Epoch: 15, Loss: 0.9517301321029663, Validation Accuracy: 0.6916666666666667\n",
      "Epoch: 16, Loss: 0.9143996834754944, Validation Accuracy: 0.6975833333333333\n",
      "Epoch: 17, Loss: 0.8984740376472473, Validation Accuracy: 0.6701666666666667\n",
      "Epoch: 18, Loss: 0.9366052150726318, Validation Accuracy: 0.6434166666666666\n",
      "Epoch: 19, Loss: 0.9966034293174744, Validation Accuracy: 0.5809166666666666\n",
      "Epoch: 20, Loss: 1.1778243780136108, Validation Accuracy: 0.6831666666666667\n",
      "Epoch: 21, Loss: 0.9006931781768799, Validation Accuracy: 0.7231666666666666\n",
      "Epoch: 22, Loss: 0.8166465759277344, Validation Accuracy: 0.754\n",
      "Epoch: 23, Loss: 0.7330510020256042, Validation Accuracy: 0.7628333333333334\n",
      "Epoch: 24, Loss: 0.7043964266777039, Validation Accuracy: 0.7753333333333333\n",
      "Epoch: 25, Loss: 0.6703407168388367, Validation Accuracy: 0.7795\n",
      "Epoch: 26, Loss: 0.6518810987472534, Validation Accuracy: 0.7870833333333334\n",
      "Epoch: 27, Loss: 0.6299261450767517, Validation Accuracy: 0.7923333333333333\n",
      "Epoch: 28, Loss: 0.6162101030349731, Validation Accuracy: 0.7963333333333333\n",
      "Epoch: 29, Loss: 0.6001424789428711, Validation Accuracy: 0.8010833333333334\n",
      "Epoch: 30, Loss: 0.589792788028717, Validation Accuracy: 0.805\n",
      "Epoch: 31, Loss: 0.5771924257278442, Validation Accuracy: 0.8083333333333333\n",
      "Epoch: 32, Loss: 0.5698739290237427, Validation Accuracy: 0.81275\n",
      "Epoch: 33, Loss: 0.5606352686882019, Validation Accuracy: 0.81025\n",
      "Epoch: 34, Loss: 0.5564746856689453, Validation Accuracy: 0.8158333333333333\n",
      "Epoch: 35, Loss: 0.5511307120323181, Validation Accuracy: 0.81025\n",
      "Epoch: 36, Loss: 0.5513913631439209, Validation Accuracy: 0.8161666666666667\n",
      "Epoch: 37, Loss: 0.5509034395217896, Validation Accuracy: 0.8064166666666667\n",
      "Epoch: 38, Loss: 0.5585080981254578, Validation Accuracy: 0.8110833333333334\n",
      "Epoch: 39, Loss: 0.5599219799041748, Validation Accuracy: 0.8005\n",
      "Epoch: 40, Loss: 0.5694230794906616, Validation Accuracy: 0.8123333333333334\n",
      "Epoch: 41, Loss: 0.5583469271659851, Validation Accuracy: 0.8065833333333333\n",
      "Epoch: 42, Loss: 0.5545772314071655, Validation Accuracy: 0.8254166666666667\n",
      "Epoch: 43, Loss: 0.5256752371788025, Validation Accuracy: 0.8254166666666667\n",
      "Epoch: 44, Loss: 0.5086689591407776, Validation Accuracy: 0.84125\n",
      "Epoch: 45, Loss: 0.4836074113845825, Validation Accuracy: 0.84075\n",
      "Epoch: 46, Loss: 0.47008806467056274, Validation Accuracy: 0.8526666666666667\n",
      "Epoch: 47, Loss: 0.45654821395874023, Validation Accuracy: 0.8508333333333333\n",
      "Epoch: 48, Loss: 0.4478653073310852, Validation Accuracy: 0.8575\n",
      "Epoch: 49, Loss: 0.4399785101413727, Validation Accuracy: 0.8563333333333333\n",
      "Epoch: 50, Loss: 0.43397220969200134, Validation Accuracy: 0.8598333333333333\n",
      "Epoch: 51, Loss: 0.428428053855896, Validation Accuracy: 0.8604166666666667\n",
      "Epoch: 52, Loss: 0.423679918050766, Validation Accuracy: 0.8625833333333334\n",
      "Epoch: 53, Loss: 0.41912809014320374, Validation Accuracy: 0.8639166666666667\n",
      "Epoch: 54, Loss: 0.41503235697746277, Validation Accuracy: 0.8655\n",
      "Epoch: 55, Loss: 0.41108012199401855, Validation Accuracy: 0.8668333333333333\n",
      "Epoch: 56, Loss: 0.4074036180973053, Validation Accuracy: 0.8683333333333333\n",
      "Epoch: 57, Loss: 0.4037947654724121, Validation Accuracy: 0.8686666666666667\n",
      "Epoch: 58, Loss: 0.4004555344581604, Validation Accuracy: 0.8704166666666666\n",
      "Epoch: 59, Loss: 0.3971291780471802, Validation Accuracy: 0.8716666666666667\n",
      "Epoch: 60, Loss: 0.39401349425315857, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 61, Loss: 0.39093640446662903, Validation Accuracy: 0.8744166666666666\n",
      "Epoch: 62, Loss: 0.3880237936973572, Validation Accuracy: 0.8750833333333333\n",
      "Epoch: 63, Loss: 0.3851516544818878, Validation Accuracy: 0.8755833333333334\n",
      "Epoch: 64, Loss: 0.38246965408325195, Validation Accuracy: 0.8769166666666667\n",
      "Epoch: 65, Loss: 0.379782497882843, Validation Accuracy: 0.877\n",
      "Epoch: 66, Loss: 0.3772795498371124, Validation Accuracy: 0.8786666666666667\n",
      "Epoch: 67, Loss: 0.3748103976249695, Validation Accuracy: 0.8781666666666667\n",
      "Epoch: 68, Loss: 0.37249189615249634, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 69, Loss: 0.37024012207984924, Validation Accuracy: 0.87975\n",
      "Epoch: 70, Loss: 0.3681214451789856, Validation Accuracy: 0.8818333333333334\n",
      "Epoch: 71, Loss: 0.3660472333431244, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 72, Loss: 0.36407411098480225, Validation Accuracy: 0.8829166666666667\n",
      "Epoch: 73, Loss: 0.3621615767478943, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 74, Loss: 0.36040714383125305, Validation Accuracy: 0.88375\n",
      "Epoch: 75, Loss: 0.3587101995944977, Validation Accuracy: 0.8825833333333334\n",
      "Epoch: 76, Loss: 0.3572198450565338, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 77, Loss: 0.35572466254234314, Validation Accuracy: 0.8831666666666667\n",
      "Epoch: 78, Loss: 0.3544582426548004, Validation Accuracy: 0.88475\n",
      "Epoch: 79, Loss: 0.3532688319683075, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 80, Loss: 0.3523223102092743, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 81, Loss: 0.35135069489479065, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 82, Loss: 0.3505955934524536, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 83, Loss: 0.3496551811695099, Validation Accuracy: 0.8845833333333334\n",
      "Epoch: 84, Loss: 0.3490853011608124, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 85, Loss: 0.3480709493160248, Validation Accuracy: 0.8851666666666667\n",
      "Epoch: 86, Loss: 0.3473469913005829, Validation Accuracy: 0.8866666666666667\n",
      "Epoch: 87, Loss: 0.3461657762527466, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 88, Loss: 0.34520915150642395, Validation Accuracy: 0.8875\n",
      "Epoch: 89, Loss: 0.34368839859962463, Validation Accuracy: 0.88675\n",
      "Epoch: 90, Loss: 0.342325896024704, Validation Accuracy: 0.8885\n",
      "Epoch: 91, Loss: 0.3402993083000183, Validation Accuracy: 0.8885833333333333\n",
      "Epoch: 92, Loss: 0.3385593295097351, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 93, Loss: 0.33624738454818726, Validation Accuracy: 0.89\n",
      "Epoch: 94, Loss: 0.33407333493232727, Validation Accuracy: 0.892\n",
      "Epoch: 95, Loss: 0.3314821124076843, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 96, Loss: 0.329183965921402, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 97, Loss: 0.3265639543533325, Validation Accuracy: 0.8936666666666667\n",
      "Epoch: 98, Loss: 0.3242301344871521, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 99, Loss: 0.321856826543808, Validation Accuracy: 0.8949166666666667\n",
      "Dataset 67\n",
      "Epoch: 0, Loss: 3.9904561042785645, Validation Accuracy: 0.14991666666666667\n",
      "Epoch: 1, Loss: 4.149325370788574, Validation Accuracy: 0.16883333333333334\n",
      "Epoch: 2, Loss: 4.188869476318359, Validation Accuracy: 0.15208333333333332\n",
      "Epoch: 3, Loss: 2.664156198501587, Validation Accuracy: 0.13858333333333334\n",
      "Epoch: 4, Loss: 2.319479465484619, Validation Accuracy: 0.2579166666666667\n",
      "Epoch: 5, Loss: 2.068118095397949, Validation Accuracy: 0.36825\n",
      "Epoch: 6, Loss: 1.9116287231445312, Validation Accuracy: 0.4206666666666667\n",
      "Epoch: 7, Loss: 1.7589573860168457, Validation Accuracy: 0.45066666666666666\n",
      "Epoch: 8, Loss: 1.632382869720459, Validation Accuracy: 0.47558333333333336\n",
      "Epoch: 9, Loss: 1.5351086854934692, Validation Accuracy: 0.49366666666666664\n",
      "Epoch: 10, Loss: 1.4530843496322632, Validation Accuracy: 0.5126666666666667\n",
      "Epoch: 11, Loss: 1.3813673257827759, Validation Accuracy: 0.5309166666666667\n",
      "Epoch: 12, Loss: 1.3166518211364746, Validation Accuracy: 0.55025\n",
      "Epoch: 13, Loss: 1.256851077079773, Validation Accuracy: 0.5671666666666667\n",
      "Epoch: 14, Loss: 1.2009098529815674, Validation Accuracy: 0.5885\n",
      "Epoch: 15, Loss: 1.1481705904006958, Validation Accuracy: 0.6063333333333333\n",
      "Epoch: 16, Loss: 1.0987663269042969, Validation Accuracy: 0.639\n",
      "Epoch: 17, Loss: 1.0541623830795288, Validation Accuracy: 0.6574166666666666\n",
      "Epoch: 18, Loss: 1.018847942352295, Validation Accuracy: 0.6785833333333333\n",
      "Epoch: 19, Loss: 1.0071684122085571, Validation Accuracy: 0.6535\n",
      "Epoch: 20, Loss: 1.0447014570236206, Validation Accuracy: 0.6005833333333334\n",
      "Epoch: 21, Loss: 1.1978729963302612, Validation Accuracy: 0.565\n",
      "Epoch: 22, Loss: 1.306579351425171, Validation Accuracy: 0.6029166666666667\n",
      "Epoch: 23, Loss: 1.181347370147705, Validation Accuracy: 0.7144166666666667\n",
      "Epoch: 24, Loss: 0.9115247130393982, Validation Accuracy: 0.7340833333333333\n",
      "Epoch: 25, Loss: 0.8292278051376343, Validation Accuracy: 0.7544166666666666\n",
      "Epoch: 26, Loss: 0.7874477505683899, Validation Accuracy: 0.7549166666666667\n",
      "Epoch: 27, Loss: 0.7645431160926819, Validation Accuracy: 0.7636666666666667\n",
      "Epoch: 28, Loss: 0.7467092871665955, Validation Accuracy: 0.7681666666666667\n",
      "Epoch: 29, Loss: 0.7236595153808594, Validation Accuracy: 0.7724166666666666\n",
      "Epoch: 30, Loss: 0.7130143046379089, Validation Accuracy: 0.78175\n",
      "Epoch: 31, Loss: 0.6894975304603577, Validation Accuracy: 0.7814166666666666\n",
      "Epoch: 32, Loss: 0.6807171106338501, Validation Accuracy: 0.79475\n",
      "Epoch: 33, Loss: 0.6579173803329468, Validation Accuracy: 0.7920833333333334\n",
      "Epoch: 34, Loss: 0.6505789160728455, Validation Accuracy: 0.80375\n",
      "Epoch: 35, Loss: 0.6297677159309387, Validation Accuracy: 0.8025\n",
      "Epoch: 36, Loss: 0.622559666633606, Validation Accuracy: 0.8140833333333334\n",
      "Epoch: 37, Loss: 0.6043722629547119, Validation Accuracy: 0.81075\n",
      "Epoch: 38, Loss: 0.5972971320152283, Validation Accuracy: 0.8224166666666667\n",
      "Epoch: 39, Loss: 0.5813596844673157, Validation Accuracy: 0.81925\n",
      "Epoch: 40, Loss: 0.5744969844818115, Validation Accuracy: 0.82925\n",
      "Epoch: 41, Loss: 0.5605251789093018, Validation Accuracy: 0.8255\n",
      "Epoch: 42, Loss: 0.5538497567176819, Validation Accuracy: 0.8349166666666666\n",
      "Epoch: 43, Loss: 0.5416183471679688, Validation Accuracy: 0.8319166666666666\n",
      "Epoch: 44, Loss: 0.5354112386703491, Validation Accuracy: 0.8405833333333333\n",
      "Epoch: 45, Loss: 0.5248439908027649, Validation Accuracy: 0.83975\n",
      "Epoch: 46, Loss: 0.5188040137290955, Validation Accuracy: 0.8448333333333333\n",
      "Epoch: 47, Loss: 0.5099988579750061, Validation Accuracy: 0.84475\n",
      "Epoch: 48, Loss: 0.5044217705726624, Validation Accuracy: 0.8479166666666667\n",
      "Epoch: 49, Loss: 0.49655982851982117, Validation Accuracy: 0.8483333333333334\n",
      "Epoch: 50, Loss: 0.4914621114730835, Validation Accuracy: 0.8515\n",
      "Epoch: 51, Loss: 0.4846035838127136, Validation Accuracy: 0.8516666666666667\n",
      "Epoch: 52, Loss: 0.4797021746635437, Validation Accuracy: 0.8553333333333333\n",
      "Epoch: 53, Loss: 0.4736054539680481, Validation Accuracy: 0.85525\n",
      "Epoch: 54, Loss: 0.46900784969329834, Validation Accuracy: 0.8586666666666667\n",
      "Epoch: 55, Loss: 0.4633943736553192, Validation Accuracy: 0.85775\n",
      "Epoch: 56, Loss: 0.45897090435028076, Validation Accuracy: 0.8613333333333333\n",
      "Epoch: 57, Loss: 0.453673392534256, Validation Accuracy: 0.8599166666666667\n",
      "Epoch: 58, Loss: 0.4493926167488098, Validation Accuracy: 0.8641666666666666\n",
      "Epoch: 59, Loss: 0.444490522146225, Validation Accuracy: 0.863\n",
      "Epoch: 60, Loss: 0.4403468370437622, Validation Accuracy: 0.8665833333333334\n",
      "Epoch: 61, Loss: 0.43576258420944214, Validation Accuracy: 0.8650833333333333\n",
      "Epoch: 62, Loss: 0.43183085322380066, Validation Accuracy: 0.8690833333333333\n",
      "Epoch: 63, Loss: 0.4275762140750885, Validation Accuracy: 0.8679166666666667\n",
      "Epoch: 64, Loss: 0.42396458983421326, Validation Accuracy: 0.8713333333333333\n",
      "Epoch: 65, Loss: 0.4200821816921234, Validation Accuracy: 0.8700833333333333\n",
      "Epoch: 66, Loss: 0.4166713356971741, Validation Accuracy: 0.8729166666666667\n",
      "Epoch: 67, Loss: 0.41303637623786926, Validation Accuracy: 0.8724166666666666\n",
      "Epoch: 68, Loss: 0.4097733497619629, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 69, Loss: 0.40641504526138306, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 70, Loss: 0.4033365845680237, Validation Accuracy: 0.8765833333333334\n",
      "Epoch: 71, Loss: 0.4002331495285034, Validation Accuracy: 0.8765\n",
      "Epoch: 72, Loss: 0.3973555862903595, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 73, Loss: 0.39447686076164246, Validation Accuracy: 0.8781666666666667\n",
      "Epoch: 74, Loss: 0.3917175233364105, Validation Accuracy: 0.88025\n",
      "Epoch: 75, Loss: 0.3890460133552551, Validation Accuracy: 0.87975\n",
      "Epoch: 76, Loss: 0.3864230811595917, Validation Accuracy: 0.8814166666666666\n",
      "Epoch: 77, Loss: 0.38386958837509155, Validation Accuracy: 0.8810833333333333\n",
      "Epoch: 78, Loss: 0.3814263641834259, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 79, Loss: 0.37905973196029663, Validation Accuracy: 0.88275\n",
      "Epoch: 80, Loss: 0.37675267457962036, Validation Accuracy: 0.88425\n",
      "Epoch: 81, Loss: 0.3745556175708771, Validation Accuracy: 0.8833333333333333\n",
      "Epoch: 82, Loss: 0.37241142988204956, Validation Accuracy: 0.88575\n",
      "Epoch: 83, Loss: 0.3703250586986542, Validation Accuracy: 0.88375\n",
      "Epoch: 84, Loss: 0.368285596370697, Validation Accuracy: 0.887\n",
      "Epoch: 85, Loss: 0.366313636302948, Validation Accuracy: 0.8849166666666667\n",
      "Epoch: 86, Loss: 0.3643795847892761, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 87, Loss: 0.3625037968158722, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 88, Loss: 0.36062443256378174, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 89, Loss: 0.35879528522491455, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 90, Loss: 0.35700199007987976, Validation Accuracy: 0.89025\n",
      "Epoch: 91, Loss: 0.35525479912757874, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 92, Loss: 0.3535328507423401, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 93, Loss: 0.3518444299697876, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 94, Loss: 0.35018929839134216, Validation Accuracy: 0.8925\n",
      "Epoch: 95, Loss: 0.3485649824142456, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 96, Loss: 0.3469216227531433, Validation Accuracy: 0.894\n",
      "Epoch: 97, Loss: 0.345345675945282, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 98, Loss: 0.34376704692840576, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 99, Loss: 0.34224775433540344, Validation Accuracy: 0.8925833333333333\n",
      "Dataset 68\n",
      "Epoch: 0, Loss: 3.571956157684326, Validation Accuracy: 0.2205\n",
      "Epoch: 1, Loss: 2.6357882022857666, Validation Accuracy: 0.23791666666666667\n",
      "Epoch: 2, Loss: 2.28299617767334, Validation Accuracy: 0.26708333333333334\n",
      "Epoch: 3, Loss: 2.1106410026550293, Validation Accuracy: 0.41475\n",
      "Epoch: 4, Loss: 1.6657459735870361, Validation Accuracy: 0.45325\n",
      "Epoch: 5, Loss: 1.5516986846923828, Validation Accuracy: 0.4255833333333333\n",
      "Epoch: 6, Loss: 1.5495339632034302, Validation Accuracy: 0.5496666666666666\n",
      "Epoch: 7, Loss: 1.3326674699783325, Validation Accuracy: 0.58175\n",
      "Epoch: 8, Loss: 1.2274179458618164, Validation Accuracy: 0.6264166666666666\n",
      "Epoch: 9, Loss: 1.1321258544921875, Validation Accuracy: 0.63475\n",
      "Epoch: 10, Loss: 1.075535774230957, Validation Accuracy: 0.6668333333333333\n",
      "Epoch: 11, Loss: 1.0148558616638184, Validation Accuracy: 0.6494166666666666\n",
      "Epoch: 12, Loss: 0.9956468939781189, Validation Accuracy: 0.68275\n",
      "Epoch: 13, Loss: 0.945155918598175, Validation Accuracy: 0.6595\n",
      "Epoch: 14, Loss: 0.9457953572273254, Validation Accuracy: 0.703\n",
      "Epoch: 15, Loss: 0.8762696385383606, Validation Accuracy: 0.70225\n",
      "Epoch: 16, Loss: 0.8462753295898438, Validation Accuracy: 0.7365\n",
      "Epoch: 17, Loss: 0.7835808992385864, Validation Accuracy: 0.7500833333333333\n",
      "Epoch: 18, Loss: 0.7434569597244263, Validation Accuracy: 0.7623333333333333\n",
      "Epoch: 19, Loss: 0.7150810360908508, Validation Accuracy: 0.7695\n",
      "Epoch: 20, Loss: 0.690927267074585, Validation Accuracy: 0.767\n",
      "Epoch: 21, Loss: 0.6960407495498657, Validation Accuracy: 0.7633333333333333\n",
      "Epoch: 22, Loss: 0.6982865929603577, Validation Accuracy: 0.7385833333333334\n",
      "Epoch: 23, Loss: 0.7439736127853394, Validation Accuracy: 0.73775\n",
      "Epoch: 24, Loss: 0.7576994895935059, Validation Accuracy: 0.7396666666666667\n",
      "Epoch: 25, Loss: 0.7384655475616455, Validation Accuracy: 0.7815\n",
      "Epoch: 26, Loss: 0.6637014150619507, Validation Accuracy: 0.80775\n",
      "Epoch: 27, Loss: 0.5912264585494995, Validation Accuracy: 0.8271666666666667\n",
      "Epoch: 28, Loss: 0.5487449765205383, Validation Accuracy: 0.83525\n",
      "Epoch: 29, Loss: 0.5264613628387451, Validation Accuracy: 0.8413333333333334\n",
      "Epoch: 30, Loss: 0.5118409991264343, Validation Accuracy: 0.8459166666666667\n",
      "Epoch: 31, Loss: 0.5009255409240723, Validation Accuracy: 0.8483333333333334\n",
      "Epoch: 32, Loss: 0.49172696471214294, Validation Accuracy: 0.85125\n",
      "Epoch: 33, Loss: 0.4836159348487854, Validation Accuracy: 0.8531666666666666\n",
      "Epoch: 34, Loss: 0.4762561321258545, Validation Accuracy: 0.8555833333333334\n",
      "Epoch: 35, Loss: 0.46946749091148376, Validation Accuracy: 0.8575833333333334\n",
      "Epoch: 36, Loss: 0.46314865350723267, Validation Accuracy: 0.8584166666666667\n",
      "Epoch: 37, Loss: 0.4572402834892273, Validation Accuracy: 0.8603333333333333\n",
      "Epoch: 38, Loss: 0.4516492784023285, Validation Accuracy: 0.8618333333333333\n",
      "Epoch: 39, Loss: 0.4463540017604828, Validation Accuracy: 0.8629166666666667\n",
      "Epoch: 40, Loss: 0.4413645565509796, Validation Accuracy: 0.86525\n",
      "Epoch: 41, Loss: 0.4366050660610199, Validation Accuracy: 0.8649166666666667\n",
      "Epoch: 42, Loss: 0.432081937789917, Validation Accuracy: 0.86675\n",
      "Epoch: 43, Loss: 0.42774537205696106, Validation Accuracy: 0.8684166666666666\n",
      "Epoch: 44, Loss: 0.4236004650592804, Validation Accuracy: 0.8685833333333334\n",
      "Epoch: 45, Loss: 0.41962695121765137, Validation Accuracy: 0.8715\n",
      "Epoch: 46, Loss: 0.41581258177757263, Validation Accuracy: 0.8703333333333333\n",
      "Epoch: 47, Loss: 0.41214725375175476, Validation Accuracy: 0.8735\n",
      "Epoch: 48, Loss: 0.4086075723171234, Validation Accuracy: 0.8733333333333333\n",
      "Epoch: 49, Loss: 0.4051847755908966, Validation Accuracy: 0.8755\n",
      "Epoch: 50, Loss: 0.4019091725349426, Validation Accuracy: 0.8748333333333334\n",
      "Epoch: 51, Loss: 0.3987612724304199, Validation Accuracy: 0.8771666666666667\n",
      "Epoch: 52, Loss: 0.3957318663597107, Validation Accuracy: 0.87575\n",
      "Epoch: 53, Loss: 0.3928130567073822, Validation Accuracy: 0.8786666666666667\n",
      "Epoch: 54, Loss: 0.39001545310020447, Validation Accuracy: 0.8771666666666667\n",
      "Epoch: 55, Loss: 0.38734638690948486, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 56, Loss: 0.38475725054740906, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 57, Loss: 0.38242998719215393, Validation Accuracy: 0.8823333333333333\n",
      "Epoch: 58, Loss: 0.38020995259284973, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 59, Loss: 0.3782784938812256, Validation Accuracy: 0.8843333333333333\n",
      "Epoch: 60, Loss: 0.37656739354133606, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 61, Loss: 0.375222772359848, Validation Accuracy: 0.885\n",
      "Epoch: 62, Loss: 0.3742346167564392, Validation Accuracy: 0.8813333333333333\n",
      "Epoch: 63, Loss: 0.37359562516212463, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 64, Loss: 0.37357068061828613, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 65, Loss: 0.37418094277381897, Validation Accuracy: 0.884\n",
      "Epoch: 66, Loss: 0.37559863924980164, Validation Accuracy: 0.88025\n",
      "Epoch: 67, Loss: 0.37789714336395264, Validation Accuracy: 0.8813333333333333\n",
      "Epoch: 68, Loss: 0.38135436177253723, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 69, Loss: 0.38587358593940735, Validation Accuracy: 0.87775\n",
      "Epoch: 70, Loss: 0.3915075957775116, Validation Accuracy: 0.8711666666666666\n",
      "Epoch: 71, Loss: 0.3973589539527893, Validation Accuracy: 0.8731666666666666\n",
      "Epoch: 72, Loss: 0.4034043848514557, Validation Accuracy: 0.8665\n",
      "Epoch: 73, Loss: 0.40669670701026917, Validation Accuracy: 0.8705833333333334\n",
      "Epoch: 74, Loss: 0.4073474109172821, Validation Accuracy: 0.8679166666666667\n",
      "Epoch: 75, Loss: 0.4014166295528412, Validation Accuracy: 0.8775833333333334\n",
      "Epoch: 76, Loss: 0.3910601735115051, Validation Accuracy: 0.88\n",
      "Epoch: 77, Loss: 0.3764643967151642, Validation Accuracy: 0.88725\n",
      "Epoch: 78, Loss: 0.36290302872657776, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 79, Loss: 0.35086753964424133, Validation Accuracy: 0.8959166666666667\n",
      "Epoch: 80, Loss: 0.34307661652565, Validation Accuracy: 0.89575\n",
      "Epoch: 81, Loss: 0.3373461365699768, Validation Accuracy: 0.8986666666666666\n",
      "Epoch: 82, Loss: 0.33361101150512695, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 83, Loss: 0.3306109309196472, Validation Accuracy: 0.8995\n",
      "Epoch: 84, Loss: 0.32829782366752625, Validation Accuracy: 0.8986666666666666\n",
      "Epoch: 85, Loss: 0.3262740969657898, Validation Accuracy: 0.9000833333333333\n",
      "Epoch: 86, Loss: 0.32447680830955505, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 87, Loss: 0.3227933943271637, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 88, Loss: 0.32120755314826965, Validation Accuracy: 0.90025\n",
      "Epoch: 89, Loss: 0.31968870759010315, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 90, Loss: 0.31821537017822266, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 91, Loss: 0.3167846202850342, Validation Accuracy: 0.90275\n",
      "Epoch: 92, Loss: 0.3153894543647766, Validation Accuracy: 0.9023333333333333\n",
      "Epoch: 93, Loss: 0.31402331590652466, Validation Accuracy: 0.90375\n",
      "Epoch: 94, Loss: 0.31268295645713806, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 95, Loss: 0.31136593222618103, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 96, Loss: 0.31007203459739685, Validation Accuracy: 0.9054166666666666\n",
      "Epoch: 97, Loss: 0.30879682302474976, Validation Accuracy: 0.9061666666666667\n",
      "Epoch: 98, Loss: 0.30754125118255615, Validation Accuracy: 0.9060833333333334\n",
      "Epoch: 99, Loss: 0.30630651116371155, Validation Accuracy: 0.9075833333333333\n",
      "Dataset 69\n",
      "Epoch: 0, Loss: 4.126603603363037, Validation Accuracy: 0.15933333333333333\n",
      "Epoch: 1, Loss: 3.373081684112549, Validation Accuracy: 0.16233333333333333\n",
      "Epoch: 2, Loss: 3.1430504322052, Validation Accuracy: 0.15291666666666667\n",
      "Epoch: 3, Loss: 2.756476640701294, Validation Accuracy: 0.234\n",
      "Epoch: 4, Loss: 2.131606101989746, Validation Accuracy: 0.2801666666666667\n",
      "Epoch: 5, Loss: 1.9863923788070679, Validation Accuracy: 0.3665833333333333\n",
      "Epoch: 6, Loss: 1.8323489427566528, Validation Accuracy: 0.41208333333333336\n",
      "Epoch: 7, Loss: 1.706628441810608, Validation Accuracy: 0.47008333333333335\n",
      "Epoch: 8, Loss: 1.585794448852539, Validation Accuracy: 0.5073333333333333\n",
      "Epoch: 9, Loss: 1.4664220809936523, Validation Accuracy: 0.5521666666666667\n",
      "Epoch: 10, Loss: 1.355074167251587, Validation Accuracy: 0.58125\n",
      "Epoch: 11, Loss: 1.2556750774383545, Validation Accuracy: 0.6176666666666667\n",
      "Epoch: 12, Loss: 1.1675572395324707, Validation Accuracy: 0.6438333333333334\n",
      "Epoch: 13, Loss: 1.0900352001190186, Validation Accuracy: 0.6736666666666666\n",
      "Epoch: 14, Loss: 1.0221070051193237, Validation Accuracy: 0.68675\n",
      "Epoch: 15, Loss: 0.9629372358322144, Validation Accuracy: 0.7081666666666667\n",
      "Epoch: 16, Loss: 0.9155609607696533, Validation Accuracy: 0.71125\n",
      "Epoch: 17, Loss: 0.8781639933586121, Validation Accuracy: 0.7209166666666667\n",
      "Epoch: 18, Loss: 0.8611622452735901, Validation Accuracy: 0.7095\n",
      "Epoch: 19, Loss: 0.8582761287689209, Validation Accuracy: 0.6975\n",
      "Epoch: 20, Loss: 0.8914313912391663, Validation Accuracy: 0.6896666666666667\n",
      "Epoch: 21, Loss: 0.8938854932785034, Validation Accuracy: 0.6985\n",
      "Epoch: 22, Loss: 0.8757832050323486, Validation Accuracy: 0.73525\n",
      "Epoch: 23, Loss: 0.7811263799667358, Validation Accuracy: 0.7636666666666667\n",
      "Epoch: 24, Loss: 0.7127347588539124, Validation Accuracy: 0.7806666666666666\n",
      "Epoch: 25, Loss: 0.6715248227119446, Validation Accuracy: 0.7894166666666667\n",
      "Epoch: 26, Loss: 0.6447590589523315, Validation Accuracy: 0.79575\n",
      "Epoch: 27, Loss: 0.6294392347335815, Validation Accuracy: 0.7959166666666667\n",
      "Epoch: 28, Loss: 0.6173651814460754, Validation Accuracy: 0.8025833333333333\n",
      "Epoch: 29, Loss: 0.6097024083137512, Validation Accuracy: 0.7973333333333333\n",
      "Epoch: 30, Loss: 0.6021119952201843, Validation Accuracy: 0.808\n",
      "Epoch: 31, Loss: 0.5961915850639343, Validation Accuracy: 0.8018333333333333\n",
      "Epoch: 32, Loss: 0.5857060551643372, Validation Accuracy: 0.81525\n",
      "Epoch: 33, Loss: 0.575712263584137, Validation Accuracy: 0.814\n",
      "Epoch: 34, Loss: 0.558251678943634, Validation Accuracy: 0.8269166666666666\n",
      "Epoch: 35, Loss: 0.5439615845680237, Validation Accuracy: 0.82675\n",
      "Epoch: 36, Loss: 0.5260118246078491, Validation Accuracy: 0.8381666666666666\n",
      "Epoch: 37, Loss: 0.5121787786483765, Validation Accuracy: 0.8389166666666666\n",
      "Epoch: 38, Loss: 0.49789854884147644, Validation Accuracy: 0.8454166666666667\n",
      "Epoch: 39, Loss: 0.4869832694530487, Validation Accuracy: 0.846\n",
      "Epoch: 40, Loss: 0.47694340348243713, Validation Accuracy: 0.8518333333333333\n",
      "Epoch: 41, Loss: 0.4687066376209259, Validation Accuracy: 0.8528333333333333\n",
      "Epoch: 42, Loss: 0.4613405764102936, Validation Accuracy: 0.8569166666666667\n",
      "Epoch: 43, Loss: 0.45482897758483887, Validation Accuracy: 0.8575\n",
      "Epoch: 44, Loss: 0.44892001152038574, Validation Accuracy: 0.8598333333333333\n",
      "Epoch: 45, Loss: 0.4434565007686615, Validation Accuracy: 0.86075\n",
      "Epoch: 46, Loss: 0.4383675158023834, Validation Accuracy: 0.8623333333333333\n",
      "Epoch: 47, Loss: 0.4336121380329132, Validation Accuracy: 0.8640833333333333\n",
      "Epoch: 48, Loss: 0.42904362082481384, Validation Accuracy: 0.8653333333333333\n",
      "Epoch: 49, Loss: 0.4246973395347595, Validation Accuracy: 0.8669166666666667\n",
      "Epoch: 50, Loss: 0.4205198585987091, Validation Accuracy: 0.8685833333333334\n",
      "Epoch: 51, Loss: 0.41652098298072815, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 52, Loss: 0.41266751289367676, Validation Accuracy: 0.8705\n",
      "Epoch: 53, Loss: 0.4089435935020447, Validation Accuracy: 0.87225\n",
      "Epoch: 54, Loss: 0.405338853597641, Validation Accuracy: 0.87275\n",
      "Epoch: 55, Loss: 0.4018346071243286, Validation Accuracy: 0.87375\n",
      "Epoch: 56, Loss: 0.3984261155128479, Validation Accuracy: 0.87475\n",
      "Epoch: 57, Loss: 0.39512014389038086, Validation Accuracy: 0.8753333333333333\n",
      "Epoch: 58, Loss: 0.3919178545475006, Validation Accuracy: 0.8771666666666667\n",
      "Epoch: 59, Loss: 0.3888028860092163, Validation Accuracy: 0.87725\n",
      "Epoch: 60, Loss: 0.3857618272304535, Validation Accuracy: 0.8785\n",
      "Epoch: 61, Loss: 0.38280370831489563, Validation Accuracy: 0.8788333333333334\n",
      "Epoch: 62, Loss: 0.37993505597114563, Validation Accuracy: 0.8804166666666666\n",
      "Epoch: 63, Loss: 0.3771267533302307, Validation Accuracy: 0.881\n",
      "Epoch: 64, Loss: 0.3743843138217926, Validation Accuracy: 0.883\n",
      "Epoch: 65, Loss: 0.3717062175273895, Validation Accuracy: 0.8829166666666667\n",
      "Epoch: 66, Loss: 0.36909544467926025, Validation Accuracy: 0.8841666666666667\n",
      "Epoch: 67, Loss: 0.36654481291770935, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 68, Loss: 0.3640647828578949, Validation Accuracy: 0.8859166666666667\n",
      "Epoch: 69, Loss: 0.36164191365242004, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 70, Loss: 0.3592776656150818, Validation Accuracy: 0.8868333333333334\n",
      "Epoch: 71, Loss: 0.3569571077823639, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 72, Loss: 0.35469040274620056, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 73, Loss: 0.35245656967163086, Validation Accuracy: 0.8889166666666667\n",
      "Epoch: 74, Loss: 0.35028767585754395, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 75, Loss: 0.3481478691101074, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 76, Loss: 0.346070259809494, Validation Accuracy: 0.89125\n",
      "Epoch: 77, Loss: 0.34402143955230713, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 78, Loss: 0.34204405546188354, Validation Accuracy: 0.893\n",
      "Epoch: 79, Loss: 0.34009867906570435, Validation Accuracy: 0.893\n",
      "Epoch: 80, Loss: 0.3382212817668915, Validation Accuracy: 0.89375\n",
      "Epoch: 81, Loss: 0.33636215329170227, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 82, Loss: 0.33456963300704956, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 83, Loss: 0.33277761936187744, Validation Accuracy: 0.8951666666666667\n",
      "Epoch: 84, Loss: 0.33103665709495544, Validation Accuracy: 0.8963333333333333\n",
      "Epoch: 85, Loss: 0.3293014466762543, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 86, Loss: 0.32760846614837646, Validation Accuracy: 0.89725\n",
      "Epoch: 87, Loss: 0.32592737674713135, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 88, Loss: 0.3242947459220886, Validation Accuracy: 0.8985\n",
      "Epoch: 89, Loss: 0.3226872980594635, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 90, Loss: 0.32112348079681396, Validation Accuracy: 0.89925\n",
      "Epoch: 91, Loss: 0.3195859491825104, Validation Accuracy: 0.8995\n",
      "Epoch: 92, Loss: 0.3180733919143677, Validation Accuracy: 0.9\n",
      "Epoch: 93, Loss: 0.3165893852710724, Validation Accuracy: 0.9000833333333333\n",
      "Epoch: 94, Loss: 0.315118670463562, Validation Accuracy: 0.90075\n",
      "Epoch: 95, Loss: 0.3136790692806244, Validation Accuracy: 0.9005\n",
      "Epoch: 96, Loss: 0.3122675120830536, Validation Accuracy: 0.90175\n",
      "Epoch: 97, Loss: 0.3108595907688141, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 98, Loss: 0.3094700872898102, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 99, Loss: 0.3081222176551819, Validation Accuracy: 0.9024166666666666\n",
      "Dataset 70\n",
      "Epoch: 0, Loss: 3.2781169414520264, Validation Accuracy: 0.2635\n",
      "Epoch: 1, Loss: 2.3756401538848877, Validation Accuracy: 0.21866666666666668\n",
      "Epoch: 2, Loss: 2.6044697761535645, Validation Accuracy: 0.23108333333333334\n",
      "Epoch: 3, Loss: 3.0098822116851807, Validation Accuracy: 0.233\n",
      "Epoch: 4, Loss: 2.304908514022827, Validation Accuracy: 0.36516666666666664\n",
      "Epoch: 5, Loss: 1.7911986112594604, Validation Accuracy: 0.45058333333333334\n",
      "Epoch: 6, Loss: 1.5922513008117676, Validation Accuracy: 0.51975\n",
      "Epoch: 7, Loss: 1.45035982131958, Validation Accuracy: 0.55125\n",
      "Epoch: 8, Loss: 1.3409676551818848, Validation Accuracy: 0.58325\n",
      "Epoch: 9, Loss: 1.2500895261764526, Validation Accuracy: 0.6050833333333333\n",
      "Epoch: 10, Loss: 1.17826509475708, Validation Accuracy: 0.6191666666666666\n",
      "Epoch: 11, Loss: 1.1370066404342651, Validation Accuracy: 0.6225\n",
      "Epoch: 12, Loss: 1.1188219785690308, Validation Accuracy: 0.6030833333333333\n",
      "Epoch: 13, Loss: 1.1536543369293213, Validation Accuracy: 0.6256666666666667\n",
      "Epoch: 14, Loss: 1.0893298387527466, Validation Accuracy: 0.6585\n",
      "Epoch: 15, Loss: 1.0167231559753418, Validation Accuracy: 0.70625\n",
      "Epoch: 16, Loss: 0.8965518474578857, Validation Accuracy: 0.7309166666666667\n",
      "Epoch: 17, Loss: 0.8365371823310852, Validation Accuracy: 0.74725\n",
      "Epoch: 18, Loss: 0.7885777950286865, Validation Accuracy: 0.76\n",
      "Epoch: 19, Loss: 0.7535879611968994, Validation Accuracy: 0.76975\n",
      "Epoch: 20, Loss: 0.7241591811180115, Validation Accuracy: 0.7764166666666666\n",
      "Epoch: 21, Loss: 0.7000320553779602, Validation Accuracy: 0.7814166666666666\n",
      "Epoch: 22, Loss: 0.6789209842681885, Validation Accuracy: 0.78775\n",
      "Epoch: 23, Loss: 0.6611613631248474, Validation Accuracy: 0.7918333333333333\n",
      "Epoch: 24, Loss: 0.6452952027320862, Validation Accuracy: 0.7971666666666667\n",
      "Epoch: 25, Loss: 0.632524311542511, Validation Accuracy: 0.7983333333333333\n",
      "Epoch: 26, Loss: 0.621427595615387, Validation Accuracy: 0.8029166666666666\n",
      "Epoch: 27, Loss: 0.6126688718795776, Validation Accuracy: 0.804\n",
      "Epoch: 28, Loss: 0.6051622629165649, Validation Accuracy: 0.80675\n",
      "Epoch: 29, Loss: 0.598345935344696, Validation Accuracy: 0.8073333333333333\n",
      "Epoch: 30, Loss: 0.5915526151657104, Validation Accuracy: 0.8111666666666667\n",
      "Epoch: 31, Loss: 0.5828421115875244, Validation Accuracy: 0.8126666666666666\n",
      "Epoch: 32, Loss: 0.5731416940689087, Validation Accuracy: 0.8178333333333333\n",
      "Epoch: 33, Loss: 0.560356855392456, Validation Accuracy: 0.822\n",
      "Epoch: 34, Loss: 0.5473069548606873, Validation Accuracy: 0.82825\n",
      "Epoch: 35, Loss: 0.5324397087097168, Validation Accuracy: 0.83375\n",
      "Epoch: 36, Loss: 0.5195031762123108, Validation Accuracy: 0.8394166666666667\n",
      "Epoch: 37, Loss: 0.5061929821968079, Validation Accuracy: 0.842\n",
      "Epoch: 38, Loss: 0.4954170882701874, Validation Accuracy: 0.8466666666666667\n",
      "Epoch: 39, Loss: 0.4846188426017761, Validation Accuracy: 0.8500833333333333\n",
      "Epoch: 40, Loss: 0.4759169816970825, Validation Accuracy: 0.85325\n",
      "Epoch: 41, Loss: 0.4674845039844513, Validation Accuracy: 0.8549166666666667\n",
      "Epoch: 42, Loss: 0.46034595370292664, Validation Accuracy: 0.8580833333333333\n",
      "Epoch: 43, Loss: 0.45352521538734436, Validation Accuracy: 0.8603333333333333\n",
      "Epoch: 44, Loss: 0.44739896059036255, Validation Accuracy: 0.86075\n",
      "Epoch: 45, Loss: 0.44160518050193787, Validation Accuracy: 0.863\n",
      "Epoch: 46, Loss: 0.4362364113330841, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 47, Loss: 0.43103209137916565, Validation Accuracy: 0.86575\n",
      "Epoch: 48, Loss: 0.4261487126350403, Validation Accuracy: 0.8665833333333334\n",
      "Epoch: 49, Loss: 0.4214859902858734, Validation Accuracy: 0.8685833333333334\n",
      "Epoch: 50, Loss: 0.41706037521362305, Validation Accuracy: 0.8689166666666667\n",
      "Epoch: 51, Loss: 0.4127977192401886, Validation Accuracy: 0.8706666666666667\n",
      "Epoch: 52, Loss: 0.40871381759643555, Validation Accuracy: 0.8716666666666667\n",
      "Epoch: 53, Loss: 0.4047797918319702, Validation Accuracy: 0.8724166666666666\n",
      "Epoch: 54, Loss: 0.4010121524333954, Validation Accuracy: 0.8744166666666666\n",
      "Epoch: 55, Loss: 0.3973679542541504, Validation Accuracy: 0.8755833333333334\n",
      "Epoch: 56, Loss: 0.39384278655052185, Validation Accuracy: 0.87675\n",
      "Epoch: 57, Loss: 0.3904474377632141, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 58, Loss: 0.3871367871761322, Validation Accuracy: 0.87825\n",
      "Epoch: 59, Loss: 0.3839469254016876, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 60, Loss: 0.38084423542022705, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 61, Loss: 0.3778191804885864, Validation Accuracy: 0.8815\n",
      "Epoch: 62, Loss: 0.3748772442340851, Validation Accuracy: 0.8833333333333333\n",
      "Epoch: 63, Loss: 0.37201908230781555, Validation Accuracy: 0.88325\n",
      "Epoch: 64, Loss: 0.36923566460609436, Validation Accuracy: 0.8850833333333333\n",
      "Epoch: 65, Loss: 0.3665210008621216, Validation Accuracy: 0.8845\n",
      "Epoch: 66, Loss: 0.36387011408805847, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 67, Loss: 0.36128026247024536, Validation Accuracy: 0.8855833333333333\n",
      "Epoch: 68, Loss: 0.3587781488895416, Validation Accuracy: 0.8879166666666667\n",
      "Epoch: 69, Loss: 0.35631948709487915, Validation Accuracy: 0.8874166666666666\n",
      "Epoch: 70, Loss: 0.3539460003376007, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 71, Loss: 0.3516143262386322, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 72, Loss: 0.3493639826774597, Validation Accuracy: 0.8903333333333333\n",
      "Epoch: 73, Loss: 0.3471560776233673, Validation Accuracy: 0.8904166666666666\n",
      "Epoch: 74, Loss: 0.3450295329093933, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 75, Loss: 0.34294092655181885, Validation Accuracy: 0.8915\n",
      "Epoch: 76, Loss: 0.34090909361839294, Validation Accuracy: 0.8935\n",
      "Epoch: 77, Loss: 0.3389199674129486, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 78, Loss: 0.33699655532836914, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 79, Loss: 0.335095077753067, Validation Accuracy: 0.89375\n",
      "Epoch: 80, Loss: 0.3332732617855072, Validation Accuracy: 0.8965\n",
      "Epoch: 81, Loss: 0.3314587473869324, Validation Accuracy: 0.8954166666666666\n",
      "Epoch: 82, Loss: 0.3297213613986969, Validation Accuracy: 0.8971666666666667\n",
      "Epoch: 83, Loss: 0.32799264788627625, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 84, Loss: 0.3263346254825592, Validation Accuracy: 0.8985833333333333\n",
      "Epoch: 85, Loss: 0.32466045022010803, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 86, Loss: 0.323076993227005, Validation Accuracy: 0.89975\n",
      "Epoch: 87, Loss: 0.32148605585098267, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 88, Loss: 0.3199787139892578, Validation Accuracy: 0.901\n",
      "Epoch: 89, Loss: 0.31842678785324097, Validation Accuracy: 0.89925\n",
      "Epoch: 90, Loss: 0.3169758915901184, Validation Accuracy: 0.90125\n",
      "Epoch: 91, Loss: 0.3154904544353485, Validation Accuracy: 0.8999166666666667\n",
      "Epoch: 92, Loss: 0.3141172230243683, Validation Accuracy: 0.9028333333333334\n",
      "Epoch: 93, Loss: 0.3127252459526062, Validation Accuracy: 0.901\n",
      "Epoch: 94, Loss: 0.31142494082450867, Validation Accuracy: 0.9034166666666666\n",
      "Epoch: 95, Loss: 0.31005561351776123, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 96, Loss: 0.30881136655807495, Validation Accuracy: 0.9039166666666667\n",
      "Epoch: 97, Loss: 0.30748578906059265, Validation Accuracy: 0.9016666666666666\n",
      "Epoch: 98, Loss: 0.30633822083473206, Validation Accuracy: 0.9044166666666666\n",
      "Epoch: 99, Loss: 0.30505234003067017, Validation Accuracy: 0.903\n",
      "Dataset 71\n",
      "Epoch: 0, Loss: 3.7105562686920166, Validation Accuracy: 0.15358333333333332\n",
      "Epoch: 1, Loss: 2.6745409965515137, Validation Accuracy: 0.26108333333333333\n",
      "Epoch: 2, Loss: 2.2533626556396484, Validation Accuracy: 0.22883333333333333\n",
      "Epoch: 3, Loss: 2.610934019088745, Validation Accuracy: 0.15108333333333332\n",
      "Epoch: 4, Loss: 2.752070665359497, Validation Accuracy: 0.2960833333333333\n",
      "Epoch: 5, Loss: 2.1593990325927734, Validation Accuracy: 0.3815\n",
      "Epoch: 6, Loss: 1.8052314519882202, Validation Accuracy: 0.46325\n",
      "Epoch: 7, Loss: 1.665820837020874, Validation Accuracy: 0.49533333333333335\n",
      "Epoch: 8, Loss: 1.5323580503463745, Validation Accuracy: 0.5263333333333333\n",
      "Epoch: 9, Loss: 1.431036114692688, Validation Accuracy: 0.5519166666666667\n",
      "Epoch: 10, Loss: 1.3322913646697998, Validation Accuracy: 0.6133333333333333\n",
      "Epoch: 11, Loss: 1.1956323385238647, Validation Accuracy: 0.6370833333333333\n",
      "Epoch: 12, Loss: 1.1178219318389893, Validation Accuracy: 0.6684166666666667\n",
      "Epoch: 13, Loss: 1.0343945026397705, Validation Accuracy: 0.6786666666666666\n",
      "Epoch: 14, Loss: 0.9911226630210876, Validation Accuracy: 0.6964166666666667\n",
      "Epoch: 15, Loss: 0.9307891726493835, Validation Accuracy: 0.6935\n",
      "Epoch: 16, Loss: 0.9204941987991333, Validation Accuracy: 0.7184166666666667\n",
      "Epoch: 17, Loss: 0.8510286211967468, Validation Accuracy: 0.7226666666666667\n",
      "Epoch: 18, Loss: 0.8335484266281128, Validation Accuracy: 0.7451666666666666\n",
      "Epoch: 19, Loss: 0.7660130262374878, Validation Accuracy: 0.7565\n",
      "Epoch: 20, Loss: 0.7398186326026917, Validation Accuracy: 0.7669166666666667\n",
      "Epoch: 21, Loss: 0.6976953744888306, Validation Accuracy: 0.7765\n",
      "Epoch: 22, Loss: 0.6787265539169312, Validation Accuracy: 0.7813333333333333\n",
      "Epoch: 23, Loss: 0.6529832482337952, Validation Accuracy: 0.7905833333333333\n",
      "Epoch: 24, Loss: 0.6413922309875488, Validation Accuracy: 0.79\n",
      "Epoch: 25, Loss: 0.623923122882843, Validation Accuracy: 0.7989166666666667\n",
      "Epoch: 26, Loss: 0.6164539456367493, Validation Accuracy: 0.79875\n",
      "Epoch: 27, Loss: 0.6025604009628296, Validation Accuracy: 0.8055\n",
      "Epoch: 28, Loss: 0.5959001183509827, Validation Accuracy: 0.80675\n",
      "Epoch: 29, Loss: 0.5822039246559143, Validation Accuracy: 0.8124166666666667\n",
      "Epoch: 30, Loss: 0.5725180506706238, Validation Accuracy: 0.8171666666666667\n",
      "Epoch: 31, Loss: 0.5566291213035583, Validation Accuracy: 0.8230833333333333\n",
      "Epoch: 32, Loss: 0.5436384081840515, Validation Accuracy: 0.8294166666666667\n",
      "Epoch: 33, Loss: 0.5272316336631775, Validation Accuracy: 0.8360833333333333\n",
      "Epoch: 34, Loss: 0.5140335559844971, Validation Accuracy: 0.8386666666666667\n",
      "Epoch: 35, Loss: 0.5005029439926147, Validation Accuracy: 0.8440833333333333\n",
      "Epoch: 36, Loss: 0.48970887064933777, Validation Accuracy: 0.8473333333333334\n",
      "Epoch: 37, Loss: 0.4793107807636261, Validation Accuracy: 0.8515\n",
      "Epoch: 38, Loss: 0.4704810380935669, Validation Accuracy: 0.8540833333333333\n",
      "Epoch: 39, Loss: 0.46236804127693176, Validation Accuracy: 0.85675\n",
      "Epoch: 40, Loss: 0.4552438259124756, Validation Accuracy: 0.8585\n",
      "Epoch: 41, Loss: 0.44879788160324097, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 42, Loss: 0.4429053068161011, Validation Accuracy: 0.8629166666666667\n",
      "Epoch: 43, Loss: 0.4375004470348358, Validation Accuracy: 0.8645833333333334\n",
      "Epoch: 44, Loss: 0.4325333535671234, Validation Accuracy: 0.8661666666666666\n",
      "Epoch: 45, Loss: 0.4278665781021118, Validation Accuracy: 0.8673333333333333\n",
      "Epoch: 46, Loss: 0.4236878752708435, Validation Accuracy: 0.8690833333333333\n",
      "Epoch: 47, Loss: 0.4195725619792938, Validation Accuracy: 0.87\n",
      "Epoch: 48, Loss: 0.41603708267211914, Validation Accuracy: 0.871\n",
      "Epoch: 49, Loss: 0.4125974476337433, Validation Accuracy: 0.872\n",
      "Epoch: 50, Loss: 0.40946900844573975, Validation Accuracy: 0.8725\n",
      "Epoch: 51, Loss: 0.40635114908218384, Validation Accuracy: 0.8740833333333333\n",
      "Epoch: 52, Loss: 0.4035407304763794, Validation Accuracy: 0.87425\n",
      "Epoch: 53, Loss: 0.40058082342147827, Validation Accuracy: 0.876\n",
      "Epoch: 54, Loss: 0.39797598123550415, Validation Accuracy: 0.8766666666666667\n",
      "Epoch: 55, Loss: 0.3950479030609131, Validation Accuracy: 0.8779166666666667\n",
      "Epoch: 56, Loss: 0.39265763759613037, Validation Accuracy: 0.8785\n",
      "Epoch: 57, Loss: 0.38963738083839417, Validation Accuracy: 0.8795833333333334\n",
      "Epoch: 58, Loss: 0.38730311393737793, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 59, Loss: 0.3841628134250641, Validation Accuracy: 0.88125\n",
      "Epoch: 60, Loss: 0.3817545175552368, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 61, Loss: 0.37845516204833984, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 62, Loss: 0.37597787380218506, Validation Accuracy: 0.8841666666666667\n",
      "Epoch: 63, Loss: 0.37256553769111633, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 64, Loss: 0.36994636058807373, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 65, Loss: 0.3666606843471527, Validation Accuracy: 0.88775\n",
      "Epoch: 66, Loss: 0.36395829916000366, Validation Accuracy: 0.8886666666666667\n",
      "Epoch: 67, Loss: 0.3607986569404602, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 68, Loss: 0.3581819236278534, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 69, Loss: 0.3553166091442108, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 70, Loss: 0.35283443331718445, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 71, Loss: 0.35021182894706726, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 72, Loss: 0.347887247800827, Validation Accuracy: 0.8936666666666667\n",
      "Epoch: 73, Loss: 0.3454124629497528, Validation Accuracy: 0.89475\n",
      "Epoch: 74, Loss: 0.3432105779647827, Validation Accuracy: 0.8951666666666667\n",
      "Epoch: 75, Loss: 0.3409586250782013, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 76, Loss: 0.33885830640792847, Validation Accuracy: 0.8963333333333333\n",
      "Epoch: 77, Loss: 0.33674007654190063, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 78, Loss: 0.3347545564174652, Validation Accuracy: 0.8978333333333334\n",
      "Epoch: 79, Loss: 0.3327712118625641, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 80, Loss: 0.33093148469924927, Validation Accuracy: 0.8983333333333333\n",
      "Epoch: 81, Loss: 0.3290417492389679, Validation Accuracy: 0.8995\n",
      "Epoch: 82, Loss: 0.3272790312767029, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 83, Loss: 0.32548651099205017, Validation Accuracy: 0.9\n",
      "Epoch: 84, Loss: 0.32379353046417236, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 85, Loss: 0.32212549448013306, Validation Accuracy: 0.901\n",
      "Epoch: 86, Loss: 0.320516437292099, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 87, Loss: 0.31892630457878113, Validation Accuracy: 0.9020833333333333\n",
      "Epoch: 88, Loss: 0.3173844814300537, Validation Accuracy: 0.9035\n",
      "Epoch: 89, Loss: 0.31585535407066345, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 90, Loss: 0.31437429785728455, Validation Accuracy: 0.904\n",
      "Epoch: 91, Loss: 0.3129327893257141, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 92, Loss: 0.311523973941803, Validation Accuracy: 0.90475\n",
      "Epoch: 93, Loss: 0.3101262152194977, Validation Accuracy: 0.9045833333333333\n",
      "Epoch: 94, Loss: 0.3087729215621948, Validation Accuracy: 0.905\n",
      "Epoch: 95, Loss: 0.3074348270893097, Validation Accuracy: 0.905\n",
      "Epoch: 96, Loss: 0.3061205744743347, Validation Accuracy: 0.9059166666666667\n",
      "Epoch: 97, Loss: 0.30484089255332947, Validation Accuracy: 0.90575\n",
      "Epoch: 98, Loss: 0.303575336933136, Validation Accuracy: 0.9068333333333334\n",
      "Epoch: 99, Loss: 0.30233821272850037, Validation Accuracy: 0.9065\n",
      "Dataset 72\n",
      "Epoch: 0, Loss: 4.0212178230285645, Validation Accuracy: 0.18241666666666667\n",
      "Epoch: 1, Loss: 3.2576494216918945, Validation Accuracy: 0.20783333333333334\n",
      "Epoch: 2, Loss: 2.9875378608703613, Validation Accuracy: 0.2285\n",
      "Epoch: 3, Loss: 2.399413824081421, Validation Accuracy: 0.29241666666666666\n",
      "Epoch: 4, Loss: 1.9770780801773071, Validation Accuracy: 0.3774166666666667\n",
      "Epoch: 5, Loss: 1.7735763788223267, Validation Accuracy: 0.4544166666666667\n",
      "Epoch: 6, Loss: 1.594712257385254, Validation Accuracy: 0.5216666666666666\n",
      "Epoch: 7, Loss: 1.4436899423599243, Validation Accuracy: 0.5754166666666667\n",
      "Epoch: 8, Loss: 1.313632845878601, Validation Accuracy: 0.6025\n",
      "Epoch: 9, Loss: 1.211594820022583, Validation Accuracy: 0.62625\n",
      "Epoch: 10, Loss: 1.1316678524017334, Validation Accuracy: 0.6406666666666667\n",
      "Epoch: 11, Loss: 1.065427303314209, Validation Accuracy: 0.6590833333333334\n",
      "Epoch: 12, Loss: 1.0072953701019287, Validation Accuracy: 0.6723333333333333\n",
      "Epoch: 13, Loss: 0.9554837346076965, Validation Accuracy: 0.6889166666666666\n",
      "Epoch: 14, Loss: 0.9105471968650818, Validation Accuracy: 0.6980833333333333\n",
      "Epoch: 15, Loss: 0.8773756623268127, Validation Accuracy: 0.7005\n",
      "Epoch: 16, Loss: 0.8690679669380188, Validation Accuracy: 0.6573333333333333\n",
      "Epoch: 17, Loss: 0.9228459596633911, Validation Accuracy: 0.6179166666666667\n",
      "Epoch: 18, Loss: 1.0767159461975098, Validation Accuracy: 0.6094166666666667\n",
      "Epoch: 19, Loss: 1.0420458316802979, Validation Accuracy: 0.6756666666666666\n",
      "Epoch: 20, Loss: 0.9007132053375244, Validation Accuracy: 0.74175\n",
      "Epoch: 21, Loss: 0.7532288432121277, Validation Accuracy: 0.7701666666666667\n",
      "Epoch: 22, Loss: 0.6978948712348938, Validation Accuracy: 0.7885\n",
      "Epoch: 23, Loss: 0.6666404604911804, Validation Accuracy: 0.7883333333333333\n",
      "Epoch: 24, Loss: 0.6443316340446472, Validation Accuracy: 0.8000833333333334\n",
      "Epoch: 25, Loss: 0.6252772808074951, Validation Accuracy: 0.7979166666666667\n",
      "Epoch: 26, Loss: 0.6111525297164917, Validation Accuracy: 0.807\n",
      "Epoch: 27, Loss: 0.5997136831283569, Validation Accuracy: 0.8000833333333334\n",
      "Epoch: 28, Loss: 0.5962380170822144, Validation Accuracy: 0.8041666666666667\n",
      "Epoch: 29, Loss: 0.5955153107643127, Validation Accuracy: 0.7866666666666666\n",
      "Epoch: 30, Loss: 0.6135090589523315, Validation Accuracy: 0.7865\n",
      "Epoch: 31, Loss: 0.6246092319488525, Validation Accuracy: 0.7605\n",
      "Epoch: 32, Loss: 0.6714476346969604, Validation Accuracy: 0.7713333333333333\n",
      "Epoch: 33, Loss: 0.6510602831840515, Validation Accuracy: 0.765\n",
      "Epoch: 34, Loss: 0.6612101197242737, Validation Accuracy: 0.79525\n",
      "Epoch: 35, Loss: 0.5935089588165283, Validation Accuracy: 0.8066666666666666\n",
      "Epoch: 36, Loss: 0.5608118176460266, Validation Accuracy: 0.8271666666666667\n",
      "Epoch: 37, Loss: 0.5262105464935303, Validation Accuracy: 0.8343333333333334\n",
      "Epoch: 38, Loss: 0.5070416927337646, Validation Accuracy: 0.8409166666666666\n",
      "Epoch: 39, Loss: 0.49271467328071594, Validation Accuracy: 0.8446666666666667\n",
      "Epoch: 40, Loss: 0.48174768686294556, Validation Accuracy: 0.8465833333333334\n",
      "Epoch: 41, Loss: 0.4728364944458008, Validation Accuracy: 0.8495833333333334\n",
      "Epoch: 42, Loss: 0.46510738134384155, Validation Accuracy: 0.85175\n",
      "Epoch: 43, Loss: 0.45819613337516785, Validation Accuracy: 0.85375\n",
      "Epoch: 44, Loss: 0.4520755708217621, Validation Accuracy: 0.8544166666666667\n",
      "Epoch: 45, Loss: 0.44630447030067444, Validation Accuracy: 0.8565833333333334\n",
      "Epoch: 46, Loss: 0.4410955011844635, Validation Accuracy: 0.8579166666666667\n",
      "Epoch: 47, Loss: 0.43616265058517456, Validation Accuracy: 0.8585833333333334\n",
      "Epoch: 48, Loss: 0.43166837096214294, Validation Accuracy: 0.86\n",
      "Epoch: 49, Loss: 0.42754462361335754, Validation Accuracy: 0.8609166666666667\n",
      "Epoch: 50, Loss: 0.42369750142097473, Validation Accuracy: 0.86225\n",
      "Epoch: 51, Loss: 0.4202481806278229, Validation Accuracy: 0.86175\n",
      "Epoch: 52, Loss: 0.417309045791626, Validation Accuracy: 0.8639166666666667\n",
      "Epoch: 53, Loss: 0.41482633352279663, Validation Accuracy: 0.8620833333333333\n",
      "Epoch: 54, Loss: 0.4130927324295044, Validation Accuracy: 0.86475\n",
      "Epoch: 55, Loss: 0.41184699535369873, Validation Accuracy: 0.8624166666666667\n",
      "Epoch: 56, Loss: 0.411846399307251, Validation Accuracy: 0.865\n",
      "Epoch: 57, Loss: 0.41232502460479736, Validation Accuracy: 0.861\n",
      "Epoch: 58, Loss: 0.4150061309337616, Validation Accuracy: 0.8630833333333333\n",
      "Epoch: 59, Loss: 0.4177735447883606, Validation Accuracy: 0.8575833333333334\n",
      "Epoch: 60, Loss: 0.42345210909843445, Validation Accuracy: 0.8600833333333333\n",
      "Epoch: 61, Loss: 0.4263232946395874, Validation Accuracy: 0.8541666666666666\n",
      "Epoch: 62, Loss: 0.43237927556037903, Validation Accuracy: 0.85825\n",
      "Epoch: 63, Loss: 0.4311155676841736, Validation Accuracy: 0.8545833333333334\n",
      "Epoch: 64, Loss: 0.43200892210006714, Validation Accuracy: 0.8608333333333333\n",
      "Epoch: 65, Loss: 0.42252129316329956, Validation Accuracy: 0.8605\n",
      "Epoch: 66, Loss: 0.4145508110523224, Validation Accuracy: 0.8683333333333333\n",
      "Epoch: 67, Loss: 0.4001438319683075, Validation Accuracy: 0.86925\n",
      "Epoch: 68, Loss: 0.3897693157196045, Validation Accuracy: 0.8754166666666666\n",
      "Epoch: 69, Loss: 0.37882983684539795, Validation Accuracy: 0.8751666666666666\n",
      "Epoch: 70, Loss: 0.3716334104537964, Validation Accuracy: 0.8790833333333333\n",
      "Epoch: 71, Loss: 0.364908367395401, Validation Accuracy: 0.88\n",
      "Epoch: 72, Loss: 0.36025553941726685, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 73, Loss: 0.3558589220046997, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 74, Loss: 0.3525294065475464, Validation Accuracy: 0.8843333333333333\n",
      "Epoch: 75, Loss: 0.34932926297187805, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 76, Loss: 0.34670206904411316, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 77, Loss: 0.3441561758518219, Validation Accuracy: 0.8854166666666666\n",
      "Epoch: 78, Loss: 0.3419376313686371, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 79, Loss: 0.33975788950920105, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 80, Loss: 0.33774814009666443, Validation Accuracy: 0.88725\n",
      "Epoch: 81, Loss: 0.33576902747154236, Validation Accuracy: 0.8879166666666667\n",
      "Epoch: 82, Loss: 0.3338691294193268, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 83, Loss: 0.33199769258499146, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 84, Loss: 0.33021727204322815, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 85, Loss: 0.32845741510391235, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 86, Loss: 0.32675880193710327, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 87, Loss: 0.32509666681289673, Validation Accuracy: 0.8913333333333333\n",
      "Epoch: 88, Loss: 0.32343196868896484, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 89, Loss: 0.3218460977077484, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 90, Loss: 0.32028231024742126, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 91, Loss: 0.31877389550209045, Validation Accuracy: 0.8929166666666667\n",
      "Epoch: 92, Loss: 0.3172793686389923, Validation Accuracy: 0.89375\n",
      "Epoch: 93, Loss: 0.31582340598106384, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 94, Loss: 0.31440475583076477, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 95, Loss: 0.3130083680152893, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 96, Loss: 0.3116229772567749, Validation Accuracy: 0.89575\n",
      "Epoch: 97, Loss: 0.31030938029289246, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 98, Loss: 0.3089812994003296, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 99, Loss: 0.3077423572540283, Validation Accuracy: 0.8960833333333333\n",
      "Dataset 73\n",
      "Epoch: 0, Loss: 3.5180466175079346, Validation Accuracy: 0.17133333333333334\n",
      "Epoch: 1, Loss: 4.327486991882324, Validation Accuracy: 0.23225\n",
      "Epoch: 2, Loss: 3.2620933055877686, Validation Accuracy: 0.15733333333333333\n",
      "Epoch: 3, Loss: 2.51544451713562, Validation Accuracy: 0.31975\n",
      "Epoch: 4, Loss: 1.9107149839401245, Validation Accuracy: 0.379\n",
      "Epoch: 5, Loss: 1.7911937236785889, Validation Accuracy: 0.4156666666666667\n",
      "Epoch: 6, Loss: 1.6970469951629639, Validation Accuracy: 0.45025\n",
      "Epoch: 7, Loss: 1.6142619848251343, Validation Accuracy: 0.4728333333333333\n",
      "Epoch: 8, Loss: 1.5381625890731812, Validation Accuracy: 0.5000833333333333\n",
      "Epoch: 9, Loss: 1.466647982597351, Validation Accuracy: 0.524\n",
      "Epoch: 10, Loss: 1.3990954160690308, Validation Accuracy: 0.5479166666666667\n",
      "Epoch: 11, Loss: 1.3352965116500854, Validation Accuracy: 0.5693333333333334\n",
      "Epoch: 12, Loss: 1.2755545377731323, Validation Accuracy: 0.58825\n",
      "Epoch: 13, Loss: 1.2206310033798218, Validation Accuracy: 0.6065833333333334\n",
      "Epoch: 14, Loss: 1.1706390380859375, Validation Accuracy: 0.6254166666666666\n",
      "Epoch: 15, Loss: 1.1254351139068604, Validation Accuracy: 0.6408333333333334\n",
      "Epoch: 16, Loss: 1.084294319152832, Validation Accuracy: 0.652\n",
      "Epoch: 17, Loss: 1.0466912984848022, Validation Accuracy: 0.6588333333333334\n",
      "Epoch: 18, Loss: 1.01278555393219, Validation Accuracy: 0.6721666666666667\n",
      "Epoch: 19, Loss: 0.9835376143455505, Validation Accuracy: 0.6674166666666667\n",
      "Epoch: 20, Loss: 0.9648048281669617, Validation Accuracy: 0.6745\n",
      "Epoch: 21, Loss: 0.9649767875671387, Validation Accuracy: 0.6378333333333334\n",
      "Epoch: 22, Loss: 1.024290919303894, Validation Accuracy: 0.62\n",
      "Epoch: 23, Loss: 1.0782017707824707, Validation Accuracy: 0.5863333333333334\n",
      "Epoch: 24, Loss: 1.1764109134674072, Validation Accuracy: 0.67125\n",
      "Epoch: 25, Loss: 0.9267072081565857, Validation Accuracy: 0.7144166666666667\n",
      "Epoch: 26, Loss: 0.8438150882720947, Validation Accuracy: 0.7379166666666667\n",
      "Epoch: 27, Loss: 0.7974465489387512, Validation Accuracy: 0.7431666666666666\n",
      "Epoch: 28, Loss: 0.7719051837921143, Validation Accuracy: 0.7545833333333334\n",
      "Epoch: 29, Loss: 0.7529321312904358, Validation Accuracy: 0.7539166666666667\n",
      "Epoch: 30, Loss: 0.7386568784713745, Validation Accuracy: 0.76025\n",
      "Epoch: 31, Loss: 0.7356692552566528, Validation Accuracy: 0.752\n",
      "Epoch: 32, Loss: 0.7339141964912415, Validation Accuracy: 0.74975\n",
      "Epoch: 33, Loss: 0.7625627517700195, Validation Accuracy: 0.7395\n",
      "Epoch: 34, Loss: 0.7685616612434387, Validation Accuracy: 0.7318333333333333\n",
      "Epoch: 35, Loss: 0.8279933333396912, Validation Accuracy: 0.7321666666666666\n",
      "Epoch: 36, Loss: 0.7927073836326599, Validation Accuracy: 0.7473333333333333\n",
      "Epoch: 37, Loss: 0.7878658175468445, Validation Accuracy: 0.7541666666666667\n",
      "Epoch: 38, Loss: 0.7290137410163879, Validation Accuracy: 0.7791666666666667\n",
      "Epoch: 39, Loss: 0.6770543456077576, Validation Accuracy: 0.7769166666666667\n",
      "Epoch: 40, Loss: 0.6605298519134521, Validation Accuracy: 0.7829166666666667\n",
      "Epoch: 41, Loss: 0.6451045870780945, Validation Accuracy: 0.7736666666666666\n",
      "Epoch: 42, Loss: 0.6533956527709961, Validation Accuracy: 0.77675\n",
      "Epoch: 43, Loss: 0.6537950038909912, Validation Accuracy: 0.772\n",
      "Epoch: 44, Loss: 0.6595208048820496, Validation Accuracy: 0.7798333333333334\n",
      "Epoch: 45, Loss: 0.6433857083320618, Validation Accuracy: 0.7870833333333334\n",
      "Epoch: 46, Loss: 0.6216775178909302, Validation Accuracy: 0.8040833333333334\n",
      "Epoch: 47, Loss: 0.5880008339881897, Validation Accuracy: 0.8128333333333333\n",
      "Epoch: 48, Loss: 0.5608184933662415, Validation Accuracy: 0.82275\n",
      "Epoch: 49, Loss: 0.5365216732025146, Validation Accuracy: 0.832\n",
      "Epoch: 50, Loss: 0.5195193290710449, Validation Accuracy: 0.834\n",
      "Epoch: 51, Loss: 0.5058556199073792, Validation Accuracy: 0.8403333333333334\n",
      "Epoch: 52, Loss: 0.49528104066848755, Validation Accuracy: 0.8415833333333333\n",
      "Epoch: 53, Loss: 0.48625651001930237, Validation Accuracy: 0.8454166666666667\n",
      "Epoch: 54, Loss: 0.47855615615844727, Validation Accuracy: 0.846\n",
      "Epoch: 55, Loss: 0.47172048687934875, Validation Accuracy: 0.8491666666666666\n",
      "Epoch: 56, Loss: 0.4656335711479187, Validation Accuracy: 0.8508333333333333\n",
      "Epoch: 57, Loss: 0.4599209129810333, Validation Accuracy: 0.8538333333333333\n",
      "Epoch: 58, Loss: 0.4547426700592041, Validation Accuracy: 0.8536666666666667\n",
      "Epoch: 59, Loss: 0.4498738944530487, Validation Accuracy: 0.8565833333333334\n",
      "Epoch: 60, Loss: 0.4453659951686859, Validation Accuracy: 0.8579166666666667\n",
      "Epoch: 61, Loss: 0.4412509799003601, Validation Accuracy: 0.8595\n",
      "Epoch: 62, Loss: 0.4373420774936676, Validation Accuracy: 0.86025\n",
      "Epoch: 63, Loss: 0.4340711534023285, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 64, Loss: 0.4309968948364258, Validation Accuracy: 0.8605\n",
      "Epoch: 65, Loss: 0.42884117364883423, Validation Accuracy: 0.863\n",
      "Epoch: 66, Loss: 0.42656323313713074, Validation Accuracy: 0.8625\n",
      "Epoch: 67, Loss: 0.42591992020606995, Validation Accuracy: 0.8635\n",
      "Epoch: 68, Loss: 0.4243170917034149, Validation Accuracy: 0.8619166666666667\n",
      "Epoch: 69, Loss: 0.4256182312965393, Validation Accuracy: 0.8619166666666667\n",
      "Epoch: 70, Loss: 0.4245002865791321, Validation Accuracy: 0.8594166666666667\n",
      "Epoch: 71, Loss: 0.42784711718559265, Validation Accuracy: 0.8605833333333334\n",
      "Epoch: 72, Loss: 0.4261859953403473, Validation Accuracy: 0.8586666666666667\n",
      "Epoch: 73, Loss: 0.4302791357040405, Validation Accuracy: 0.8599166666666667\n",
      "Epoch: 74, Loss: 0.42582783102989197, Validation Accuracy: 0.8593333333333333\n",
      "Epoch: 75, Loss: 0.4275539219379425, Validation Accuracy: 0.8624166666666667\n",
      "Epoch: 76, Loss: 0.41961637139320374, Validation Accuracy: 0.8625\n",
      "Epoch: 77, Loss: 0.41715461015701294, Validation Accuracy: 0.8675\n",
      "Epoch: 78, Loss: 0.4076351225376129, Validation Accuracy: 0.8686666666666667\n",
      "Epoch: 79, Loss: 0.4025449752807617, Validation Accuracy: 0.8725833333333334\n",
      "Epoch: 80, Loss: 0.39412397146224976, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 81, Loss: 0.38887205719947815, Validation Accuracy: 0.8774166666666666\n",
      "Epoch: 82, Loss: 0.382405161857605, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 83, Loss: 0.37789207696914673, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 84, Loss: 0.372814416885376, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 85, Loss: 0.36907634139060974, Validation Accuracy: 0.88425\n",
      "Epoch: 86, Loss: 0.3651716411113739, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 87, Loss: 0.36199450492858887, Validation Accuracy: 0.8859166666666667\n",
      "Epoch: 88, Loss: 0.3587510287761688, Validation Accuracy: 0.88625\n",
      "Epoch: 89, Loss: 0.3559861183166504, Validation Accuracy: 0.8883333333333333\n",
      "Epoch: 90, Loss: 0.353211373090744, Validation Accuracy: 0.88725\n",
      "Epoch: 91, Loss: 0.3507521152496338, Validation Accuracy: 0.8890833333333333\n",
      "Epoch: 92, Loss: 0.3483325242996216, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 93, Loss: 0.3460732102394104, Validation Accuracy: 0.8904166666666666\n",
      "Epoch: 94, Loss: 0.34388530254364014, Validation Accuracy: 0.89\n",
      "Epoch: 95, Loss: 0.34181371331214905, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 96, Loss: 0.3397519886493683, Validation Accuracy: 0.8915\n",
      "Epoch: 97, Loss: 0.3378256857395172, Validation Accuracy: 0.8929166666666667\n",
      "Epoch: 98, Loss: 0.3358781337738037, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 99, Loss: 0.3340672254562378, Validation Accuracy: 0.8945\n",
      "Dataset 74\n",
      "Epoch: 0, Loss: 3.2325077056884766, Validation Accuracy: 0.17158333333333334\n",
      "Epoch: 1, Loss: 2.5584094524383545, Validation Accuracy: 0.2653333333333333\n",
      "Epoch: 2, Loss: 2.0855352878570557, Validation Accuracy: 0.3343333333333333\n",
      "Epoch: 3, Loss: 1.877846360206604, Validation Accuracy: 0.44583333333333336\n",
      "Epoch: 4, Loss: 1.6328246593475342, Validation Accuracy: 0.4960833333333333\n",
      "Epoch: 5, Loss: 1.4989370107650757, Validation Accuracy: 0.5348333333333334\n",
      "Epoch: 6, Loss: 1.3888438940048218, Validation Accuracy: 0.5691666666666667\n",
      "Epoch: 7, Loss: 1.294951319694519, Validation Accuracy: 0.5955833333333334\n",
      "Epoch: 8, Loss: 1.213564157485962, Validation Accuracy: 0.61825\n",
      "Epoch: 9, Loss: 1.1421725749969482, Validation Accuracy: 0.643\n",
      "Epoch: 10, Loss: 1.0809974670410156, Validation Accuracy: 0.6553333333333333\n",
      "Epoch: 11, Loss: 1.0348697900772095, Validation Accuracy: 0.6604166666666667\n",
      "Epoch: 12, Loss: 1.0183298587799072, Validation Accuracy: 0.6246666666666667\n",
      "Epoch: 13, Loss: 1.0878028869628906, Validation Accuracy: 0.5750833333333333\n",
      "Epoch: 14, Loss: 1.2296403646469116, Validation Accuracy: 0.5163333333333333\n",
      "Epoch: 15, Loss: 1.3997740745544434, Validation Accuracy: 0.64675\n",
      "Epoch: 16, Loss: 1.0260515213012695, Validation Accuracy: 0.7361666666666666\n",
      "Epoch: 17, Loss: 0.8414333462715149, Validation Accuracy: 0.752\n",
      "Epoch: 18, Loss: 0.7861893177032471, Validation Accuracy: 0.7618333333333334\n",
      "Epoch: 19, Loss: 0.7492914795875549, Validation Accuracy: 0.773\n",
      "Epoch: 20, Loss: 0.7204602956771851, Validation Accuracy: 0.7804166666666666\n",
      "Epoch: 21, Loss: 0.6956232190132141, Validation Accuracy: 0.78725\n",
      "Epoch: 22, Loss: 0.6736108064651489, Validation Accuracy: 0.7943333333333333\n",
      "Epoch: 23, Loss: 0.6537778973579407, Validation Accuracy: 0.7991666666666667\n",
      "Epoch: 24, Loss: 0.6357535719871521, Validation Accuracy: 0.8058333333333333\n",
      "Epoch: 25, Loss: 0.6192131042480469, Validation Accuracy: 0.8105833333333333\n",
      "Epoch: 26, Loss: 0.6040083169937134, Validation Accuracy: 0.8145\n",
      "Epoch: 27, Loss: 0.5899457335472107, Validation Accuracy: 0.8191666666666667\n",
      "Epoch: 28, Loss: 0.576859712600708, Validation Accuracy: 0.8233333333333334\n",
      "Epoch: 29, Loss: 0.5647090077400208, Validation Accuracy: 0.8245\n",
      "Epoch: 30, Loss: 0.5534620881080627, Validation Accuracy: 0.8294166666666667\n",
      "Epoch: 31, Loss: 0.5430788397789001, Validation Accuracy: 0.82925\n",
      "Epoch: 32, Loss: 0.5335844159126282, Validation Accuracy: 0.8356666666666667\n",
      "Epoch: 33, Loss: 0.5249821543693542, Validation Accuracy: 0.8355833333333333\n",
      "Epoch: 34, Loss: 0.517370879650116, Validation Accuracy: 0.8384166666666667\n",
      "Epoch: 35, Loss: 0.5109634399414062, Validation Accuracy: 0.8406666666666667\n",
      "Epoch: 36, Loss: 0.5059271454811096, Validation Accuracy: 0.8393333333333334\n",
      "Epoch: 37, Loss: 0.5032787919044495, Validation Accuracy: 0.8418333333333333\n",
      "Epoch: 38, Loss: 0.5025427937507629, Validation Accuracy: 0.8401666666666666\n",
      "Epoch: 39, Loss: 0.5058422684669495, Validation Accuracy: 0.8380833333333333\n",
      "Epoch: 40, Loss: 0.5123198628425598, Validation Accuracy: 0.8291666666666667\n",
      "Epoch: 41, Loss: 0.5256081223487854, Validation Accuracy: 0.8279166666666666\n",
      "Epoch: 42, Loss: 0.5408477187156677, Validation Accuracy: 0.8178333333333333\n",
      "Epoch: 43, Loss: 0.5590448379516602, Validation Accuracy: 0.8171666666666667\n",
      "Epoch: 44, Loss: 0.565003514289856, Validation Accuracy: 0.8164166666666667\n",
      "Epoch: 45, Loss: 0.5593053102493286, Validation Accuracy: 0.8298333333333333\n",
      "Epoch: 46, Loss: 0.5314019918441772, Validation Accuracy: 0.8403333333333334\n",
      "Epoch: 47, Loss: 0.4969624876976013, Validation Accuracy: 0.8521666666666666\n",
      "Epoch: 48, Loss: 0.4658653438091278, Validation Accuracy: 0.862\n",
      "Epoch: 49, Loss: 0.44487980008125305, Validation Accuracy: 0.86525\n",
      "Epoch: 50, Loss: 0.43184611201286316, Validation Accuracy: 0.86925\n",
      "Epoch: 51, Loss: 0.42307689785957336, Validation Accuracy: 0.871\n",
      "Epoch: 52, Loss: 0.416858971118927, Validation Accuracy: 0.8733333333333333\n",
      "Epoch: 53, Loss: 0.41184961795806885, Validation Accuracy: 0.8745\n",
      "Epoch: 54, Loss: 0.4074728190898895, Validation Accuracy: 0.8750833333333333\n",
      "Epoch: 55, Loss: 0.4035227596759796, Validation Accuracy: 0.8766666666666667\n",
      "Epoch: 56, Loss: 0.3998306393623352, Validation Accuracy: 0.87725\n",
      "Epoch: 57, Loss: 0.3963550925254822, Validation Accuracy: 0.8781666666666667\n",
      "Epoch: 58, Loss: 0.3930343687534332, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 59, Loss: 0.3898583650588989, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 60, Loss: 0.38679957389831543, Validation Accuracy: 0.8815\n",
      "Epoch: 61, Loss: 0.3838404417037964, Validation Accuracy: 0.88225\n",
      "Epoch: 62, Loss: 0.3809840977191925, Validation Accuracy: 0.88325\n",
      "Epoch: 63, Loss: 0.37821316719055176, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 64, Loss: 0.37552517652511597, Validation Accuracy: 0.88475\n",
      "Epoch: 65, Loss: 0.3729130029678345, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 66, Loss: 0.37037280201911926, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 67, Loss: 0.3679018020629883, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 68, Loss: 0.36550214886665344, Validation Accuracy: 0.8883333333333333\n",
      "Epoch: 69, Loss: 0.36316797137260437, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 70, Loss: 0.3608919382095337, Validation Accuracy: 0.8900833333333333\n",
      "Epoch: 71, Loss: 0.3586714267730713, Validation Accuracy: 0.8905\n",
      "Epoch: 72, Loss: 0.356501966714859, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 73, Loss: 0.35438719391822815, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 74, Loss: 0.35232698917388916, Validation Accuracy: 0.89225\n",
      "Epoch: 75, Loss: 0.3503110408782959, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 76, Loss: 0.3483439087867737, Validation Accuracy: 0.89325\n",
      "Epoch: 77, Loss: 0.34641972184181213, Validation Accuracy: 0.89375\n",
      "Epoch: 78, Loss: 0.34453529119491577, Validation Accuracy: 0.8939166666666667\n",
      "Epoch: 79, Loss: 0.34268924593925476, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 80, Loss: 0.3408832252025604, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 81, Loss: 0.3391154110431671, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 82, Loss: 0.33738139271736145, Validation Accuracy: 0.8973333333333333\n",
      "Epoch: 83, Loss: 0.33568036556243896, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 84, Loss: 0.33401021361351013, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 85, Loss: 0.3323661983013153, Validation Accuracy: 0.89925\n",
      "Epoch: 86, Loss: 0.3307468593120575, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 87, Loss: 0.329152375459671, Validation Accuracy: 0.9000833333333333\n",
      "Epoch: 88, Loss: 0.32758629322052, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 89, Loss: 0.32604801654815674, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 90, Loss: 0.324540913105011, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 91, Loss: 0.32305908203125, Validation Accuracy: 0.90225\n",
      "Epoch: 92, Loss: 0.3215993344783783, Validation Accuracy: 0.90275\n",
      "Epoch: 93, Loss: 0.32016506791114807, Validation Accuracy: 0.9026666666666666\n",
      "Epoch: 94, Loss: 0.3187524676322937, Validation Accuracy: 0.90325\n",
      "Epoch: 95, Loss: 0.31736090779304504, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 96, Loss: 0.3159918487071991, Validation Accuracy: 0.90325\n",
      "Epoch: 97, Loss: 0.314642071723938, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 98, Loss: 0.313313364982605, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 99, Loss: 0.3120094835758209, Validation Accuracy: 0.9038333333333334\n",
      "Dataset 75\n",
      "Epoch: 0, Loss: 3.4103140830993652, Validation Accuracy: 0.20225\n",
      "Epoch: 1, Loss: 2.659179925918579, Validation Accuracy: 0.2778333333333333\n",
      "Epoch: 2, Loss: 2.017723560333252, Validation Accuracy: 0.42133333333333334\n",
      "Epoch: 3, Loss: 1.6966636180877686, Validation Accuracy: 0.4588333333333333\n",
      "Epoch: 4, Loss: 1.5493242740631104, Validation Accuracy: 0.5069166666666667\n",
      "Epoch: 5, Loss: 1.4319236278533936, Validation Accuracy: 0.5345833333333333\n",
      "Epoch: 6, Loss: 1.333301067352295, Validation Accuracy: 0.5606666666666666\n",
      "Epoch: 7, Loss: 1.2586947679519653, Validation Accuracy: 0.5648333333333333\n",
      "Epoch: 8, Loss: 1.219372034072876, Validation Accuracy: 0.5598333333333333\n",
      "Epoch: 9, Loss: 1.2267321348190308, Validation Accuracy: 0.5538333333333333\n",
      "Epoch: 10, Loss: 1.228147029876709, Validation Accuracy: 0.5766666666666667\n",
      "Epoch: 11, Loss: 1.161737322807312, Validation Accuracy: 0.6334166666666666\n",
      "Epoch: 12, Loss: 1.0433913469314575, Validation Accuracy: 0.6745\n",
      "Epoch: 13, Loss: 0.9377066493034363, Validation Accuracy: 0.7046666666666667\n",
      "Epoch: 14, Loss: 0.8705665469169617, Validation Accuracy: 0.7185\n",
      "Epoch: 15, Loss: 0.8282894492149353, Validation Accuracy: 0.733\n",
      "Epoch: 16, Loss: 0.7960230112075806, Validation Accuracy: 0.7326666666666667\n",
      "Epoch: 17, Loss: 0.7861036658287048, Validation Accuracy: 0.74025\n",
      "Epoch: 18, Loss: 0.776831865310669, Validation Accuracy: 0.715\n",
      "Epoch: 19, Loss: 0.8136269450187683, Validation Accuracy: 0.7246666666666667\n",
      "Epoch: 20, Loss: 0.8102864623069763, Validation Accuracy: 0.6945833333333333\n",
      "Epoch: 21, Loss: 0.8509310483932495, Validation Accuracy: 0.74425\n",
      "Epoch: 22, Loss: 0.7673128843307495, Validation Accuracy: 0.7505\n",
      "Epoch: 23, Loss: 0.717218279838562, Validation Accuracy: 0.791\n",
      "Epoch: 24, Loss: 0.6480669379234314, Validation Accuracy: 0.7914166666666667\n",
      "Epoch: 25, Loss: 0.6199693083763123, Validation Accuracy: 0.8078333333333333\n",
      "Epoch: 26, Loss: 0.596390426158905, Validation Accuracy: 0.8073333333333333\n",
      "Epoch: 27, Loss: 0.5807740688323975, Validation Accuracy: 0.8175\n",
      "Epoch: 28, Loss: 0.5667031407356262, Validation Accuracy: 0.8179166666666666\n",
      "Epoch: 29, Loss: 0.5547861456871033, Validation Accuracy: 0.8236666666666667\n",
      "Epoch: 30, Loss: 0.5438825488090515, Validation Accuracy: 0.8246666666666667\n",
      "Epoch: 31, Loss: 0.5340903401374817, Validation Accuracy: 0.8295\n",
      "Epoch: 32, Loss: 0.5248614549636841, Validation Accuracy: 0.8313333333333334\n",
      "Epoch: 33, Loss: 0.5164903402328491, Validation Accuracy: 0.8336666666666667\n",
      "Epoch: 34, Loss: 0.5085455179214478, Validation Accuracy: 0.8380833333333333\n",
      "Epoch: 35, Loss: 0.5012513399124146, Validation Accuracy: 0.8391666666666666\n",
      "Epoch: 36, Loss: 0.49438807368278503, Validation Accuracy: 0.84275\n",
      "Epoch: 37, Loss: 0.4879938066005707, Validation Accuracy: 0.84325\n",
      "Epoch: 38, Loss: 0.48207882046699524, Validation Accuracy: 0.8461666666666666\n",
      "Epoch: 39, Loss: 0.47650256752967834, Validation Accuracy: 0.8470833333333333\n",
      "Epoch: 40, Loss: 0.4715428948402405, Validation Accuracy: 0.84925\n",
      "Epoch: 41, Loss: 0.46685802936553955, Validation Accuracy: 0.84975\n",
      "Epoch: 42, Loss: 0.46319323778152466, Validation Accuracy: 0.8530833333333333\n",
      "Epoch: 43, Loss: 0.45923465490341187, Validation Accuracy: 0.8524166666666667\n",
      "Epoch: 44, Loss: 0.45705506205558777, Validation Accuracy: 0.8539166666666667\n",
      "Epoch: 45, Loss: 0.4538741409778595, Validation Accuracy: 0.8546666666666667\n",
      "Epoch: 46, Loss: 0.45314306020736694, Validation Accuracy: 0.8551666666666666\n",
      "Epoch: 47, Loss: 0.4504638612270355, Validation Accuracy: 0.8563333333333333\n",
      "Epoch: 48, Loss: 0.45117756724357605, Validation Accuracy: 0.8554166666666667\n",
      "Epoch: 49, Loss: 0.4482481777667999, Validation Accuracy: 0.85675\n",
      "Epoch: 50, Loss: 0.44949206709861755, Validation Accuracy: 0.8574166666666667\n",
      "Epoch: 51, Loss: 0.44482988119125366, Validation Accuracy: 0.8588333333333333\n",
      "Epoch: 52, Loss: 0.4447069764137268, Validation Accuracy: 0.8586666666666667\n",
      "Epoch: 53, Loss: 0.43777522444725037, Validation Accuracy: 0.8623333333333333\n",
      "Epoch: 54, Loss: 0.4350891411304474, Validation Accuracy: 0.8625\n",
      "Epoch: 55, Loss: 0.42701008915901184, Validation Accuracy: 0.8665833333333334\n",
      "Epoch: 56, Loss: 0.4220467209815979, Validation Accuracy: 0.8678333333333333\n",
      "Epoch: 57, Loss: 0.4140150547027588, Validation Accuracy: 0.87175\n",
      "Epoch: 58, Loss: 0.40817904472351074, Validation Accuracy: 0.8729166666666667\n",
      "Epoch: 59, Loss: 0.4012407958507538, Validation Accuracy: 0.8755\n",
      "Epoch: 60, Loss: 0.39600786566734314, Validation Accuracy: 0.8770833333333333\n",
      "Epoch: 61, Loss: 0.3904765546321869, Validation Accuracy: 0.87925\n",
      "Epoch: 62, Loss: 0.3860127031803131, Validation Accuracy: 0.88\n",
      "Epoch: 63, Loss: 0.3815084993839264, Validation Accuracy: 0.8815\n",
      "Epoch: 64, Loss: 0.37773391604423523, Validation Accuracy: 0.883\n",
      "Epoch: 65, Loss: 0.37403881549835205, Validation Accuracy: 0.885\n",
      "Epoch: 66, Loss: 0.37082767486572266, Validation Accuracy: 0.8854166666666666\n",
      "Epoch: 67, Loss: 0.3676675260066986, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 68, Loss: 0.3648044168949127, Validation Accuracy: 0.8873333333333333\n",
      "Epoch: 69, Loss: 0.3620133101940155, Validation Accuracy: 0.88875\n",
      "Epoch: 70, Loss: 0.35942521691322327, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 71, Loss: 0.3568877875804901, Validation Accuracy: 0.89\n",
      "Epoch: 72, Loss: 0.354481965303421, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 73, Loss: 0.35215282440185547, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 74, Loss: 0.3499070703983307, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 75, Loss: 0.34769177436828613, Validation Accuracy: 0.892\n",
      "Epoch: 76, Loss: 0.3455796241760254, Validation Accuracy: 0.893\n",
      "Epoch: 77, Loss: 0.34350404143333435, Validation Accuracy: 0.89325\n",
      "Epoch: 78, Loss: 0.3415051996707916, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 79, Loss: 0.3395291268825531, Validation Accuracy: 0.89375\n",
      "Epoch: 80, Loss: 0.3376195430755615, Validation Accuracy: 0.89575\n",
      "Epoch: 81, Loss: 0.3357268273830414, Validation Accuracy: 0.8955\n",
      "Epoch: 82, Loss: 0.33388450741767883, Validation Accuracy: 0.897\n",
      "Epoch: 83, Loss: 0.3320748209953308, Validation Accuracy: 0.89625\n",
      "Epoch: 84, Loss: 0.33030179142951965, Validation Accuracy: 0.8978333333333334\n",
      "Epoch: 85, Loss: 0.3285489082336426, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 86, Loss: 0.32684075832366943, Validation Accuracy: 0.8985\n",
      "Epoch: 87, Loss: 0.325155645608902, Validation Accuracy: 0.8985\n",
      "Epoch: 88, Loss: 0.3235202133655548, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 89, Loss: 0.3218962550163269, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 90, Loss: 0.32031792402267456, Validation Accuracy: 0.9001666666666667\n",
      "Epoch: 91, Loss: 0.31876257061958313, Validation Accuracy: 0.89975\n",
      "Epoch: 92, Loss: 0.31724581122398376, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 93, Loss: 0.31575214862823486, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 94, Loss: 0.31428736448287964, Validation Accuracy: 0.9016666666666666\n",
      "Epoch: 95, Loss: 0.3128513693809509, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 96, Loss: 0.3114471733570099, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 97, Loss: 0.31006139516830444, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 98, Loss: 0.30869773030281067, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 99, Loss: 0.30735379457473755, Validation Accuracy: 0.904\n",
      "Dataset 76\n",
      "Epoch: 0, Loss: 3.818742513656616, Validation Accuracy: 0.166\n",
      "Epoch: 1, Loss: 2.7854862213134766, Validation Accuracy: 0.19133333333333333\n",
      "Epoch: 2, Loss: 2.7716927528381348, Validation Accuracy: 0.21716666666666667\n",
      "Epoch: 3, Loss: 3.7979605197906494, Validation Accuracy: 0.32375\n",
      "Epoch: 4, Loss: 1.9048818349838257, Validation Accuracy: 0.42225\n",
      "Epoch: 5, Loss: 1.675648808479309, Validation Accuracy: 0.4653333333333333\n",
      "Epoch: 6, Loss: 1.5571177005767822, Validation Accuracy: 0.5096666666666667\n",
      "Epoch: 7, Loss: 1.4660340547561646, Validation Accuracy: 0.5300833333333334\n",
      "Epoch: 8, Loss: 1.3811336755752563, Validation Accuracy: 0.563\n",
      "Epoch: 9, Loss: 1.3084149360656738, Validation Accuracy: 0.5738333333333333\n",
      "Epoch: 10, Loss: 1.2445148229599, Validation Accuracy: 0.5884166666666667\n",
      "Epoch: 11, Loss: 1.1969068050384521, Validation Accuracy: 0.5985\n",
      "Epoch: 12, Loss: 1.1569690704345703, Validation Accuracy: 0.6035\n",
      "Epoch: 13, Loss: 1.1320383548736572, Validation Accuracy: 0.6145833333333334\n",
      "Epoch: 14, Loss: 1.1141889095306396, Validation Accuracy: 0.6065833333333334\n",
      "Epoch: 15, Loss: 1.1046470403671265, Validation Accuracy: 0.6208333333333333\n",
      "Epoch: 16, Loss: 1.086522102355957, Validation Accuracy: 0.6275833333333334\n",
      "Epoch: 17, Loss: 1.0515369176864624, Validation Accuracy: 0.6529166666666667\n",
      "Epoch: 18, Loss: 0.998173177242279, Validation Accuracy: 0.67075\n",
      "Epoch: 19, Loss: 0.946466326713562, Validation Accuracy: 0.692\n",
      "Epoch: 20, Loss: 0.900911271572113, Validation Accuracy: 0.7060833333333333\n",
      "Epoch: 21, Loss: 0.866418719291687, Validation Accuracy: 0.7150833333333333\n",
      "Epoch: 22, Loss: 0.8351982235908508, Validation Accuracy: 0.7255833333333334\n",
      "Epoch: 23, Loss: 0.8115907311439514, Validation Accuracy: 0.7308333333333333\n",
      "Epoch: 24, Loss: 0.7883481383323669, Validation Accuracy: 0.7390833333333333\n",
      "Epoch: 25, Loss: 0.7721481919288635, Validation Accuracy: 0.7433333333333333\n",
      "Epoch: 26, Loss: 0.7523676753044128, Validation Accuracy: 0.74875\n",
      "Epoch: 27, Loss: 0.7416883707046509, Validation Accuracy: 0.7518333333333334\n",
      "Epoch: 28, Loss: 0.7231796979904175, Validation Accuracy: 0.756\n",
      "Epoch: 29, Loss: 0.7153876423835754, Validation Accuracy: 0.75925\n",
      "Epoch: 30, Loss: 0.6959583163261414, Validation Accuracy: 0.7644166666666666\n",
      "Epoch: 31, Loss: 0.6879042983055115, Validation Accuracy: 0.7703333333333333\n",
      "Epoch: 32, Loss: 0.667107343673706, Validation Accuracy: 0.7745\n",
      "Epoch: 33, Loss: 0.6571944355964661, Validation Accuracy: 0.7824166666666666\n",
      "Epoch: 34, Loss: 0.6360207200050354, Validation Accuracy: 0.7880833333333334\n",
      "Epoch: 35, Loss: 0.6247639656066895, Validation Accuracy: 0.7926666666666666\n",
      "Epoch: 36, Loss: 0.6056427359580994, Validation Accuracy: 0.7999166666666667\n",
      "Epoch: 37, Loss: 0.5949137806892395, Validation Accuracy: 0.8035\n",
      "Epoch: 38, Loss: 0.5788942575454712, Validation Accuracy: 0.8091666666666667\n",
      "Epoch: 39, Loss: 0.5696985125541687, Validation Accuracy: 0.8106666666666666\n",
      "Epoch: 40, Loss: 0.5563567876815796, Validation Accuracy: 0.8169166666666666\n",
      "Epoch: 41, Loss: 0.5489637851715088, Validation Accuracy: 0.8183333333333334\n",
      "Epoch: 42, Loss: 0.537983238697052, Validation Accuracy: 0.8221666666666667\n",
      "Epoch: 43, Loss: 0.5318819284439087, Validation Accuracy: 0.8236666666666667\n",
      "Epoch: 44, Loss: 0.5221885442733765, Validation Accuracy: 0.8285\n",
      "Epoch: 45, Loss: 0.5170494318008423, Validation Accuracy: 0.8278333333333333\n",
      "Epoch: 46, Loss: 0.5080812573432922, Validation Accuracy: 0.8341666666666666\n",
      "Epoch: 47, Loss: 0.5035049915313721, Validation Accuracy: 0.8306666666666667\n",
      "Epoch: 48, Loss: 0.49524417519569397, Validation Accuracy: 0.8383333333333334\n",
      "Epoch: 49, Loss: 0.4911439120769501, Validation Accuracy: 0.8350833333333333\n",
      "Epoch: 50, Loss: 0.48327070474624634, Validation Accuracy: 0.84275\n",
      "Epoch: 51, Loss: 0.47934114933013916, Validation Accuracy: 0.8405\n",
      "Epoch: 52, Loss: 0.4717901647090912, Validation Accuracy: 0.8465833333333334\n",
      "Epoch: 53, Loss: 0.46772700548171997, Validation Accuracy: 0.8443333333333334\n",
      "Epoch: 54, Loss: 0.4604395031929016, Validation Accuracy: 0.8504166666666667\n",
      "Epoch: 55, Loss: 0.4563876986503601, Validation Accuracy: 0.8479166666666667\n",
      "Epoch: 56, Loss: 0.44927722215652466, Validation Accuracy: 0.855\n",
      "Epoch: 57, Loss: 0.4449932873249054, Validation Accuracy: 0.8533333333333334\n",
      "Epoch: 58, Loss: 0.43828055262565613, Validation Accuracy: 0.8585833333333334\n",
      "Epoch: 59, Loss: 0.43397244811058044, Validation Accuracy: 0.8565\n",
      "Epoch: 60, Loss: 0.4278009831905365, Validation Accuracy: 0.86175\n",
      "Epoch: 61, Loss: 0.42345693707466125, Validation Accuracy: 0.8613333333333333\n",
      "Epoch: 62, Loss: 0.4179336428642273, Validation Accuracy: 0.8645\n",
      "Epoch: 63, Loss: 0.4139101207256317, Validation Accuracy: 0.8655833333333334\n",
      "Epoch: 64, Loss: 0.4089888632297516, Validation Accuracy: 0.867\n",
      "Epoch: 65, Loss: 0.40519434213638306, Validation Accuracy: 0.8689166666666667\n",
      "Epoch: 66, Loss: 0.4007546305656433, Validation Accuracy: 0.8695\n",
      "Epoch: 67, Loss: 0.3972497284412384, Validation Accuracy: 0.87125\n",
      "Epoch: 68, Loss: 0.3931877911090851, Validation Accuracy: 0.873\n",
      "Epoch: 69, Loss: 0.389929860830307, Validation Accuracy: 0.87375\n",
      "Epoch: 70, Loss: 0.38621407747268677, Validation Accuracy: 0.8756666666666667\n",
      "Epoch: 71, Loss: 0.38313359022140503, Validation Accuracy: 0.87575\n",
      "Epoch: 72, Loss: 0.37973901629447937, Validation Accuracy: 0.8776666666666667\n",
      "Epoch: 73, Loss: 0.37680575251579285, Validation Accuracy: 0.87825\n",
      "Epoch: 74, Loss: 0.3735792338848114, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 75, Loss: 0.3708122968673706, Validation Accuracy: 0.8795833333333334\n",
      "Epoch: 76, Loss: 0.36785396933555603, Validation Accuracy: 0.88\n",
      "Epoch: 77, Loss: 0.36527368426322937, Validation Accuracy: 0.881\n",
      "Epoch: 78, Loss: 0.36248400807380676, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 79, Loss: 0.3600352704524994, Validation Accuracy: 0.88325\n",
      "Epoch: 80, Loss: 0.35737812519073486, Validation Accuracy: 0.8845833333333334\n",
      "Epoch: 81, Loss: 0.35505807399749756, Validation Accuracy: 0.8846666666666667\n",
      "Epoch: 82, Loss: 0.3525821268558502, Validation Accuracy: 0.8864166666666666\n",
      "Epoch: 83, Loss: 0.35031798481941223, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 84, Loss: 0.34796229004859924, Validation Accuracy: 0.88775\n",
      "Epoch: 85, Loss: 0.3457968235015869, Validation Accuracy: 0.88825\n",
      "Epoch: 86, Loss: 0.34359732270240784, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 87, Loss: 0.341523677110672, Validation Accuracy: 0.88925\n",
      "Epoch: 88, Loss: 0.3394108712673187, Validation Accuracy: 0.89\n",
      "Epoch: 89, Loss: 0.33743536472320557, Validation Accuracy: 0.8903333333333333\n",
      "Epoch: 90, Loss: 0.3354063928127289, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 91, Loss: 0.3335144817829132, Validation Accuracy: 0.891\n",
      "Epoch: 92, Loss: 0.33159339427948, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 93, Loss: 0.32978054881095886, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 94, Loss: 0.3279554843902588, Validation Accuracy: 0.8925\n",
      "Epoch: 95, Loss: 0.3262362778186798, Validation Accuracy: 0.8929166666666667\n",
      "Epoch: 96, Loss: 0.32448482513427734, Validation Accuracy: 0.89275\n",
      "Epoch: 97, Loss: 0.3228391408920288, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 98, Loss: 0.32116004824638367, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 99, Loss: 0.31957072019577026, Validation Accuracy: 0.8935\n",
      "Dataset 77\n",
      "Epoch: 0, Loss: 3.7395529747009277, Validation Accuracy: 0.11066666666666666\n",
      "Epoch: 1, Loss: 3.1234488487243652, Validation Accuracy: 0.23841666666666667\n",
      "Epoch: 2, Loss: 2.2403981685638428, Validation Accuracy: 0.35191666666666666\n",
      "Epoch: 3, Loss: 1.8655164241790771, Validation Accuracy: 0.41625\n",
      "Epoch: 4, Loss: 1.6901487112045288, Validation Accuracy: 0.47258333333333336\n",
      "Epoch: 5, Loss: 1.5605278015136719, Validation Accuracy: 0.5095833333333334\n",
      "Epoch: 6, Loss: 1.447218894958496, Validation Accuracy: 0.5504166666666667\n",
      "Epoch: 7, Loss: 1.3460081815719604, Validation Accuracy: 0.5836666666666667\n",
      "Epoch: 8, Loss: 1.2617661952972412, Validation Accuracy: 0.57375\n",
      "Epoch: 9, Loss: 1.238510012626648, Validation Accuracy: 0.6011666666666666\n",
      "Epoch: 10, Loss: 1.1924314498901367, Validation Accuracy: 0.5700833333333334\n",
      "Epoch: 11, Loss: 1.202662467956543, Validation Accuracy: 0.6506666666666666\n",
      "Epoch: 12, Loss: 1.0384647846221924, Validation Accuracy: 0.69425\n",
      "Epoch: 13, Loss: 0.910914957523346, Validation Accuracy: 0.7155\n",
      "Epoch: 14, Loss: 0.8461107015609741, Validation Accuracy: 0.7366666666666667\n",
      "Epoch: 15, Loss: 0.7885430455207825, Validation Accuracy: 0.7461666666666666\n",
      "Epoch: 16, Loss: 0.7524545788764954, Validation Accuracy: 0.7585\n",
      "Epoch: 17, Loss: 0.7145334482192993, Validation Accuracy: 0.7675833333333333\n",
      "Epoch: 18, Loss: 0.6906746625900269, Validation Accuracy: 0.7755\n",
      "Epoch: 19, Loss: 0.6667788624763489, Validation Accuracy: 0.779\n",
      "Epoch: 20, Loss: 0.652255654335022, Validation Accuracy: 0.7785833333333333\n",
      "Epoch: 21, Loss: 0.6426787972450256, Validation Accuracy: 0.7811666666666667\n",
      "Epoch: 22, Loss: 0.6433250904083252, Validation Accuracy: 0.76775\n",
      "Epoch: 23, Loss: 0.6567021012306213, Validation Accuracy: 0.7660833333333333\n",
      "Epoch: 24, Loss: 0.6732997894287109, Validation Accuracy: 0.7575\n",
      "Epoch: 25, Loss: 0.683440089225769, Validation Accuracy: 0.7676666666666667\n",
      "Epoch: 26, Loss: 0.664965808391571, Validation Accuracy: 0.7835833333333333\n",
      "Epoch: 27, Loss: 0.6193501949310303, Validation Accuracy: 0.8036666666666666\n",
      "Epoch: 28, Loss: 0.5758967399597168, Validation Accuracy: 0.8181666666666667\n",
      "Epoch: 29, Loss: 0.5417276620864868, Validation Accuracy: 0.8238333333333333\n",
      "Epoch: 30, Loss: 0.5205439925193787, Validation Accuracy: 0.8324166666666667\n",
      "Epoch: 31, Loss: 0.505529522895813, Validation Accuracy: 0.8344166666666667\n",
      "Epoch: 32, Loss: 0.4943905174732208, Validation Accuracy: 0.8396666666666667\n",
      "Epoch: 33, Loss: 0.48484089970588684, Validation Accuracy: 0.84025\n",
      "Epoch: 34, Loss: 0.47663256525993347, Validation Accuracy: 0.8444166666666667\n",
      "Epoch: 35, Loss: 0.4691615402698517, Validation Accuracy: 0.8459166666666667\n",
      "Epoch: 36, Loss: 0.4624064266681671, Validation Accuracy: 0.8490833333333333\n",
      "Epoch: 37, Loss: 0.45606619119644165, Validation Accuracy: 0.8516666666666667\n",
      "Epoch: 38, Loss: 0.4501693844795227, Validation Accuracy: 0.8540833333333333\n",
      "Epoch: 39, Loss: 0.44457677006721497, Validation Accuracy: 0.8555\n",
      "Epoch: 40, Loss: 0.4392792284488678, Validation Accuracy: 0.8580833333333333\n",
      "Epoch: 41, Loss: 0.43420106172561646, Validation Accuracy: 0.8588333333333333\n",
      "Epoch: 42, Loss: 0.42940905690193176, Validation Accuracy: 0.861\n",
      "Epoch: 43, Loss: 0.4247933030128479, Validation Accuracy: 0.8623333333333333\n",
      "Epoch: 44, Loss: 0.42040717601776123, Validation Accuracy: 0.8645833333333334\n",
      "Epoch: 45, Loss: 0.41618290543556213, Validation Accuracy: 0.8661666666666666\n",
      "Epoch: 46, Loss: 0.41213876008987427, Validation Accuracy: 0.8669166666666667\n",
      "Epoch: 47, Loss: 0.4082069396972656, Validation Accuracy: 0.8688333333333333\n",
      "Epoch: 48, Loss: 0.40443021059036255, Validation Accuracy: 0.8694166666666666\n",
      "Epoch: 49, Loss: 0.40082499384880066, Validation Accuracy: 0.8714166666666666\n",
      "Epoch: 50, Loss: 0.3973473012447357, Validation Accuracy: 0.8719166666666667\n",
      "Epoch: 51, Loss: 0.39400365948677063, Validation Accuracy: 0.87375\n",
      "Epoch: 52, Loss: 0.39076536893844604, Validation Accuracy: 0.8741666666666666\n",
      "Epoch: 53, Loss: 0.3876711130142212, Validation Accuracy: 0.87625\n",
      "Epoch: 54, Loss: 0.3847223222255707, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 55, Loss: 0.3819192349910736, Validation Accuracy: 0.8765833333333334\n",
      "Epoch: 56, Loss: 0.379302442073822, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 57, Loss: 0.3767833113670349, Validation Accuracy: 0.87775\n",
      "Epoch: 58, Loss: 0.37453997135162354, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 59, Loss: 0.372330904006958, Validation Accuracy: 0.87875\n",
      "Epoch: 60, Loss: 0.3705011010169983, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 61, Loss: 0.3686998784542084, Validation Accuracy: 0.8805\n",
      "Epoch: 62, Loss: 0.3672714829444885, Validation Accuracy: 0.8813333333333333\n",
      "Epoch: 63, Loss: 0.36593225598335266, Validation Accuracy: 0.8813333333333333\n",
      "Epoch: 64, Loss: 0.3650166690349579, Validation Accuracy: 0.8814166666666666\n",
      "Epoch: 65, Loss: 0.36426490545272827, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 66, Loss: 0.3639339208602905, Validation Accuracy: 0.8810833333333333\n",
      "Epoch: 67, Loss: 0.3637537360191345, Validation Accuracy: 0.88175\n",
      "Epoch: 68, Loss: 0.3637259602546692, Validation Accuracy: 0.8805\n",
      "Epoch: 69, Loss: 0.36378374695777893, Validation Accuracy: 0.88125\n",
      "Epoch: 70, Loss: 0.36397024989128113, Validation Accuracy: 0.88025\n",
      "Epoch: 71, Loss: 0.3639701008796692, Validation Accuracy: 0.8805833333333334\n",
      "Epoch: 72, Loss: 0.3637940585613251, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 73, Loss: 0.36310815811157227, Validation Accuracy: 0.8815\n",
      "Epoch: 74, Loss: 0.3615941107273102, Validation Accuracy: 0.88125\n",
      "Epoch: 75, Loss: 0.3594679832458496, Validation Accuracy: 0.8833333333333333\n",
      "Epoch: 76, Loss: 0.356240838766098, Validation Accuracy: 0.8835\n",
      "Epoch: 77, Loss: 0.35266223549842834, Validation Accuracy: 0.88575\n",
      "Epoch: 78, Loss: 0.34821638464927673, Validation Accuracy: 0.8864166666666666\n",
      "Epoch: 79, Loss: 0.3439353108406067, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 80, Loss: 0.33913183212280273, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 81, Loss: 0.33517342805862427, Validation Accuracy: 0.8914166666666666\n",
      "Epoch: 82, Loss: 0.33111757040023804, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 83, Loss: 0.32774078845977783, Validation Accuracy: 0.8944166666666666\n",
      "Epoch: 84, Loss: 0.32455649971961975, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 85, Loss: 0.3217920958995819, Validation Accuracy: 0.89675\n",
      "Epoch: 86, Loss: 0.3192121386528015, Validation Accuracy: 0.89525\n",
      "Epoch: 87, Loss: 0.316964328289032, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 88, Loss: 0.3148254156112671, Validation Accuracy: 0.897\n",
      "Epoch: 89, Loss: 0.31296980381011963, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 90, Loss: 0.31114956736564636, Validation Accuracy: 0.8979166666666667\n",
      "Epoch: 91, Loss: 0.3095022439956665, Validation Accuracy: 0.8996666666666666\n",
      "Epoch: 92, Loss: 0.30786871910095215, Validation Accuracy: 0.89925\n",
      "Epoch: 93, Loss: 0.30636492371559143, Validation Accuracy: 0.9005\n",
      "Epoch: 94, Loss: 0.3048524260520935, Validation Accuracy: 0.9006666666666666\n",
      "Epoch: 95, Loss: 0.3034612536430359, Validation Accuracy: 0.901\n",
      "Epoch: 96, Loss: 0.3020557165145874, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 97, Loss: 0.300727516412735, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 98, Loss: 0.2994194030761719, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 99, Loss: 0.29813799262046814, Validation Accuracy: 0.902\n",
      "Dataset 78\n",
      "Epoch: 0, Loss: 3.190315008163452, Validation Accuracy: 0.2781666666666667\n",
      "Epoch: 1, Loss: 2.139641523361206, Validation Accuracy: 0.37216666666666665\n",
      "Epoch: 2, Loss: 1.7638099193572998, Validation Accuracy: 0.4424166666666667\n",
      "Epoch: 3, Loss: 1.5630964040756226, Validation Accuracy: 0.5100833333333333\n",
      "Epoch: 4, Loss: 1.4138141870498657, Validation Accuracy: 0.5469166666666667\n",
      "Epoch: 5, Loss: 1.2934809923171997, Validation Accuracy: 0.5789166666666666\n",
      "Epoch: 6, Loss: 1.2116279602050781, Validation Accuracy: 0.58475\n",
      "Epoch: 7, Loss: 1.1654176712036133, Validation Accuracy: 0.6060833333333333\n",
      "Epoch: 8, Loss: 1.138243556022644, Validation Accuracy: 0.5991666666666666\n",
      "Epoch: 9, Loss: 1.1059277057647705, Validation Accuracy: 0.6475\n",
      "Epoch: 10, Loss: 1.0216363668441772, Validation Accuracy: 0.6741666666666667\n",
      "Epoch: 11, Loss: 0.9290604591369629, Validation Accuracy: 0.7058333333333333\n",
      "Epoch: 12, Loss: 0.8450359106063843, Validation Accuracy: 0.7293333333333333\n",
      "Epoch: 13, Loss: 0.7916228175163269, Validation Accuracy: 0.7410833333333333\n",
      "Epoch: 14, Loss: 0.7472134828567505, Validation Accuracy: 0.7549166666666667\n",
      "Epoch: 15, Loss: 0.7156583666801453, Validation Accuracy: 0.7645833333333333\n",
      "Epoch: 16, Loss: 0.6872547268867493, Validation Accuracy: 0.775\n",
      "Epoch: 17, Loss: 0.6642267107963562, Validation Accuracy: 0.7790833333333333\n",
      "Epoch: 18, Loss: 0.6433272957801819, Validation Accuracy: 0.7895833333333333\n",
      "Epoch: 19, Loss: 0.6250159740447998, Validation Accuracy: 0.7923333333333333\n",
      "Epoch: 20, Loss: 0.6083469390869141, Validation Accuracy: 0.79975\n",
      "Epoch: 21, Loss: 0.5931784510612488, Validation Accuracy: 0.8053333333333333\n",
      "Epoch: 22, Loss: 0.5793066620826721, Validation Accuracy: 0.809\n",
      "Epoch: 23, Loss: 0.5665665864944458, Validation Accuracy: 0.8136666666666666\n",
      "Epoch: 24, Loss: 0.5548369288444519, Validation Accuracy: 0.81825\n",
      "Epoch: 25, Loss: 0.5439565181732178, Validation Accuracy: 0.8214166666666667\n",
      "Epoch: 26, Loss: 0.5339229106903076, Validation Accuracy: 0.825\n",
      "Epoch: 27, Loss: 0.5246739387512207, Validation Accuracy: 0.8280833333333333\n",
      "Epoch: 28, Loss: 0.5162432789802551, Validation Accuracy: 0.8293333333333334\n",
      "Epoch: 29, Loss: 0.5085625648498535, Validation Accuracy: 0.8341666666666666\n",
      "Epoch: 30, Loss: 0.5017734169960022, Validation Accuracy: 0.8338333333333333\n",
      "Epoch: 31, Loss: 0.4959851801395416, Validation Accuracy: 0.838\n",
      "Epoch: 32, Loss: 0.4917721450328827, Validation Accuracy: 0.8376666666666667\n",
      "Epoch: 33, Loss: 0.4888891875743866, Validation Accuracy: 0.8395833333333333\n",
      "Epoch: 34, Loss: 0.48906245827674866, Validation Accuracy: 0.836\n",
      "Epoch: 35, Loss: 0.49028217792510986, Validation Accuracy: 0.8371666666666666\n",
      "Epoch: 36, Loss: 0.4964712858200073, Validation Accuracy: 0.83\n",
      "Epoch: 37, Loss: 0.5015437006950378, Validation Accuracy: 0.8308333333333333\n",
      "Epoch: 38, Loss: 0.5124189257621765, Validation Accuracy: 0.8255\n",
      "Epoch: 39, Loss: 0.5123400688171387, Validation Accuracy: 0.8305\n",
      "Epoch: 40, Loss: 0.5148665308952332, Validation Accuracy: 0.8310833333333333\n",
      "Epoch: 41, Loss: 0.49722957611083984, Validation Accuracy: 0.8414166666666667\n",
      "Epoch: 42, Loss: 0.4827355444431305, Validation Accuracy: 0.8465\n",
      "Epoch: 43, Loss: 0.4587119221687317, Validation Accuracy: 0.8558333333333333\n",
      "Epoch: 44, Loss: 0.44289514422416687, Validation Accuracy: 0.858\n",
      "Epoch: 45, Loss: 0.4286330044269562, Validation Accuracy: 0.8631666666666666\n",
      "Epoch: 46, Loss: 0.4197823107242584, Validation Accuracy: 0.86525\n",
      "Epoch: 47, Loss: 0.412557989358902, Validation Accuracy: 0.868\n",
      "Epoch: 48, Loss: 0.40700268745422363, Validation Accuracy: 0.87\n",
      "Epoch: 49, Loss: 0.4021468460559845, Validation Accuracy: 0.8715\n",
      "Epoch: 50, Loss: 0.39792105555534363, Validation Accuracy: 0.8728333333333333\n",
      "Epoch: 51, Loss: 0.39396214485168457, Validation Accuracy: 0.8743333333333333\n",
      "Epoch: 52, Loss: 0.39031681418418884, Validation Accuracy: 0.8753333333333333\n",
      "Epoch: 53, Loss: 0.38680726289749146, Validation Accuracy: 0.8766666666666667\n",
      "Epoch: 54, Loss: 0.38347920775413513, Validation Accuracy: 0.8771666666666667\n",
      "Epoch: 55, Loss: 0.3802982270717621, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 56, Loss: 0.37723204493522644, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 57, Loss: 0.3742673695087433, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 58, Loss: 0.3713884949684143, Validation Accuracy: 0.88125\n",
      "Epoch: 59, Loss: 0.36860448122024536, Validation Accuracy: 0.88275\n",
      "Epoch: 60, Loss: 0.3659047484397888, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 61, Loss: 0.36327579617500305, Validation Accuracy: 0.8841666666666667\n",
      "Epoch: 62, Loss: 0.3607236444950104, Validation Accuracy: 0.8845\n",
      "Epoch: 63, Loss: 0.3582388460636139, Validation Accuracy: 0.8855\n",
      "Epoch: 64, Loss: 0.355826199054718, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 65, Loss: 0.35347700119018555, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 66, Loss: 0.3511870205402374, Validation Accuracy: 0.8879166666666667\n",
      "Epoch: 67, Loss: 0.34894853830337524, Validation Accuracy: 0.8881666666666667\n",
      "Epoch: 68, Loss: 0.34676775336265564, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 69, Loss: 0.3446418046951294, Validation Accuracy: 0.88925\n",
      "Epoch: 70, Loss: 0.3425675332546234, Validation Accuracy: 0.8899166666666667\n",
      "Epoch: 71, Loss: 0.3405393660068512, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 72, Loss: 0.33855727314949036, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 73, Loss: 0.33661341667175293, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 74, Loss: 0.3347056806087494, Validation Accuracy: 0.89225\n",
      "Epoch: 75, Loss: 0.3328341245651245, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 76, Loss: 0.3309939503669739, Validation Accuracy: 0.8935\n",
      "Epoch: 77, Loss: 0.32919397950172424, Validation Accuracy: 0.89425\n",
      "Epoch: 78, Loss: 0.32742661237716675, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 79, Loss: 0.32568931579589844, Validation Accuracy: 0.895\n",
      "Epoch: 80, Loss: 0.3239840269088745, Validation Accuracy: 0.8951666666666667\n",
      "Epoch: 81, Loss: 0.3223035931587219, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 82, Loss: 0.3206552267074585, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 83, Loss: 0.31903672218322754, Validation Accuracy: 0.8971666666666667\n",
      "Epoch: 84, Loss: 0.3174397945404053, Validation Accuracy: 0.8971666666666667\n",
      "Epoch: 85, Loss: 0.315871000289917, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 86, Loss: 0.31432804465293884, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 87, Loss: 0.31281355023384094, Validation Accuracy: 0.899\n",
      "Epoch: 88, Loss: 0.3113219439983368, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 89, Loss: 0.3098592162132263, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 90, Loss: 0.3084210753440857, Validation Accuracy: 0.8995\n",
      "Epoch: 91, Loss: 0.3070085942745209, Validation Accuracy: 0.9001666666666667\n",
      "Epoch: 92, Loss: 0.3056198060512543, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 93, Loss: 0.30425140261650085, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 94, Loss: 0.3029021918773651, Validation Accuracy: 0.901\n",
      "Epoch: 95, Loss: 0.30157142877578735, Validation Accuracy: 0.9019166666666667\n",
      "Epoch: 96, Loss: 0.3002551198005676, Validation Accuracy: 0.90175\n",
      "Epoch: 97, Loss: 0.2989580035209656, Validation Accuracy: 0.9034166666666666\n",
      "Epoch: 98, Loss: 0.2976827621459961, Validation Accuracy: 0.903\n",
      "Epoch: 99, Loss: 0.29642489552497864, Validation Accuracy: 0.9046666666666666\n",
      "Dataset 79\n",
      "Epoch: 0, Loss: 3.4091548919677734, Validation Accuracy: 0.14291666666666666\n",
      "Epoch: 1, Loss: 2.767385721206665, Validation Accuracy: 0.23933333333333334\n",
      "Epoch: 2, Loss: 2.2142322063446045, Validation Accuracy: 0.3516666666666667\n",
      "Epoch: 3, Loss: 1.921492338180542, Validation Accuracy: 0.4305833333333333\n",
      "Epoch: 4, Loss: 1.656259298324585, Validation Accuracy: 0.47925\n",
      "Epoch: 5, Loss: 1.495633602142334, Validation Accuracy: 0.5296666666666666\n",
      "Epoch: 6, Loss: 1.3650262355804443, Validation Accuracy: 0.5689166666666666\n",
      "Epoch: 7, Loss: 1.2507215738296509, Validation Accuracy: 0.6143333333333333\n",
      "Epoch: 8, Loss: 1.1626338958740234, Validation Accuracy: 0.61925\n",
      "Epoch: 9, Loss: 1.1108646392822266, Validation Accuracy: 0.59975\n",
      "Epoch: 10, Loss: 1.1584919691085815, Validation Accuracy: 0.5680833333333334\n",
      "Epoch: 11, Loss: 1.2481244802474976, Validation Accuracy: 0.5645\n",
      "Epoch: 12, Loss: 1.2795910835266113, Validation Accuracy: 0.6646666666666666\n",
      "Epoch: 13, Loss: 0.9865003228187561, Validation Accuracy: 0.71375\n",
      "Epoch: 14, Loss: 0.8612087965011597, Validation Accuracy: 0.7384166666666667\n",
      "Epoch: 15, Loss: 0.8011408448219299, Validation Accuracy: 0.7459166666666667\n",
      "Epoch: 16, Loss: 0.7634450793266296, Validation Accuracy: 0.7589166666666667\n",
      "Epoch: 17, Loss: 0.7361720204353333, Validation Accuracy: 0.7614166666666666\n",
      "Epoch: 18, Loss: 0.7101684808731079, Validation Accuracy: 0.7730833333333333\n",
      "Epoch: 19, Loss: 0.6921894550323486, Validation Accuracy: 0.7704166666666666\n",
      "Epoch: 20, Loss: 0.674261212348938, Validation Accuracy: 0.7840833333333334\n",
      "Epoch: 21, Loss: 0.6609001159667969, Validation Accuracy: 0.7798333333333334\n",
      "Epoch: 22, Loss: 0.6461029648780823, Validation Accuracy: 0.7959166666666667\n",
      "Epoch: 23, Loss: 0.6328330039978027, Validation Accuracy: 0.7905833333333333\n",
      "Epoch: 24, Loss: 0.6165384650230408, Validation Accuracy: 0.8053333333333333\n",
      "Epoch: 25, Loss: 0.6006547212600708, Validation Accuracy: 0.80575\n",
      "Epoch: 26, Loss: 0.5823821425437927, Validation Accuracy: 0.8149166666666666\n",
      "Epoch: 27, Loss: 0.567656397819519, Validation Accuracy: 0.8143333333333334\n",
      "Epoch: 28, Loss: 0.5520471334457397, Validation Accuracy: 0.8223333333333334\n",
      "Epoch: 29, Loss: 0.5433223247528076, Validation Accuracy: 0.817\n",
      "Epoch: 30, Loss: 0.5357463955879211, Validation Accuracy: 0.8224166666666667\n",
      "Epoch: 31, Loss: 0.5396683216094971, Validation Accuracy: 0.814\n",
      "Epoch: 32, Loss: 0.5471687316894531, Validation Accuracy: 0.8083333333333333\n",
      "Epoch: 33, Loss: 0.5769424438476562, Validation Accuracy: 0.7955833333333333\n",
      "Epoch: 34, Loss: 0.5980173349380493, Validation Accuracy: 0.7793333333333333\n",
      "Epoch: 35, Loss: 0.6456749439239502, Validation Accuracy: 0.7855833333333333\n",
      "Epoch: 36, Loss: 0.6261917948722839, Validation Accuracy: 0.7935833333333333\n",
      "Epoch: 37, Loss: 0.6067627668380737, Validation Accuracy: 0.82075\n",
      "Epoch: 38, Loss: 0.536677360534668, Validation Accuracy: 0.8405833333333333\n",
      "Epoch: 39, Loss: 0.49114957451820374, Validation Accuracy: 0.8508333333333333\n",
      "Epoch: 40, Loss: 0.45945101976394653, Validation Accuracy: 0.85625\n",
      "Epoch: 41, Loss: 0.44361284375190735, Validation Accuracy: 0.8616666666666667\n",
      "Epoch: 42, Loss: 0.43328455090522766, Validation Accuracy: 0.86325\n",
      "Epoch: 43, Loss: 0.4259133040904999, Validation Accuracy: 0.867\n",
      "Epoch: 44, Loss: 0.41978463530540466, Validation Accuracy: 0.8676666666666667\n",
      "Epoch: 45, Loss: 0.4144256114959717, Validation Accuracy: 0.8703333333333333\n",
      "Epoch: 46, Loss: 0.40956810116767883, Validation Accuracy: 0.8711666666666666\n",
      "Epoch: 47, Loss: 0.40506604313850403, Validation Accuracy: 0.8725\n",
      "Epoch: 48, Loss: 0.4008288085460663, Validation Accuracy: 0.8738333333333334\n",
      "Epoch: 49, Loss: 0.3967934250831604, Validation Accuracy: 0.8754166666666666\n",
      "Epoch: 50, Loss: 0.39296162128448486, Validation Accuracy: 0.8755\n",
      "Epoch: 51, Loss: 0.38929417729377747, Validation Accuracy: 0.8770833333333333\n",
      "Epoch: 52, Loss: 0.3857790529727936, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 53, Loss: 0.38239747285842896, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 54, Loss: 0.37912875413894653, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 55, Loss: 0.3759702444076538, Validation Accuracy: 0.88175\n",
      "Epoch: 56, Loss: 0.3729185461997986, Validation Accuracy: 0.8825\n",
      "Epoch: 57, Loss: 0.369961678981781, Validation Accuracy: 0.8833333333333333\n",
      "Epoch: 58, Loss: 0.3670875132083893, Validation Accuracy: 0.88475\n",
      "Epoch: 59, Loss: 0.36428752541542053, Validation Accuracy: 0.8850833333333333\n",
      "Epoch: 60, Loss: 0.3615688383579254, Validation Accuracy: 0.88625\n",
      "Epoch: 61, Loss: 0.35892781615257263, Validation Accuracy: 0.8866666666666667\n",
      "Epoch: 62, Loss: 0.35634276270866394, Validation Accuracy: 0.8874166666666666\n",
      "Epoch: 63, Loss: 0.3538281321525574, Validation Accuracy: 0.8879166666666667\n",
      "Epoch: 64, Loss: 0.35137662291526794, Validation Accuracy: 0.8885\n",
      "Epoch: 65, Loss: 0.34898579120635986, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 66, Loss: 0.3466518521308899, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 67, Loss: 0.3443748652935028, Validation Accuracy: 0.89075\n",
      "Epoch: 68, Loss: 0.3421505093574524, Validation Accuracy: 0.892\n",
      "Epoch: 69, Loss: 0.339973509311676, Validation Accuracy: 0.8923333333333333\n",
      "Epoch: 70, Loss: 0.33784639835357666, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 71, Loss: 0.3357669711112976, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 72, Loss: 0.3337399959564209, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 73, Loss: 0.3317534327507019, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 74, Loss: 0.3298127353191376, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 75, Loss: 0.32791584730148315, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 76, Loss: 0.3260563611984253, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 77, Loss: 0.324230432510376, Validation Accuracy: 0.89725\n",
      "Epoch: 78, Loss: 0.32243624329566956, Validation Accuracy: 0.8975\n",
      "Epoch: 79, Loss: 0.3206753432750702, Validation Accuracy: 0.89825\n",
      "Epoch: 80, Loss: 0.3189516067504883, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 81, Loss: 0.31726327538490295, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 82, Loss: 0.31560686230659485, Validation Accuracy: 0.8996666666666666\n",
      "Epoch: 83, Loss: 0.31398245692253113, Validation Accuracy: 0.90075\n",
      "Epoch: 84, Loss: 0.3123861253261566, Validation Accuracy: 0.9005\n",
      "Epoch: 85, Loss: 0.3108120262622833, Validation Accuracy: 0.9015833333333333\n",
      "Epoch: 86, Loss: 0.30925676226615906, Validation Accuracy: 0.90175\n",
      "Epoch: 87, Loss: 0.30773085355758667, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 88, Loss: 0.30622783303260803, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 89, Loss: 0.304751455783844, Validation Accuracy: 0.9028333333333334\n",
      "Epoch: 90, Loss: 0.30329862236976624, Validation Accuracy: 0.9035\n",
      "Epoch: 91, Loss: 0.3018704950809479, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 92, Loss: 0.3004676401615143, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 93, Loss: 0.2990848124027252, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 94, Loss: 0.2977238595485687, Validation Accuracy: 0.90525\n",
      "Epoch: 95, Loss: 0.29638510942459106, Validation Accuracy: 0.9055\n",
      "Epoch: 96, Loss: 0.2950640618801117, Validation Accuracy: 0.90625\n",
      "Epoch: 97, Loss: 0.2937633991241455, Validation Accuracy: 0.90625\n",
      "Epoch: 98, Loss: 0.2924799919128418, Validation Accuracy: 0.9070833333333334\n",
      "Epoch: 99, Loss: 0.2912149727344513, Validation Accuracy: 0.9071666666666667\n",
      "Dataset 80\n",
      "Epoch: 0, Loss: 3.572399139404297, Validation Accuracy: 0.13275\n",
      "Epoch: 1, Loss: 3.3636956214904785, Validation Accuracy: 0.23041666666666666\n",
      "Epoch: 2, Loss: 2.385896682739258, Validation Accuracy: 0.30291666666666667\n",
      "Epoch: 3, Loss: 2.0976779460906982, Validation Accuracy: 0.33558333333333334\n",
      "Epoch: 4, Loss: 1.871798038482666, Validation Accuracy: 0.456\n",
      "Epoch: 5, Loss: 1.6103920936584473, Validation Accuracy: 0.5088333333333334\n",
      "Epoch: 6, Loss: 1.4784562587738037, Validation Accuracy: 0.5481666666666667\n",
      "Epoch: 7, Loss: 1.356734275817871, Validation Accuracy: 0.5754166666666667\n",
      "Epoch: 8, Loss: 1.2659097909927368, Validation Accuracy: 0.6046666666666667\n",
      "Epoch: 9, Loss: 1.1848114728927612, Validation Accuracy: 0.6205833333333334\n",
      "Epoch: 10, Loss: 1.1160894632339478, Validation Accuracy: 0.6441666666666667\n",
      "Epoch: 11, Loss: 1.0557063817977905, Validation Accuracy: 0.653\n",
      "Epoch: 12, Loss: 1.0049571990966797, Validation Accuracy: 0.6689166666666667\n",
      "Epoch: 13, Loss: 0.95957350730896, Validation Accuracy: 0.6759166666666667\n",
      "Epoch: 14, Loss: 0.9246326684951782, Validation Accuracy: 0.6806666666666666\n",
      "Epoch: 15, Loss: 0.901469886302948, Validation Accuracy: 0.6768333333333333\n",
      "Epoch: 16, Loss: 0.9029017686843872, Validation Accuracy: 0.6595833333333333\n",
      "Epoch: 17, Loss: 0.9392279386520386, Validation Accuracy: 0.6385833333333333\n",
      "Epoch: 18, Loss: 0.9998680949211121, Validation Accuracy: 0.6510833333333333\n",
      "Epoch: 19, Loss: 0.9502820372581482, Validation Accuracy: 0.6971666666666667\n",
      "Epoch: 20, Loss: 0.8560138940811157, Validation Accuracy: 0.7469166666666667\n",
      "Epoch: 21, Loss: 0.7363595366477966, Validation Accuracy: 0.7665\n",
      "Epoch: 22, Loss: 0.6906825304031372, Validation Accuracy: 0.7773333333333333\n",
      "Epoch: 23, Loss: 0.6564344763755798, Validation Accuracy: 0.78775\n",
      "Epoch: 24, Loss: 0.6318358182907104, Validation Accuracy: 0.7959166666666667\n",
      "Epoch: 25, Loss: 0.6097694635391235, Validation Accuracy: 0.8010833333333334\n",
      "Epoch: 26, Loss: 0.5913962721824646, Validation Accuracy: 0.8068333333333333\n",
      "Epoch: 27, Loss: 0.574944257736206, Validation Accuracy: 0.8095\n",
      "Epoch: 28, Loss: 0.5607699155807495, Validation Accuracy: 0.8155\n",
      "Epoch: 29, Loss: 0.547878086566925, Validation Accuracy: 0.8170833333333334\n",
      "Epoch: 30, Loss: 0.5367388129234314, Validation Accuracy: 0.8221666666666667\n",
      "Epoch: 31, Loss: 0.5266466736793518, Validation Accuracy: 0.8235833333333333\n",
      "Epoch: 32, Loss: 0.5177924633026123, Validation Accuracy: 0.82775\n",
      "Epoch: 33, Loss: 0.5097503066062927, Validation Accuracy: 0.8269166666666666\n",
      "Epoch: 34, Loss: 0.5023873448371887, Validation Accuracy: 0.8329166666666666\n",
      "Epoch: 35, Loss: 0.49526241421699524, Validation Accuracy: 0.8326666666666667\n",
      "Epoch: 36, Loss: 0.48846471309661865, Validation Accuracy: 0.8361666666666666\n",
      "Epoch: 37, Loss: 0.4817197322845459, Validation Accuracy: 0.8371666666666666\n",
      "Epoch: 38, Loss: 0.4748782813549042, Validation Accuracy: 0.8411666666666666\n",
      "Epoch: 39, Loss: 0.4679790735244751, Validation Accuracy: 0.8428333333333333\n",
      "Epoch: 40, Loss: 0.46062901616096497, Validation Accuracy: 0.84625\n",
      "Epoch: 41, Loss: 0.45357686281204224, Validation Accuracy: 0.8478333333333333\n",
      "Epoch: 42, Loss: 0.44621163606643677, Validation Accuracy: 0.851\n",
      "Epoch: 43, Loss: 0.43942293524742126, Validation Accuracy: 0.853\n",
      "Epoch: 44, Loss: 0.43244197964668274, Validation Accuracy: 0.8566666666666667\n",
      "Epoch: 45, Loss: 0.4263298213481903, Validation Accuracy: 0.859\n",
      "Epoch: 46, Loss: 0.4199800491333008, Validation Accuracy: 0.8628333333333333\n",
      "Epoch: 47, Loss: 0.41441091895103455, Validation Accuracy: 0.8626666666666667\n",
      "Epoch: 48, Loss: 0.4087503254413605, Validation Accuracy: 0.8656666666666667\n",
      "Epoch: 49, Loss: 0.40382665395736694, Validation Accuracy: 0.8653333333333333\n",
      "Epoch: 50, Loss: 0.3989364802837372, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 51, Loss: 0.394505113363266, Validation Accuracy: 0.8698333333333333\n",
      "Epoch: 52, Loss: 0.3902682363986969, Validation Accuracy: 0.8723333333333333\n",
      "Epoch: 53, Loss: 0.3862871825695038, Validation Accuracy: 0.8725\n",
      "Epoch: 54, Loss: 0.38244175910949707, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 55, Loss: 0.37887024879455566, Validation Accuracy: 0.8755833333333334\n",
      "Epoch: 56, Loss: 0.37539157271385193, Validation Accuracy: 0.8766666666666667\n",
      "Epoch: 57, Loss: 0.3721139430999756, Validation Accuracy: 0.8775833333333334\n",
      "Epoch: 58, Loss: 0.3689602017402649, Validation Accuracy: 0.8781666666666667\n",
      "Epoch: 59, Loss: 0.36594143509864807, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 60, Loss: 0.3630062937736511, Validation Accuracy: 0.8800833333333333\n",
      "Epoch: 61, Loss: 0.3601818382740021, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 62, Loss: 0.3574467897415161, Validation Accuracy: 0.88175\n",
      "Epoch: 63, Loss: 0.35479432344436646, Validation Accuracy: 0.883\n",
      "Epoch: 64, Loss: 0.35223254561424255, Validation Accuracy: 0.8835\n",
      "Epoch: 65, Loss: 0.3497541844844818, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 66, Loss: 0.34735727310180664, Validation Accuracy: 0.8850833333333333\n",
      "Epoch: 67, Loss: 0.34501928091049194, Validation Accuracy: 0.8851666666666667\n",
      "Epoch: 68, Loss: 0.3427439332008362, Validation Accuracy: 0.88625\n",
      "Epoch: 69, Loss: 0.34052881598472595, Validation Accuracy: 0.8866666666666667\n",
      "Epoch: 70, Loss: 0.3383709788322449, Validation Accuracy: 0.88775\n",
      "Epoch: 71, Loss: 0.33626988530158997, Validation Accuracy: 0.888\n",
      "Epoch: 72, Loss: 0.3342166244983673, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 73, Loss: 0.3322100043296814, Validation Accuracy: 0.8896666666666667\n",
      "Epoch: 74, Loss: 0.3302457928657532, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 75, Loss: 0.3283213973045349, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 76, Loss: 0.32644030451774597, Validation Accuracy: 0.8914166666666666\n",
      "Epoch: 77, Loss: 0.324594110250473, Validation Accuracy: 0.89175\n",
      "Epoch: 78, Loss: 0.32278668880462646, Validation Accuracy: 0.8925\n",
      "Epoch: 79, Loss: 0.3210155963897705, Validation Accuracy: 0.8925833333333333\n",
      "Epoch: 80, Loss: 0.3192848265171051, Validation Accuracy: 0.893\n",
      "Epoch: 81, Loss: 0.3175906836986542, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 82, Loss: 0.31593048572540283, Validation Accuracy: 0.8941666666666667\n",
      "Epoch: 83, Loss: 0.3143012821674347, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 84, Loss: 0.31270620226860046, Validation Accuracy: 0.89525\n",
      "Epoch: 85, Loss: 0.31113916635513306, Validation Accuracy: 0.8953333333333333\n",
      "Epoch: 86, Loss: 0.3096018135547638, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 87, Loss: 0.3080975413322449, Validation Accuracy: 0.896\n",
      "Epoch: 88, Loss: 0.30661869049072266, Validation Accuracy: 0.8970833333333333\n",
      "Epoch: 89, Loss: 0.30516961216926575, Validation Accuracy: 0.89775\n",
      "Epoch: 90, Loss: 0.30374637246131897, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 91, Loss: 0.3023483455181122, Validation Accuracy: 0.8988333333333334\n",
      "Epoch: 92, Loss: 0.3009742796421051, Validation Accuracy: 0.8993333333333333\n",
      "Epoch: 93, Loss: 0.2996239960193634, Validation Accuracy: 0.8995\n",
      "Epoch: 94, Loss: 0.29829519987106323, Validation Accuracy: 0.9\n",
      "Epoch: 95, Loss: 0.2969859838485718, Validation Accuracy: 0.90025\n",
      "Epoch: 96, Loss: 0.2956984341144562, Validation Accuracy: 0.901\n",
      "Epoch: 97, Loss: 0.2944300174713135, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 98, Loss: 0.293184369802475, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 99, Loss: 0.291959673166275, Validation Accuracy: 0.902\n",
      "Dataset 81\n",
      "Epoch: 0, Loss: 3.5992844104766846, Validation Accuracy: 0.16433333333333333\n",
      "Epoch: 1, Loss: 2.7495250701904297, Validation Accuracy: 0.23866666666666667\n",
      "Epoch: 2, Loss: 2.22029972076416, Validation Accuracy: 0.2574166666666667\n",
      "Epoch: 3, Loss: 2.17376708984375, Validation Accuracy: 0.25233333333333335\n",
      "Epoch: 4, Loss: 2.116065502166748, Validation Accuracy: 0.3606666666666667\n",
      "Epoch: 5, Loss: 1.7616140842437744, Validation Accuracy: 0.41591666666666666\n",
      "Epoch: 6, Loss: 1.6357113122940063, Validation Accuracy: 0.4685\n",
      "Epoch: 7, Loss: 1.507333517074585, Validation Accuracy: 0.51475\n",
      "Epoch: 8, Loss: 1.3931469917297363, Validation Accuracy: 0.5496666666666666\n",
      "Epoch: 9, Loss: 1.301969289779663, Validation Accuracy: 0.57625\n",
      "Epoch: 10, Loss: 1.2210510969161987, Validation Accuracy: 0.6054166666666667\n",
      "Epoch: 11, Loss: 1.1447080373764038, Validation Accuracy: 0.6301666666666667\n",
      "Epoch: 12, Loss: 1.0732799768447876, Validation Accuracy: 0.6585833333333333\n",
      "Epoch: 13, Loss: 1.0078370571136475, Validation Accuracy: 0.6788333333333333\n",
      "Epoch: 14, Loss: 0.948749840259552, Validation Accuracy: 0.69675\n",
      "Epoch: 15, Loss: 0.8961136341094971, Validation Accuracy: 0.7151666666666666\n",
      "Epoch: 16, Loss: 0.8496838212013245, Validation Accuracy: 0.7281666666666666\n",
      "Epoch: 17, Loss: 0.8100259900093079, Validation Accuracy: 0.73825\n",
      "Epoch: 18, Loss: 0.7802870273590088, Validation Accuracy: 0.73575\n",
      "Epoch: 19, Loss: 0.7691559791564941, Validation Accuracy: 0.7198333333333333\n",
      "Epoch: 20, Loss: 0.8065972328186035, Validation Accuracy: 0.6786666666666666\n",
      "Epoch: 21, Loss: 0.9307559132575989, Validation Accuracy: 0.6159166666666667\n",
      "Epoch: 22, Loss: 1.1338489055633545, Validation Accuracy: 0.6763333333333333\n",
      "Epoch: 23, Loss: 0.937749981880188, Validation Accuracy: 0.7335833333333334\n",
      "Epoch: 24, Loss: 0.7482261657714844, Validation Accuracy: 0.7958333333333333\n",
      "Epoch: 25, Loss: 0.6326536536216736, Validation Accuracy: 0.8073333333333333\n",
      "Epoch: 26, Loss: 0.6005293130874634, Validation Accuracy: 0.815\n",
      "Epoch: 27, Loss: 0.5791848301887512, Validation Accuracy: 0.8195833333333333\n",
      "Epoch: 28, Loss: 0.5619572997093201, Validation Accuracy: 0.8263333333333334\n",
      "Epoch: 29, Loss: 0.5470860004425049, Validation Accuracy: 0.82775\n",
      "Epoch: 30, Loss: 0.5343345999717712, Validation Accuracy: 0.8313333333333334\n",
      "Epoch: 31, Loss: 0.523603081703186, Validation Accuracy: 0.8313333333333334\n",
      "Epoch: 32, Loss: 0.5156972408294678, Validation Accuracy: 0.8336666666666667\n",
      "Epoch: 33, Loss: 0.5110108852386475, Validation Accuracy: 0.82825\n",
      "Epoch: 34, Loss: 0.5132353901863098, Validation Accuracy: 0.8276666666666667\n",
      "Epoch: 35, Loss: 0.5197550654411316, Validation Accuracy: 0.8165833333333333\n",
      "Epoch: 36, Loss: 0.5431597232818604, Validation Accuracy: 0.8095\n",
      "Epoch: 37, Loss: 0.5599421858787537, Validation Accuracy: 0.7945\n",
      "Epoch: 38, Loss: 0.5939128994941711, Validation Accuracy: 0.80225\n",
      "Epoch: 39, Loss: 0.5783402323722839, Validation Accuracy: 0.8035833333333333\n",
      "Epoch: 40, Loss: 0.5679972767829895, Validation Accuracy: 0.8238333333333333\n",
      "Epoch: 41, Loss: 0.5238776206970215, Validation Accuracy: 0.8344166666666667\n",
      "Epoch: 42, Loss: 0.4954128563404083, Validation Accuracy: 0.8479166666666667\n",
      "Epoch: 43, Loss: 0.4637782871723175, Validation Accuracy: 0.8540833333333333\n",
      "Epoch: 44, Loss: 0.44550052285194397, Validation Accuracy: 0.86275\n",
      "Epoch: 45, Loss: 0.42986756563186646, Validation Accuracy: 0.86525\n",
      "Epoch: 46, Loss: 0.4200149476528168, Validation Accuracy: 0.8698333333333333\n",
      "Epoch: 47, Loss: 0.4114147424697876, Validation Accuracy: 0.8711666666666666\n",
      "Epoch: 48, Loss: 0.4048751890659332, Validation Accuracy: 0.8748333333333334\n",
      "Epoch: 49, Loss: 0.39893025159835815, Validation Accuracy: 0.8751666666666666\n",
      "Epoch: 50, Loss: 0.3939420282840729, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 51, Loss: 0.3892548084259033, Validation Accuracy: 0.878\n",
      "Epoch: 52, Loss: 0.3849887251853943, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 53, Loss: 0.3809569776058197, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 54, Loss: 0.3772152066230774, Validation Accuracy: 0.8829166666666667\n",
      "Epoch: 55, Loss: 0.373573362827301, Validation Accuracy: 0.8835\n",
      "Epoch: 56, Loss: 0.3701910674571991, Validation Accuracy: 0.8846666666666667\n",
      "Epoch: 57, Loss: 0.36690229177474976, Validation Accuracy: 0.88575\n",
      "Epoch: 58, Loss: 0.36380359530448914, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 59, Loss: 0.3607795536518097, Validation Accuracy: 0.887\n",
      "Epoch: 60, Loss: 0.35790184140205383, Validation Accuracy: 0.8876666666666667\n",
      "Epoch: 61, Loss: 0.3550874888896942, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 62, Loss: 0.3524066209793091, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 63, Loss: 0.3497737944126129, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 64, Loss: 0.3472779095172882, Validation Accuracy: 0.8900833333333333\n",
      "Epoch: 65, Loss: 0.3448101878166199, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 66, Loss: 0.34244853258132935, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 67, Loss: 0.34012413024902344, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 68, Loss: 0.33789417147636414, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 69, Loss: 0.3356797993183136, Validation Accuracy: 0.89325\n",
      "Epoch: 70, Loss: 0.33361390233039856, Validation Accuracy: 0.89525\n",
      "Epoch: 71, Loss: 0.3315618336200714, Validation Accuracy: 0.8940833333333333\n",
      "Epoch: 72, Loss: 0.32960495352745056, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 73, Loss: 0.32765644788742065, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 74, Loss: 0.3257957696914673, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 75, Loss: 0.3239523768424988, Validation Accuracy: 0.8965\n",
      "Epoch: 76, Loss: 0.3222031593322754, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 77, Loss: 0.3204716742038727, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 78, Loss: 0.3188239634037018, Validation Accuracy: 0.89925\n",
      "Epoch: 79, Loss: 0.3171776831150055, Validation Accuracy: 0.89875\n",
      "Epoch: 80, Loss: 0.31560492515563965, Validation Accuracy: 0.8998333333333334\n",
      "Epoch: 81, Loss: 0.3140600621700287, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 82, Loss: 0.31261593103408813, Validation Accuracy: 0.90075\n",
      "Epoch: 83, Loss: 0.3111472427845001, Validation Accuracy: 0.9005\n",
      "Epoch: 84, Loss: 0.3098256289958954, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 85, Loss: 0.30842792987823486, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 86, Loss: 0.30717960000038147, Validation Accuracy: 0.9023333333333333\n",
      "Epoch: 87, Loss: 0.3058491051197052, Validation Accuracy: 0.90125\n",
      "Epoch: 88, Loss: 0.30470818281173706, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 89, Loss: 0.3033679723739624, Validation Accuracy: 0.9021666666666667\n",
      "Epoch: 90, Loss: 0.30227982997894287, Validation Accuracy: 0.9050833333333334\n",
      "Epoch: 91, Loss: 0.3009469509124756, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 92, Loss: 0.29990601539611816, Validation Accuracy: 0.9056666666666666\n",
      "Epoch: 93, Loss: 0.29856908321380615, Validation Accuracy: 0.9041666666666667\n",
      "Epoch: 94, Loss: 0.29760605096817017, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 95, Loss: 0.2962782084941864, Validation Accuracy: 0.90475\n",
      "Epoch: 96, Loss: 0.2953170835971832, Validation Accuracy: 0.9075833333333333\n",
      "Epoch: 97, Loss: 0.2939501404762268, Validation Accuracy: 0.90575\n",
      "Epoch: 98, Loss: 0.2930087745189667, Validation Accuracy: 0.908\n",
      "Epoch: 99, Loss: 0.29166141152381897, Validation Accuracy: 0.90625\n",
      "Dataset 82\n",
      "Epoch: 0, Loss: 3.733489513397217, Validation Accuracy: 0.13866666666666666\n",
      "Epoch: 1, Loss: 3.308274507522583, Validation Accuracy: 0.20858333333333334\n",
      "Epoch: 2, Loss: 2.6273386478424072, Validation Accuracy: 0.19758333333333333\n",
      "Epoch: 3, Loss: 2.4671080112457275, Validation Accuracy: 0.2648333333333333\n",
      "Epoch: 4, Loss: 2.032895088195801, Validation Accuracy: 0.3785833333333333\n",
      "Epoch: 5, Loss: 1.7811551094055176, Validation Accuracy: 0.47491666666666665\n",
      "Epoch: 6, Loss: 1.574908971786499, Validation Accuracy: 0.5489166666666667\n",
      "Epoch: 7, Loss: 1.3940322399139404, Validation Accuracy: 0.6028333333333333\n",
      "Epoch: 8, Loss: 1.2374297380447388, Validation Accuracy: 0.6423333333333333\n",
      "Epoch: 9, Loss: 1.1114059686660767, Validation Accuracy: 0.6739166666666667\n",
      "Epoch: 10, Loss: 1.0117284059524536, Validation Accuracy: 0.6966666666666667\n",
      "Epoch: 11, Loss: 0.9325815439224243, Validation Accuracy: 0.7143333333333334\n",
      "Epoch: 12, Loss: 0.8700398802757263, Validation Accuracy: 0.72475\n",
      "Epoch: 13, Loss: 0.8216162919998169, Validation Accuracy: 0.742\n",
      "Epoch: 14, Loss: 0.7890126705169678, Validation Accuracy: 0.7408333333333333\n",
      "Epoch: 15, Loss: 0.7715175747871399, Validation Accuracy: 0.73725\n",
      "Epoch: 16, Loss: 0.7903259992599487, Validation Accuracy: 0.725\n",
      "Epoch: 17, Loss: 0.8159350752830505, Validation Accuracy: 0.7015\n",
      "Epoch: 18, Loss: 0.8878024816513062, Validation Accuracy: 0.7105833333333333\n",
      "Epoch: 19, Loss: 0.8483749032020569, Validation Accuracy: 0.7156666666666667\n",
      "Epoch: 20, Loss: 0.8018761277198792, Validation Accuracy: 0.7246666666666667\n",
      "Epoch: 21, Loss: 0.7886486053466797, Validation Accuracy: 0.71825\n",
      "Epoch: 22, Loss: 0.7978048324584961, Validation Accuracy: 0.7515833333333334\n",
      "Epoch: 23, Loss: 0.7255234122276306, Validation Accuracy: 0.7751666666666667\n",
      "Epoch: 24, Loss: 0.654291033744812, Validation Accuracy: 0.8045833333333333\n",
      "Epoch: 25, Loss: 0.5839127898216248, Validation Accuracy: 0.81625\n",
      "Epoch: 26, Loss: 0.5496212840080261, Validation Accuracy: 0.8248333333333333\n",
      "Epoch: 27, Loss: 0.5301110148429871, Validation Accuracy: 0.82875\n",
      "Epoch: 28, Loss: 0.5169456601142883, Validation Accuracy: 0.8316666666666667\n",
      "Epoch: 29, Loss: 0.5060762763023376, Validation Accuracy: 0.83475\n",
      "Epoch: 30, Loss: 0.49654096364974976, Validation Accuracy: 0.8375\n",
      "Epoch: 31, Loss: 0.48789212107658386, Validation Accuracy: 0.8399166666666666\n",
      "Epoch: 32, Loss: 0.47991862893104553, Validation Accuracy: 0.8435833333333334\n",
      "Epoch: 33, Loss: 0.47245264053344727, Validation Accuracy: 0.84425\n",
      "Epoch: 34, Loss: 0.4654810428619385, Validation Accuracy: 0.8478333333333333\n",
      "Epoch: 35, Loss: 0.45891574025154114, Validation Accuracy: 0.8498333333333333\n",
      "Epoch: 36, Loss: 0.4527183473110199, Validation Accuracy: 0.8521666666666666\n",
      "Epoch: 37, Loss: 0.44686242938041687, Validation Accuracy: 0.85425\n",
      "Epoch: 38, Loss: 0.4413101375102997, Validation Accuracy: 0.8556666666666667\n",
      "Epoch: 39, Loss: 0.43601110577583313, Validation Accuracy: 0.8575833333333334\n",
      "Epoch: 40, Loss: 0.4309645891189575, Validation Accuracy: 0.85925\n",
      "Epoch: 41, Loss: 0.42614734172821045, Validation Accuracy: 0.8608333333333333\n",
      "Epoch: 42, Loss: 0.42154574394226074, Validation Accuracy: 0.8631666666666666\n",
      "Epoch: 43, Loss: 0.41713806986808777, Validation Accuracy: 0.8641666666666666\n",
      "Epoch: 44, Loss: 0.41289466619491577, Validation Accuracy: 0.8659166666666667\n",
      "Epoch: 45, Loss: 0.40881088376045227, Validation Accuracy: 0.8673333333333333\n",
      "Epoch: 46, Loss: 0.40487852692604065, Validation Accuracy: 0.8683333333333333\n",
      "Epoch: 47, Loss: 0.40108928084373474, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 48, Loss: 0.39743396639823914, Validation Accuracy: 0.8698333333333333\n",
      "Epoch: 49, Loss: 0.3938997685909271, Validation Accuracy: 0.87175\n",
      "Epoch: 50, Loss: 0.39049434661865234, Validation Accuracy: 0.8720833333333333\n",
      "Epoch: 51, Loss: 0.387200266122818, Validation Accuracy: 0.8729166666666667\n",
      "Epoch: 52, Loss: 0.38399744033813477, Validation Accuracy: 0.8741666666666666\n",
      "Epoch: 53, Loss: 0.380894273519516, Validation Accuracy: 0.8748333333333334\n",
      "Epoch: 54, Loss: 0.3778860569000244, Validation Accuracy: 0.87625\n",
      "Epoch: 55, Loss: 0.3749702572822571, Validation Accuracy: 0.8771666666666667\n",
      "Epoch: 56, Loss: 0.3721465766429901, Validation Accuracy: 0.8776666666666667\n",
      "Epoch: 57, Loss: 0.36940503120422363, Validation Accuracy: 0.8779166666666667\n",
      "Epoch: 58, Loss: 0.3667356073856354, Validation Accuracy: 0.87875\n",
      "Epoch: 59, Loss: 0.3641449511051178, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 60, Loss: 0.36162036657333374, Validation Accuracy: 0.88025\n",
      "Epoch: 61, Loss: 0.35916951298713684, Validation Accuracy: 0.8805833333333334\n",
      "Epoch: 62, Loss: 0.35677531361579895, Validation Accuracy: 0.8823333333333333\n",
      "Epoch: 63, Loss: 0.3544398546218872, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 64, Loss: 0.35216838121414185, Validation Accuracy: 0.8835\n",
      "Epoch: 65, Loss: 0.3499557673931122, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 66, Loss: 0.3477937877178192, Validation Accuracy: 0.8846666666666667\n",
      "Epoch: 67, Loss: 0.3456890881061554, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 68, Loss: 0.34364160895347595, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 69, Loss: 0.34163689613342285, Validation Accuracy: 0.887\n",
      "Epoch: 70, Loss: 0.3396703600883484, Validation Accuracy: 0.8876666666666667\n",
      "Epoch: 71, Loss: 0.33774253726005554, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 72, Loss: 0.33585307002067566, Validation Accuracy: 0.889\n",
      "Epoch: 73, Loss: 0.3340045213699341, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 74, Loss: 0.33219391107559204, Validation Accuracy: 0.89025\n",
      "Epoch: 75, Loss: 0.3304170072078705, Validation Accuracy: 0.8913333333333333\n",
      "Epoch: 76, Loss: 0.3286776542663574, Validation Accuracy: 0.891\n",
      "Epoch: 77, Loss: 0.32696765661239624, Validation Accuracy: 0.892\n",
      "Epoch: 78, Loss: 0.3252921998500824, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 79, Loss: 0.32364600896835327, Validation Accuracy: 0.89225\n",
      "Epoch: 80, Loss: 0.32202404737472534, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 81, Loss: 0.3204314708709717, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 82, Loss: 0.31886038184165955, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 83, Loss: 0.31731486320495605, Validation Accuracy: 0.89425\n",
      "Epoch: 84, Loss: 0.315796822309494, Validation Accuracy: 0.8951666666666667\n",
      "Epoch: 85, Loss: 0.31431129574775696, Validation Accuracy: 0.8953333333333333\n",
      "Epoch: 86, Loss: 0.31284651160240173, Validation Accuracy: 0.8959166666666667\n",
      "Epoch: 87, Loss: 0.3114086091518402, Validation Accuracy: 0.8963333333333333\n",
      "Epoch: 88, Loss: 0.30998843908309937, Validation Accuracy: 0.8966666666666666\n",
      "Epoch: 89, Loss: 0.30859166383743286, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 90, Loss: 0.30721694231033325, Validation Accuracy: 0.8971666666666667\n",
      "Epoch: 91, Loss: 0.3058701455593109, Validation Accuracy: 0.89725\n",
      "Epoch: 92, Loss: 0.3045426905155182, Validation Accuracy: 0.8971666666666667\n",
      "Epoch: 93, Loss: 0.30323389172554016, Validation Accuracy: 0.898\n",
      "Epoch: 94, Loss: 0.3019386827945709, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 95, Loss: 0.30066409707069397, Validation Accuracy: 0.8985\n",
      "Epoch: 96, Loss: 0.29940342903137207, Validation Accuracy: 0.8983333333333333\n",
      "Epoch: 97, Loss: 0.29816997051239014, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 98, Loss: 0.29694536328315735, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 99, Loss: 0.2957445979118347, Validation Accuracy: 0.8999166666666667\n",
      "Dataset 83\n",
      "Epoch: 0, Loss: 3.968254327774048, Validation Accuracy: 0.1415\n",
      "Epoch: 1, Loss: 3.6344878673553467, Validation Accuracy: 0.16133333333333333\n",
      "Epoch: 2, Loss: 2.7436585426330566, Validation Accuracy: 0.25808333333333333\n",
      "Epoch: 3, Loss: 2.1915082931518555, Validation Accuracy: 0.29741666666666666\n",
      "Epoch: 4, Loss: 1.9407057762145996, Validation Accuracy: 0.347\n",
      "Epoch: 5, Loss: 1.8131463527679443, Validation Accuracy: 0.39966666666666667\n",
      "Epoch: 6, Loss: 1.699503779411316, Validation Accuracy: 0.45258333333333334\n",
      "Epoch: 7, Loss: 1.5925623178482056, Validation Accuracy: 0.4985833333333333\n",
      "Epoch: 8, Loss: 1.4928534030914307, Validation Accuracy: 0.5355833333333333\n",
      "Epoch: 9, Loss: 1.3979434967041016, Validation Accuracy: 0.57175\n",
      "Epoch: 10, Loss: 1.3075141906738281, Validation Accuracy: 0.6035833333333334\n",
      "Epoch: 11, Loss: 1.2219698429107666, Validation Accuracy: 0.63175\n",
      "Epoch: 12, Loss: 1.142427921295166, Validation Accuracy: 0.65425\n",
      "Epoch: 13, Loss: 1.0697468519210815, Validation Accuracy: 0.6788333333333333\n",
      "Epoch: 14, Loss: 1.0040887594223022, Validation Accuracy: 0.69825\n",
      "Epoch: 15, Loss: 0.945676326751709, Validation Accuracy: 0.71625\n",
      "Epoch: 16, Loss: 0.8937311172485352, Validation Accuracy: 0.7308333333333333\n",
      "Epoch: 17, Loss: 0.8479605913162231, Validation Accuracy: 0.7410833333333333\n",
      "Epoch: 18, Loss: 0.8078722357749939, Validation Accuracy: 0.7525\n",
      "Epoch: 19, Loss: 0.7733259797096252, Validation Accuracy: 0.7598333333333334\n",
      "Epoch: 20, Loss: 0.7451726794242859, Validation Accuracy: 0.7624166666666666\n",
      "Epoch: 21, Loss: 0.7268590331077576, Validation Accuracy: 0.7601666666666667\n",
      "Epoch: 22, Loss: 0.7329002022743225, Validation Accuracy: 0.7429166666666667\n",
      "Epoch: 23, Loss: 0.7755218744277954, Validation Accuracy: 0.6770833333333334\n",
      "Epoch: 24, Loss: 0.9579659700393677, Validation Accuracy: 0.66875\n",
      "Epoch: 25, Loss: 0.9921062588691711, Validation Accuracy: 0.6369166666666667\n",
      "Epoch: 26, Loss: 1.0537792444229126, Validation Accuracy: 0.7554166666666666\n",
      "Epoch: 27, Loss: 0.7499814629554749, Validation Accuracy: 0.7760833333333333\n",
      "Epoch: 28, Loss: 0.6724028587341309, Validation Accuracy: 0.8039166666666666\n",
      "Epoch: 29, Loss: 0.6048684120178223, Validation Accuracy: 0.8138333333333333\n",
      "Epoch: 30, Loss: 0.5780376195907593, Validation Accuracy: 0.8194166666666667\n",
      "Epoch: 31, Loss: 0.5567396283149719, Validation Accuracy: 0.82675\n",
      "Epoch: 32, Loss: 0.5414474606513977, Validation Accuracy: 0.8281666666666667\n",
      "Epoch: 33, Loss: 0.5285611748695374, Validation Accuracy: 0.83425\n",
      "Epoch: 34, Loss: 0.5176104307174683, Validation Accuracy: 0.8360833333333333\n",
      "Epoch: 35, Loss: 0.5075394511222839, Validation Accuracy: 0.8401666666666666\n",
      "Epoch: 36, Loss: 0.4986383318901062, Validation Accuracy: 0.8414166666666667\n",
      "Epoch: 37, Loss: 0.4902070164680481, Validation Accuracy: 0.8459166666666667\n",
      "Epoch: 38, Loss: 0.48259851336479187, Validation Accuracy: 0.8455\n",
      "Epoch: 39, Loss: 0.4752209186553955, Validation Accuracy: 0.8509166666666667\n",
      "Epoch: 40, Loss: 0.46844205260276794, Validation Accuracy: 0.8500833333333333\n",
      "Epoch: 41, Loss: 0.4618152379989624, Validation Accuracy: 0.8543333333333333\n",
      "Epoch: 42, Loss: 0.4557853937149048, Validation Accuracy: 0.8539166666666667\n",
      "Epoch: 43, Loss: 0.44978564977645874, Validation Accuracy: 0.85825\n",
      "Epoch: 44, Loss: 0.4442751407623291, Validation Accuracy: 0.8583333333333333\n",
      "Epoch: 45, Loss: 0.43881791830062866, Validation Accuracy: 0.8605833333333334\n",
      "Epoch: 46, Loss: 0.4337744116783142, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 47, Loss: 0.4288085997104645, Validation Accuracy: 0.864\n",
      "Epoch: 48, Loss: 0.42414993047714233, Validation Accuracy: 0.8649166666666667\n",
      "Epoch: 49, Loss: 0.41961565613746643, Validation Accuracy: 0.8673333333333333\n",
      "Epoch: 50, Loss: 0.415294885635376, Validation Accuracy: 0.8681666666666666\n",
      "Epoch: 51, Loss: 0.4111592173576355, Validation Accuracy: 0.86975\n",
      "Epoch: 52, Loss: 0.4071647524833679, Validation Accuracy: 0.8700833333333333\n",
      "Epoch: 53, Loss: 0.4033343493938446, Validation Accuracy: 0.87225\n",
      "Epoch: 54, Loss: 0.3996870517730713, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 55, Loss: 0.39613160490989685, Validation Accuracy: 0.87425\n",
      "Epoch: 56, Loss: 0.392713338136673, Validation Accuracy: 0.8750833333333333\n",
      "Epoch: 57, Loss: 0.38945138454437256, Validation Accuracy: 0.87575\n",
      "Epoch: 58, Loss: 0.3862585127353668, Validation Accuracy: 0.8769166666666667\n",
      "Epoch: 59, Loss: 0.3831987977027893, Validation Accuracy: 0.87725\n",
      "Epoch: 60, Loss: 0.38021039962768555, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 61, Loss: 0.37734460830688477, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 62, Loss: 0.37454503774642944, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 63, Loss: 0.3718327283859253, Validation Accuracy: 0.8818333333333334\n",
      "Epoch: 64, Loss: 0.3691815733909607, Validation Accuracy: 0.8834166666666666\n",
      "Epoch: 65, Loss: 0.3666079044342041, Validation Accuracy: 0.8835\n",
      "Epoch: 66, Loss: 0.3641003370285034, Validation Accuracy: 0.885\n",
      "Epoch: 67, Loss: 0.36165904998779297, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 68, Loss: 0.3592846989631653, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 69, Loss: 0.35697123408317566, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 70, Loss: 0.35471290349960327, Validation Accuracy: 0.88775\n",
      "Epoch: 71, Loss: 0.3525136709213257, Validation Accuracy: 0.88825\n",
      "Epoch: 72, Loss: 0.3503764569759369, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 73, Loss: 0.3482933044433594, Validation Accuracy: 0.89\n",
      "Epoch: 74, Loss: 0.3462573289871216, Validation Accuracy: 0.8905\n",
      "Epoch: 75, Loss: 0.3442673683166504, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 76, Loss: 0.3423280417919159, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 77, Loss: 0.34042999148368835, Validation Accuracy: 0.89275\n",
      "Epoch: 78, Loss: 0.3385688364505768, Validation Accuracy: 0.8935833333333333\n",
      "Epoch: 79, Loss: 0.33674630522727966, Validation Accuracy: 0.8944166666666666\n",
      "Epoch: 80, Loss: 0.3349614143371582, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 81, Loss: 0.33320531249046326, Validation Accuracy: 0.8954166666666666\n",
      "Epoch: 82, Loss: 0.3314829170703888, Validation Accuracy: 0.89625\n",
      "Epoch: 83, Loss: 0.32979488372802734, Validation Accuracy: 0.8970833333333333\n",
      "Epoch: 84, Loss: 0.32813897728919983, Validation Accuracy: 0.8974166666666666\n",
      "Epoch: 85, Loss: 0.3265126645565033, Validation Accuracy: 0.89775\n",
      "Epoch: 86, Loss: 0.3249177932739258, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 87, Loss: 0.3233494162559509, Validation Accuracy: 0.8988333333333334\n",
      "Epoch: 88, Loss: 0.3218075633049011, Validation Accuracy: 0.899\n",
      "Epoch: 89, Loss: 0.3202936053276062, Validation Accuracy: 0.89975\n",
      "Epoch: 90, Loss: 0.31880131363868713, Validation Accuracy: 0.8998333333333334\n",
      "Epoch: 91, Loss: 0.3173311948776245, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 92, Loss: 0.31588441133499146, Validation Accuracy: 0.9013333333333333\n",
      "Epoch: 93, Loss: 0.31445884704589844, Validation Accuracy: 0.902\n",
      "Epoch: 94, Loss: 0.31305602192878723, Validation Accuracy: 0.9028333333333334\n",
      "Epoch: 95, Loss: 0.31167536973953247, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 96, Loss: 0.3103158175945282, Validation Accuracy: 0.90325\n",
      "Epoch: 97, Loss: 0.30897724628448486, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 98, Loss: 0.30765917897224426, Validation Accuracy: 0.90475\n",
      "Epoch: 99, Loss: 0.30636686086654663, Validation Accuracy: 0.90525\n",
      "Dataset 84\n",
      "Epoch: 0, Loss: 4.104794979095459, Validation Accuracy: 0.133\n",
      "Epoch: 1, Loss: 4.250533580780029, Validation Accuracy: 0.1125\n",
      "Epoch: 2, Loss: 4.729597091674805, Validation Accuracy: 0.10258333333333333\n",
      "Epoch: 3, Loss: 9.842101097106934, Validation Accuracy: 0.1205\n",
      "Epoch: 4, Loss: 3.32786226272583, Validation Accuracy: 0.1355\n",
      "Epoch: 5, Loss: 4.788341999053955, Validation Accuracy: 0.18941666666666668\n",
      "Epoch: 6, Loss: 2.1522016525268555, Validation Accuracy: 0.2559166666666667\n",
      "Epoch: 7, Loss: 2.0533087253570557, Validation Accuracy: 0.27941666666666665\n",
      "Epoch: 8, Loss: 1.9843857288360596, Validation Accuracy: 0.2991666666666667\n",
      "Epoch: 9, Loss: 1.9202088117599487, Validation Accuracy: 0.33\n",
      "Epoch: 10, Loss: 1.8627973794937134, Validation Accuracy: 0.35025\n",
      "Epoch: 11, Loss: 1.8139011859893799, Validation Accuracy: 0.3620833333333333\n",
      "Epoch: 12, Loss: 1.7704048156738281, Validation Accuracy: 0.3714166666666667\n",
      "Epoch: 13, Loss: 1.7302004098892212, Validation Accuracy: 0.37925\n",
      "Epoch: 14, Loss: 1.6921979188919067, Validation Accuracy: 0.38658333333333333\n",
      "Epoch: 15, Loss: 1.6557118892669678, Validation Accuracy: 0.39466666666666667\n",
      "Epoch: 16, Loss: 1.6202503442764282, Validation Accuracy: 0.4028333333333333\n",
      "Epoch: 17, Loss: 1.585552453994751, Validation Accuracy: 0.4156666666666667\n",
      "Epoch: 18, Loss: 1.55128014087677, Validation Accuracy: 0.42325\n",
      "Epoch: 19, Loss: 1.5174319744110107, Validation Accuracy: 0.43666666666666665\n",
      "Epoch: 20, Loss: 1.4849421977996826, Validation Accuracy: 0.44358333333333333\n",
      "Epoch: 21, Loss: 1.4572786092758179, Validation Accuracy: 0.45108333333333334\n",
      "Epoch: 22, Loss: 1.451219916343689, Validation Accuracy: 0.43275\n",
      "Epoch: 23, Loss: 1.497793436050415, Validation Accuracy: 0.3411666666666667\n",
      "Epoch: 24, Loss: 1.7235667705535889, Validation Accuracy: 0.44875\n",
      "Epoch: 25, Loss: 1.491697907447815, Validation Accuracy: 0.46416666666666667\n",
      "Epoch: 26, Loss: 1.4223659038543701, Validation Accuracy: 0.4970833333333333\n",
      "Epoch: 27, Loss: 1.3657625913619995, Validation Accuracy: 0.4900833333333333\n",
      "Epoch: 28, Loss: 1.3633347749710083, Validation Accuracy: 0.5331666666666667\n",
      "Epoch: 29, Loss: 1.290988564491272, Validation Accuracy: 0.5331666666666667\n",
      "Epoch: 30, Loss: 1.2757397890090942, Validation Accuracy: 0.5503333333333333\n",
      "Epoch: 31, Loss: 1.2472330331802368, Validation Accuracy: 0.52825\n",
      "Epoch: 32, Loss: 1.264227032661438, Validation Accuracy: 0.5363333333333333\n",
      "Epoch: 33, Loss: 1.2693097591400146, Validation Accuracy: 0.46625\n",
      "Epoch: 34, Loss: 1.3798003196716309, Validation Accuracy: 0.52025\n",
      "Epoch: 35, Loss: 1.315516471862793, Validation Accuracy: 0.46475\n",
      "Epoch: 36, Loss: 1.4694736003875732, Validation Accuracy: 0.4969166666666667\n",
      "Epoch: 37, Loss: 1.4372252225875854, Validation Accuracy: 0.6155833333333334\n",
      "Epoch: 38, Loss: 1.1254340410232544, Validation Accuracy: 0.6416666666666667\n",
      "Epoch: 39, Loss: 1.0495365858078003, Validation Accuracy: 0.64425\n",
      "Epoch: 40, Loss: 1.0232683420181274, Validation Accuracy: 0.6500833333333333\n",
      "Epoch: 41, Loss: 1.0375365018844604, Validation Accuracy: 0.6294166666666666\n",
      "Epoch: 42, Loss: 1.0381468534469604, Validation Accuracy: 0.6075\n",
      "Epoch: 43, Loss: 1.1368093490600586, Validation Accuracy: 0.6169166666666667\n",
      "Epoch: 44, Loss: 1.0471957921981812, Validation Accuracy: 0.61875\n",
      "Epoch: 45, Loss: 1.0965887308120728, Validation Accuracy: 0.61875\n",
      "Epoch: 46, Loss: 1.0390641689300537, Validation Accuracy: 0.6460833333333333\n",
      "Epoch: 47, Loss: 1.0250694751739502, Validation Accuracy: 0.6339166666666667\n",
      "Epoch: 48, Loss: 1.0012506246566772, Validation Accuracy: 0.67725\n",
      "Epoch: 49, Loss: 0.950922429561615, Validation Accuracy: 0.66525\n",
      "Epoch: 50, Loss: 0.9324020147323608, Validation Accuracy: 0.7028333333333333\n",
      "Epoch: 51, Loss: 0.8904492855072021, Validation Accuracy: 0.6901666666666667\n",
      "Epoch: 52, Loss: 0.877381443977356, Validation Accuracy: 0.7151666666666666\n",
      "Epoch: 53, Loss: 0.8488965034484863, Validation Accuracy: 0.70425\n",
      "Epoch: 54, Loss: 0.8409500122070312, Validation Accuracy: 0.72275\n",
      "Epoch: 55, Loss: 0.8223260641098022, Validation Accuracy: 0.7126666666666667\n",
      "Epoch: 56, Loss: 0.8170578479766846, Validation Accuracy: 0.7261666666666666\n",
      "Epoch: 57, Loss: 0.8072781562805176, Validation Accuracy: 0.714\n",
      "Epoch: 58, Loss: 0.8034021854400635, Validation Accuracy: 0.7235\n",
      "Epoch: 59, Loss: 0.8120723366737366, Validation Accuracy: 0.7079166666666666\n",
      "Epoch: 60, Loss: 0.8064603805541992, Validation Accuracy: 0.6991666666666667\n",
      "Epoch: 61, Loss: 0.8665811419487, Validation Accuracy: 0.7101666666666666\n",
      "Epoch: 62, Loss: 0.8012260794639587, Validation Accuracy: 0.68975\n",
      "Epoch: 63, Loss: 0.8812648057937622, Validation Accuracy: 0.7340833333333333\n",
      "Epoch: 64, Loss: 0.763826847076416, Validation Accuracy: 0.7225\n",
      "Epoch: 65, Loss: 0.8098143935203552, Validation Accuracy: 0.7450833333333333\n",
      "Epoch: 66, Loss: 0.7591290473937988, Validation Accuracy: 0.7301666666666666\n",
      "Epoch: 67, Loss: 0.8102947473526001, Validation Accuracy: 0.7365833333333334\n",
      "Epoch: 68, Loss: 0.7810822129249573, Validation Accuracy: 0.7295833333333334\n",
      "Epoch: 69, Loss: 0.7972553968429565, Validation Accuracy: 0.7515833333333334\n",
      "Epoch: 70, Loss: 0.7446179986000061, Validation Accuracy: 0.7664166666666666\n",
      "Epoch: 71, Loss: 0.7066777944564819, Validation Accuracy: 0.7869166666666667\n",
      "Epoch: 72, Loss: 0.6517451405525208, Validation Accuracy: 0.798\n",
      "Epoch: 73, Loss: 0.6227905750274658, Validation Accuracy: 0.8065\n",
      "Epoch: 74, Loss: 0.6004016399383545, Validation Accuracy: 0.805\n",
      "Epoch: 75, Loss: 0.5908116698265076, Validation Accuracy: 0.8118333333333333\n",
      "Epoch: 76, Loss: 0.5824761390686035, Validation Accuracy: 0.8039166666666666\n",
      "Epoch: 77, Loss: 0.5866026282310486, Validation Accuracy: 0.8013333333333333\n",
      "Epoch: 78, Loss: 0.5908812880516052, Validation Accuracy: 0.7823333333333333\n",
      "Epoch: 79, Loss: 0.621677577495575, Validation Accuracy: 0.768\n",
      "Epoch: 80, Loss: 0.6482650637626648, Validation Accuracy: 0.742\n",
      "Epoch: 81, Loss: 0.7113479971885681, Validation Accuracy: 0.7338333333333333\n",
      "Epoch: 82, Loss: 0.7475244998931885, Validation Accuracy: 0.7369166666666667\n",
      "Epoch: 83, Loss: 0.7189391851425171, Validation Accuracy: 0.7645\n",
      "Epoch: 84, Loss: 0.6915553212165833, Validation Accuracy: 0.7866666666666666\n",
      "Epoch: 85, Loss: 0.6085560917854309, Validation Accuracy: 0.8143333333333334\n",
      "Epoch: 86, Loss: 0.5759636759757996, Validation Accuracy: 0.8178333333333333\n",
      "Epoch: 87, Loss: 0.5469030141830444, Validation Accuracy: 0.83425\n",
      "Epoch: 88, Loss: 0.5323529839515686, Validation Accuracy: 0.8305\n",
      "Epoch: 89, Loss: 0.5197991728782654, Validation Accuracy: 0.8410833333333333\n",
      "Epoch: 90, Loss: 0.5116502046585083, Validation Accuracy: 0.8348333333333333\n",
      "Epoch: 91, Loss: 0.505151093006134, Validation Accuracy: 0.8444166666666667\n",
      "Epoch: 92, Loss: 0.49960747361183167, Validation Accuracy: 0.8368333333333333\n",
      "Epoch: 93, Loss: 0.49608153104782104, Validation Accuracy: 0.8454166666666667\n",
      "Epoch: 94, Loss: 0.49217137694358826, Validation Accuracy: 0.8389166666666666\n",
      "Epoch: 95, Loss: 0.49133923649787903, Validation Accuracy: 0.84475\n",
      "Epoch: 96, Loss: 0.4892614781856537, Validation Accuracy: 0.8353333333333334\n",
      "Epoch: 97, Loss: 0.4924103319644928, Validation Accuracy: 0.8411666666666666\n",
      "Epoch: 98, Loss: 0.4923463463783264, Validation Accuracy: 0.82925\n",
      "Epoch: 99, Loss: 0.5014858841896057, Validation Accuracy: 0.8331666666666667\n",
      "Dataset 85\n",
      "Epoch: 0, Loss: 2.722005605697632, Validation Accuracy: 0.24058333333333334\n",
      "Epoch: 1, Loss: 2.2586302757263184, Validation Accuracy: 0.2668333333333333\n",
      "Epoch: 2, Loss: 1.9015979766845703, Validation Accuracy: 0.3248333333333333\n",
      "Epoch: 3, Loss: 1.7674471139907837, Validation Accuracy: 0.38116666666666665\n",
      "Epoch: 4, Loss: 1.6545284986495972, Validation Accuracy: 0.425\n",
      "Epoch: 5, Loss: 1.5570847988128662, Validation Accuracy: 0.46116666666666667\n",
      "Epoch: 6, Loss: 1.478515625, Validation Accuracy: 0.4820833333333333\n",
      "Epoch: 7, Loss: 1.4187208414077759, Validation Accuracy: 0.49675\n",
      "Epoch: 8, Loss: 1.3969467878341675, Validation Accuracy: 0.47783333333333333\n",
      "Epoch: 9, Loss: 1.450108528137207, Validation Accuracy: 0.44816666666666666\n",
      "Epoch: 10, Loss: 1.5307585000991821, Validation Accuracy: 0.46758333333333335\n",
      "Epoch: 11, Loss: 1.513938307762146, Validation Accuracy: 0.55425\n",
      "Epoch: 12, Loss: 1.2542083263397217, Validation Accuracy: 0.593\n",
      "Epoch: 13, Loss: 1.1259818077087402, Validation Accuracy: 0.6218333333333333\n",
      "Epoch: 14, Loss: 1.0795137882232666, Validation Accuracy: 0.6134166666666667\n",
      "Epoch: 15, Loss: 1.048157811164856, Validation Accuracy: 0.6350833333333333\n",
      "Epoch: 16, Loss: 1.0508308410644531, Validation Accuracy: 0.5978333333333333\n",
      "Epoch: 17, Loss: 1.074652910232544, Validation Accuracy: 0.615\n",
      "Epoch: 18, Loss: 1.0969139337539673, Validation Accuracy: 0.6096666666666667\n",
      "Epoch: 19, Loss: 1.0590131282806396, Validation Accuracy: 0.6730833333333334\n",
      "Epoch: 20, Loss: 0.9593859910964966, Validation Accuracy: 0.6901666666666667\n",
      "Epoch: 21, Loss: 0.879517674446106, Validation Accuracy: 0.7263333333333334\n",
      "Epoch: 22, Loss: 0.8260217905044556, Validation Accuracy: 0.7231666666666666\n",
      "Epoch: 23, Loss: 0.8047757744789124, Validation Accuracy: 0.7248333333333333\n",
      "Epoch: 24, Loss: 0.8068605065345764, Validation Accuracy: 0.6860833333333334\n",
      "Epoch: 25, Loss: 0.8840506076812744, Validation Accuracy: 0.6653333333333333\n",
      "Epoch: 26, Loss: 0.9260750412940979, Validation Accuracy: 0.6229166666666667\n",
      "Epoch: 27, Loss: 1.0465662479400635, Validation Accuracy: 0.7125833333333333\n",
      "Epoch: 28, Loss: 0.8111191391944885, Validation Accuracy: 0.75325\n",
      "Epoch: 29, Loss: 0.7431747317314148, Validation Accuracy: 0.7695\n",
      "Epoch: 30, Loss: 0.6914556622505188, Validation Accuracy: 0.7778333333333334\n",
      "Epoch: 31, Loss: 0.6711960434913635, Validation Accuracy: 0.7848333333333334\n",
      "Epoch: 32, Loss: 0.6464386582374573, Validation Accuracy: 0.78875\n",
      "Epoch: 33, Loss: 0.6375499367713928, Validation Accuracy: 0.79075\n",
      "Epoch: 34, Loss: 0.6230599284172058, Validation Accuracy: 0.792\n",
      "Epoch: 35, Loss: 0.6226176619529724, Validation Accuracy: 0.7915833333333333\n",
      "Epoch: 36, Loss: 0.6150819659233093, Validation Accuracy: 0.788\n",
      "Epoch: 37, Loss: 0.6241981387138367, Validation Accuracy: 0.7864166666666667\n",
      "Epoch: 38, Loss: 0.6196216344833374, Validation Accuracy: 0.7831666666666667\n",
      "Epoch: 39, Loss: 0.6367307305335999, Validation Accuracy: 0.7841666666666667\n",
      "Epoch: 40, Loss: 0.6212990880012512, Validation Accuracy: 0.78525\n",
      "Epoch: 41, Loss: 0.6286237239837646, Validation Accuracy: 0.7964166666666667\n",
      "Epoch: 42, Loss: 0.593539834022522, Validation Accuracy: 0.8053333333333333\n",
      "Epoch: 43, Loss: 0.5828587412834167, Validation Accuracy: 0.8168333333333333\n",
      "Epoch: 44, Loss: 0.5503272414207458, Validation Accuracy: 0.8228333333333333\n",
      "Epoch: 45, Loss: 0.537748396396637, Validation Accuracy: 0.8305\n",
      "Epoch: 46, Loss: 0.518149197101593, Validation Accuracy: 0.8316666666666667\n",
      "Epoch: 47, Loss: 0.508802056312561, Validation Accuracy: 0.8378333333333333\n",
      "Epoch: 48, Loss: 0.49674054980278015, Validation Accuracy: 0.8401666666666666\n",
      "Epoch: 49, Loss: 0.49022603034973145, Validation Accuracy: 0.8429166666666666\n",
      "Epoch: 50, Loss: 0.4817545711994171, Validation Accuracy: 0.8444166666666667\n",
      "Epoch: 51, Loss: 0.4770457446575165, Validation Accuracy: 0.84675\n",
      "Epoch: 52, Loss: 0.47052761912345886, Validation Accuracy: 0.8470833333333333\n",
      "Epoch: 53, Loss: 0.46707940101623535, Validation Accuracy: 0.8491666666666666\n",
      "Epoch: 54, Loss: 0.46183836460113525, Validation Accuracy: 0.85\n",
      "Epoch: 55, Loss: 0.4599880874156952, Validation Accuracy: 0.8515\n",
      "Epoch: 56, Loss: 0.4556173086166382, Validation Accuracy: 0.8514166666666667\n",
      "Epoch: 57, Loss: 0.45553356409072876, Validation Accuracy: 0.853\n",
      "Epoch: 58, Loss: 0.45187413692474365, Validation Accuracy: 0.8501666666666666\n",
      "Epoch: 59, Loss: 0.453631192445755, Validation Accuracy: 0.8525833333333334\n",
      "Epoch: 60, Loss: 0.45062118768692017, Validation Accuracy: 0.8511666666666666\n",
      "Epoch: 61, Loss: 0.45380544662475586, Validation Accuracy: 0.8539166666666667\n",
      "Epoch: 62, Loss: 0.450675368309021, Validation Accuracy: 0.8513333333333334\n",
      "Epoch: 63, Loss: 0.45330968499183655, Validation Accuracy: 0.85325\n",
      "Epoch: 64, Loss: 0.4493328928947449, Validation Accuracy: 0.852\n",
      "Epoch: 65, Loss: 0.44846415519714355, Validation Accuracy: 0.85625\n",
      "Epoch: 66, Loss: 0.44239985942840576, Validation Accuracy: 0.8551666666666666\n",
      "Epoch: 67, Loss: 0.43654462695121765, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 68, Loss: 0.42865800857543945, Validation Accuracy: 0.86125\n",
      "Epoch: 69, Loss: 0.4204842448234558, Validation Accuracy: 0.8653333333333333\n",
      "Epoch: 70, Loss: 0.4134865999221802, Validation Accuracy: 0.86625\n",
      "Epoch: 71, Loss: 0.4065614342689514, Validation Accuracy: 0.8705833333333334\n",
      "Epoch: 72, Loss: 0.4013809859752655, Validation Accuracy: 0.8705833333333334\n",
      "Epoch: 73, Loss: 0.39681094884872437, Validation Accuracy: 0.8735833333333334\n",
      "Epoch: 74, Loss: 0.39350464940071106, Validation Accuracy: 0.8715\n",
      "Epoch: 75, Loss: 0.3908030688762665, Validation Accuracy: 0.8745833333333334\n",
      "Epoch: 76, Loss: 0.38883501291275024, Validation Accuracy: 0.8728333333333333\n",
      "Epoch: 77, Loss: 0.3874284625053406, Validation Accuracy: 0.8744166666666666\n",
      "Epoch: 78, Loss: 0.38664209842681885, Validation Accuracy: 0.8731666666666666\n",
      "Epoch: 79, Loss: 0.3863327205181122, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 80, Loss: 0.38697120547294617, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 81, Loss: 0.3874129354953766, Validation Accuracy: 0.8718333333333333\n",
      "Epoch: 82, Loss: 0.3893994987010956, Validation Accuracy: 0.8719166666666667\n",
      "Epoch: 83, Loss: 0.38979434967041016, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 84, Loss: 0.3921094238758087, Validation Accuracy: 0.87175\n",
      "Epoch: 85, Loss: 0.3904206156730652, Validation Accuracy: 0.8719166666666667\n",
      "Epoch: 86, Loss: 0.39124080538749695, Validation Accuracy: 0.87225\n",
      "Epoch: 87, Loss: 0.38613802194595337, Validation Accuracy: 0.8746666666666667\n",
      "Epoch: 88, Loss: 0.38383036851882935, Validation Accuracy: 0.8764166666666666\n",
      "Epoch: 89, Loss: 0.375576376914978, Validation Accuracy: 0.8800833333333333\n",
      "Epoch: 90, Loss: 0.37049853801727295, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 91, Loss: 0.3619382381439209, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 92, Loss: 0.3564927279949188, Validation Accuracy: 0.8849166666666667\n",
      "Epoch: 93, Loss: 0.34991541504859924, Validation Accuracy: 0.8885\n",
      "Epoch: 94, Loss: 0.3457043468952179, Validation Accuracy: 0.88825\n",
      "Epoch: 95, Loss: 0.3411506414413452, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 96, Loss: 0.33798906207084656, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 97, Loss: 0.3347964584827423, Validation Accuracy: 0.89325\n",
      "Epoch: 98, Loss: 0.3324202597141266, Validation Accuracy: 0.8929166666666667\n",
      "Epoch: 99, Loss: 0.3299449682235718, Validation Accuracy: 0.89525\n",
      "Dataset 86\n",
      "Epoch: 0, Loss: 3.812028408050537, Validation Accuracy: 0.17216666666666666\n",
      "Epoch: 1, Loss: 3.0435593128204346, Validation Accuracy: 0.23266666666666666\n",
      "Epoch: 2, Loss: 3.4715588092803955, Validation Accuracy: 0.2544166666666667\n",
      "Epoch: 3, Loss: 2.0825917720794678, Validation Accuracy: 0.324\n",
      "Epoch: 4, Loss: 1.9330110549926758, Validation Accuracy: 0.33658333333333335\n",
      "Epoch: 5, Loss: 1.8769807815551758, Validation Accuracy: 0.3685833333333333\n",
      "Epoch: 6, Loss: 1.7570576667785645, Validation Accuracy: 0.4005\n",
      "Epoch: 7, Loss: 1.6758601665496826, Validation Accuracy: 0.43075\n",
      "Epoch: 8, Loss: 1.5961263179779053, Validation Accuracy: 0.4554166666666667\n",
      "Epoch: 9, Loss: 1.5227363109588623, Validation Accuracy: 0.495\n",
      "Epoch: 10, Loss: 1.448736548423767, Validation Accuracy: 0.5224166666666666\n",
      "Epoch: 11, Loss: 1.3758795261383057, Validation Accuracy: 0.5608333333333333\n",
      "Epoch: 12, Loss: 1.3035261631011963, Validation Accuracy: 0.5915833333333333\n",
      "Epoch: 13, Loss: 1.232998251914978, Validation Accuracy: 0.62825\n",
      "Epoch: 14, Loss: 1.1650967597961426, Validation Accuracy: 0.6476666666666666\n",
      "Epoch: 15, Loss: 1.1020878553390503, Validation Accuracy: 0.6728333333333333\n",
      "Epoch: 16, Loss: 1.0445811748504639, Validation Accuracy: 0.68375\n",
      "Epoch: 17, Loss: 0.9936153888702393, Validation Accuracy: 0.7024166666666667\n",
      "Epoch: 18, Loss: 0.9491590857505798, Validation Accuracy: 0.7099166666666666\n",
      "Epoch: 19, Loss: 0.9108877778053284, Validation Accuracy: 0.7178333333333333\n",
      "Epoch: 20, Loss: 0.8796306252479553, Validation Accuracy: 0.7271666666666666\n",
      "Epoch: 21, Loss: 0.8542128801345825, Validation Accuracy: 0.7213333333333334\n",
      "Epoch: 22, Loss: 0.8442583084106445, Validation Accuracy: 0.72875\n",
      "Epoch: 23, Loss: 0.8357771635055542, Validation Accuracy: 0.6871666666666667\n",
      "Epoch: 24, Loss: 0.883632481098175, Validation Accuracy: 0.713\n",
      "Epoch: 25, Loss: 0.8544902205467224, Validation Accuracy: 0.6518333333333334\n",
      "Epoch: 26, Loss: 0.9398120045661926, Validation Accuracy: 0.7319166666666667\n",
      "Epoch: 27, Loss: 0.8061630129814148, Validation Accuracy: 0.7140833333333333\n",
      "Epoch: 28, Loss: 0.800724446773529, Validation Accuracy: 0.7606666666666667\n",
      "Epoch: 29, Loss: 0.7440499663352966, Validation Accuracy: 0.748\n",
      "Epoch: 30, Loss: 0.7302708625793457, Validation Accuracy: 0.776\n",
      "Epoch: 31, Loss: 0.7074262499809265, Validation Accuracy: 0.7599166666666667\n",
      "Epoch: 32, Loss: 0.6976680755615234, Validation Accuracy: 0.78425\n",
      "Epoch: 33, Loss: 0.6840693950653076, Validation Accuracy: 0.7665833333333333\n",
      "Epoch: 34, Loss: 0.6775678992271423, Validation Accuracy: 0.7893333333333333\n",
      "Epoch: 35, Loss: 0.6668332815170288, Validation Accuracy: 0.7715\n",
      "Epoch: 36, Loss: 0.6613502502441406, Validation Accuracy: 0.7935\n",
      "Epoch: 37, Loss: 0.6509633660316467, Validation Accuracy: 0.77725\n",
      "Epoch: 38, Loss: 0.6450607776641846, Validation Accuracy: 0.7994166666666667\n",
      "Epoch: 39, Loss: 0.6337031126022339, Validation Accuracy: 0.7851666666666667\n",
      "Epoch: 40, Loss: 0.62752765417099, Validation Accuracy: 0.8056666666666666\n",
      "Epoch: 41, Loss: 0.6155360341072083, Validation Accuracy: 0.7924166666666667\n",
      "Epoch: 42, Loss: 0.6097995638847351, Validation Accuracy: 0.8120833333333334\n",
      "Epoch: 43, Loss: 0.5979041457176208, Validation Accuracy: 0.7991666666666667\n",
      "Epoch: 44, Loss: 0.5936926603317261, Validation Accuracy: 0.8176666666666667\n",
      "Epoch: 45, Loss: 0.5820326805114746, Validation Accuracy: 0.8063333333333333\n",
      "Epoch: 46, Loss: 0.5794896483421326, Validation Accuracy: 0.8230833333333333\n",
      "Epoch: 47, Loss: 0.5676993727684021, Validation Accuracy: 0.8115\n",
      "Epoch: 48, Loss: 0.566211462020874, Validation Accuracy: 0.8281666666666667\n",
      "Epoch: 49, Loss: 0.5542294383049011, Validation Accuracy: 0.8196666666666667\n",
      "Epoch: 50, Loss: 0.5532182455062866, Validation Accuracy: 0.8321666666666667\n",
      "Epoch: 51, Loss: 0.5412175059318542, Validation Accuracy: 0.8251666666666667\n",
      "Epoch: 52, Loss: 0.5403419137001038, Validation Accuracy: 0.8365\n",
      "Epoch: 53, Loss: 0.5286732912063599, Validation Accuracy: 0.8310833333333333\n",
      "Epoch: 54, Loss: 0.5273711681365967, Validation Accuracy: 0.83975\n",
      "Epoch: 55, Loss: 0.5163876414299011, Validation Accuracy: 0.83825\n",
      "Epoch: 56, Loss: 0.5148311257362366, Validation Accuracy: 0.8444166666666667\n",
      "Epoch: 57, Loss: 0.5050872564315796, Validation Accuracy: 0.8430833333333333\n",
      "Epoch: 58, Loss: 0.5032023191452026, Validation Accuracy: 0.8483333333333334\n",
      "Epoch: 59, Loss: 0.4945802390575409, Validation Accuracy: 0.8476666666666667\n",
      "Epoch: 60, Loss: 0.4926377832889557, Validation Accuracy: 0.8523333333333334\n",
      "Epoch: 61, Loss: 0.4852333068847656, Validation Accuracy: 0.8509166666666667\n",
      "Epoch: 62, Loss: 0.483429491519928, Validation Accuracy: 0.855\n",
      "Epoch: 63, Loss: 0.47696638107299805, Validation Accuracy: 0.8529166666666667\n",
      "Epoch: 64, Loss: 0.4752766191959381, Validation Accuracy: 0.8574166666666667\n",
      "Epoch: 65, Loss: 0.4695045053958893, Validation Accuracy: 0.8551666666666666\n",
      "Epoch: 66, Loss: 0.4681027829647064, Validation Accuracy: 0.8593333333333333\n",
      "Epoch: 67, Loss: 0.46288394927978516, Validation Accuracy: 0.8578333333333333\n",
      "Epoch: 68, Loss: 0.46172598004341125, Validation Accuracy: 0.8608333333333333\n",
      "Epoch: 69, Loss: 0.45687422156333923, Validation Accuracy: 0.8605\n",
      "Epoch: 70, Loss: 0.4557637572288513, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 71, Loss: 0.45132771134376526, Validation Accuracy: 0.8620833333333333\n",
      "Epoch: 72, Loss: 0.45031237602233887, Validation Accuracy: 0.8650833333333333\n",
      "Epoch: 73, Loss: 0.44600218534469604, Validation Accuracy: 0.8645\n",
      "Epoch: 74, Loss: 0.4450176954269409, Validation Accuracy: 0.8676666666666667\n",
      "Epoch: 75, Loss: 0.4407969117164612, Validation Accuracy: 0.8674166666666666\n",
      "Epoch: 76, Loss: 0.4397280812263489, Validation Accuracy: 0.8699166666666667\n",
      "Epoch: 77, Loss: 0.43540722131729126, Validation Accuracy: 0.8698333333333333\n",
      "Epoch: 78, Loss: 0.4342290759086609, Validation Accuracy: 0.8713333333333333\n",
      "Epoch: 79, Loss: 0.4298880994319916, Validation Accuracy: 0.8718333333333333\n",
      "Epoch: 80, Loss: 0.4284035563468933, Validation Accuracy: 0.8728333333333333\n",
      "Epoch: 81, Loss: 0.4240160584449768, Validation Accuracy: 0.8741666666666666\n",
      "Epoch: 82, Loss: 0.4222433567047119, Validation Accuracy: 0.8751666666666666\n",
      "Epoch: 83, Loss: 0.41790494322776794, Validation Accuracy: 0.8761666666666666\n",
      "Epoch: 84, Loss: 0.41599056124687195, Validation Accuracy: 0.8765833333333334\n",
      "Epoch: 85, Loss: 0.4118936061859131, Validation Accuracy: 0.879\n",
      "Epoch: 86, Loss: 0.4098002016544342, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 87, Loss: 0.4060450494289398, Validation Accuracy: 0.8810833333333333\n",
      "Epoch: 88, Loss: 0.40394705533981323, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 89, Loss: 0.4005047082901001, Validation Accuracy: 0.8835\n",
      "Epoch: 90, Loss: 0.39845791459083557, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 91, Loss: 0.395336389541626, Validation Accuracy: 0.8850833333333333\n",
      "Epoch: 92, Loss: 0.3934169411659241, Validation Accuracy: 0.88425\n",
      "Epoch: 93, Loss: 0.39059674739837646, Validation Accuracy: 0.8865\n",
      "Epoch: 94, Loss: 0.38880831003189087, Validation Accuracy: 0.88575\n",
      "Epoch: 95, Loss: 0.38625115156173706, Validation Accuracy: 0.888\n",
      "Epoch: 96, Loss: 0.38460078835487366, Validation Accuracy: 0.8866666666666667\n",
      "Epoch: 97, Loss: 0.3821895718574524, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 98, Loss: 0.3806329071521759, Validation Accuracy: 0.8879166666666667\n",
      "Epoch: 99, Loss: 0.3783131241798401, Validation Accuracy: 0.8905\n",
      "Dataset 87\n",
      "Epoch: 0, Loss: 4.471282005310059, Validation Accuracy: 0.14275\n",
      "Epoch: 1, Loss: 3.7467029094696045, Validation Accuracy: 0.131\n",
      "Epoch: 2, Loss: 3.226865530014038, Validation Accuracy: 0.17675\n",
      "Epoch: 3, Loss: 2.3283400535583496, Validation Accuracy: 0.27308333333333334\n",
      "Epoch: 4, Loss: 1.9757091999053955, Validation Accuracy: 0.34041666666666665\n",
      "Epoch: 5, Loss: 1.856776475906372, Validation Accuracy: 0.3819166666666667\n",
      "Epoch: 6, Loss: 1.7632832527160645, Validation Accuracy: 0.4151666666666667\n",
      "Epoch: 7, Loss: 1.6863170862197876, Validation Accuracy: 0.439\n",
      "Epoch: 8, Loss: 1.6160297393798828, Validation Accuracy: 0.46041666666666664\n",
      "Epoch: 9, Loss: 1.5510883331298828, Validation Accuracy: 0.4805\n",
      "Epoch: 10, Loss: 1.491356611251831, Validation Accuracy: 0.49616666666666664\n",
      "Epoch: 11, Loss: 1.4377353191375732, Validation Accuracy: 0.5154166666666666\n",
      "Epoch: 12, Loss: 1.3929626941680908, Validation Accuracy: 0.51475\n",
      "Epoch: 13, Loss: 1.3696142435073853, Validation Accuracy: 0.52475\n",
      "Epoch: 14, Loss: 1.3695374727249146, Validation Accuracy: 0.49625\n",
      "Epoch: 15, Loss: 1.4376063346862793, Validation Accuracy: 0.53025\n",
      "Epoch: 16, Loss: 1.3419642448425293, Validation Accuracy: 0.5555833333333333\n",
      "Epoch: 17, Loss: 1.2810109853744507, Validation Accuracy: 0.59175\n",
      "Epoch: 18, Loss: 1.1639939546585083, Validation Accuracy: 0.6088333333333333\n",
      "Epoch: 19, Loss: 1.1085847616195679, Validation Accuracy: 0.61775\n",
      "Epoch: 20, Loss: 1.0614501237869263, Validation Accuracy: 0.6334166666666666\n",
      "Epoch: 21, Loss: 1.0239923000335693, Validation Accuracy: 0.6400833333333333\n",
      "Epoch: 22, Loss: 0.987107515335083, Validation Accuracy: 0.6544166666666666\n",
      "Epoch: 23, Loss: 0.9545731544494629, Validation Accuracy: 0.6586666666666666\n",
      "Epoch: 24, Loss: 0.9226385951042175, Validation Accuracy: 0.66975\n",
      "Epoch: 25, Loss: 0.8962154984474182, Validation Accuracy: 0.69825\n",
      "Epoch: 26, Loss: 0.8720489740371704, Validation Accuracy: 0.6818333333333333\n",
      "Epoch: 27, Loss: 0.8587049245834351, Validation Accuracy: 0.72025\n",
      "Epoch: 28, Loss: 0.8516796231269836, Validation Accuracy: 0.6761666666666667\n",
      "Epoch: 29, Loss: 0.8654919266700745, Validation Accuracy: 0.6996666666666667\n",
      "Epoch: 30, Loss: 0.8873112797737122, Validation Accuracy: 0.654\n",
      "Epoch: 31, Loss: 0.907916247844696, Validation Accuracy: 0.6931666666666667\n",
      "Epoch: 32, Loss: 0.8986568450927734, Validation Accuracy: 0.7028333333333333\n",
      "Epoch: 33, Loss: 0.832429051399231, Validation Accuracy: 0.749\n",
      "Epoch: 34, Loss: 0.7754731178283691, Validation Accuracy: 0.7643333333333333\n",
      "Epoch: 35, Loss: 0.7294068932533264, Validation Accuracy: 0.7845833333333333\n",
      "Epoch: 36, Loss: 0.7003900408744812, Validation Accuracy: 0.7874166666666667\n",
      "Epoch: 37, Loss: 0.6745499968528748, Validation Accuracy: 0.7958333333333333\n",
      "Epoch: 38, Loss: 0.6591808795928955, Validation Accuracy: 0.7991666666666667\n",
      "Epoch: 39, Loss: 0.6414293050765991, Validation Accuracy: 0.80225\n",
      "Epoch: 40, Loss: 0.6323315501213074, Validation Accuracy: 0.8046666666666666\n",
      "Epoch: 41, Loss: 0.6193317174911499, Validation Accuracy: 0.8054166666666667\n",
      "Epoch: 42, Loss: 0.6160443425178528, Validation Accuracy: 0.8051666666666667\n",
      "Epoch: 43, Loss: 0.6066725254058838, Validation Accuracy: 0.8044166666666667\n",
      "Epoch: 44, Loss: 0.6100475788116455, Validation Accuracy: 0.8020833333333334\n",
      "Epoch: 45, Loss: 0.6033110618591309, Validation Accuracy: 0.7999166666666667\n",
      "Epoch: 46, Loss: 0.6112579107284546, Validation Accuracy: 0.7985833333333333\n",
      "Epoch: 47, Loss: 0.6054747700691223, Validation Accuracy: 0.7956666666666666\n",
      "Epoch: 48, Loss: 0.6095823049545288, Validation Accuracy: 0.7956666666666666\n",
      "Epoch: 49, Loss: 0.6017884612083435, Validation Accuracy: 0.8020833333333334\n",
      "Epoch: 50, Loss: 0.5908281803131104, Validation Accuracy: 0.8049166666666666\n",
      "Epoch: 51, Loss: 0.5777051448822021, Validation Accuracy: 0.8160833333333334\n",
      "Epoch: 52, Loss: 0.5554385781288147, Validation Accuracy: 0.82225\n",
      "Epoch: 53, Loss: 0.5408862829208374, Validation Accuracy: 0.83025\n",
      "Epoch: 54, Loss: 0.520621657371521, Validation Accuracy: 0.83425\n",
      "Epoch: 55, Loss: 0.5087468028068542, Validation Accuracy: 0.8391666666666666\n",
      "Epoch: 56, Loss: 0.4947721064090729, Validation Accuracy: 0.8435\n",
      "Epoch: 57, Loss: 0.4860095679759979, Validation Accuracy: 0.8469166666666667\n",
      "Epoch: 58, Loss: 0.4765210449695587, Validation Accuracy: 0.84925\n",
      "Epoch: 59, Loss: 0.4700958728790283, Validation Accuracy: 0.85125\n",
      "Epoch: 60, Loss: 0.46319055557250977, Validation Accuracy: 0.8529166666666667\n",
      "Epoch: 61, Loss: 0.4582858085632324, Validation Accuracy: 0.85525\n",
      "Epoch: 62, Loss: 0.4532037079334259, Validation Accuracy: 0.855\n",
      "Epoch: 63, Loss: 0.44952794909477234, Validation Accuracy: 0.8575833333333334\n",
      "Epoch: 64, Loss: 0.44592955708503723, Validation Accuracy: 0.8555833333333334\n",
      "Epoch: 65, Loss: 0.4433826208114624, Validation Accuracy: 0.85825\n",
      "Epoch: 66, Loss: 0.4410422444343567, Validation Accuracy: 0.8563333333333333\n",
      "Epoch: 67, Loss: 0.439575731754303, Validation Accuracy: 0.8589166666666667\n",
      "Epoch: 68, Loss: 0.4384412467479706, Validation Accuracy: 0.85625\n",
      "Epoch: 69, Loss: 0.4376614987850189, Validation Accuracy: 0.8584166666666667\n",
      "Epoch: 70, Loss: 0.4375547170639038, Validation Accuracy: 0.85625\n",
      "Epoch: 71, Loss: 0.4364842474460602, Validation Accuracy: 0.8595833333333334\n",
      "Epoch: 72, Loss: 0.4362685978412628, Validation Accuracy: 0.8569166666666667\n",
      "Epoch: 73, Loss: 0.43347835540771484, Validation Accuracy: 0.86075\n",
      "Epoch: 74, Loss: 0.4314546585083008, Validation Accuracy: 0.85975\n",
      "Epoch: 75, Loss: 0.42600956559181213, Validation Accuracy: 0.8648333333333333\n",
      "Epoch: 76, Loss: 0.4214745759963989, Validation Accuracy: 0.865\n",
      "Epoch: 77, Loss: 0.41436246037483215, Validation Accuracy: 0.8685\n",
      "Epoch: 78, Loss: 0.408223956823349, Validation Accuracy: 0.87075\n",
      "Epoch: 79, Loss: 0.4012185335159302, Validation Accuracy: 0.8738333333333334\n",
      "Epoch: 80, Loss: 0.39544644951820374, Validation Accuracy: 0.8761666666666666\n",
      "Epoch: 81, Loss: 0.3896152675151825, Validation Accuracy: 0.8764166666666666\n",
      "Epoch: 82, Loss: 0.3848012685775757, Validation Accuracy: 0.8800833333333333\n",
      "Epoch: 83, Loss: 0.38041239976882935, Validation Accuracy: 0.8791666666666667\n",
      "Epoch: 84, Loss: 0.3766661286354065, Validation Accuracy: 0.8825833333333334\n",
      "Epoch: 85, Loss: 0.37331804633140564, Validation Accuracy: 0.8809166666666667\n",
      "Epoch: 86, Loss: 0.37032008171081543, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 87, Loss: 0.36754968762397766, Validation Accuracy: 0.8825833333333334\n",
      "Epoch: 88, Loss: 0.3649841248989105, Validation Accuracy: 0.8849166666666667\n",
      "Epoch: 89, Loss: 0.36258456110954285, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 90, Loss: 0.3603360652923584, Validation Accuracy: 0.8856666666666667\n",
      "Epoch: 91, Loss: 0.35817524790763855, Validation Accuracy: 0.885\n",
      "Epoch: 92, Loss: 0.3561466932296753, Validation Accuracy: 0.8865\n",
      "Epoch: 93, Loss: 0.3541816473007202, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 94, Loss: 0.3523067235946655, Validation Accuracy: 0.8868333333333334\n",
      "Epoch: 95, Loss: 0.3505518436431885, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 96, Loss: 0.3488277196884155, Validation Accuracy: 0.8886666666666667\n",
      "Epoch: 97, Loss: 0.34725674986839294, Validation Accuracy: 0.8884166666666666\n",
      "Epoch: 98, Loss: 0.34569111466407776, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 99, Loss: 0.3442619740962982, Validation Accuracy: 0.889\n",
      "Dataset 88\n",
      "Epoch: 0, Loss: 2.9277942180633545, Validation Accuracy: 0.18966666666666668\n",
      "Epoch: 1, Loss: 2.263650417327881, Validation Accuracy: 0.2838333333333333\n",
      "Epoch: 2, Loss: 1.9589861631393433, Validation Accuracy: 0.3720833333333333\n",
      "Epoch: 3, Loss: 1.7914780378341675, Validation Accuracy: 0.4206666666666667\n",
      "Epoch: 4, Loss: 1.6521157026290894, Validation Accuracy: 0.4663333333333333\n",
      "Epoch: 5, Loss: 1.529107928276062, Validation Accuracy: 0.5045833333333334\n",
      "Epoch: 6, Loss: 1.4176723957061768, Validation Accuracy: 0.5410833333333334\n",
      "Epoch: 7, Loss: 1.3179367780685425, Validation Accuracy: 0.5656666666666667\n",
      "Epoch: 8, Loss: 1.2297180891036987, Validation Accuracy: 0.5915\n",
      "Epoch: 9, Loss: 1.1522935628890991, Validation Accuracy: 0.61175\n",
      "Epoch: 10, Loss: 1.0841448307037354, Validation Accuracy: 0.63275\n",
      "Epoch: 11, Loss: 1.0238631963729858, Validation Accuracy: 0.64775\n",
      "Epoch: 12, Loss: 0.9719470739364624, Validation Accuracy: 0.66825\n",
      "Epoch: 13, Loss: 0.9314804673194885, Validation Accuracy: 0.6619166666666667\n",
      "Epoch: 14, Loss: 0.9112564921379089, Validation Accuracy: 0.66325\n",
      "Epoch: 15, Loss: 0.9595633745193481, Validation Accuracy: 0.615\n",
      "Epoch: 16, Loss: 0.9985342025756836, Validation Accuracy: 0.6116666666666667\n",
      "Epoch: 17, Loss: 1.2089343070983887, Validation Accuracy: 0.67475\n",
      "Epoch: 18, Loss: 0.8683395981788635, Validation Accuracy: 0.7364166666666667\n",
      "Epoch: 19, Loss: 0.760015606880188, Validation Accuracy: 0.7464166666666666\n",
      "Epoch: 20, Loss: 0.7291070818901062, Validation Accuracy: 0.7548333333333334\n",
      "Epoch: 21, Loss: 0.706947922706604, Validation Accuracy: 0.7569166666666667\n",
      "Epoch: 22, Loss: 0.6927734613418579, Validation Accuracy: 0.7540833333333333\n",
      "Epoch: 23, Loss: 0.6925928592681885, Validation Accuracy: 0.73825\n",
      "Epoch: 24, Loss: 0.7201195359230042, Validation Accuracy: 0.7100833333333333\n",
      "Epoch: 25, Loss: 0.7842118144035339, Validation Accuracy: 0.6665833333333333\n",
      "Epoch: 26, Loss: 0.9035822153091431, Validation Accuracy: 0.6781666666666667\n",
      "Epoch: 27, Loss: 0.8563194870948792, Validation Accuracy: 0.72175\n",
      "Epoch: 28, Loss: 0.7765043377876282, Validation Accuracy: 0.7791666666666667\n",
      "Epoch: 29, Loss: 0.6385436058044434, Validation Accuracy: 0.804\n",
      "Epoch: 30, Loss: 0.5923031568527222, Validation Accuracy: 0.811\n",
      "Epoch: 31, Loss: 0.5678007006645203, Validation Accuracy: 0.8195\n",
      "Epoch: 32, Loss: 0.55158931016922, Validation Accuracy: 0.823\n",
      "Epoch: 33, Loss: 0.5386145710945129, Validation Accuracy: 0.8288333333333333\n",
      "Epoch: 34, Loss: 0.5277959108352661, Validation Accuracy: 0.8310833333333333\n",
      "Epoch: 35, Loss: 0.5185297727584839, Validation Accuracy: 0.8331666666666667\n",
      "Epoch: 36, Loss: 0.5111932754516602, Validation Accuracy: 0.8345\n",
      "Epoch: 37, Loss: 0.5056970119476318, Validation Accuracy: 0.8353333333333334\n",
      "Epoch: 38, Loss: 0.5046692490577698, Validation Accuracy: 0.8343333333333334\n",
      "Epoch: 39, Loss: 0.5067319869995117, Validation Accuracy: 0.8274166666666667\n",
      "Epoch: 40, Loss: 0.5249086022377014, Validation Accuracy: 0.8189166666666666\n",
      "Epoch: 41, Loss: 0.5428622961044312, Validation Accuracy: 0.791\n",
      "Epoch: 42, Loss: 0.6160258650779724, Validation Accuracy: 0.7959166666666667\n",
      "Epoch: 43, Loss: 0.6063772439956665, Validation Accuracy: 0.7676666666666667\n",
      "Epoch: 44, Loss: 0.6854250431060791, Validation Accuracy: 0.8238333333333333\n",
      "Epoch: 45, Loss: 0.5364949703216553, Validation Accuracy: 0.83625\n",
      "Epoch: 46, Loss: 0.5038712024688721, Validation Accuracy: 0.8506666666666667\n",
      "Epoch: 47, Loss: 0.45589208602905273, Validation Accuracy: 0.8570833333333333\n",
      "Epoch: 48, Loss: 0.4422391653060913, Validation Accuracy: 0.8601666666666666\n",
      "Epoch: 49, Loss: 0.4323556423187256, Validation Accuracy: 0.8626666666666667\n",
      "Epoch: 50, Loss: 0.42587703466415405, Validation Accuracy: 0.8644166666666667\n",
      "Epoch: 51, Loss: 0.4204903841018677, Validation Accuracy: 0.86625\n",
      "Epoch: 52, Loss: 0.41590416431427, Validation Accuracy: 0.8673333333333333\n",
      "Epoch: 53, Loss: 0.41178157925605774, Validation Accuracy: 0.86925\n",
      "Epoch: 54, Loss: 0.40816250443458557, Validation Accuracy: 0.8694166666666666\n",
      "Epoch: 55, Loss: 0.40500447154045105, Validation Accuracy: 0.8706666666666667\n",
      "Epoch: 56, Loss: 0.40236201882362366, Validation Accuracy: 0.87025\n",
      "Epoch: 57, Loss: 0.40043941140174866, Validation Accuracy: 0.8705833333333334\n",
      "Epoch: 58, Loss: 0.399405300617218, Validation Accuracy: 0.8698333333333333\n",
      "Epoch: 59, Loss: 0.3997783064842224, Validation Accuracy: 0.8696666666666667\n",
      "Epoch: 60, Loss: 0.40186116099357605, Validation Accuracy: 0.8668333333333333\n",
      "Epoch: 61, Loss: 0.40670421719551086, Validation Accuracy: 0.8639166666666667\n",
      "Epoch: 62, Loss: 0.41456785798072815, Validation Accuracy: 0.8585833333333334\n",
      "Epoch: 63, Loss: 0.42761939764022827, Validation Accuracy: 0.85325\n",
      "Epoch: 64, Loss: 0.442505419254303, Validation Accuracy: 0.8441666666666666\n",
      "Epoch: 65, Loss: 0.46211546659469604, Validation Accuracy: 0.84225\n",
      "Epoch: 66, Loss: 0.47282636165618896, Validation Accuracy: 0.8365833333333333\n",
      "Epoch: 67, Loss: 0.4751603901386261, Validation Accuracy: 0.85025\n",
      "Epoch: 68, Loss: 0.45376378297805786, Validation Accuracy: 0.85575\n",
      "Epoch: 69, Loss: 0.4277225434780121, Validation Accuracy: 0.8715833333333334\n",
      "Epoch: 70, Loss: 0.3978430926799774, Validation Accuracy: 0.8753333333333333\n",
      "Epoch: 71, Loss: 0.37889978289604187, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 72, Loss: 0.36621060967445374, Validation Accuracy: 0.884\n",
      "Epoch: 73, Loss: 0.35880589485168457, Validation Accuracy: 0.8865\n",
      "Epoch: 74, Loss: 0.353524386882782, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 75, Loss: 0.34976452589035034, Validation Accuracy: 0.8874166666666666\n",
      "Epoch: 76, Loss: 0.3466475307941437, Validation Accuracy: 0.8885833333333333\n",
      "Epoch: 77, Loss: 0.34398120641708374, Validation Accuracy: 0.88875\n",
      "Epoch: 78, Loss: 0.3415708541870117, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 79, Loss: 0.33933812379837036, Validation Accuracy: 0.8896666666666667\n",
      "Epoch: 80, Loss: 0.3372240662574768, Validation Accuracy: 0.8905\n",
      "Epoch: 81, Loss: 0.3352087140083313, Validation Accuracy: 0.89075\n",
      "Epoch: 82, Loss: 0.3332684338092804, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 83, Loss: 0.33138683438301086, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 84, Loss: 0.32955557107925415, Validation Accuracy: 0.89225\n",
      "Epoch: 85, Loss: 0.3277687132358551, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 86, Loss: 0.3260248601436615, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 87, Loss: 0.32432031631469727, Validation Accuracy: 0.8935833333333333\n",
      "Epoch: 88, Loss: 0.3226514160633087, Validation Accuracy: 0.894\n",
      "Epoch: 89, Loss: 0.321017861366272, Validation Accuracy: 0.8945\n",
      "Epoch: 90, Loss: 0.3194153308868408, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 91, Loss: 0.3178393840789795, Validation Accuracy: 0.8950833333333333\n",
      "Epoch: 92, Loss: 0.31628942489624023, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 93, Loss: 0.3147657811641693, Validation Accuracy: 0.896\n",
      "Epoch: 94, Loss: 0.3132689297199249, Validation Accuracy: 0.8964166666666666\n",
      "Epoch: 95, Loss: 0.3118009865283966, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 96, Loss: 0.3103582262992859, Validation Accuracy: 0.8965\n",
      "Epoch: 97, Loss: 0.30893993377685547, Validation Accuracy: 0.8966666666666666\n",
      "Epoch: 98, Loss: 0.30754366517066956, Validation Accuracy: 0.89725\n",
      "Epoch: 99, Loss: 0.3061697483062744, Validation Accuracy: 0.8980833333333333\n",
      "Dataset 89\n",
      "Epoch: 0, Loss: 3.316906690597534, Validation Accuracy: 0.23508333333333334\n",
      "Epoch: 1, Loss: 2.581848382949829, Validation Accuracy: 0.25225\n",
      "Epoch: 2, Loss: 2.1675760746002197, Validation Accuracy: 0.32966666666666666\n",
      "Epoch: 3, Loss: 1.8802809715270996, Validation Accuracy: 0.4250833333333333\n",
      "Epoch: 4, Loss: 1.7120522260665894, Validation Accuracy: 0.47691666666666666\n",
      "Epoch: 5, Loss: 1.5712450742721558, Validation Accuracy: 0.52525\n",
      "Epoch: 6, Loss: 1.4380910396575928, Validation Accuracy: 0.5635\n",
      "Epoch: 7, Loss: 1.312914490699768, Validation Accuracy: 0.60375\n",
      "Epoch: 8, Loss: 1.2003117799758911, Validation Accuracy: 0.6304166666666666\n",
      "Epoch: 9, Loss: 1.1054120063781738, Validation Accuracy: 0.6591666666666667\n",
      "Epoch: 10, Loss: 1.0445173978805542, Validation Accuracy: 0.6310833333333333\n",
      "Epoch: 11, Loss: 1.0706043243408203, Validation Accuracy: 0.5505833333333333\n",
      "Epoch: 12, Loss: 1.2897645235061646, Validation Accuracy: 0.4305\n",
      "Epoch: 13, Loss: 1.665496587753296, Validation Accuracy: 0.585\n",
      "Epoch: 14, Loss: 1.19637930393219, Validation Accuracy: 0.6961666666666667\n",
      "Epoch: 15, Loss: 0.9181074500083923, Validation Accuracy: 0.7266666666666667\n",
      "Epoch: 16, Loss: 0.8426744937896729, Validation Accuracy: 0.745\n",
      "Epoch: 17, Loss: 0.7805577516555786, Validation Accuracy: 0.7605\n",
      "Epoch: 18, Loss: 0.7451309561729431, Validation Accuracy: 0.7671666666666667\n",
      "Epoch: 19, Loss: 0.7110669016838074, Validation Accuracy: 0.77875\n",
      "Epoch: 20, Loss: 0.6877289414405823, Validation Accuracy: 0.78325\n",
      "Epoch: 21, Loss: 0.6646289825439453, Validation Accuracy: 0.7909166666666667\n",
      "Epoch: 22, Loss: 0.6476553678512573, Validation Accuracy: 0.7926666666666666\n",
      "Epoch: 23, Loss: 0.6299117207527161, Validation Accuracy: 0.8029166666666666\n",
      "Epoch: 24, Loss: 0.6170264482498169, Validation Accuracy: 0.8010833333333334\n",
      "Epoch: 25, Loss: 0.6029080152511597, Validation Accuracy: 0.8101666666666667\n",
      "Epoch: 26, Loss: 0.5930782556533813, Validation Accuracy: 0.8085\n",
      "Epoch: 27, Loss: 0.5814939141273499, Validation Accuracy: 0.8173333333333334\n",
      "Epoch: 28, Loss: 0.5743927359580994, Validation Accuracy: 0.8136666666666666\n",
      "Epoch: 29, Loss: 0.5647056698799133, Validation Accuracy: 0.8228333333333333\n",
      "Epoch: 30, Loss: 0.5599943399429321, Validation Accuracy: 0.8174166666666667\n",
      "Epoch: 31, Loss: 0.5523266196250916, Validation Accuracy: 0.82625\n",
      "Epoch: 32, Loss: 0.5502484440803528, Validation Accuracy: 0.8193333333333334\n",
      "Epoch: 33, Loss: 0.5449185967445374, Validation Accuracy: 0.8268333333333333\n",
      "Epoch: 34, Loss: 0.5468863844871521, Validation Accuracy: 0.8209166666666666\n",
      "Epoch: 35, Loss: 0.5432737469673157, Validation Accuracy: 0.8228333333333333\n",
      "Epoch: 36, Loss: 0.5499571561813354, Validation Accuracy: 0.8215833333333333\n",
      "Epoch: 37, Loss: 0.543549656867981, Validation Accuracy: 0.82275\n",
      "Epoch: 38, Loss: 0.5506247282028198, Validation Accuracy: 0.8254166666666667\n",
      "Epoch: 39, Loss: 0.5332047939300537, Validation Accuracy: 0.8305833333333333\n",
      "Epoch: 40, Loss: 0.5307095050811768, Validation Accuracy: 0.8375833333333333\n",
      "Epoch: 41, Loss: 0.5055288672447205, Validation Accuracy: 0.8463333333333334\n",
      "Epoch: 42, Loss: 0.49547433853149414, Validation Accuracy: 0.8485\n",
      "Epoch: 43, Loss: 0.47642263770103455, Validation Accuracy: 0.8535833333333334\n",
      "Epoch: 44, Loss: 0.46710696816444397, Validation Accuracy: 0.858\n",
      "Epoch: 45, Loss: 0.45539331436157227, Validation Accuracy: 0.8590833333333333\n",
      "Epoch: 46, Loss: 0.4483799934387207, Validation Accuracy: 0.8640833333333333\n",
      "Epoch: 47, Loss: 0.4408189356327057, Validation Accuracy: 0.865\n",
      "Epoch: 48, Loss: 0.43530359864234924, Validation Accuracy: 0.868\n",
      "Epoch: 49, Loss: 0.4296315014362335, Validation Accuracy: 0.86825\n",
      "Epoch: 50, Loss: 0.42490077018737793, Validation Accuracy: 0.8713333333333333\n",
      "Epoch: 51, Loss: 0.4203375577926636, Validation Accuracy: 0.8719166666666667\n",
      "Epoch: 52, Loss: 0.4162072241306305, Validation Accuracy: 0.87275\n",
      "Epoch: 53, Loss: 0.4122091829776764, Validation Accuracy: 0.874\n",
      "Epoch: 54, Loss: 0.4084617793560028, Validation Accuracy: 0.8755\n",
      "Epoch: 55, Loss: 0.40482547879219055, Validation Accuracy: 0.8764166666666666\n",
      "Epoch: 56, Loss: 0.40145209431648254, Validation Accuracy: 0.8780833333333333\n",
      "Epoch: 57, Loss: 0.3981091380119324, Validation Accuracy: 0.87875\n",
      "Epoch: 58, Loss: 0.39499539136886597, Validation Accuracy: 0.8799166666666667\n",
      "Epoch: 59, Loss: 0.39186421036720276, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 60, Loss: 0.38893184065818787, Validation Accuracy: 0.88075\n",
      "Epoch: 61, Loss: 0.3860674202442169, Validation Accuracy: 0.8831666666666667\n",
      "Epoch: 62, Loss: 0.3833310902118683, Validation Accuracy: 0.88175\n",
      "Epoch: 63, Loss: 0.38062456250190735, Validation Accuracy: 0.8845\n",
      "Epoch: 64, Loss: 0.37805911898612976, Validation Accuracy: 0.8845833333333334\n",
      "Epoch: 65, Loss: 0.3754712641239166, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 66, Loss: 0.37301310896873474, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 67, Loss: 0.37059473991394043, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 68, Loss: 0.36829936504364014, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 69, Loss: 0.36600396037101746, Validation Accuracy: 0.88825\n",
      "Epoch: 70, Loss: 0.36378347873687744, Validation Accuracy: 0.88875\n",
      "Epoch: 71, Loss: 0.3615942895412445, Validation Accuracy: 0.8890833333333333\n",
      "Epoch: 72, Loss: 0.35948851704597473, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 73, Loss: 0.35740572214126587, Validation Accuracy: 0.8900833333333333\n",
      "Epoch: 74, Loss: 0.3554096221923828, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 75, Loss: 0.3534148335456848, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 76, Loss: 0.3514779806137085, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 77, Loss: 0.3495713174343109, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 78, Loss: 0.34771841764450073, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 79, Loss: 0.34589076042175293, Validation Accuracy: 0.8934166666666666\n",
      "Epoch: 80, Loss: 0.3441197872161865, Validation Accuracy: 0.8925833333333333\n",
      "Epoch: 81, Loss: 0.3423645794391632, Validation Accuracy: 0.894\n",
      "Epoch: 82, Loss: 0.34067612886428833, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 83, Loss: 0.3389816880226135, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 84, Loss: 0.33734580874443054, Validation Accuracy: 0.89525\n",
      "Epoch: 85, Loss: 0.3357224762439728, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 86, Loss: 0.3341312110424042, Validation Accuracy: 0.8955833333333333\n",
      "Epoch: 87, Loss: 0.33256205916404724, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 88, Loss: 0.33101528882980347, Validation Accuracy: 0.8960833333333333\n",
      "Epoch: 89, Loss: 0.32950514554977417, Validation Accuracy: 0.8976666666666666\n",
      "Epoch: 90, Loss: 0.3280083239078522, Validation Accuracy: 0.8975833333333333\n",
      "Epoch: 91, Loss: 0.3265376091003418, Validation Accuracy: 0.8990833333333333\n",
      "Epoch: 92, Loss: 0.32509931921958923, Validation Accuracy: 0.8984166666666666\n",
      "Epoch: 93, Loss: 0.32368120551109314, Validation Accuracy: 0.89975\n",
      "Epoch: 94, Loss: 0.32229599356651306, Validation Accuracy: 0.8995\n",
      "Epoch: 95, Loss: 0.32090985774993896, Validation Accuracy: 0.9008333333333334\n",
      "Epoch: 96, Loss: 0.31955376267433167, Validation Accuracy: 0.9\n",
      "Epoch: 97, Loss: 0.31820380687713623, Validation Accuracy: 0.90125\n",
      "Epoch: 98, Loss: 0.31689807772636414, Validation Accuracy: 0.90075\n",
      "Epoch: 99, Loss: 0.3155781924724579, Validation Accuracy: 0.9018333333333334\n",
      "Dataset 90\n",
      "Epoch: 0, Loss: 3.297058582305908, Validation Accuracy: 0.21575\n",
      "Epoch: 1, Loss: 2.4944565296173096, Validation Accuracy: 0.31808333333333333\n",
      "Epoch: 2, Loss: 1.9437475204467773, Validation Accuracy: 0.36075\n",
      "Epoch: 3, Loss: 1.7577065229415894, Validation Accuracy: 0.4115\n",
      "Epoch: 4, Loss: 1.6424283981323242, Validation Accuracy: 0.45858333333333334\n",
      "Epoch: 5, Loss: 1.554248571395874, Validation Accuracy: 0.5176666666666667\n",
      "Epoch: 6, Loss: 1.4039177894592285, Validation Accuracy: 0.5950833333333333\n",
      "Epoch: 7, Loss: 1.2044804096221924, Validation Accuracy: 0.6421666666666667\n",
      "Epoch: 8, Loss: 1.0855498313903809, Validation Accuracy: 0.66225\n",
      "Epoch: 9, Loss: 1.0066277980804443, Validation Accuracy: 0.6851666666666667\n",
      "Epoch: 10, Loss: 0.9458917379379272, Validation Accuracy: 0.6943333333333334\n",
      "Epoch: 11, Loss: 0.9047335386276245, Validation Accuracy: 0.7104166666666667\n",
      "Epoch: 12, Loss: 0.8705191016197205, Validation Accuracy: 0.70225\n",
      "Epoch: 13, Loss: 0.8689214587211609, Validation Accuracy: 0.7185833333333334\n",
      "Epoch: 14, Loss: 0.8464012145996094, Validation Accuracy: 0.6978333333333333\n",
      "Epoch: 15, Loss: 0.8726303577423096, Validation Accuracy: 0.7275\n",
      "Epoch: 16, Loss: 0.8138591051101685, Validation Accuracy: 0.7241666666666666\n",
      "Epoch: 17, Loss: 0.7989628911018372, Validation Accuracy: 0.74375\n",
      "Epoch: 18, Loss: 0.7568432092666626, Validation Accuracy: 0.7655\n",
      "Epoch: 19, Loss: 0.7165637016296387, Validation Accuracy: 0.7601666666666667\n",
      "Epoch: 20, Loss: 0.7051649689674377, Validation Accuracy: 0.7818333333333334\n",
      "Epoch: 21, Loss: 0.6727593541145325, Validation Accuracy: 0.7671666666666667\n",
      "Epoch: 22, Loss: 0.686943531036377, Validation Accuracy: 0.7661666666666667\n",
      "Epoch: 23, Loss: 0.6998758912086487, Validation Accuracy: 0.7326666666666667\n",
      "Epoch: 24, Loss: 0.7605290412902832, Validation Accuracy: 0.7171666666666666\n",
      "Epoch: 25, Loss: 0.8164514303207397, Validation Accuracy: 0.6973333333333334\n",
      "Epoch: 26, Loss: 0.8393318057060242, Validation Accuracy: 0.753\n",
      "Epoch: 27, Loss: 0.7224494814872742, Validation Accuracy: 0.7905833333333333\n",
      "Epoch: 28, Loss: 0.6229203343391418, Validation Accuracy: 0.823\n",
      "Epoch: 29, Loss: 0.5568442940711975, Validation Accuracy: 0.8318333333333333\n",
      "Epoch: 30, Loss: 0.5290630459785461, Validation Accuracy: 0.8408333333333333\n",
      "Epoch: 31, Loss: 0.5114207863807678, Validation Accuracy: 0.8443333333333334\n",
      "Epoch: 32, Loss: 0.4996950328350067, Validation Accuracy: 0.8485\n",
      "Epoch: 33, Loss: 0.48981985449790955, Validation Accuracy: 0.851\n",
      "Epoch: 34, Loss: 0.4814777970314026, Validation Accuracy: 0.8539166666666667\n",
      "Epoch: 35, Loss: 0.473856657743454, Validation Accuracy: 0.8553333333333333\n",
      "Epoch: 36, Loss: 0.4670276343822479, Validation Accuracy: 0.8579166666666667\n",
      "Epoch: 37, Loss: 0.4606550335884094, Validation Accuracy: 0.8575\n",
      "Epoch: 38, Loss: 0.45477983355522156, Validation Accuracy: 0.8605833333333334\n",
      "Epoch: 39, Loss: 0.44927456974983215, Validation Accuracy: 0.86075\n",
      "Epoch: 40, Loss: 0.4441462755203247, Validation Accuracy: 0.86325\n",
      "Epoch: 41, Loss: 0.4392804801464081, Validation Accuracy: 0.8634166666666667\n",
      "Epoch: 42, Loss: 0.434756338596344, Validation Accuracy: 0.865\n",
      "Epoch: 43, Loss: 0.4304848909378052, Validation Accuracy: 0.8658333333333333\n",
      "Epoch: 44, Loss: 0.4264693260192871, Validation Accuracy: 0.8673333333333333\n",
      "Epoch: 45, Loss: 0.4227292537689209, Validation Accuracy: 0.8679166666666667\n",
      "Epoch: 46, Loss: 0.41931086778640747, Validation Accuracy: 0.8689166666666667\n",
      "Epoch: 47, Loss: 0.41611701250076294, Validation Accuracy: 0.8699166666666667\n",
      "Epoch: 48, Loss: 0.41337862610816956, Validation Accuracy: 0.8689166666666667\n",
      "Epoch: 49, Loss: 0.41098546981811523, Validation Accuracy: 0.8696666666666667\n",
      "Epoch: 50, Loss: 0.40930160880088806, Validation Accuracy: 0.8694166666666666\n",
      "Epoch: 51, Loss: 0.4079866409301758, Validation Accuracy: 0.87\n",
      "Epoch: 52, Loss: 0.4079550504684448, Validation Accuracy: 0.8684166666666666\n",
      "Epoch: 53, Loss: 0.4083411395549774, Validation Accuracy: 0.8683333333333333\n",
      "Epoch: 54, Loss: 0.4107314944267273, Validation Accuracy: 0.866\n",
      "Epoch: 55, Loss: 0.4135247766971588, Validation Accuracy: 0.8635\n",
      "Epoch: 56, Loss: 0.41926470398902893, Validation Accuracy: 0.862\n",
      "Epoch: 57, Loss: 0.4245133101940155, Validation Accuracy: 0.85725\n",
      "Epoch: 58, Loss: 0.43293285369873047, Validation Accuracy: 0.8588333333333333\n",
      "Epoch: 59, Loss: 0.4371299743652344, Validation Accuracy: 0.8526666666666667\n",
      "Epoch: 60, Loss: 0.4427609145641327, Validation Accuracy: 0.8578333333333333\n",
      "Epoch: 61, Loss: 0.4382579028606415, Validation Accuracy: 0.85625\n",
      "Epoch: 62, Loss: 0.43260645866394043, Validation Accuracy: 0.8649166666666667\n",
      "Epoch: 63, Loss: 0.41723746061325073, Validation Accuracy: 0.8695\n",
      "Epoch: 64, Loss: 0.4035153090953827, Validation Accuracy: 0.8760833333333333\n",
      "Epoch: 65, Loss: 0.3885103464126587, Validation Accuracy: 0.88\n",
      "Epoch: 66, Loss: 0.3776372969150543, Validation Accuracy: 0.884\n",
      "Epoch: 67, Loss: 0.3692389726638794, Validation Accuracy: 0.8849166666666667\n",
      "Epoch: 68, Loss: 0.36360111832618713, Validation Accuracy: 0.8870833333333333\n",
      "Epoch: 69, Loss: 0.3591657280921936, Validation Accuracy: 0.8876666666666667\n",
      "Epoch: 70, Loss: 0.35576939582824707, Validation Accuracy: 0.88825\n",
      "Epoch: 71, Loss: 0.35288020968437195, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 72, Loss: 0.3503781259059906, Validation Accuracy: 0.889\n",
      "Epoch: 73, Loss: 0.3481173813343048, Validation Accuracy: 0.889\n",
      "Epoch: 74, Loss: 0.3460146486759186, Validation Accuracy: 0.89025\n",
      "Epoch: 75, Loss: 0.3440203368663788, Validation Accuracy: 0.8903333333333333\n",
      "Epoch: 76, Loss: 0.3421206474304199, Validation Accuracy: 0.89125\n",
      "Epoch: 77, Loss: 0.34028738737106323, Validation Accuracy: 0.8918333333333334\n",
      "Epoch: 78, Loss: 0.33852115273475647, Validation Accuracy: 0.8921666666666667\n",
      "Epoch: 79, Loss: 0.3367905914783478, Validation Accuracy: 0.893\n",
      "Epoch: 80, Loss: 0.33510899543762207, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 81, Loss: 0.33346474170684814, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 82, Loss: 0.3318595290184021, Validation Accuracy: 0.8944166666666666\n",
      "Epoch: 83, Loss: 0.3302929699420929, Validation Accuracy: 0.8958333333333334\n",
      "Epoch: 84, Loss: 0.3287579417228699, Validation Accuracy: 0.8961666666666667\n",
      "Epoch: 85, Loss: 0.3272513747215271, Validation Accuracy: 0.89725\n",
      "Epoch: 86, Loss: 0.3257758617401123, Validation Accuracy: 0.8975\n",
      "Epoch: 87, Loss: 0.32432880997657776, Validation Accuracy: 0.8983333333333333\n",
      "Epoch: 88, Loss: 0.32290592789649963, Validation Accuracy: 0.8983333333333333\n",
      "Epoch: 89, Loss: 0.32150766253471375, Validation Accuracy: 0.8989166666666667\n",
      "Epoch: 90, Loss: 0.32013627886772156, Validation Accuracy: 0.89925\n",
      "Epoch: 91, Loss: 0.31878694891929626, Validation Accuracy: 0.8999166666666667\n",
      "Epoch: 92, Loss: 0.317457377910614, Validation Accuracy: 0.9000833333333333\n",
      "Epoch: 93, Loss: 0.3161434829235077, Validation Accuracy: 0.9003333333333333\n",
      "Epoch: 94, Loss: 0.3148505687713623, Validation Accuracy: 0.9009166666666667\n",
      "Epoch: 95, Loss: 0.31357577443122864, Validation Accuracy: 0.901\n",
      "Epoch: 96, Loss: 0.3123219907283783, Validation Accuracy: 0.9015\n",
      "Epoch: 97, Loss: 0.31109166145324707, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 98, Loss: 0.30988308787345886, Validation Accuracy: 0.9020833333333333\n",
      "Epoch: 99, Loss: 0.3086903393268585, Validation Accuracy: 0.902\n",
      "Dataset 91\n",
      "Epoch: 0, Loss: 3.9453890323638916, Validation Accuracy: 0.13025\n",
      "Epoch: 1, Loss: 3.5809991359710693, Validation Accuracy: 0.22183333333333333\n",
      "Epoch: 2, Loss: 2.4774320125579834, Validation Accuracy: 0.28408333333333335\n",
      "Epoch: 3, Loss: 1.9588842391967773, Validation Accuracy: 0.359\n",
      "Epoch: 4, Loss: 1.786169409751892, Validation Accuracy: 0.41641666666666666\n",
      "Epoch: 5, Loss: 1.6467121839523315, Validation Accuracy: 0.47783333333333333\n",
      "Epoch: 6, Loss: 1.4948700666427612, Validation Accuracy: 0.5191666666666667\n",
      "Epoch: 7, Loss: 1.3825554847717285, Validation Accuracy: 0.5621666666666667\n",
      "Epoch: 8, Loss: 1.2845731973648071, Validation Accuracy: 0.5899166666666666\n",
      "Epoch: 9, Loss: 1.1985019445419312, Validation Accuracy: 0.6189166666666667\n",
      "Epoch: 10, Loss: 1.1223499774932861, Validation Accuracy: 0.6385833333333333\n",
      "Epoch: 11, Loss: 1.0552101135253906, Validation Accuracy: 0.66175\n",
      "Epoch: 12, Loss: 0.9960259795188904, Validation Accuracy: 0.6805833333333333\n",
      "Epoch: 13, Loss: 0.9440490007400513, Validation Accuracy: 0.6948333333333333\n",
      "Epoch: 14, Loss: 0.8993160724639893, Validation Accuracy: 0.7065\n",
      "Epoch: 15, Loss: 0.8614437580108643, Validation Accuracy: 0.719\n",
      "Epoch: 16, Loss: 0.8313282132148743, Validation Accuracy: 0.7235\n",
      "Epoch: 17, Loss: 0.808311939239502, Validation Accuracy: 0.7278333333333333\n",
      "Epoch: 18, Loss: 0.8023527264595032, Validation Accuracy: 0.7234166666666667\n",
      "Epoch: 19, Loss: 0.8068335652351379, Validation Accuracy: 0.7035\n",
      "Epoch: 20, Loss: 0.8726558685302734, Validation Accuracy: 0.6975\n",
      "Epoch: 21, Loss: 0.8668607473373413, Validation Accuracy: 0.6783333333333333\n",
      "Epoch: 22, Loss: 0.9456183314323425, Validation Accuracy: 0.7370833333333333\n",
      "Epoch: 23, Loss: 0.7622494101524353, Validation Accuracy: 0.758\n",
      "Epoch: 24, Loss: 0.7180963754653931, Validation Accuracy: 0.77775\n",
      "Epoch: 25, Loss: 0.6616563200950623, Validation Accuracy: 0.788\n",
      "Epoch: 26, Loss: 0.6394488215446472, Validation Accuracy: 0.7945833333333333\n",
      "Epoch: 27, Loss: 0.6183323860168457, Validation Accuracy: 0.80075\n",
      "Epoch: 28, Loss: 0.6036434769630432, Validation Accuracy: 0.8045833333333333\n",
      "Epoch: 29, Loss: 0.5898528695106506, Validation Accuracy: 0.8085\n",
      "Epoch: 30, Loss: 0.5782618522644043, Validation Accuracy: 0.8113333333333334\n",
      "Epoch: 31, Loss: 0.5674101114273071, Validation Accuracy: 0.8135\n",
      "Epoch: 32, Loss: 0.5578884482383728, Validation Accuracy: 0.8176666666666667\n",
      "Epoch: 33, Loss: 0.5490872263908386, Validation Accuracy: 0.8193333333333334\n",
      "Epoch: 34, Loss: 0.5415736436843872, Validation Accuracy: 0.82125\n",
      "Epoch: 35, Loss: 0.5351000428199768, Validation Accuracy: 0.8235\n",
      "Epoch: 36, Loss: 0.5304573774337769, Validation Accuracy: 0.8240833333333333\n",
      "Epoch: 37, Loss: 0.5274911522865295, Validation Accuracy: 0.8225\n",
      "Epoch: 38, Loss: 0.5276927351951599, Validation Accuracy: 0.8225\n",
      "Epoch: 39, Loss: 0.5310582518577576, Validation Accuracy: 0.8169166666666666\n",
      "Epoch: 40, Loss: 0.5394366383552551, Validation Accuracy: 0.812\n",
      "Epoch: 41, Loss: 0.5506153702735901, Validation Accuracy: 0.8043333333333333\n",
      "Epoch: 42, Loss: 0.5642640590667725, Validation Accuracy: 0.8008333333333333\n",
      "Epoch: 43, Loss: 0.5735418796539307, Validation Accuracy: 0.8006666666666666\n",
      "Epoch: 44, Loss: 0.5710692405700684, Validation Accuracy: 0.80725\n",
      "Epoch: 45, Loss: 0.5559131503105164, Validation Accuracy: 0.8161666666666667\n",
      "Epoch: 46, Loss: 0.5297018885612488, Validation Accuracy: 0.8275833333333333\n",
      "Epoch: 47, Loss: 0.5046080946922302, Validation Accuracy: 0.8368333333333333\n",
      "Epoch: 48, Loss: 0.4824105203151703, Validation Accuracy: 0.8431666666666666\n",
      "Epoch: 49, Loss: 0.467492014169693, Validation Accuracy: 0.8479166666666667\n",
      "Epoch: 50, Loss: 0.4559873938560486, Validation Accuracy: 0.8503333333333334\n",
      "Epoch: 51, Loss: 0.44799256324768066, Validation Accuracy: 0.85425\n",
      "Epoch: 52, Loss: 0.4409445524215698, Validation Accuracy: 0.8544166666666667\n",
      "Epoch: 53, Loss: 0.4354441463947296, Validation Accuracy: 0.8590833333333333\n",
      "Epoch: 54, Loss: 0.4303819239139557, Validation Accuracy: 0.8571666666666666\n",
      "Epoch: 55, Loss: 0.42607975006103516, Validation Accuracy: 0.8621666666666666\n",
      "Epoch: 56, Loss: 0.421957790851593, Validation Accuracy: 0.8585833333333334\n",
      "Epoch: 57, Loss: 0.4183396100997925, Validation Accuracy: 0.8643333333333333\n",
      "Epoch: 58, Loss: 0.414724200963974, Validation Accuracy: 0.861\n",
      "Epoch: 59, Loss: 0.4115273952484131, Validation Accuracy: 0.8655833333333334\n",
      "Epoch: 60, Loss: 0.4084644317626953, Validation Accuracy: 0.86275\n",
      "Epoch: 61, Loss: 0.4056088924407959, Validation Accuracy: 0.8671666666666666\n",
      "Epoch: 62, Loss: 0.4029202163219452, Validation Accuracy: 0.8655\n",
      "Epoch: 63, Loss: 0.4004109799861908, Validation Accuracy: 0.86825\n",
      "Epoch: 64, Loss: 0.39806750416755676, Validation Accuracy: 0.8671666666666666\n",
      "Epoch: 65, Loss: 0.3959423303604126, Validation Accuracy: 0.8688333333333333\n",
      "Epoch: 66, Loss: 0.3940662145614624, Validation Accuracy: 0.86925\n",
      "Epoch: 67, Loss: 0.39246147871017456, Validation Accuracy: 0.8696666666666667\n",
      "Epoch: 68, Loss: 0.3909115791320801, Validation Accuracy: 0.8699166666666667\n",
      "Epoch: 69, Loss: 0.3897756338119507, Validation Accuracy: 0.8708333333333333\n",
      "Epoch: 70, Loss: 0.38872990012168884, Validation Accuracy: 0.87\n",
      "Epoch: 71, Loss: 0.3882254660129547, Validation Accuracy: 0.87075\n",
      "Epoch: 72, Loss: 0.38749536871910095, Validation Accuracy: 0.8709166666666667\n",
      "Epoch: 73, Loss: 0.387364000082016, Validation Accuracy: 0.8714166666666666\n",
      "Epoch: 74, Loss: 0.38660889863967896, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 75, Loss: 0.3866555988788605, Validation Accuracy: 0.8714166666666666\n",
      "Epoch: 76, Loss: 0.3856933116912842, Validation Accuracy: 0.8710833333333333\n",
      "Epoch: 77, Loss: 0.38541552424430847, Validation Accuracy: 0.8724166666666666\n",
      "Epoch: 78, Loss: 0.38358259201049805, Validation Accuracy: 0.8718333333333333\n",
      "Epoch: 79, Loss: 0.38248997926712036, Validation Accuracy: 0.8730833333333333\n",
      "Epoch: 80, Loss: 0.3793925344944, Validation Accuracy: 0.87375\n",
      "Epoch: 81, Loss: 0.3769574761390686, Validation Accuracy: 0.8745833333333334\n",
      "Epoch: 82, Loss: 0.37278449535369873, Validation Accuracy: 0.87625\n",
      "Epoch: 83, Loss: 0.36925220489501953, Validation Accuracy: 0.8771666666666667\n",
      "Epoch: 84, Loss: 0.3645947277545929, Validation Accuracy: 0.8788333333333334\n",
      "Epoch: 85, Loss: 0.36060473322868347, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 86, Loss: 0.35624319314956665, Validation Accuracy: 0.8821666666666667\n",
      "Epoch: 87, Loss: 0.35249459743499756, Validation Accuracy: 0.88325\n",
      "Epoch: 88, Loss: 0.34878653287887573, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 89, Loss: 0.3455207049846649, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 90, Loss: 0.3424606919288635, Validation Accuracy: 0.88575\n",
      "Epoch: 91, Loss: 0.3397546112537384, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 92, Loss: 0.33722060918807983, Validation Accuracy: 0.8866666666666667\n",
      "Epoch: 93, Loss: 0.33488863706588745, Validation Accuracy: 0.88925\n",
      "Epoch: 94, Loss: 0.332698255777359, Validation Accuracy: 0.88875\n",
      "Epoch: 95, Loss: 0.3307081162929535, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 96, Loss: 0.32879284024238586, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 97, Loss: 0.3269864320755005, Validation Accuracy: 0.8916666666666667\n",
      "Epoch: 98, Loss: 0.32529425621032715, Validation Accuracy: 0.89125\n",
      "Epoch: 99, Loss: 0.32362100481987, Validation Accuracy: 0.8926666666666667\n",
      "Dataset 92\n",
      "Epoch: 0, Loss: 3.916167736053467, Validation Accuracy: 0.12325\n",
      "Epoch: 1, Loss: 5.206894874572754, Validation Accuracy: 0.15458333333333332\n",
      "Epoch: 2, Loss: 4.897713661193848, Validation Accuracy: 0.15041666666666667\n",
      "Epoch: 3, Loss: 4.151345729827881, Validation Accuracy: 0.20675\n",
      "Epoch: 4, Loss: 2.690261125564575, Validation Accuracy: 0.15416666666666667\n",
      "Epoch: 5, Loss: 2.4985780715942383, Validation Accuracy: 0.2705\n",
      "Epoch: 6, Loss: 2.0548160076141357, Validation Accuracy: 0.3235\n",
      "Epoch: 7, Loss: 1.9449368715286255, Validation Accuracy: 0.3455\n",
      "Epoch: 8, Loss: 1.8798922300338745, Validation Accuracy: 0.362\n",
      "Epoch: 9, Loss: 1.829542636871338, Validation Accuracy: 0.37733333333333335\n",
      "Epoch: 10, Loss: 1.7840646505355835, Validation Accuracy: 0.39066666666666666\n",
      "Epoch: 11, Loss: 1.742058277130127, Validation Accuracy: 0.4035\n",
      "Epoch: 12, Loss: 1.7007877826690674, Validation Accuracy: 0.4205\n",
      "Epoch: 13, Loss: 1.6575547456741333, Validation Accuracy: 0.4390833333333333\n",
      "Epoch: 14, Loss: 1.610592246055603, Validation Accuracy: 0.46108333333333335\n",
      "Epoch: 15, Loss: 1.5585455894470215, Validation Accuracy: 0.4866666666666667\n",
      "Epoch: 16, Loss: 1.5011262893676758, Validation Accuracy: 0.5105833333333333\n",
      "Epoch: 17, Loss: 1.4391329288482666, Validation Accuracy: 0.5374166666666667\n",
      "Epoch: 18, Loss: 1.372109055519104, Validation Accuracy: 0.565\n",
      "Epoch: 19, Loss: 1.3000596761703491, Validation Accuracy: 0.5921666666666666\n",
      "Epoch: 20, Loss: 1.225070595741272, Validation Accuracy: 0.6206666666666667\n",
      "Epoch: 21, Loss: 1.1503499746322632, Validation Accuracy: 0.6461666666666667\n",
      "Epoch: 22, Loss: 1.0803465843200684, Validation Accuracy: 0.67575\n",
      "Epoch: 23, Loss: 1.0210347175598145, Validation Accuracy: 0.6725833333333333\n",
      "Epoch: 24, Loss: 0.9862018823623657, Validation Accuracy: 0.6569166666666667\n",
      "Epoch: 25, Loss: 1.0408364534378052, Validation Accuracy: 0.49783333333333335\n",
      "Epoch: 26, Loss: 1.4466825723648071, Validation Accuracy: 0.42525\n",
      "Epoch: 27, Loss: 1.6973296403884888, Validation Accuracy: 0.52375\n",
      "Epoch: 28, Loss: 1.3191509246826172, Validation Accuracy: 0.6781666666666667\n",
      "Epoch: 29, Loss: 0.9816598892211914, Validation Accuracy: 0.7224166666666667\n",
      "Epoch: 30, Loss: 0.8802676796913147, Validation Accuracy: 0.7435833333333334\n",
      "Epoch: 31, Loss: 0.8168707489967346, Validation Accuracy: 0.7566666666666667\n",
      "Epoch: 32, Loss: 0.7706863880157471, Validation Accuracy: 0.76675\n",
      "Epoch: 33, Loss: 0.7361757159233093, Validation Accuracy: 0.77375\n",
      "Epoch: 34, Loss: 0.7095018625259399, Validation Accuracy: 0.7794166666666666\n",
      "Epoch: 35, Loss: 0.687953531742096, Validation Accuracy: 0.78525\n",
      "Epoch: 36, Loss: 0.6697583794593811, Validation Accuracy: 0.7899166666666667\n",
      "Epoch: 37, Loss: 0.6539160013198853, Validation Accuracy: 0.794\n",
      "Epoch: 38, Loss: 0.6398976445198059, Validation Accuracy: 0.7975833333333333\n",
      "Epoch: 39, Loss: 0.627191960811615, Validation Accuracy: 0.80175\n",
      "Epoch: 40, Loss: 0.6155291795730591, Validation Accuracy: 0.8055833333333333\n",
      "Epoch: 41, Loss: 0.6047280430793762, Validation Accuracy: 0.8081666666666667\n",
      "Epoch: 42, Loss: 0.5946481823921204, Validation Accuracy: 0.8111666666666667\n",
      "Epoch: 43, Loss: 0.5852075219154358, Validation Accuracy: 0.81325\n",
      "Epoch: 44, Loss: 0.576312243938446, Validation Accuracy: 0.8154166666666667\n",
      "Epoch: 45, Loss: 0.5678812861442566, Validation Accuracy: 0.8175\n",
      "Epoch: 46, Loss: 0.5598544478416443, Validation Accuracy: 0.8200833333333334\n",
      "Epoch: 47, Loss: 0.5522212386131287, Validation Accuracy: 0.8231666666666667\n",
      "Epoch: 48, Loss: 0.5449671149253845, Validation Accuracy: 0.8259166666666666\n",
      "Epoch: 49, Loss: 0.5380867123603821, Validation Accuracy: 0.8274166666666667\n",
      "Epoch: 50, Loss: 0.5314906239509583, Validation Accuracy: 0.8301666666666667\n",
      "Epoch: 51, Loss: 0.5251515507698059, Validation Accuracy: 0.8333333333333334\n",
      "Epoch: 52, Loss: 0.5190373659133911, Validation Accuracy: 0.83525\n",
      "Epoch: 53, Loss: 0.5131475925445557, Validation Accuracy: 0.8375\n",
      "Epoch: 54, Loss: 0.5074834227561951, Validation Accuracy: 0.84025\n",
      "Epoch: 55, Loss: 0.5020269751548767, Validation Accuracy: 0.8435833333333334\n",
      "Epoch: 56, Loss: 0.49677348136901855, Validation Accuracy: 0.8451666666666666\n",
      "Epoch: 57, Loss: 0.4917144477367401, Validation Accuracy: 0.84625\n",
      "Epoch: 58, Loss: 0.4868380129337311, Validation Accuracy: 0.8478333333333333\n",
      "Epoch: 59, Loss: 0.48212724924087524, Validation Accuracy: 0.8493333333333334\n",
      "Epoch: 60, Loss: 0.4775838553905487, Validation Accuracy: 0.85075\n",
      "Epoch: 61, Loss: 0.47319483757019043, Validation Accuracy: 0.8519166666666667\n",
      "Epoch: 62, Loss: 0.4689444303512573, Validation Accuracy: 0.8531666666666666\n",
      "Epoch: 63, Loss: 0.4648270606994629, Validation Accuracy: 0.8551666666666666\n",
      "Epoch: 64, Loss: 0.46084341406822205, Validation Accuracy: 0.8556666666666667\n",
      "Epoch: 65, Loss: 0.45699378848075867, Validation Accuracy: 0.8575\n",
      "Epoch: 66, Loss: 0.45328760147094727, Validation Accuracy: 0.8575\n",
      "Epoch: 67, Loss: 0.4497242569923401, Validation Accuracy: 0.8591666666666666\n",
      "Epoch: 68, Loss: 0.44632744789123535, Validation Accuracy: 0.8594166666666667\n",
      "Epoch: 69, Loss: 0.4431628882884979, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 70, Loss: 0.4402469992637634, Validation Accuracy: 0.86125\n",
      "Epoch: 71, Loss: 0.43773970007896423, Validation Accuracy: 0.86375\n",
      "Epoch: 72, Loss: 0.43573540449142456, Validation Accuracy: 0.8624166666666667\n",
      "Epoch: 73, Loss: 0.4347634017467499, Validation Accuracy: 0.8641666666666666\n",
      "Epoch: 74, Loss: 0.4349179267883301, Validation Accuracy: 0.8615\n",
      "Epoch: 75, Loss: 0.43776756525039673, Validation Accuracy: 0.8603333333333333\n",
      "Epoch: 76, Loss: 0.4433944523334503, Validation Accuracy: 0.8520833333333333\n",
      "Epoch: 77, Loss: 0.456973135471344, Validation Accuracy: 0.846\n",
      "Epoch: 78, Loss: 0.4755744934082031, Validation Accuracy: 0.83025\n",
      "Epoch: 79, Loss: 0.5146864652633667, Validation Accuracy: 0.81225\n",
      "Epoch: 80, Loss: 0.552530825138092, Validation Accuracy: 0.7921666666666667\n",
      "Epoch: 81, Loss: 0.6213837265968323, Validation Accuracy: 0.7928333333333333\n",
      "Epoch: 82, Loss: 0.611431896686554, Validation Accuracy: 0.8015833333333333\n",
      "Epoch: 83, Loss: 0.5903582572937012, Validation Accuracy: 0.8451666666666666\n",
      "Epoch: 84, Loss: 0.47660061717033386, Validation Accuracy: 0.86525\n",
      "Epoch: 85, Loss: 0.42902761697769165, Validation Accuracy: 0.8701666666666666\n",
      "Epoch: 86, Loss: 0.40794476866722107, Validation Accuracy: 0.8765\n",
      "Epoch: 87, Loss: 0.4007972776889801, Validation Accuracy: 0.877\n",
      "Epoch: 88, Loss: 0.39647090435028076, Validation Accuracy: 0.87925\n",
      "Epoch: 89, Loss: 0.3931780457496643, Validation Accuracy: 0.8795833333333334\n",
      "Epoch: 90, Loss: 0.3902619481086731, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 91, Loss: 0.3875882625579834, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 92, Loss: 0.3850689232349396, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 93, Loss: 0.38266581296920776, Validation Accuracy: 0.8814166666666666\n",
      "Epoch: 94, Loss: 0.3803556263446808, Validation Accuracy: 0.8818333333333334\n",
      "Epoch: 95, Loss: 0.3781193494796753, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 96, Loss: 0.3759617209434509, Validation Accuracy: 0.88275\n",
      "Epoch: 97, Loss: 0.3738681674003601, Validation Accuracy: 0.88325\n",
      "Epoch: 98, Loss: 0.3718334138393402, Validation Accuracy: 0.8841666666666667\n",
      "Epoch: 99, Loss: 0.369843065738678, Validation Accuracy: 0.8845833333333334\n",
      "Dataset 93\n",
      "Epoch: 0, Loss: 3.7200443744659424, Validation Accuracy: 0.10416666666666667\n",
      "Epoch: 1, Loss: 2.825453042984009, Validation Accuracy: 0.23458333333333334\n",
      "Epoch: 2, Loss: 2.135951280593872, Validation Accuracy: 0.33108333333333334\n",
      "Epoch: 3, Loss: 1.8862714767456055, Validation Accuracy: 0.3660833333333333\n",
      "Epoch: 4, Loss: 1.7688933610916138, Validation Accuracy: 0.4058333333333333\n",
      "Epoch: 5, Loss: 1.6758118867874146, Validation Accuracy: 0.4315833333333333\n",
      "Epoch: 6, Loss: 1.5836690664291382, Validation Accuracy: 0.46858333333333335\n",
      "Epoch: 7, Loss: 1.5020198822021484, Validation Accuracy: 0.4935833333333333\n",
      "Epoch: 8, Loss: 1.4167240858078003, Validation Accuracy: 0.5343333333333333\n",
      "Epoch: 9, Loss: 1.3357888460159302, Validation Accuracy: 0.5545\n",
      "Epoch: 10, Loss: 1.2530492544174194, Validation Accuracy: 0.593\n",
      "Epoch: 11, Loss: 1.194948673248291, Validation Accuracy: 0.5928333333333333\n",
      "Epoch: 12, Loss: 1.1699774265289307, Validation Accuracy: 0.5286666666666666\n",
      "Epoch: 13, Loss: 1.3678134679794312, Validation Accuracy: 0.53\n",
      "Epoch: 14, Loss: 1.3921804428100586, Validation Accuracy: 0.48733333333333334\n",
      "Epoch: 15, Loss: 1.5890896320343018, Validation Accuracy: 0.5985\n",
      "Epoch: 16, Loss: 1.1394132375717163, Validation Accuracy: 0.7140833333333333\n",
      "Epoch: 17, Loss: 0.8882851600646973, Validation Accuracy: 0.74425\n",
      "Epoch: 18, Loss: 0.8150240778923035, Validation Accuracy: 0.7546666666666667\n",
      "Epoch: 19, Loss: 0.7675126194953918, Validation Accuracy: 0.7639166666666667\n",
      "Epoch: 20, Loss: 0.7320271730422974, Validation Accuracy: 0.7726666666666666\n",
      "Epoch: 21, Loss: 0.7035371661186218, Validation Accuracy: 0.779\n",
      "Epoch: 22, Loss: 0.6805406212806702, Validation Accuracy: 0.7829166666666667\n",
      "Epoch: 23, Loss: 0.6618964076042175, Validation Accuracy: 0.78825\n",
      "Epoch: 24, Loss: 0.6488096714019775, Validation Accuracy: 0.78975\n",
      "Epoch: 25, Loss: 0.6440503001213074, Validation Accuracy: 0.7786666666666666\n",
      "Epoch: 26, Loss: 0.6541781425476074, Validation Accuracy: 0.7638333333333334\n",
      "Epoch: 27, Loss: 0.6936041712760925, Validation Accuracy: 0.7248333333333333\n",
      "Epoch: 28, Loss: 0.7666986584663391, Validation Accuracy: 0.6949166666666666\n",
      "Epoch: 29, Loss: 0.8537599444389343, Validation Accuracy: 0.7038333333333333\n",
      "Epoch: 30, Loss: 0.8211676478385925, Validation Accuracy: 0.76425\n",
      "Epoch: 31, Loss: 0.6881787776947021, Validation Accuracy: 0.79125\n",
      "Epoch: 32, Loss: 0.6073089241981506, Validation Accuracy: 0.8173333333333334\n",
      "Epoch: 33, Loss: 0.5690703392028809, Validation Accuracy: 0.818\n",
      "Epoch: 34, Loss: 0.5513672828674316, Validation Accuracy: 0.8271666666666667\n",
      "Epoch: 35, Loss: 0.5386209487915039, Validation Accuracy: 0.8285\n",
      "Epoch: 36, Loss: 0.5288222432136536, Validation Accuracy: 0.83275\n",
      "Epoch: 37, Loss: 0.5201881527900696, Validation Accuracy: 0.8348333333333333\n",
      "Epoch: 38, Loss: 0.5125679969787598, Validation Accuracy: 0.8373333333333334\n",
      "Epoch: 39, Loss: 0.5055601596832275, Validation Accuracy: 0.8389166666666666\n",
      "Epoch: 40, Loss: 0.49916011095046997, Validation Accuracy: 0.8410833333333333\n",
      "Epoch: 41, Loss: 0.4930841326713562, Validation Accuracy: 0.8430833333333333\n",
      "Epoch: 42, Loss: 0.48747843503952026, Validation Accuracy: 0.8454166666666667\n",
      "Epoch: 43, Loss: 0.4820917844772339, Validation Accuracy: 0.8465833333333334\n",
      "Epoch: 44, Loss: 0.47714611887931824, Validation Accuracy: 0.8490833333333333\n",
      "Epoch: 45, Loss: 0.47236165404319763, Validation Accuracy: 0.84925\n",
      "Epoch: 46, Loss: 0.46810653805732727, Validation Accuracy: 0.8530833333333333\n",
      "Epoch: 47, Loss: 0.46389928460121155, Validation Accuracy: 0.8513333333333334\n",
      "Epoch: 48, Loss: 0.4603036642074585, Validation Accuracy: 0.8560833333333333\n",
      "Epoch: 49, Loss: 0.45672526955604553, Validation Accuracy: 0.8535833333333334\n",
      "Epoch: 50, Loss: 0.45384910702705383, Validation Accuracy: 0.8566666666666667\n",
      "Epoch: 51, Loss: 0.4510529041290283, Validation Accuracy: 0.8553333333333333\n",
      "Epoch: 52, Loss: 0.44906753301620483, Validation Accuracy: 0.8584166666666667\n",
      "Epoch: 53, Loss: 0.4472118020057678, Validation Accuracy: 0.8554166666666667\n",
      "Epoch: 54, Loss: 0.44625023007392883, Validation Accuracy: 0.8583333333333333\n",
      "Epoch: 55, Loss: 0.4452227056026459, Validation Accuracy: 0.8559166666666667\n",
      "Epoch: 56, Loss: 0.44511640071868896, Validation Accuracy: 0.8576666666666667\n",
      "Epoch: 57, Loss: 0.44449833035469055, Validation Accuracy: 0.8549166666666667\n",
      "Epoch: 58, Loss: 0.44478103518486023, Validation Accuracy: 0.8573333333333333\n",
      "Epoch: 59, Loss: 0.4437403082847595, Validation Accuracy: 0.8549166666666667\n",
      "Epoch: 60, Loss: 0.443458616733551, Validation Accuracy: 0.8583333333333333\n",
      "Epoch: 61, Loss: 0.44100114703178406, Validation Accuracy: 0.8575\n",
      "Epoch: 62, Loss: 0.4391729235649109, Validation Accuracy: 0.86\n",
      "Epoch: 63, Loss: 0.4346897006034851, Validation Accuracy: 0.8600833333333333\n",
      "Epoch: 64, Loss: 0.4309801161289215, Validation Accuracy: 0.8641666666666666\n",
      "Epoch: 65, Loss: 0.42518529295921326, Validation Accuracy: 0.8639166666666667\n",
      "Epoch: 66, Loss: 0.4202413260936737, Validation Accuracy: 0.8680833333333333\n",
      "Epoch: 67, Loss: 0.4141407608985901, Validation Accuracy: 0.86825\n",
      "Epoch: 68, Loss: 0.40907952189445496, Validation Accuracy: 0.8720833333333333\n",
      "Epoch: 69, Loss: 0.40387409925460815, Validation Accuracy: 0.8715\n",
      "Epoch: 70, Loss: 0.399522989988327, Validation Accuracy: 0.87575\n",
      "Epoch: 71, Loss: 0.3952842056751251, Validation Accuracy: 0.8749166666666667\n",
      "Epoch: 72, Loss: 0.39164435863494873, Validation Accuracy: 0.8775833333333334\n",
      "Epoch: 73, Loss: 0.3881610035896301, Validation Accuracy: 0.8771666666666667\n",
      "Epoch: 74, Loss: 0.385125070810318, Validation Accuracy: 0.87975\n",
      "Epoch: 75, Loss: 0.38223156332969666, Validation Accuracy: 0.8799166666666667\n",
      "Epoch: 76, Loss: 0.3796626925468445, Validation Accuracy: 0.8815833333333334\n",
      "Epoch: 77, Loss: 0.37716010212898254, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 78, Loss: 0.3748778998851776, Validation Accuracy: 0.8830833333333333\n",
      "Epoch: 79, Loss: 0.37267568707466125, Validation Accuracy: 0.88325\n",
      "Epoch: 80, Loss: 0.3706003725528717, Validation Accuracy: 0.8845833333333334\n",
      "Epoch: 81, Loss: 0.36856111884117126, Validation Accuracy: 0.88475\n",
      "Epoch: 82, Loss: 0.3666747212409973, Validation Accuracy: 0.88575\n",
      "Epoch: 83, Loss: 0.36478284001350403, Validation Accuracy: 0.8858333333333334\n",
      "Epoch: 84, Loss: 0.36301323771476746, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 85, Loss: 0.3612229824066162, Validation Accuracy: 0.8865\n",
      "Epoch: 86, Loss: 0.3595404326915741, Validation Accuracy: 0.88775\n",
      "Epoch: 87, Loss: 0.35784444212913513, Validation Accuracy: 0.8885\n",
      "Epoch: 88, Loss: 0.3562504053115845, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 89, Loss: 0.3546450138092041, Validation Accuracy: 0.88975\n",
      "Epoch: 90, Loss: 0.3531125485897064, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 91, Loss: 0.3515738248825073, Validation Accuracy: 0.8900833333333333\n",
      "Epoch: 92, Loss: 0.3500930070877075, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 93, Loss: 0.34859228134155273, Validation Accuracy: 0.891\n",
      "Epoch: 94, Loss: 0.3471619784832001, Validation Accuracy: 0.892\n",
      "Epoch: 95, Loss: 0.3457180857658386, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 96, Loss: 0.34432005882263184, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 97, Loss: 0.3428930342197418, Validation Accuracy: 0.89275\n",
      "Epoch: 98, Loss: 0.3415544927120209, Validation Accuracy: 0.8935833333333333\n",
      "Epoch: 99, Loss: 0.34017160534858704, Validation Accuracy: 0.8938333333333334\n",
      "Dataset 94\n",
      "Epoch: 0, Loss: 2.981254816055298, Validation Accuracy: 0.21933333333333332\n",
      "Epoch: 1, Loss: 2.780601978302002, Validation Accuracy: 0.25516666666666665\n",
      "Epoch: 2, Loss: 2.9342684745788574, Validation Accuracy: 0.275\n",
      "Epoch: 3, Loss: 1.9584205150604248, Validation Accuracy: 0.3928333333333333\n",
      "Epoch: 4, Loss: 1.6691350936889648, Validation Accuracy: 0.45166666666666666\n",
      "Epoch: 5, Loss: 1.5404198169708252, Validation Accuracy: 0.49983333333333335\n",
      "Epoch: 6, Loss: 1.4313101768493652, Validation Accuracy: 0.54675\n",
      "Epoch: 7, Loss: 1.3285279273986816, Validation Accuracy: 0.5860833333333333\n",
      "Epoch: 8, Loss: 1.2324496507644653, Validation Accuracy: 0.6205833333333334\n",
      "Epoch: 9, Loss: 1.1461256742477417, Validation Accuracy: 0.6456666666666667\n",
      "Epoch: 10, Loss: 1.0708624124526978, Validation Accuracy: 0.6664166666666667\n",
      "Epoch: 11, Loss: 1.0057549476623535, Validation Accuracy: 0.68425\n",
      "Epoch: 12, Loss: 0.9494146108627319, Validation Accuracy: 0.70225\n",
      "Epoch: 13, Loss: 0.9004184603691101, Validation Accuracy: 0.71575\n",
      "Epoch: 14, Loss: 0.8575969934463501, Validation Accuracy: 0.72825\n",
      "Epoch: 15, Loss: 0.8203361630439758, Validation Accuracy: 0.7395833333333334\n",
      "Epoch: 16, Loss: 0.7888336777687073, Validation Accuracy: 0.7481666666666666\n",
      "Epoch: 17, Loss: 0.7641401290893555, Validation Accuracy: 0.7473333333333333\n",
      "Epoch: 18, Loss: 0.7525031566619873, Validation Accuracy: 0.74075\n",
      "Epoch: 19, Loss: 0.7670140862464905, Validation Accuracy: 0.71\n",
      "Epoch: 20, Loss: 0.8467741012573242, Validation Accuracy: 0.6629166666666667\n",
      "Epoch: 21, Loss: 0.9793016910552979, Validation Accuracy: 0.6296666666666667\n",
      "Epoch: 22, Loss: 1.0999208688735962, Validation Accuracy: 0.688\n",
      "Epoch: 23, Loss: 0.8851324319839478, Validation Accuracy: 0.7650833333333333\n",
      "Epoch: 24, Loss: 0.6965128779411316, Validation Accuracy: 0.7888333333333334\n",
      "Epoch: 25, Loss: 0.6436207890510559, Validation Accuracy: 0.8015833333333333\n",
      "Epoch: 26, Loss: 0.6163620352745056, Validation Accuracy: 0.8069166666666666\n",
      "Epoch: 27, Loss: 0.5988911390304565, Validation Accuracy: 0.8113333333333334\n",
      "Epoch: 28, Loss: 0.5842986106872559, Validation Accuracy: 0.8166666666666667\n",
      "Epoch: 29, Loss: 0.5717291831970215, Validation Accuracy: 0.8199166666666666\n",
      "Epoch: 30, Loss: 0.5602568984031677, Validation Accuracy: 0.8229166666666666\n",
      "Epoch: 31, Loss: 0.5498586297035217, Validation Accuracy: 0.8269166666666666\n",
      "Epoch: 32, Loss: 0.5402102470397949, Validation Accuracy: 0.8300833333333333\n",
      "Epoch: 33, Loss: 0.531294584274292, Validation Accuracy: 0.8348333333333333\n",
      "Epoch: 34, Loss: 0.5229010581970215, Validation Accuracy: 0.8378333333333333\n",
      "Epoch: 35, Loss: 0.5150662660598755, Validation Accuracy: 0.8408333333333333\n",
      "Epoch: 36, Loss: 0.5076825618743896, Validation Accuracy: 0.8418333333333333\n",
      "Epoch: 37, Loss: 0.5007501840591431, Validation Accuracy: 0.8443333333333334\n",
      "Epoch: 38, Loss: 0.49419623613357544, Validation Accuracy: 0.8464166666666667\n",
      "Epoch: 39, Loss: 0.4879923462867737, Validation Accuracy: 0.848\n",
      "Epoch: 40, Loss: 0.4820958375930786, Validation Accuracy: 0.8488333333333333\n",
      "Epoch: 41, Loss: 0.4764852821826935, Validation Accuracy: 0.85225\n",
      "Epoch: 42, Loss: 0.4711245596408844, Validation Accuracy: 0.8515833333333334\n",
      "Epoch: 43, Loss: 0.4659990668296814, Validation Accuracy: 0.8549166666666667\n",
      "Epoch: 44, Loss: 0.46109718084335327, Validation Accuracy: 0.8548333333333333\n",
      "Epoch: 45, Loss: 0.4564366042613983, Validation Accuracy: 0.8568333333333333\n",
      "Epoch: 46, Loss: 0.45199939608573914, Validation Accuracy: 0.85775\n",
      "Epoch: 47, Loss: 0.4478144645690918, Validation Accuracy: 0.85925\n",
      "Epoch: 48, Loss: 0.4439501464366913, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 49, Loss: 0.44045183062553406, Validation Accuracy: 0.8614166666666667\n",
      "Epoch: 50, Loss: 0.4375835061073303, Validation Accuracy: 0.8628333333333333\n",
      "Epoch: 51, Loss: 0.43565014004707336, Validation Accuracy: 0.8600833333333333\n",
      "Epoch: 52, Loss: 0.4352974593639374, Validation Accuracy: 0.8603333333333333\n",
      "Epoch: 53, Loss: 0.4374801516532898, Validation Accuracy: 0.8556666666666667\n",
      "Epoch: 54, Loss: 0.44455650448799133, Validation Accuracy: 0.8506666666666667\n",
      "Epoch: 55, Loss: 0.4593648314476013, Validation Accuracy: 0.83825\n",
      "Epoch: 56, Loss: 0.4868505597114563, Validation Accuracy: 0.822\n",
      "Epoch: 57, Loss: 0.5315843224525452, Validation Accuracy: 0.7963333333333333\n",
      "Epoch: 58, Loss: 0.5893701910972595, Validation Accuracy: 0.7858333333333334\n",
      "Epoch: 59, Loss: 0.6281319856643677, Validation Accuracy: 0.789\n",
      "Epoch: 60, Loss: 0.6047455072402954, Validation Accuracy: 0.824\n",
      "Epoch: 61, Loss: 0.5221376419067383, Validation Accuracy: 0.8483333333333334\n",
      "Epoch: 62, Loss: 0.45158329606056213, Validation Accuracy: 0.8666666666666667\n",
      "Epoch: 63, Loss: 0.4170631170272827, Validation Accuracy: 0.8718333333333333\n",
      "Epoch: 64, Loss: 0.4036632180213928, Validation Accuracy: 0.8745\n",
      "Epoch: 65, Loss: 0.3970048129558563, Validation Accuracy: 0.87675\n",
      "Epoch: 66, Loss: 0.3927166759967804, Validation Accuracy: 0.8761666666666666\n",
      "Epoch: 67, Loss: 0.38923799991607666, Validation Accuracy: 0.8779166666666667\n",
      "Epoch: 68, Loss: 0.38618090748786926, Validation Accuracy: 0.8781666666666667\n",
      "Epoch: 69, Loss: 0.38334915041923523, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 70, Loss: 0.38069406151771545, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 71, Loss: 0.3781659007072449, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 72, Loss: 0.3757438659667969, Validation Accuracy: 0.8815\n",
      "Epoch: 73, Loss: 0.3734186589717865, Validation Accuracy: 0.8819166666666667\n",
      "Epoch: 74, Loss: 0.3711715638637543, Validation Accuracy: 0.8825833333333334\n",
      "Epoch: 75, Loss: 0.36899715662002563, Validation Accuracy: 0.88325\n",
      "Epoch: 76, Loss: 0.3668881356716156, Validation Accuracy: 0.8840833333333333\n",
      "Epoch: 77, Loss: 0.36483991146087646, Validation Accuracy: 0.88475\n",
      "Epoch: 78, Loss: 0.36284366250038147, Validation Accuracy: 0.8850833333333333\n",
      "Epoch: 79, Loss: 0.3608908951282501, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 80, Loss: 0.35898926854133606, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 81, Loss: 0.35713431239128113, Validation Accuracy: 0.8874166666666666\n",
      "Epoch: 82, Loss: 0.3553240895271301, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 83, Loss: 0.3535539507865906, Validation Accuracy: 0.8885\n",
      "Epoch: 84, Loss: 0.35182255506515503, Validation Accuracy: 0.8894166666666666\n",
      "Epoch: 85, Loss: 0.35013192892074585, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 86, Loss: 0.34847167134284973, Validation Accuracy: 0.89025\n",
      "Epoch: 87, Loss: 0.3468461036682129, Validation Accuracy: 0.8905\n",
      "Epoch: 88, Loss: 0.3452531397342682, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 89, Loss: 0.343686044216156, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 90, Loss: 0.34214529395103455, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 91, Loss: 0.34063273668289185, Validation Accuracy: 0.892\n",
      "Epoch: 92, Loss: 0.33914756774902344, Validation Accuracy: 0.89275\n",
      "Epoch: 93, Loss: 0.3376932740211487, Validation Accuracy: 0.8933333333333333\n",
      "Epoch: 94, Loss: 0.3362700939178467, Validation Accuracy: 0.8939166666666667\n",
      "Epoch: 95, Loss: 0.33487147092819214, Validation Accuracy: 0.89425\n",
      "Epoch: 96, Loss: 0.3334942162036896, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 97, Loss: 0.33213552832603455, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 98, Loss: 0.3308010995388031, Validation Accuracy: 0.8956666666666667\n",
      "Epoch: 99, Loss: 0.3294822871685028, Validation Accuracy: 0.8958333333333334\n",
      "Dataset 95\n",
      "Epoch: 0, Loss: 4.474114418029785, Validation Accuracy: 0.11025\n",
      "Epoch: 1, Loss: 3.81410813331604, Validation Accuracy: 0.14083333333333334\n",
      "Epoch: 2, Loss: 2.932643175125122, Validation Accuracy: 0.19666666666666666\n",
      "Epoch: 3, Loss: 2.212836980819702, Validation Accuracy: 0.2605\n",
      "Epoch: 4, Loss: 2.0258290767669678, Validation Accuracy: 0.2876666666666667\n",
      "Epoch: 5, Loss: 1.9520395994186401, Validation Accuracy: 0.31125\n",
      "Epoch: 6, Loss: 1.8939387798309326, Validation Accuracy: 0.33425\n",
      "Epoch: 7, Loss: 1.8378102779388428, Validation Accuracy: 0.36033333333333334\n",
      "Epoch: 8, Loss: 1.7791334390640259, Validation Accuracy: 0.38575\n",
      "Epoch: 9, Loss: 1.7152336835861206, Validation Accuracy: 0.41441666666666666\n",
      "Epoch: 10, Loss: 1.644430160522461, Validation Accuracy: 0.44608333333333333\n",
      "Epoch: 11, Loss: 1.5676767826080322, Validation Accuracy: 0.47783333333333333\n",
      "Epoch: 12, Loss: 1.4899064302444458, Validation Accuracy: 0.50475\n",
      "Epoch: 13, Loss: 1.4156485795974731, Validation Accuracy: 0.52875\n",
      "Epoch: 14, Loss: 1.3451499938964844, Validation Accuracy: 0.5540833333333334\n",
      "Epoch: 15, Loss: 1.2785108089447021, Validation Accuracy: 0.5761666666666667\n",
      "Epoch: 16, Loss: 1.2156697511672974, Validation Accuracy: 0.5968333333333333\n",
      "Epoch: 17, Loss: 1.1561154127120972, Validation Accuracy: 0.6186666666666667\n",
      "Epoch: 18, Loss: 1.0994471311569214, Validation Accuracy: 0.6413333333333333\n",
      "Epoch: 19, Loss: 1.0457135438919067, Validation Accuracy: 0.6638333333333334\n",
      "Epoch: 20, Loss: 0.9950699806213379, Validation Accuracy: 0.6821666666666667\n",
      "Epoch: 21, Loss: 0.948121190071106, Validation Accuracy: 0.6990833333333333\n",
      "Epoch: 22, Loss: 0.9049640893936157, Validation Accuracy: 0.7135\n",
      "Epoch: 23, Loss: 0.8652192950248718, Validation Accuracy: 0.7265\n",
      "Epoch: 24, Loss: 0.8285516500473022, Validation Accuracy: 0.7405833333333334\n",
      "Epoch: 25, Loss: 0.7950446009635925, Validation Accuracy: 0.75125\n",
      "Epoch: 26, Loss: 0.7648271322250366, Validation Accuracy: 0.7615833333333333\n",
      "Epoch: 27, Loss: 0.7380723357200623, Validation Accuracy: 0.7661666666666667\n",
      "Epoch: 28, Loss: 0.7173920273780823, Validation Accuracy: 0.7658333333333334\n",
      "Epoch: 29, Loss: 0.7156162261962891, Validation Accuracy: 0.7179166666666666\n",
      "Epoch: 30, Loss: 0.7993500828742981, Validation Accuracy: 0.6061666666666666\n",
      "Epoch: 31, Loss: 1.1290456056594849, Validation Accuracy: 0.48541666666666666\n",
      "Epoch: 32, Loss: 1.5715712308883667, Validation Accuracy: 0.6590833333333334\n",
      "Epoch: 33, Loss: 0.9661439657211304, Validation Accuracy: 0.7589166666666667\n",
      "Epoch: 34, Loss: 0.7496890425682068, Validation Accuracy: 0.7921666666666667\n",
      "Epoch: 35, Loss: 0.6769693493843079, Validation Accuracy: 0.8010833333333334\n",
      "Epoch: 36, Loss: 0.6387842297554016, Validation Accuracy: 0.8113333333333334\n",
      "Epoch: 37, Loss: 0.611664891242981, Validation Accuracy: 0.8164166666666667\n",
      "Epoch: 38, Loss: 0.5915400385856628, Validation Accuracy: 0.8206666666666667\n",
      "Epoch: 39, Loss: 0.5752794742584229, Validation Accuracy: 0.8256666666666667\n",
      "Epoch: 40, Loss: 0.5618003010749817, Validation Accuracy: 0.8283333333333334\n",
      "Epoch: 41, Loss: 0.5506045818328857, Validation Accuracy: 0.8303333333333334\n",
      "Epoch: 42, Loss: 0.5416489243507385, Validation Accuracy: 0.8333333333333334\n",
      "Epoch: 43, Loss: 0.5355022549629211, Validation Accuracy: 0.8314166666666667\n",
      "Epoch: 44, Loss: 0.5333876609802246, Validation Accuracy: 0.8268333333333333\n",
      "Epoch: 45, Loss: 0.5385258793830872, Validation Accuracy: 0.8201666666666667\n",
      "Epoch: 46, Loss: 0.5553732514381409, Validation Accuracy: 0.8005\n",
      "Epoch: 47, Loss: 0.5921012163162231, Validation Accuracy: 0.7785833333333333\n",
      "Epoch: 48, Loss: 0.64528489112854, Validation Accuracy: 0.7665\n",
      "Epoch: 49, Loss: 0.6804129481315613, Validation Accuracy: 0.76925\n",
      "Epoch: 50, Loss: 0.6762239933013916, Validation Accuracy: 0.7999166666666667\n",
      "Epoch: 51, Loss: 0.5943583846092224, Validation Accuracy: 0.82175\n",
      "Epoch: 52, Loss: 0.5498998761177063, Validation Accuracy: 0.8373333333333334\n",
      "Epoch: 53, Loss: 0.507196843624115, Validation Accuracy: 0.8448333333333333\n",
      "Epoch: 54, Loss: 0.4883332848548889, Validation Accuracy: 0.85275\n",
      "Epoch: 55, Loss: 0.4739414155483246, Validation Accuracy: 0.85475\n",
      "Epoch: 56, Loss: 0.46505334973335266, Validation Accuracy: 0.8584166666666667\n",
      "Epoch: 57, Loss: 0.4574371874332428, Validation Accuracy: 0.859\n",
      "Epoch: 58, Loss: 0.4514372944831848, Validation Accuracy: 0.8625833333333334\n",
      "Epoch: 59, Loss: 0.4460723400115967, Validation Accuracy: 0.8623333333333333\n",
      "Epoch: 60, Loss: 0.441456139087677, Validation Accuracy: 0.8655833333333334\n",
      "Epoch: 61, Loss: 0.4371091425418854, Validation Accuracy: 0.865\n",
      "Epoch: 62, Loss: 0.43306678533554077, Validation Accuracy: 0.8674166666666666\n",
      "Epoch: 63, Loss: 0.4292954206466675, Validation Accuracy: 0.8678333333333333\n",
      "Epoch: 64, Loss: 0.4257254898548126, Validation Accuracy: 0.86975\n",
      "Epoch: 65, Loss: 0.4223340153694153, Validation Accuracy: 0.8701666666666666\n",
      "Epoch: 66, Loss: 0.4191362261772156, Validation Accuracy: 0.87175\n",
      "Epoch: 67, Loss: 0.4160923957824707, Validation Accuracy: 0.8721666666666666\n",
      "Epoch: 68, Loss: 0.4132041037082672, Validation Accuracy: 0.8734166666666666\n",
      "Epoch: 69, Loss: 0.4103781282901764, Validation Accuracy: 0.874\n",
      "Epoch: 70, Loss: 0.4077673852443695, Validation Accuracy: 0.87525\n",
      "Epoch: 71, Loss: 0.4051055610179901, Validation Accuracy: 0.8759166666666667\n",
      "Epoch: 72, Loss: 0.4026663899421692, Validation Accuracy: 0.87675\n",
      "Epoch: 73, Loss: 0.40011894702911377, Validation Accuracy: 0.87725\n",
      "Epoch: 74, Loss: 0.39790019392967224, Validation Accuracy: 0.8776666666666667\n",
      "Epoch: 75, Loss: 0.3955009877681732, Validation Accuracy: 0.879\n",
      "Epoch: 76, Loss: 0.3934952914714813, Validation Accuracy: 0.8785833333333334\n",
      "Epoch: 77, Loss: 0.391287237405777, Validation Accuracy: 0.8801666666666667\n",
      "Epoch: 78, Loss: 0.38950756192207336, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 79, Loss: 0.3874301612377167, Validation Accuracy: 0.882\n",
      "Epoch: 80, Loss: 0.3857831358909607, Validation Accuracy: 0.8818333333333334\n",
      "Epoch: 81, Loss: 0.3838505446910858, Validation Accuracy: 0.88325\n",
      "Epoch: 82, Loss: 0.38237693905830383, Validation Accuracy: 0.8830833333333333\n",
      "Epoch: 83, Loss: 0.380526602268219, Validation Accuracy: 0.8843333333333333\n",
      "Epoch: 84, Loss: 0.3791583180427551, Validation Accuracy: 0.88425\n",
      "Epoch: 85, Loss: 0.37736979126930237, Validation Accuracy: 0.8849166666666667\n",
      "Epoch: 86, Loss: 0.3760766088962555, Validation Accuracy: 0.88525\n",
      "Epoch: 87, Loss: 0.3743685185909271, Validation Accuracy: 0.88625\n",
      "Epoch: 88, Loss: 0.373134970664978, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 89, Loss: 0.37138548493385315, Validation Accuracy: 0.8873333333333333\n",
      "Epoch: 90, Loss: 0.3700706362724304, Validation Accuracy: 0.887\n",
      "Epoch: 91, Loss: 0.36828604340553284, Validation Accuracy: 0.88825\n",
      "Epoch: 92, Loss: 0.36692264676094055, Validation Accuracy: 0.8875833333333333\n",
      "Epoch: 93, Loss: 0.3649708330631256, Validation Accuracy: 0.8895833333333333\n",
      "Epoch: 94, Loss: 0.3634912371635437, Validation Accuracy: 0.88925\n",
      "Epoch: 95, Loss: 0.3614124059677124, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 96, Loss: 0.359793096780777, Validation Accuracy: 0.89125\n",
      "Epoch: 97, Loss: 0.35764575004577637, Validation Accuracy: 0.89325\n",
      "Epoch: 98, Loss: 0.35587015748023987, Validation Accuracy: 0.8920833333333333\n",
      "Epoch: 99, Loss: 0.35370492935180664, Validation Accuracy: 0.8943333333333333\n",
      "Dataset 96\n",
      "Epoch: 0, Loss: 3.8491666316986084, Validation Accuracy: 0.12725\n",
      "Epoch: 1, Loss: 3.6193039417266846, Validation Accuracy: 0.15991666666666668\n",
      "Epoch: 2, Loss: 2.5785269737243652, Validation Accuracy: 0.27241666666666664\n",
      "Epoch: 3, Loss: 2.1579654216766357, Validation Accuracy: 0.30916666666666665\n",
      "Epoch: 4, Loss: 1.9166536331176758, Validation Accuracy: 0.34541666666666665\n",
      "Epoch: 5, Loss: 1.805949091911316, Validation Accuracy: 0.3844166666666667\n",
      "Epoch: 6, Loss: 1.6943283081054688, Validation Accuracy: 0.4131666666666667\n",
      "Epoch: 7, Loss: 1.6305525302886963, Validation Accuracy: 0.44208333333333333\n",
      "Epoch: 8, Loss: 1.5547288656234741, Validation Accuracy: 0.46158333333333335\n",
      "Epoch: 9, Loss: 1.5054138898849487, Validation Accuracy: 0.4835\n",
      "Epoch: 10, Loss: 1.4410423040390015, Validation Accuracy: 0.504\n",
      "Epoch: 11, Loss: 1.3938499689102173, Validation Accuracy: 0.5241666666666667\n",
      "Epoch: 12, Loss: 1.3300666809082031, Validation Accuracy: 0.5480833333333334\n",
      "Epoch: 13, Loss: 1.2797526121139526, Validation Accuracy: 0.566\n",
      "Epoch: 14, Loss: 1.21958589553833, Validation Accuracy: 0.59425\n",
      "Epoch: 15, Loss: 1.1719928979873657, Validation Accuracy: 0.60225\n",
      "Epoch: 16, Loss: 1.120916724205017, Validation Accuracy: 0.6299166666666667\n",
      "Epoch: 17, Loss: 1.0813673734664917, Validation Accuracy: 0.6245833333333334\n",
      "Epoch: 18, Loss: 1.0430569648742676, Validation Accuracy: 0.6501666666666667\n",
      "Epoch: 19, Loss: 1.02188241481781, Validation Accuracy: 0.6334166666666666\n",
      "Epoch: 20, Loss: 0.9998195767402649, Validation Accuracy: 0.6556666666666666\n",
      "Epoch: 21, Loss: 0.9918692111968994, Validation Accuracy: 0.64375\n",
      "Epoch: 22, Loss: 0.9635619521141052, Validation Accuracy: 0.674\n",
      "Epoch: 23, Loss: 0.9389276504516602, Validation Accuracy: 0.6775833333333333\n",
      "Epoch: 24, Loss: 0.8902789950370789, Validation Accuracy: 0.7078333333333333\n",
      "Epoch: 25, Loss: 0.8513382077217102, Validation Accuracy: 0.7104166666666667\n",
      "Epoch: 26, Loss: 0.8105790019035339, Validation Accuracy: 0.7355\n",
      "Epoch: 27, Loss: 0.7790673971176147, Validation Accuracy: 0.73625\n",
      "Epoch: 28, Loss: 0.7524160146713257, Validation Accuracy: 0.7551666666666667\n",
      "Epoch: 29, Loss: 0.7288691997528076, Validation Accuracy: 0.7543333333333333\n",
      "Epoch: 30, Loss: 0.7092679142951965, Validation Accuracy: 0.7685833333333333\n",
      "Epoch: 31, Loss: 0.690880298614502, Validation Accuracy: 0.7663333333333333\n",
      "Epoch: 32, Loss: 0.6758605241775513, Validation Accuracy: 0.77875\n",
      "Epoch: 33, Loss: 0.6604304313659668, Validation Accuracy: 0.7775833333333333\n",
      "Epoch: 34, Loss: 0.648089587688446, Validation Accuracy: 0.7876666666666666\n",
      "Epoch: 35, Loss: 0.6353373527526855, Validation Accuracy: 0.7856666666666666\n",
      "Epoch: 36, Loss: 0.6255365014076233, Validation Accuracy: 0.7945833333333333\n",
      "Epoch: 37, Loss: 0.6145848631858826, Validation Accuracy: 0.7915833333333333\n",
      "Epoch: 38, Loss: 0.6065186858177185, Validation Accuracy: 0.80025\n",
      "Epoch: 39, Loss: 0.5968073010444641, Validation Accuracy: 0.79875\n",
      "Epoch: 40, Loss: 0.589460551738739, Validation Accuracy: 0.8048333333333333\n",
      "Epoch: 41, Loss: 0.5808314681053162, Validation Accuracy: 0.805\n",
      "Epoch: 42, Loss: 0.5737836360931396, Validation Accuracy: 0.8095833333333333\n",
      "Epoch: 43, Loss: 0.5658204555511475, Validation Accuracy: 0.8100833333333334\n",
      "Epoch: 44, Loss: 0.5592411160469055, Validation Accuracy: 0.8146666666666667\n",
      "Epoch: 45, Loss: 0.5519071817398071, Validation Accuracy: 0.8159166666666666\n",
      "Epoch: 46, Loss: 0.5448626279830933, Validation Accuracy: 0.8199166666666666\n",
      "Epoch: 47, Loss: 0.5376026630401611, Validation Accuracy: 0.82225\n",
      "Epoch: 48, Loss: 0.530032217502594, Validation Accuracy: 0.826\n",
      "Epoch: 49, Loss: 0.5226221084594727, Validation Accuracy: 0.8275\n",
      "Epoch: 50, Loss: 0.5146002769470215, Validation Accuracy: 0.83175\n",
      "Epoch: 51, Loss: 0.5070448517799377, Validation Accuracy: 0.833\n",
      "Epoch: 52, Loss: 0.4987431764602661, Validation Accuracy: 0.8368333333333333\n",
      "Epoch: 53, Loss: 0.49134811758995056, Validation Accuracy: 0.8383333333333334\n",
      "Epoch: 54, Loss: 0.4833514392375946, Validation Accuracy: 0.843\n",
      "Epoch: 55, Loss: 0.47614791989326477, Validation Accuracy: 0.8440833333333333\n",
      "Epoch: 56, Loss: 0.4688536524772644, Validation Accuracy: 0.8459166666666667\n",
      "Epoch: 57, Loss: 0.46256008744239807, Validation Accuracy: 0.8494166666666667\n",
      "Epoch: 58, Loss: 0.4559348523616791, Validation Accuracy: 0.8503333333333334\n",
      "Epoch: 59, Loss: 0.4504992961883545, Validation Accuracy: 0.8530833333333333\n",
      "Epoch: 60, Loss: 0.4447299838066101, Validation Accuracy: 0.8548333333333333\n",
      "Epoch: 61, Loss: 0.4399048686027527, Validation Accuracy: 0.8565\n",
      "Epoch: 62, Loss: 0.4348028898239136, Validation Accuracy: 0.8575\n",
      "Epoch: 63, Loss: 0.43062105774879456, Validation Accuracy: 0.8595\n",
      "Epoch: 64, Loss: 0.4261418581008911, Validation Accuracy: 0.8605\n",
      "Epoch: 65, Loss: 0.4222758412361145, Validation Accuracy: 0.86225\n",
      "Epoch: 66, Loss: 0.4183386564254761, Validation Accuracy: 0.8634166666666667\n",
      "Epoch: 67, Loss: 0.4149174392223358, Validation Accuracy: 0.8650833333333333\n",
      "Epoch: 68, Loss: 0.41136083006858826, Validation Accuracy: 0.8654166666666666\n",
      "Epoch: 69, Loss: 0.4083152711391449, Validation Accuracy: 0.8669166666666667\n",
      "Epoch: 70, Loss: 0.40507739782333374, Validation Accuracy: 0.86825\n",
      "Epoch: 71, Loss: 0.4023109972476959, Validation Accuracy: 0.8693333333333333\n",
      "Epoch: 72, Loss: 0.3992070257663727, Validation Accuracy: 0.8714166666666666\n",
      "Epoch: 73, Loss: 0.3966800272464752, Validation Accuracy: 0.8715\n",
      "Epoch: 74, Loss: 0.3938256800174713, Validation Accuracy: 0.87275\n",
      "Epoch: 75, Loss: 0.3914555609226227, Validation Accuracy: 0.873\n",
      "Epoch: 76, Loss: 0.3887719213962555, Validation Accuracy: 0.8745\n",
      "Epoch: 77, Loss: 0.38662633299827576, Validation Accuracy: 0.8745833333333334\n",
      "Epoch: 78, Loss: 0.3841502368450165, Validation Accuracy: 0.87625\n",
      "Epoch: 79, Loss: 0.3822011351585388, Validation Accuracy: 0.8765\n",
      "Epoch: 80, Loss: 0.37989547848701477, Validation Accuracy: 0.87825\n",
      "Epoch: 81, Loss: 0.3780222535133362, Validation Accuracy: 0.878\n",
      "Epoch: 82, Loss: 0.3757825791835785, Validation Accuracy: 0.8795833333333334\n",
      "Epoch: 83, Loss: 0.3739444613456726, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 84, Loss: 0.3717731237411499, Validation Accuracy: 0.88075\n",
      "Epoch: 85, Loss: 0.36993175745010376, Validation Accuracy: 0.8811666666666667\n",
      "Epoch: 86, Loss: 0.36780494451522827, Validation Accuracy: 0.882\n",
      "Epoch: 87, Loss: 0.36601316928863525, Validation Accuracy: 0.8826666666666667\n",
      "Epoch: 88, Loss: 0.36394038796424866, Validation Accuracy: 0.8831666666666667\n",
      "Epoch: 89, Loss: 0.362108439207077, Validation Accuracy: 0.884\n",
      "Epoch: 90, Loss: 0.36006250977516174, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 91, Loss: 0.3583073019981384, Validation Accuracy: 0.8846666666666667\n",
      "Epoch: 92, Loss: 0.35631313920021057, Validation Accuracy: 0.88475\n",
      "Epoch: 93, Loss: 0.3545567989349365, Validation Accuracy: 0.885\n",
      "Epoch: 94, Loss: 0.3525966703891754, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 95, Loss: 0.35090580582618713, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 96, Loss: 0.34908798336982727, Validation Accuracy: 0.8871666666666667\n",
      "Epoch: 97, Loss: 0.3474527895450592, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 98, Loss: 0.3456181287765503, Validation Accuracy: 0.88875\n",
      "Epoch: 99, Loss: 0.3440283536911011, Validation Accuracy: 0.8871666666666667\n",
      "Dataset 97\n",
      "Epoch: 0, Loss: 3.6382458209991455, Validation Accuracy: 0.15408333333333332\n",
      "Epoch: 1, Loss: 2.60147762298584, Validation Accuracy: 0.24\n",
      "Epoch: 2, Loss: 2.1508407592773438, Validation Accuracy: 0.3015\n",
      "Epoch: 3, Loss: 1.9599814414978027, Validation Accuracy: 0.33841666666666664\n",
      "Epoch: 4, Loss: 1.8344361782073975, Validation Accuracy: 0.3749166666666667\n",
      "Epoch: 5, Loss: 1.729015827178955, Validation Accuracy: 0.40708333333333335\n",
      "Epoch: 6, Loss: 1.6316550970077515, Validation Accuracy: 0.44533333333333336\n",
      "Epoch: 7, Loss: 1.5384013652801514, Validation Accuracy: 0.481\n",
      "Epoch: 8, Loss: 1.4481890201568604, Validation Accuracy: 0.5175833333333333\n",
      "Epoch: 9, Loss: 1.3604665994644165, Validation Accuracy: 0.5541666666666667\n",
      "Epoch: 10, Loss: 1.2763811349868774, Validation Accuracy: 0.5886666666666667\n",
      "Epoch: 11, Loss: 1.1979748010635376, Validation Accuracy: 0.6175833333333334\n",
      "Epoch: 12, Loss: 1.1275317668914795, Validation Accuracy: 0.6429166666666667\n",
      "Epoch: 13, Loss: 1.0693813562393188, Validation Accuracy: 0.6496666666666666\n",
      "Epoch: 14, Loss: 1.033340573310852, Validation Accuracy: 0.6259166666666667\n",
      "Epoch: 15, Loss: 1.0772411823272705, Validation Accuracy: 0.5425\n",
      "Epoch: 16, Loss: 1.2800437211990356, Validation Accuracy: 0.4469166666666667\n",
      "Epoch: 17, Loss: 1.733061671257019, Validation Accuracy: 0.608\n",
      "Epoch: 18, Loss: 1.1401610374450684, Validation Accuracy: 0.6690833333333334\n",
      "Epoch: 19, Loss: 0.9993295073509216, Validation Accuracy: 0.70375\n",
      "Epoch: 20, Loss: 0.8885721564292908, Validation Accuracy: 0.7366666666666667\n",
      "Epoch: 21, Loss: 0.8282163739204407, Validation Accuracy: 0.7458333333333333\n",
      "Epoch: 22, Loss: 0.7817298769950867, Validation Accuracy: 0.7603333333333333\n",
      "Epoch: 23, Loss: 0.7480829954147339, Validation Accuracy: 0.7621666666666667\n",
      "Epoch: 24, Loss: 0.7229090332984924, Validation Accuracy: 0.77075\n",
      "Epoch: 25, Loss: 0.701474666595459, Validation Accuracy: 0.7725\n",
      "Epoch: 26, Loss: 0.6868582367897034, Validation Accuracy: 0.7779166666666667\n",
      "Epoch: 27, Loss: 0.6744937896728516, Validation Accuracy: 0.7741666666666667\n",
      "Epoch: 28, Loss: 0.6729825139045715, Validation Accuracy: 0.7724166666666666\n",
      "Epoch: 29, Loss: 0.6734997630119324, Validation Accuracy: 0.7588333333333334\n",
      "Epoch: 30, Loss: 0.698381245136261, Validation Accuracy: 0.7481666666666666\n",
      "Epoch: 31, Loss: 0.7180285453796387, Validation Accuracy: 0.72325\n",
      "Epoch: 32, Loss: 0.7664225101470947, Validation Accuracy: 0.7324166666666667\n",
      "Epoch: 33, Loss: 0.7482076287269592, Validation Accuracy: 0.74275\n",
      "Epoch: 34, Loss: 0.7222191691398621, Validation Accuracy: 0.7796666666666666\n",
      "Epoch: 35, Loss: 0.6484690308570862, Validation Accuracy: 0.7971666666666667\n",
      "Epoch: 36, Loss: 0.6054291725158691, Validation Accuracy: 0.8120833333333334\n",
      "Epoch: 37, Loss: 0.573518693447113, Validation Accuracy: 0.81875\n",
      "Epoch: 38, Loss: 0.5558170676231384, Validation Accuracy: 0.824\n",
      "Epoch: 39, Loss: 0.5425392389297485, Validation Accuracy: 0.827\n",
      "Epoch: 40, Loss: 0.5324093103408813, Validation Accuracy: 0.8305833333333333\n",
      "Epoch: 41, Loss: 0.5235947966575623, Validation Accuracy: 0.8336666666666667\n",
      "Epoch: 42, Loss: 0.5158851146697998, Validation Accuracy: 0.8351666666666666\n",
      "Epoch: 43, Loss: 0.5088738799095154, Validation Accuracy: 0.8390833333333333\n",
      "Epoch: 44, Loss: 0.5023991465568542, Validation Accuracy: 0.8391666666666666\n",
      "Epoch: 45, Loss: 0.4964542090892792, Validation Accuracy: 0.8441666666666666\n",
      "Epoch: 46, Loss: 0.4909583032131195, Validation Accuracy: 0.8436666666666667\n",
      "Epoch: 47, Loss: 0.48590078949928284, Validation Accuracy: 0.8478333333333333\n",
      "Epoch: 48, Loss: 0.48119089007377625, Validation Accuracy: 0.8475\n",
      "Epoch: 49, Loss: 0.47711828351020813, Validation Accuracy: 0.8499166666666667\n",
      "Epoch: 50, Loss: 0.47340425848960876, Validation Accuracy: 0.8498333333333333\n",
      "Epoch: 51, Loss: 0.47063732147216797, Validation Accuracy: 0.8514166666666667\n",
      "Epoch: 52, Loss: 0.4684430658817291, Validation Accuracy: 0.8511666666666666\n",
      "Epoch: 53, Loss: 0.4675320088863373, Validation Accuracy: 0.84925\n",
      "Epoch: 54, Loss: 0.4673748016357422, Validation Accuracy: 0.8483333333333334\n",
      "Epoch: 55, Loss: 0.46878987550735474, Validation Accuracy: 0.84675\n",
      "Epoch: 56, Loss: 0.4710314869880676, Validation Accuracy: 0.84475\n",
      "Epoch: 57, Loss: 0.47497016191482544, Validation Accuracy: 0.8425833333333334\n",
      "Epoch: 58, Loss: 0.4792591631412506, Validation Accuracy: 0.8393333333333334\n",
      "Epoch: 59, Loss: 0.4842534065246582, Validation Accuracy: 0.83825\n",
      "Epoch: 60, Loss: 0.48654162883758545, Validation Accuracy: 0.8383333333333334\n",
      "Epoch: 61, Loss: 0.4864582121372223, Validation Accuracy: 0.84025\n",
      "Epoch: 62, Loss: 0.480977863073349, Validation Accuracy: 0.845\n",
      "Epoch: 63, Loss: 0.4714028239250183, Validation Accuracy: 0.8495833333333334\n",
      "Epoch: 64, Loss: 0.45892611145973206, Validation Accuracy: 0.8550833333333333\n",
      "Epoch: 65, Loss: 0.44613611698150635, Validation Accuracy: 0.8603333333333333\n",
      "Epoch: 66, Loss: 0.4337002635002136, Validation Accuracy: 0.8655\n",
      "Epoch: 67, Loss: 0.42378535866737366, Validation Accuracy: 0.8674166666666666\n",
      "Epoch: 68, Loss: 0.41556814312934875, Validation Accuracy: 0.87125\n",
      "Epoch: 69, Loss: 0.4090610444545746, Validation Accuracy: 0.8725\n",
      "Epoch: 70, Loss: 0.4034554958343506, Validation Accuracy: 0.8748333333333334\n",
      "Epoch: 71, Loss: 0.39908960461616516, Validation Accuracy: 0.8749166666666667\n",
      "Epoch: 72, Loss: 0.3950338661670685, Validation Accuracy: 0.8768333333333334\n",
      "Epoch: 73, Loss: 0.3916071355342865, Validation Accuracy: 0.8781666666666667\n",
      "Epoch: 74, Loss: 0.38827791810035706, Validation Accuracy: 0.8775833333333334\n",
      "Epoch: 75, Loss: 0.385354220867157, Validation Accuracy: 0.8789166666666667\n",
      "Epoch: 76, Loss: 0.38244664669036865, Validation Accuracy: 0.8786666666666667\n",
      "Epoch: 77, Loss: 0.37980917096138, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 78, Loss: 0.3771774470806122, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 79, Loss: 0.3747866153717041, Validation Accuracy: 0.8823333333333333\n",
      "Epoch: 80, Loss: 0.37240123748779297, Validation Accuracy: 0.8816666666666667\n",
      "Epoch: 81, Loss: 0.37015390396118164, Validation Accuracy: 0.88375\n",
      "Epoch: 82, Loss: 0.36791637539863586, Validation Accuracy: 0.8833333333333333\n",
      "Epoch: 83, Loss: 0.3657852113246918, Validation Accuracy: 0.8850833333333333\n",
      "Epoch: 84, Loss: 0.363700270652771, Validation Accuracy: 0.8838333333333334\n",
      "Epoch: 85, Loss: 0.36165258288383484, Validation Accuracy: 0.88575\n",
      "Epoch: 86, Loss: 0.3596675992012024, Validation Accuracy: 0.88575\n",
      "Epoch: 87, Loss: 0.3577108085155487, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 88, Loss: 0.3558168411254883, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 89, Loss: 0.3539619445800781, Validation Accuracy: 0.8880833333333333\n",
      "Epoch: 90, Loss: 0.3521512448787689, Validation Accuracy: 0.8881666666666667\n",
      "Epoch: 91, Loss: 0.3503739535808563, Validation Accuracy: 0.889\n",
      "Epoch: 92, Loss: 0.3486423194408417, Validation Accuracy: 0.88925\n",
      "Epoch: 93, Loss: 0.34694361686706543, Validation Accuracy: 0.88975\n",
      "Epoch: 94, Loss: 0.34528207778930664, Validation Accuracy: 0.8896666666666667\n",
      "Epoch: 95, Loss: 0.34365931153297424, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 96, Loss: 0.3420756459236145, Validation Accuracy: 0.891\n",
      "Epoch: 97, Loss: 0.3405231237411499, Validation Accuracy: 0.8910833333333333\n",
      "Epoch: 98, Loss: 0.3390016555786133, Validation Accuracy: 0.8916666666666667\n",
      "Epoch: 99, Loss: 0.3375050723552704, Validation Accuracy: 0.8918333333333334\n",
      "Dataset 98\n",
      "Epoch: 0, Loss: 3.932004928588867, Validation Accuracy: 0.13933333333333334\n",
      "Epoch: 1, Loss: 3.3116400241851807, Validation Accuracy: 0.12766666666666668\n",
      "Epoch: 2, Loss: 3.0200703144073486, Validation Accuracy: 0.19625\n",
      "Epoch: 3, Loss: 2.843317747116089, Validation Accuracy: 0.17775\n",
      "Epoch: 4, Loss: 2.2388031482696533, Validation Accuracy: 0.2500833333333333\n",
      "Epoch: 5, Loss: 2.056356430053711, Validation Accuracy: 0.2975\n",
      "Epoch: 6, Loss: 1.9664114713668823, Validation Accuracy: 0.34858333333333336\n",
      "Epoch: 7, Loss: 1.8671839237213135, Validation Accuracy: 0.41283333333333333\n",
      "Epoch: 8, Loss: 1.7479513883590698, Validation Accuracy: 0.4563333333333333\n",
      "Epoch: 9, Loss: 1.6233165264129639, Validation Accuracy: 0.48933333333333334\n",
      "Epoch: 10, Loss: 1.5137648582458496, Validation Accuracy: 0.5104166666666666\n",
      "Epoch: 11, Loss: 1.4228782653808594, Validation Accuracy: 0.53225\n",
      "Epoch: 12, Loss: 1.3444392681121826, Validation Accuracy: 0.5530833333333334\n",
      "Epoch: 13, Loss: 1.2735975980758667, Validation Accuracy: 0.5755\n",
      "Epoch: 14, Loss: 1.2069530487060547, Validation Accuracy: 0.6031666666666666\n",
      "Epoch: 15, Loss: 1.142972707748413, Validation Accuracy: 0.6336666666666667\n",
      "Epoch: 16, Loss: 1.0809898376464844, Validation Accuracy: 0.65775\n",
      "Epoch: 17, Loss: 1.0215076208114624, Validation Accuracy: 0.6809166666666666\n",
      "Epoch: 18, Loss: 0.9653422832489014, Validation Accuracy: 0.6989166666666666\n",
      "Epoch: 19, Loss: 0.9132570624351501, Validation Accuracy: 0.7164166666666667\n",
      "Epoch: 20, Loss: 0.8664340972900391, Validation Accuracy: 0.7299166666666667\n",
      "Epoch: 21, Loss: 0.8249571323394775, Validation Accuracy: 0.7414166666666666\n",
      "Epoch: 22, Loss: 0.7883031964302063, Validation Accuracy: 0.7533333333333333\n",
      "Epoch: 23, Loss: 0.7559515833854675, Validation Accuracy: 0.7624166666666666\n",
      "Epoch: 24, Loss: 0.727453351020813, Validation Accuracy: 0.7705833333333333\n",
      "Epoch: 25, Loss: 0.7024711966514587, Validation Accuracy: 0.7775833333333333\n",
      "Epoch: 26, Loss: 0.6810740828514099, Validation Accuracy: 0.7826666666666666\n",
      "Epoch: 27, Loss: 0.6653009653091431, Validation Accuracy: 0.77925\n",
      "Epoch: 28, Loss: 0.6625640392303467, Validation Accuracy: 0.7653333333333333\n",
      "Epoch: 29, Loss: 0.6944711804389954, Validation Accuracy: 0.7008333333333333\n",
      "Epoch: 30, Loss: 0.8320708274841309, Validation Accuracy: 0.6246666666666667\n",
      "Epoch: 31, Loss: 1.1092115640640259, Validation Accuracy: 0.5663333333333334\n",
      "Epoch: 32, Loss: 1.2385923862457275, Validation Accuracy: 0.7049166666666666\n",
      "Epoch: 33, Loss: 0.8054367899894714, Validation Accuracy: 0.7771666666666667\n",
      "Epoch: 34, Loss: 0.6719561219215393, Validation Accuracy: 0.807\n",
      "Epoch: 35, Loss: 0.6049289703369141, Validation Accuracy: 0.8173333333333334\n",
      "Epoch: 36, Loss: 0.5747487545013428, Validation Accuracy: 0.8230833333333333\n",
      "Epoch: 37, Loss: 0.5534433722496033, Validation Accuracy: 0.8300833333333333\n",
      "Epoch: 38, Loss: 0.5386368632316589, Validation Accuracy: 0.8313333333333334\n",
      "Epoch: 39, Loss: 0.5261141657829285, Validation Accuracy: 0.8366666666666667\n",
      "Epoch: 40, Loss: 0.5156063437461853, Validation Accuracy: 0.83875\n",
      "Epoch: 41, Loss: 0.5061935782432556, Validation Accuracy: 0.8406666666666667\n",
      "Epoch: 42, Loss: 0.49781879782676697, Validation Accuracy: 0.8430833333333333\n",
      "Epoch: 43, Loss: 0.4900844991207123, Validation Accuracy: 0.8463333333333334\n",
      "Epoch: 44, Loss: 0.482954740524292, Validation Accuracy: 0.848\n",
      "Epoch: 45, Loss: 0.47632184624671936, Validation Accuracy: 0.8495833333333334\n",
      "Epoch: 46, Loss: 0.4701196551322937, Validation Accuracy: 0.8525\n",
      "Epoch: 47, Loss: 0.4642583727836609, Validation Accuracy: 0.8538333333333333\n",
      "Epoch: 48, Loss: 0.45870235562324524, Validation Accuracy: 0.8555833333333334\n",
      "Epoch: 49, Loss: 0.45340076088905334, Validation Accuracy: 0.8570833333333333\n",
      "Epoch: 50, Loss: 0.4483405649662018, Validation Accuracy: 0.8589166666666667\n",
      "Epoch: 51, Loss: 0.44351616501808167, Validation Accuracy: 0.86\n",
      "Epoch: 52, Loss: 0.43890082836151123, Validation Accuracy: 0.8605\n",
      "Epoch: 53, Loss: 0.4344738721847534, Validation Accuracy: 0.8618333333333333\n",
      "Epoch: 54, Loss: 0.4302324950695038, Validation Accuracy: 0.8630833333333333\n",
      "Epoch: 55, Loss: 0.4261608421802521, Validation Accuracy: 0.86375\n",
      "Epoch: 56, Loss: 0.42224496603012085, Validation Accuracy: 0.8645833333333334\n",
      "Epoch: 57, Loss: 0.41847163438796997, Validation Accuracy: 0.8654166666666666\n",
      "Epoch: 58, Loss: 0.41482439637184143, Validation Accuracy: 0.8665\n",
      "Epoch: 59, Loss: 0.4112991988658905, Validation Accuracy: 0.8686666666666667\n",
      "Epoch: 60, Loss: 0.407886266708374, Validation Accuracy: 0.86975\n",
      "Epoch: 61, Loss: 0.4045749008655548, Validation Accuracy: 0.8709166666666667\n",
      "Epoch: 62, Loss: 0.4013650715351105, Validation Accuracy: 0.8715\n",
      "Epoch: 63, Loss: 0.3982519209384918, Validation Accuracy: 0.8729166666666667\n",
      "Epoch: 64, Loss: 0.3952397108078003, Validation Accuracy: 0.8741666666666666\n",
      "Epoch: 65, Loss: 0.3923291563987732, Validation Accuracy: 0.87475\n",
      "Epoch: 66, Loss: 0.3895076811313629, Validation Accuracy: 0.8754166666666666\n",
      "Epoch: 67, Loss: 0.3867683410644531, Validation Accuracy: 0.87675\n",
      "Epoch: 68, Loss: 0.38410574197769165, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 69, Loss: 0.38151395320892334, Validation Accuracy: 0.8786666666666667\n",
      "Epoch: 70, Loss: 0.37898513674736023, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 71, Loss: 0.3765209913253784, Validation Accuracy: 0.8806666666666667\n",
      "Epoch: 72, Loss: 0.3741197884082794, Validation Accuracy: 0.88125\n",
      "Epoch: 73, Loss: 0.37177374958992004, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 74, Loss: 0.3694739043712616, Validation Accuracy: 0.88225\n",
      "Epoch: 75, Loss: 0.3672231435775757, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 76, Loss: 0.3650245666503906, Validation Accuracy: 0.8835833333333334\n",
      "Epoch: 77, Loss: 0.3628752529621124, Validation Accuracy: 0.884\n",
      "Epoch: 78, Loss: 0.3607726991176605, Validation Accuracy: 0.8844166666666666\n",
      "Epoch: 79, Loss: 0.3587174415588379, Validation Accuracy: 0.88475\n",
      "Epoch: 80, Loss: 0.3567093014717102, Validation Accuracy: 0.8855\n",
      "Epoch: 81, Loss: 0.354748010635376, Validation Accuracy: 0.8859166666666667\n",
      "Epoch: 82, Loss: 0.3528345823287964, Validation Accuracy: 0.8865833333333333\n",
      "Epoch: 83, Loss: 0.35096031427383423, Validation Accuracy: 0.8874166666666666\n",
      "Epoch: 84, Loss: 0.3491244316101074, Validation Accuracy: 0.8875\n",
      "Epoch: 85, Loss: 0.34732580184936523, Validation Accuracy: 0.8883333333333333\n",
      "Epoch: 86, Loss: 0.34556064009666443, Validation Accuracy: 0.88875\n",
      "Epoch: 87, Loss: 0.34383055567741394, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 88, Loss: 0.342134565114975, Validation Accuracy: 0.8905\n",
      "Epoch: 89, Loss: 0.3404718041419983, Validation Accuracy: 0.8903333333333333\n",
      "Epoch: 90, Loss: 0.3388397991657257, Validation Accuracy: 0.8909166666666667\n",
      "Epoch: 91, Loss: 0.3372352123260498, Validation Accuracy: 0.8913333333333333\n",
      "Epoch: 92, Loss: 0.3356610834598541, Validation Accuracy: 0.8919166666666667\n",
      "Epoch: 93, Loss: 0.3341151177883148, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 94, Loss: 0.33259668946266174, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 95, Loss: 0.33110615611076355, Validation Accuracy: 0.89325\n",
      "Epoch: 96, Loss: 0.3296431005001068, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 97, Loss: 0.3282037675380707, Validation Accuracy: 0.8936666666666667\n",
      "Epoch: 98, Loss: 0.3267875909805298, Validation Accuracy: 0.8945\n",
      "Epoch: 99, Loss: 0.3253922462463379, Validation Accuracy: 0.89475\n",
      "Dataset 99\n",
      "Epoch: 0, Loss: 3.589664936065674, Validation Accuracy: 0.13425\n",
      "Epoch: 1, Loss: 3.033721446990967, Validation Accuracy: 0.26125\n",
      "Epoch: 2, Loss: 2.380481004714966, Validation Accuracy: 0.25533333333333336\n",
      "Epoch: 3, Loss: 2.176612138748169, Validation Accuracy: 0.2826666666666667\n",
      "Epoch: 4, Loss: 1.965364694595337, Validation Accuracy: 0.35691666666666666\n",
      "Epoch: 5, Loss: 1.7742786407470703, Validation Accuracy: 0.4180833333333333\n",
      "Epoch: 6, Loss: 1.6455849409103394, Validation Accuracy: 0.4539166666666667\n",
      "Epoch: 7, Loss: 1.5431544780731201, Validation Accuracy: 0.48241666666666666\n",
      "Epoch: 8, Loss: 1.461969017982483, Validation Accuracy: 0.5125\n",
      "Epoch: 9, Loss: 1.3875380754470825, Validation Accuracy: 0.5306666666666666\n",
      "Epoch: 10, Loss: 1.3194541931152344, Validation Accuracy: 0.5603333333333333\n",
      "Epoch: 11, Loss: 1.2556458711624146, Validation Accuracy: 0.5751666666666667\n",
      "Epoch: 12, Loss: 1.1960136890411377, Validation Accuracy: 0.6006666666666667\n",
      "Epoch: 13, Loss: 1.1395714282989502, Validation Accuracy: 0.6164166666666666\n",
      "Epoch: 14, Loss: 1.08790123462677, Validation Accuracy: 0.6366666666666667\n",
      "Epoch: 15, Loss: 1.0420690774917603, Validation Accuracy: 0.64675\n",
      "Epoch: 16, Loss: 1.0076571702957153, Validation Accuracy: 0.6419166666666667\n",
      "Epoch: 17, Loss: 1.0024604797363281, Validation Accuracy: 0.6236666666666667\n",
      "Epoch: 18, Loss: 1.0441466569900513, Validation Accuracy: 0.5436666666666666\n",
      "Epoch: 19, Loss: 1.2235883474349976, Validation Accuracy: 0.563\n",
      "Epoch: 20, Loss: 1.2093604803085327, Validation Accuracy: 0.6075833333333334\n",
      "Epoch: 21, Loss: 1.0793837308883667, Validation Accuracy: 0.6614166666666667\n",
      "Epoch: 22, Loss: 0.9933574795722961, Validation Accuracy: 0.6786666666666666\n",
      "Epoch: 23, Loss: 0.932334303855896, Validation Accuracy: 0.7214166666666667\n",
      "Epoch: 24, Loss: 0.8413019180297852, Validation Accuracy: 0.7435833333333334\n",
      "Epoch: 25, Loss: 0.7714349031448364, Validation Accuracy: 0.7598333333333334\n",
      "Epoch: 26, Loss: 0.7275466918945312, Validation Accuracy: 0.7665833333333333\n",
      "Epoch: 27, Loss: 0.6968978047370911, Validation Accuracy: 0.7770833333333333\n",
      "Epoch: 28, Loss: 0.676334023475647, Validation Accuracy: 0.77975\n",
      "Epoch: 29, Loss: 0.6598552465438843, Validation Accuracy: 0.7831666666666667\n",
      "Epoch: 30, Loss: 0.6520334482192993, Validation Accuracy: 0.779\n",
      "Epoch: 31, Loss: 0.6476949453353882, Validation Accuracy: 0.7768333333333334\n",
      "Epoch: 32, Loss: 0.6599081754684448, Validation Accuracy: 0.76\n",
      "Epoch: 33, Loss: 0.6757177710533142, Validation Accuracy: 0.7495\n",
      "Epoch: 34, Loss: 0.7150488495826721, Validation Accuracy: 0.7366666666666667\n",
      "Epoch: 35, Loss: 0.7329153418540955, Validation Accuracy: 0.7431666666666666\n",
      "Epoch: 36, Loss: 0.7295852899551392, Validation Accuracy: 0.7550833333333333\n",
      "Epoch: 37, Loss: 0.685492992401123, Validation Accuracy: 0.7861666666666667\n",
      "Epoch: 38, Loss: 0.6207430958747864, Validation Accuracy: 0.8029166666666666\n",
      "Epoch: 39, Loss: 0.5816576480865479, Validation Accuracy: 0.8181666666666667\n",
      "Epoch: 40, Loss: 0.5505515336990356, Validation Accuracy: 0.8245833333333333\n",
      "Epoch: 41, Loss: 0.5331292152404785, Validation Accuracy: 0.8308333333333333\n",
      "Epoch: 42, Loss: 0.5190117955207825, Validation Accuracy: 0.833\n",
      "Epoch: 43, Loss: 0.5087639689445496, Validation Accuracy: 0.8370833333333333\n",
      "Epoch: 44, Loss: 0.4996461570262909, Validation Accuracy: 0.8370833333333333\n",
      "Epoch: 45, Loss: 0.4919569492340088, Validation Accuracy: 0.84225\n",
      "Epoch: 46, Loss: 0.48482248187065125, Validation Accuracy: 0.8421666666666666\n",
      "Epoch: 47, Loss: 0.4784879982471466, Validation Accuracy: 0.8469166666666667\n",
      "Epoch: 48, Loss: 0.47253984212875366, Validation Accuracy: 0.84675\n",
      "Epoch: 49, Loss: 0.4670550525188446, Validation Accuracy: 0.8496666666666667\n",
      "Epoch: 50, Loss: 0.461940199136734, Validation Accuracy: 0.8496666666666667\n",
      "Epoch: 51, Loss: 0.45719853043556213, Validation Accuracy: 0.853\n",
      "Epoch: 52, Loss: 0.4527580142021179, Validation Accuracy: 0.8525\n",
      "Epoch: 53, Loss: 0.44859081506729126, Validation Accuracy: 0.8548333333333333\n",
      "Epoch: 54, Loss: 0.444912850856781, Validation Accuracy: 0.8548333333333333\n",
      "Epoch: 55, Loss: 0.4414389133453369, Validation Accuracy: 0.8569166666666667\n",
      "Epoch: 56, Loss: 0.4386243224143982, Validation Accuracy: 0.8555833333333334\n",
      "Epoch: 57, Loss: 0.43596354126930237, Validation Accuracy: 0.8578333333333333\n",
      "Epoch: 58, Loss: 0.4343321919441223, Validation Accuracy: 0.85625\n",
      "Epoch: 59, Loss: 0.43275025486946106, Validation Accuracy: 0.8579166666666667\n",
      "Epoch: 60, Loss: 0.43295979499816895, Validation Accuracy: 0.8569166666666667\n",
      "Epoch: 61, Loss: 0.43282023072242737, Validation Accuracy: 0.8570833333333333\n",
      "Epoch: 62, Loss: 0.4365334212779999, Validation Accuracy: 0.8544166666666667\n",
      "Epoch: 63, Loss: 0.4385637938976288, Validation Accuracy: 0.85275\n",
      "Epoch: 64, Loss: 0.4475724399089813, Validation Accuracy: 0.8468333333333333\n",
      "Epoch: 65, Loss: 0.452049195766449, Validation Accuracy: 0.8426666666666667\n",
      "Epoch: 66, Loss: 0.4686373770236969, Validation Accuracy: 0.8379166666666666\n",
      "Epoch: 67, Loss: 0.4715496003627777, Validation Accuracy: 0.8366666666666667\n",
      "Epoch: 68, Loss: 0.4895446002483368, Validation Accuracy: 0.836\n",
      "Epoch: 69, Loss: 0.4780798852443695, Validation Accuracy: 0.8398333333333333\n",
      "Epoch: 70, Loss: 0.4795176088809967, Validation Accuracy: 0.8456666666666667\n",
      "Epoch: 71, Loss: 0.45131513476371765, Validation Accuracy: 0.8555833333333334\n",
      "Epoch: 72, Loss: 0.4350142478942871, Validation Accuracy: 0.8635833333333334\n",
      "Epoch: 73, Loss: 0.4125002920627594, Validation Accuracy: 0.8684166666666666\n",
      "Epoch: 74, Loss: 0.3995400667190552, Validation Accuracy: 0.8718333333333333\n",
      "Epoch: 75, Loss: 0.38989123702049255, Validation Accuracy: 0.87375\n",
      "Epoch: 76, Loss: 0.38391801714897156, Validation Accuracy: 0.8751666666666666\n",
      "Epoch: 77, Loss: 0.3797285556793213, Validation Accuracy: 0.8773333333333333\n",
      "Epoch: 78, Loss: 0.376492440700531, Validation Accuracy: 0.87725\n",
      "Epoch: 79, Loss: 0.3738739490509033, Validation Accuracy: 0.87925\n",
      "Epoch: 80, Loss: 0.37148627638816833, Validation Accuracy: 0.87825\n",
      "Epoch: 81, Loss: 0.3692963719367981, Validation Accuracy: 0.8805\n",
      "Epoch: 82, Loss: 0.36723560094833374, Validation Accuracy: 0.8803333333333333\n",
      "Epoch: 83, Loss: 0.3652782440185547, Validation Accuracy: 0.882\n",
      "Epoch: 84, Loss: 0.3633834719657898, Validation Accuracy: 0.88225\n",
      "Epoch: 85, Loss: 0.36155685782432556, Validation Accuracy: 0.88325\n",
      "Epoch: 86, Loss: 0.3597653806209564, Validation Accuracy: 0.8829166666666667\n",
      "Epoch: 87, Loss: 0.3580358922481537, Validation Accuracy: 0.8841666666666667\n",
      "Epoch: 88, Loss: 0.35632550716400146, Validation Accuracy: 0.8834166666666666\n",
      "Epoch: 89, Loss: 0.3546587824821472, Validation Accuracy: 0.8849166666666667\n",
      "Epoch: 90, Loss: 0.35302552580833435, Validation Accuracy: 0.884\n",
      "Epoch: 91, Loss: 0.35143163800239563, Validation Accuracy: 0.8853333333333333\n",
      "Epoch: 92, Loss: 0.34987279772758484, Validation Accuracy: 0.88625\n",
      "Epoch: 93, Loss: 0.348347008228302, Validation Accuracy: 0.8864166666666666\n",
      "Epoch: 94, Loss: 0.34684520959854126, Validation Accuracy: 0.8871666666666667\n",
      "Epoch: 95, Loss: 0.3453748822212219, Validation Accuracy: 0.8873333333333333\n",
      "Epoch: 96, Loss: 0.34391841292381287, Validation Accuracy: 0.8878333333333334\n",
      "Epoch: 97, Loss: 0.34248578548431396, Validation Accuracy: 0.8883333333333333\n",
      "Epoch: 98, Loss: 0.34107890725135803, Validation Accuracy: 0.8885833333333333\n",
      "Epoch: 99, Loss: 0.33969181776046753, Validation Accuracy: 0.8888333333333334\n"
     ]
    }
   ],
   "source": [
    "net = FFNet()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "train_data = train_3(model=net, optimizer=optimizer, datasets=permuted_datasets, loss_fn=cross_entropy, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_array = np.array(train_data)\n",
    "accuracies = train_data_array[:, -1]\n",
    "\n",
    "with open('permuted_mnist.pkl', 'wb') as f:\n",
    "    pickle.dump(train_data_array, f)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(accuracies)\n",
    "ax.set_xlabel('Task')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy on the last epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0\n",
      "Epoch: 0, Loss: 2.7958271503448486, Validation Accuracy: 0.19691666666666666\n",
      "Epoch: 1, Loss: 2.2053611278533936, Validation Accuracy: 0.33375\n",
      "Epoch: 2, Loss: 1.9549970626831055, Validation Accuracy: 0.46608333333333335\n",
      "Epoch: 3, Loss: 1.7439106702804565, Validation Accuracy: 0.5525833333333333\n",
      "Epoch: 4, Loss: 1.5534323453903198, Validation Accuracy: 0.5995833333333334\n",
      "Epoch: 5, Loss: 1.393304467201233, Validation Accuracy: 0.6143333333333333\n",
      "Epoch: 6, Loss: 1.2919460535049438, Validation Accuracy: 0.5690833333333334\n",
      "Epoch: 7, Loss: 1.3508007526397705, Validation Accuracy: 0.49041666666666667\n",
      "Epoch: 8, Loss: 1.7055264711380005, Validation Accuracy: 0.48091666666666666\n",
      "Epoch: 9, Loss: 1.5560224056243896, Validation Accuracy: 0.6466666666666666\n",
      "Epoch: 10, Loss: 1.1590129137039185, Validation Accuracy: 0.7041666666666667\n",
      "Epoch: 11, Loss: 0.9932851791381836, Validation Accuracy: 0.7455\n",
      "Epoch: 12, Loss: 0.887205183506012, Validation Accuracy: 0.7415\n",
      "Epoch: 13, Loss: 0.8498361706733704, Validation Accuracy: 0.7216666666666667\n",
      "Epoch: 14, Loss: 0.8757472038269043, Validation Accuracy: 0.6815833333333333\n",
      "Epoch: 15, Loss: 0.9655330181121826, Validation Accuracy: 0.6466666666666666\n",
      "Epoch: 16, Loss: 1.0943145751953125, Validation Accuracy: 0.71025\n",
      "Epoch: 17, Loss: 0.9529584050178528, Validation Accuracy: 0.7685833333333333\n",
      "Epoch: 18, Loss: 0.7443558573722839, Validation Accuracy: 0.811\n",
      "Epoch: 19, Loss: 0.6611198782920837, Validation Accuracy: 0.81425\n",
      "Epoch: 20, Loss: 0.6230127215385437, Validation Accuracy: 0.8226666666666667\n",
      "Epoch: 21, Loss: 0.5971782207489014, Validation Accuracy: 0.82375\n",
      "Epoch: 22, Loss: 0.5780036449432373, Validation Accuracy: 0.8295833333333333\n",
      "Epoch: 23, Loss: 0.5650225281715393, Validation Accuracy: 0.8259166666666666\n",
      "Epoch: 24, Loss: 0.5601369738578796, Validation Accuracy: 0.81925\n",
      "Epoch: 25, Loss: 0.5797339081764221, Validation Accuracy: 0.79075\n",
      "Epoch: 26, Loss: 0.6269227862358093, Validation Accuracy: 0.7443333333333333\n",
      "Epoch: 27, Loss: 0.7998233437538147, Validation Accuracy: 0.73875\n",
      "Epoch: 28, Loss: 0.7397218346595764, Validation Accuracy: 0.756\n",
      "Epoch: 29, Loss: 0.7054459452629089, Validation Accuracy: 0.7988333333333333\n",
      "Epoch: 30, Loss: 0.5939483046531677, Validation Accuracy: 0.8276666666666667\n",
      "Epoch: 31, Loss: 0.5370885729789734, Validation Accuracy: 0.8424166666666667\n",
      "Epoch: 32, Loss: 0.5121631026268005, Validation Accuracy: 0.8423333333333334\n",
      "Epoch: 33, Loss: 0.4949093759059906, Validation Accuracy: 0.85275\n",
      "Epoch: 34, Loss: 0.4855109453201294, Validation Accuracy: 0.8455\n",
      "Epoch: 35, Loss: 0.4814150035381317, Validation Accuracy: 0.8525\n",
      "Epoch: 36, Loss: 0.4808313250541687, Validation Accuracy: 0.8370833333333333\n",
      "Epoch: 37, Loss: 0.48785513639450073, Validation Accuracy: 0.8446666666666667\n",
      "Epoch: 38, Loss: 0.4974084496498108, Validation Accuracy: 0.8248333333333333\n",
      "Epoch: 39, Loss: 0.5139753222465515, Validation Accuracy: 0.8340833333333333\n",
      "Epoch: 40, Loss: 0.528780460357666, Validation Accuracy: 0.817\n",
      "Epoch: 41, Loss: 0.5308876037597656, Validation Accuracy: 0.8370833333333333\n",
      "Epoch: 42, Loss: 0.5263652205467224, Validation Accuracy: 0.8360833333333333\n",
      "Epoch: 43, Loss: 0.4909301698207855, Validation Accuracy: 0.8591666666666666\n",
      "Epoch: 44, Loss: 0.4693068861961365, Validation Accuracy: 0.8596666666666667\n",
      "Epoch: 45, Loss: 0.4359050393104553, Validation Accuracy: 0.8749166666666667\n",
      "Epoch: 46, Loss: 0.42439690232276917, Validation Accuracy: 0.87075\n",
      "Epoch: 47, Loss: 0.408156156539917, Validation Accuracy: 0.87925\n",
      "Epoch: 48, Loss: 0.40336087346076965, Validation Accuracy: 0.8753333333333333\n",
      "Epoch: 49, Loss: 0.39495617151260376, Validation Accuracy: 0.8818333333333334\n",
      "Epoch: 50, Loss: 0.39253008365631104, Validation Accuracy: 0.8775\n",
      "Epoch: 51, Loss: 0.3874685764312744, Validation Accuracy: 0.8825833333333334\n",
      "Epoch: 52, Loss: 0.38662824034690857, Validation Accuracy: 0.87775\n",
      "Epoch: 53, Loss: 0.38358235359191895, Validation Accuracy: 0.8821666666666667\n",
      "Epoch: 54, Loss: 0.3841344118118286, Validation Accuracy: 0.8775833333333334\n",
      "Epoch: 55, Loss: 0.38262373208999634, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 56, Loss: 0.38410359621047974, Validation Accuracy: 0.87725\n",
      "Epoch: 57, Loss: 0.38328370451927185, Validation Accuracy: 0.8808333333333334\n",
      "Epoch: 58, Loss: 0.384505033493042, Validation Accuracy: 0.8775833333333334\n",
      "Epoch: 59, Loss: 0.38320696353912354, Validation Accuracy: 0.881\n",
      "Epoch: 60, Loss: 0.38194990158081055, Validation Accuracy: 0.87875\n",
      "Epoch: 61, Loss: 0.37846165895462036, Validation Accuracy: 0.8845\n",
      "Epoch: 62, Loss: 0.3737139403820038, Validation Accuracy: 0.8820833333333333\n",
      "Epoch: 63, Loss: 0.3678489923477173, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 64, Loss: 0.3608018755912781, Validation Accuracy: 0.8874166666666666\n",
      "Epoch: 65, Loss: 0.3543895184993744, Validation Accuracy: 0.8935833333333333\n",
      "Epoch: 66, Loss: 0.3475787341594696, Validation Accuracy: 0.89325\n",
      "Epoch: 67, Loss: 0.3421383500099182, Validation Accuracy: 0.8968333333333334\n",
      "Epoch: 68, Loss: 0.3367689847946167, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 69, Loss: 0.332501620054245, Validation Accuracy: 0.8991666666666667\n",
      "Epoch: 70, Loss: 0.32840532064437866, Validation Accuracy: 0.8998333333333334\n",
      "Epoch: 71, Loss: 0.32504987716674805, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 72, Loss: 0.3219027817249298, Validation Accuracy: 0.9014166666666666\n",
      "Epoch: 73, Loss: 0.31913626194000244, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 74, Loss: 0.3165472149848938, Validation Accuracy: 0.9026666666666666\n",
      "Epoch: 75, Loss: 0.3141825497150421, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 76, Loss: 0.31195905804634094, Validation Accuracy: 0.90375\n",
      "Epoch: 77, Loss: 0.3098880350589752, Validation Accuracy: 0.90575\n",
      "Epoch: 78, Loss: 0.3079361915588379, Validation Accuracy: 0.9044166666666666\n",
      "Epoch: 79, Loss: 0.3060988485813141, Validation Accuracy: 0.9069166666666667\n",
      "Epoch: 80, Loss: 0.30437153577804565, Validation Accuracy: 0.9053333333333333\n",
      "Epoch: 81, Loss: 0.30272263288497925, Validation Accuracy: 0.9075\n",
      "Epoch: 82, Loss: 0.3011834919452667, Validation Accuracy: 0.906\n",
      "Epoch: 83, Loss: 0.29968225955963135, Validation Accuracy: 0.9081666666666667\n",
      "Epoch: 84, Loss: 0.2983643114566803, Validation Accuracy: 0.90625\n",
      "Epoch: 85, Loss: 0.29703786969184875, Validation Accuracy: 0.9083333333333333\n",
      "Epoch: 86, Loss: 0.2959544360637665, Validation Accuracy: 0.9070833333333334\n",
      "Epoch: 87, Loss: 0.2948255240917206, Validation Accuracy: 0.9085\n",
      "Epoch: 88, Loss: 0.2941283881664276, Validation Accuracy: 0.9070833333333334\n",
      "Epoch: 89, Loss: 0.2932012975215912, Validation Accuracy: 0.90875\n",
      "Epoch: 90, Loss: 0.29300642013549805, Validation Accuracy: 0.9066666666666666\n",
      "Epoch: 91, Loss: 0.2923237383365631, Validation Accuracy: 0.9091666666666667\n",
      "Epoch: 92, Loss: 0.29289332032203674, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 93, Loss: 0.29253143072128296, Validation Accuracy: 0.9086666666666666\n",
      "Epoch: 94, Loss: 0.29438936710357666, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 95, Loss: 0.29431620240211487, Validation Accuracy: 0.9089166666666667\n",
      "Epoch: 96, Loss: 0.298096626996994, Validation Accuracy: 0.9025833333333333\n",
      "Epoch: 97, Loss: 0.29788607358932495, Validation Accuracy: 0.9070833333333334\n",
      "Epoch: 98, Loss: 0.3041636049747467, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 99, Loss: 0.3028806746006012, Validation Accuracy: 0.9050833333333334\n",
      "Dataset 1\n",
      "Epoch: 0, Loss: 2.861680269241333, Validation Accuracy: 0.21825\n",
      "Epoch: 1, Loss: 2.504837989807129, Validation Accuracy: 0.30466666666666664\n",
      "Epoch: 2, Loss: 2.0186920166015625, Validation Accuracy: 0.3680833333333333\n",
      "Epoch: 3, Loss: 1.8800756931304932, Validation Accuracy: 0.51075\n",
      "Epoch: 4, Loss: 1.5253385305404663, Validation Accuracy: 0.5820833333333333\n",
      "Epoch: 5, Loss: 1.3151345252990723, Validation Accuracy: 0.6321666666666667\n",
      "Epoch: 6, Loss: 1.168730616569519, Validation Accuracy: 0.6315833333333334\n",
      "Epoch: 7, Loss: 1.0925511121749878, Validation Accuracy: 0.6189166666666667\n",
      "Epoch: 8, Loss: 1.1493600606918335, Validation Accuracy: 0.54725\n",
      "Epoch: 9, Loss: 1.3041259050369263, Validation Accuracy: 0.6256666666666667\n",
      "Epoch: 10, Loss: 1.1592720746994019, Validation Accuracy: 0.7056666666666667\n",
      "Epoch: 11, Loss: 0.9187350273132324, Validation Accuracy: 0.7195\n",
      "Epoch: 12, Loss: 0.8551768660545349, Validation Accuracy: 0.708\n",
      "Epoch: 13, Loss: 0.886307954788208, Validation Accuracy: 0.6369166666666667\n",
      "Epoch: 14, Loss: 1.008962869644165, Validation Accuracy: 0.6419166666666667\n",
      "Epoch: 15, Loss: 1.0864582061767578, Validation Accuracy: 0.6940833333333334\n",
      "Epoch: 16, Loss: 0.8805840611457825, Validation Accuracy: 0.7968333333333333\n",
      "Epoch: 17, Loss: 0.6827873587608337, Validation Accuracy: 0.8134166666666667\n",
      "Epoch: 18, Loss: 0.613459050655365, Validation Accuracy: 0.8263333333333334\n",
      "Epoch: 19, Loss: 0.5804160833358765, Validation Accuracy: 0.8311666666666667\n",
      "Epoch: 20, Loss: 0.5566709637641907, Validation Accuracy: 0.8365833333333333\n",
      "Epoch: 21, Loss: 0.5379771590232849, Validation Accuracy: 0.8416666666666667\n",
      "Epoch: 22, Loss: 0.523475706577301, Validation Accuracy: 0.8413333333333334\n",
      "Epoch: 23, Loss: 0.5129292011260986, Validation Accuracy: 0.8398333333333333\n",
      "Epoch: 24, Loss: 0.5115509033203125, Validation Accuracy: 0.8270833333333333\n",
      "Epoch: 25, Loss: 0.5250051617622375, Validation Accuracy: 0.8016666666666666\n",
      "Epoch: 26, Loss: 0.5876578688621521, Validation Accuracy: 0.7755833333333333\n",
      "Epoch: 27, Loss: 0.6500369906425476, Validation Accuracy: 0.7634166666666666\n",
      "Epoch: 28, Loss: 0.7349748015403748, Validation Accuracy: 0.803\n",
      "Epoch: 29, Loss: 0.5779969692230225, Validation Accuracy: 0.82675\n",
      "Epoch: 30, Loss: 0.5311037302017212, Validation Accuracy: 0.8356666666666667\n",
      "Epoch: 31, Loss: 0.501463770866394, Validation Accuracy: 0.8454166666666667\n",
      "Epoch: 32, Loss: 0.4925019145011902, Validation Accuracy: 0.8436666666666667\n",
      "Epoch: 33, Loss: 0.4826836884021759, Validation Accuracy: 0.8453333333333334\n",
      "Epoch: 34, Loss: 0.49698296189308167, Validation Accuracy: 0.8348333333333333\n",
      "Epoch: 35, Loss: 0.5017107129096985, Validation Accuracy: 0.8340833333333333\n",
      "Epoch: 36, Loss: 0.5335078239440918, Validation Accuracy: 0.8229166666666666\n",
      "Epoch: 37, Loss: 0.5359544157981873, Validation Accuracy: 0.8344166666666667\n",
      "Epoch: 38, Loss: 0.539591372013092, Validation Accuracy: 0.8356666666666667\n",
      "Epoch: 39, Loss: 0.5014879703521729, Validation Accuracy: 0.86075\n",
      "Epoch: 40, Loss: 0.4665680229663849, Validation Accuracy: 0.864\n",
      "Epoch: 41, Loss: 0.4306829571723938, Validation Accuracy: 0.8783333333333333\n",
      "Epoch: 42, Loss: 0.41051721572875977, Validation Accuracy: 0.8783333333333333\n",
      "Epoch: 43, Loss: 0.39488476514816284, Validation Accuracy: 0.8848333333333334\n",
      "Epoch: 44, Loss: 0.3853423297405243, Validation Accuracy: 0.8859166666666667\n",
      "Epoch: 45, Loss: 0.3775061070919037, Validation Accuracy: 0.8881666666666667\n",
      "Epoch: 46, Loss: 0.37178105115890503, Validation Accuracy: 0.8898333333333334\n",
      "Epoch: 47, Loss: 0.3666353225708008, Validation Accuracy: 0.8906666666666667\n",
      "Epoch: 48, Loss: 0.3624977767467499, Validation Accuracy: 0.8911666666666667\n",
      "Epoch: 49, Loss: 0.35860204696655273, Validation Accuracy: 0.89225\n",
      "Epoch: 50, Loss: 0.3554106056690216, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 51, Loss: 0.3524560034275055, Validation Accuracy: 0.89425\n",
      "Epoch: 52, Loss: 0.35030683875083923, Validation Accuracy: 0.8926666666666667\n",
      "Epoch: 53, Loss: 0.3483504354953766, Validation Accuracy: 0.8948333333333334\n",
      "Epoch: 54, Loss: 0.34765133261680603, Validation Accuracy: 0.891\n",
      "Epoch: 55, Loss: 0.34734871983528137, Validation Accuracy: 0.89325\n",
      "Epoch: 56, Loss: 0.34929126501083374, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 57, Loss: 0.35191968083381653, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 58, Loss: 0.35917070508003235, Validation Accuracy: 0.8778333333333334\n",
      "Epoch: 59, Loss: 0.3671828508377075, Validation Accuracy: 0.8779166666666667\n",
      "Epoch: 60, Loss: 0.3836642801761627, Validation Accuracy: 0.8666666666666667\n",
      "Epoch: 61, Loss: 0.3964625597000122, Validation Accuracy: 0.8633333333333333\n",
      "Epoch: 62, Loss: 0.41735997796058655, Validation Accuracy: 0.86\n",
      "Epoch: 63, Loss: 0.41616716980934143, Validation Accuracy: 0.8675\n",
      "Epoch: 64, Loss: 0.4115566313266754, Validation Accuracy: 0.87525\n",
      "Epoch: 65, Loss: 0.3787115514278412, Validation Accuracy: 0.8905\n",
      "Epoch: 66, Loss: 0.35603776574134827, Validation Accuracy: 0.8945833333333333\n",
      "Epoch: 67, Loss: 0.3324944078922272, Validation Accuracy: 0.90325\n",
      "Epoch: 68, Loss: 0.3223305344581604, Validation Accuracy: 0.9030833333333333\n",
      "Epoch: 69, Loss: 0.31379032135009766, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 70, Loss: 0.3094223737716675, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 71, Loss: 0.30541229248046875, Validation Accuracy: 0.90775\n",
      "Epoch: 72, Loss: 0.3025578558444977, Validation Accuracy: 0.9076666666666666\n",
      "Epoch: 73, Loss: 0.2998519837856293, Validation Accuracy: 0.9090833333333334\n",
      "Epoch: 74, Loss: 0.297529935836792, Validation Accuracy: 0.9090833333333334\n",
      "Epoch: 75, Loss: 0.29530712962150574, Validation Accuracy: 0.9101666666666667\n",
      "Epoch: 76, Loss: 0.2932495176792145, Validation Accuracy: 0.91\n",
      "Epoch: 77, Loss: 0.2912728488445282, Validation Accuracy: 0.9115\n",
      "Epoch: 78, Loss: 0.28940123319625854, Validation Accuracy: 0.9115833333333333\n",
      "Epoch: 79, Loss: 0.28758686780929565, Validation Accuracy: 0.9120833333333334\n",
      "Epoch: 80, Loss: 0.2858685851097107, Validation Accuracy: 0.912\n",
      "Epoch: 81, Loss: 0.28420087695121765, Validation Accuracy: 0.91325\n",
      "Epoch: 82, Loss: 0.2825867831707001, Validation Accuracy: 0.9130833333333334\n",
      "Epoch: 83, Loss: 0.2810193598270416, Validation Accuracy: 0.9136666666666666\n",
      "Epoch: 84, Loss: 0.2795017659664154, Validation Accuracy: 0.9135833333333333\n",
      "Epoch: 85, Loss: 0.278023362159729, Validation Accuracy: 0.91425\n",
      "Epoch: 86, Loss: 0.27659791707992554, Validation Accuracy: 0.9139166666666667\n",
      "Epoch: 87, Loss: 0.27521198987960815, Validation Accuracy: 0.9149166666666667\n",
      "Epoch: 88, Loss: 0.273872971534729, Validation Accuracy: 0.9148333333333334\n",
      "Epoch: 89, Loss: 0.27255725860595703, Validation Accuracy: 0.91525\n",
      "Epoch: 90, Loss: 0.2713092565536499, Validation Accuracy: 0.9151666666666667\n",
      "Epoch: 91, Loss: 0.2700824439525604, Validation Accuracy: 0.9156666666666666\n",
      "Epoch: 92, Loss: 0.2689415216445923, Validation Accuracy: 0.9161666666666667\n",
      "Epoch: 93, Loss: 0.2678211033344269, Validation Accuracy: 0.9165\n",
      "Epoch: 94, Loss: 0.2668066918849945, Validation Accuracy: 0.91675\n",
      "Epoch: 95, Loss: 0.26580101251602173, Validation Accuracy: 0.9163333333333333\n",
      "Epoch: 96, Loss: 0.26497599482536316, Validation Accuracy: 0.9164166666666667\n",
      "Epoch: 97, Loss: 0.2641390860080719, Validation Accuracy: 0.9173333333333333\n",
      "Epoch: 98, Loss: 0.2635881006717682, Validation Accuracy: 0.9160833333333334\n",
      "Epoch: 99, Loss: 0.26301997900009155, Validation Accuracy: 0.9175833333333333\n",
      "Dataset 0\n",
      "Epoch: 0, Loss: 2.4987354278564453, Validation Accuracy: 0.23483333333333334\n",
      "Epoch: 1, Loss: 2.1768181324005127, Validation Accuracy: 0.33525\n",
      "Epoch: 2, Loss: 1.9982783794403076, Validation Accuracy: 0.39\n",
      "Epoch: 3, Loss: 1.8499341011047363, Validation Accuracy: 0.4559166666666667\n",
      "Epoch: 4, Loss: 1.710415005683899, Validation Accuracy: 0.49816666666666665\n",
      "Epoch: 5, Loss: 1.5868451595306396, Validation Accuracy: 0.5141666666666667\n",
      "Epoch: 6, Loss: 1.5354350805282593, Validation Accuracy: 0.43566666666666665\n",
      "Epoch: 7, Loss: 1.7011616230010986, Validation Accuracy: 0.35825\n",
      "Epoch: 8, Loss: 2.2378814220428467, Validation Accuracy: 0.5136666666666667\n",
      "Epoch: 9, Loss: 1.5447250604629517, Validation Accuracy: 0.5969166666666667\n",
      "Epoch: 10, Loss: 1.3065271377563477, Validation Accuracy: 0.6626666666666666\n",
      "Epoch: 11, Loss: 1.162841558456421, Validation Accuracy: 0.6751666666666667\n",
      "Epoch: 12, Loss: 1.0628548860549927, Validation Accuracy: 0.70175\n",
      "Epoch: 13, Loss: 0.9996527433395386, Validation Accuracy: 0.6913333333333334\n",
      "Epoch: 14, Loss: 0.9582545757293701, Validation Accuracy: 0.6845833333333333\n",
      "Epoch: 15, Loss: 0.9784203171730042, Validation Accuracy: 0.6514166666666666\n",
      "Epoch: 16, Loss: 1.0087954998016357, Validation Accuracy: 0.65225\n",
      "Epoch: 17, Loss: 1.064764380455017, Validation Accuracy: 0.682\n",
      "Epoch: 18, Loss: 0.9007551074028015, Validation Accuracy: 0.733\n",
      "Epoch: 19, Loss: 0.839241623878479, Validation Accuracy: 0.72925\n",
      "Epoch: 20, Loss: 0.7819415926933289, Validation Accuracy: 0.7313333333333333\n",
      "Epoch: 21, Loss: 0.8056156635284424, Validation Accuracy: 0.69875\n",
      "Epoch: 22, Loss: 0.8329280018806458, Validation Accuracy: 0.6770833333333334\n",
      "Epoch: 23, Loss: 0.927710771560669, Validation Accuracy: 0.6863333333333334\n",
      "Epoch: 24, Loss: 0.8844952583312988, Validation Accuracy: 0.7536666666666667\n",
      "Epoch: 25, Loss: 0.7476749420166016, Validation Accuracy: 0.7998333333333333\n",
      "Epoch: 26, Loss: 0.6433598399162292, Validation Accuracy: 0.81875\n",
      "Epoch: 27, Loss: 0.604661762714386, Validation Accuracy: 0.8191666666666667\n",
      "Epoch: 28, Loss: 0.5926555395126343, Validation Accuracy: 0.8041666666666667\n",
      "Epoch: 29, Loss: 0.6182892918586731, Validation Accuracy: 0.74525\n",
      "Epoch: 30, Loss: 0.7388495206832886, Validation Accuracy: 0.6595\n",
      "Epoch: 31, Loss: 1.064008355140686, Validation Accuracy: 0.6403333333333333\n",
      "Epoch: 32, Loss: 1.1581645011901855, Validation Accuracy: 0.7335833333333334\n",
      "Epoch: 33, Loss: 0.8202846050262451, Validation Accuracy: 0.82975\n",
      "Epoch: 34, Loss: 0.5867979526519775, Validation Accuracy: 0.84175\n",
      "Epoch: 35, Loss: 0.5383639931678772, Validation Accuracy: 0.8479166666666667\n",
      "Epoch: 36, Loss: 0.515753448009491, Validation Accuracy: 0.8505833333333334\n",
      "Epoch: 37, Loss: 0.4989905059337616, Validation Accuracy: 0.8555833333333334\n",
      "Epoch: 38, Loss: 0.48542097210884094, Validation Accuracy: 0.8565\n",
      "Epoch: 39, Loss: 0.474149614572525, Validation Accuracy: 0.8589166666666667\n",
      "Epoch: 40, Loss: 0.46483927965164185, Validation Accuracy: 0.86125\n",
      "Epoch: 41, Loss: 0.45733076333999634, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 42, Loss: 0.4519026577472687, Validation Accuracy: 0.8603333333333333\n",
      "Epoch: 43, Loss: 0.4493708908557892, Validation Accuracy: 0.8595833333333334\n",
      "Epoch: 44, Loss: 0.45139074325561523, Validation Accuracy: 0.8516666666666667\n",
      "Epoch: 45, Loss: 0.46124088764190674, Validation Accuracy: 0.8435\n",
      "Epoch: 46, Loss: 0.4847774803638458, Validation Accuracy: 0.8213333333333334\n",
      "Epoch: 47, Loss: 0.530059278011322, Validation Accuracy: 0.80475\n",
      "Epoch: 48, Loss: 0.6027411222457886, Validation Accuracy: 0.7713333333333333\n",
      "Epoch: 49, Loss: 0.673107922077179, Validation Accuracy: 0.7881666666666667\n",
      "Epoch: 50, Loss: 0.6595273613929749, Validation Accuracy: 0.8185\n",
      "Epoch: 51, Loss: 0.5302279591560364, Validation Accuracy: 0.85875\n",
      "Epoch: 52, Loss: 0.4513642489910126, Validation Accuracy: 0.8706666666666667\n",
      "Epoch: 53, Loss: 0.41092777252197266, Validation Accuracy: 0.8805833333333334\n",
      "Epoch: 54, Loss: 0.39827555418014526, Validation Accuracy: 0.877\n",
      "Epoch: 55, Loss: 0.3904305100440979, Validation Accuracy: 0.8836666666666667\n",
      "Epoch: 56, Loss: 0.3845997452735901, Validation Accuracy: 0.8795833333333334\n",
      "Epoch: 57, Loss: 0.3799467086791992, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 58, Loss: 0.375886470079422, Validation Accuracy: 0.8796666666666667\n",
      "Epoch: 59, Loss: 0.3727191984653473, Validation Accuracy: 0.8871666666666667\n",
      "Epoch: 60, Loss: 0.3699067234992981, Validation Accuracy: 0.8798333333333334\n",
      "Epoch: 61, Loss: 0.36821383237838745, Validation Accuracy: 0.888\n",
      "Epoch: 62, Loss: 0.3671286702156067, Validation Accuracy: 0.8790833333333333\n",
      "Epoch: 63, Loss: 0.3679271936416626, Validation Accuracy: 0.88625\n",
      "Epoch: 64, Loss: 0.3696860373020172, Validation Accuracy: 0.874\n",
      "Epoch: 65, Loss: 0.3751285672187805, Validation Accuracy: 0.8784166666666666\n",
      "Epoch: 66, Loss: 0.3818439543247223, Validation Accuracy: 0.8655\n",
      "Epoch: 67, Loss: 0.3952493965625763, Validation Accuracy: 0.86425\n",
      "Epoch: 68, Loss: 0.40819746255874634, Validation Accuracy: 0.8530833333333333\n",
      "Epoch: 69, Loss: 0.42671439051628113, Validation Accuracy: 0.8535\n",
      "Epoch: 70, Loss: 0.4335459768772125, Validation Accuracy: 0.8510833333333333\n",
      "Epoch: 71, Loss: 0.431802362203598, Validation Accuracy: 0.8645833333333334\n",
      "Epoch: 72, Loss: 0.408454954624176, Validation Accuracy: 0.8711666666666666\n",
      "Epoch: 73, Loss: 0.38207364082336426, Validation Accuracy: 0.8899166666666667\n",
      "Epoch: 74, Loss: 0.355868935585022, Validation Accuracy: 0.88725\n",
      "Epoch: 75, Loss: 0.3397619128227234, Validation Accuracy: 0.8981666666666667\n",
      "Epoch: 76, Loss: 0.3298882842063904, Validation Accuracy: 0.894\n",
      "Epoch: 77, Loss: 0.3241887092590332, Validation Accuracy: 0.8995\n",
      "Epoch: 78, Loss: 0.32020607590675354, Validation Accuracy: 0.8970833333333333\n",
      "Epoch: 79, Loss: 0.31712260842323303, Validation Accuracy: 0.9000833333333333\n",
      "Epoch: 80, Loss: 0.31450146436691284, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 81, Loss: 0.31213030219078064, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 82, Loss: 0.30992668867111206, Validation Accuracy: 0.9010833333333333\n",
      "Epoch: 83, Loss: 0.3078279495239258, Validation Accuracy: 0.9025\n",
      "Epoch: 84, Loss: 0.30582332611083984, Validation Accuracy: 0.9025\n",
      "Epoch: 85, Loss: 0.30388960242271423, Validation Accuracy: 0.90375\n",
      "Epoch: 86, Loss: 0.3020138740539551, Validation Accuracy: 0.9035833333333333\n",
      "Epoch: 87, Loss: 0.3001914322376251, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 88, Loss: 0.29841911792755127, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 89, Loss: 0.29669368267059326, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 90, Loss: 0.2950091063976288, Validation Accuracy: 0.90425\n",
      "Epoch: 91, Loss: 0.2933633327484131, Validation Accuracy: 0.9055\n",
      "Epoch: 92, Loss: 0.2917529046535492, Validation Accuracy: 0.9049166666666667\n",
      "Epoch: 93, Loss: 0.2901720702648163, Validation Accuracy: 0.9064166666666666\n",
      "Epoch: 94, Loss: 0.28862449526786804, Validation Accuracy: 0.9056666666666666\n",
      "Epoch: 95, Loss: 0.2871050536632538, Validation Accuracy: 0.90675\n",
      "Epoch: 96, Loss: 0.2856132686138153, Validation Accuracy: 0.9069166666666667\n",
      "Epoch: 97, Loss: 0.284149706363678, Validation Accuracy: 0.9075833333333333\n",
      "Epoch: 98, Loss: 0.2827092707157135, Validation Accuracy: 0.9076666666666666\n",
      "Epoch: 99, Loss: 0.2812955379486084, Validation Accuracy: 0.9083333333333333\n",
      "Dataset 1\n",
      "Epoch: 0, Loss: 3.650681257247925, Validation Accuracy: 0.14008333333333334\n",
      "Epoch: 1, Loss: 3.3691647052764893, Validation Accuracy: 0.22591666666666665\n",
      "Epoch: 2, Loss: 2.4196066856384277, Validation Accuracy: 0.28725\n",
      "Epoch: 3, Loss: 2.0559158325195312, Validation Accuracy: 0.4125\n",
      "Epoch: 4, Loss: 1.8132022619247437, Validation Accuracy: 0.4855833333333333\n",
      "Epoch: 5, Loss: 1.6356067657470703, Validation Accuracy: 0.5276666666666666\n",
      "Epoch: 6, Loss: 1.4912902116775513, Validation Accuracy: 0.5710833333333334\n",
      "Epoch: 7, Loss: 1.3601988554000854, Validation Accuracy: 0.6098333333333333\n",
      "Epoch: 8, Loss: 1.2412211894989014, Validation Accuracy: 0.6498333333333334\n",
      "Epoch: 9, Loss: 1.1371811628341675, Validation Accuracy: 0.67225\n",
      "Epoch: 10, Loss: 1.0498507022857666, Validation Accuracy: 0.69425\n",
      "Epoch: 11, Loss: 0.982781171798706, Validation Accuracy: 0.6935\n",
      "Epoch: 12, Loss: 0.9455072283744812, Validation Accuracy: 0.6886666666666666\n",
      "Epoch: 13, Loss: 0.9499260187149048, Validation Accuracy: 0.6514166666666666\n",
      "Epoch: 14, Loss: 1.0125592947006226, Validation Accuracy: 0.6256666666666667\n",
      "Epoch: 15, Loss: 1.1015079021453857, Validation Accuracy: 0.6913333333333334\n",
      "Epoch: 16, Loss: 0.913413405418396, Validation Accuracy: 0.7275833333333334\n",
      "Epoch: 17, Loss: 0.8152393102645874, Validation Accuracy: 0.7379166666666667\n",
      "Epoch: 18, Loss: 0.7969661355018616, Validation Accuracy: 0.7418333333333333\n",
      "Epoch: 19, Loss: 0.7555285692214966, Validation Accuracy: 0.7563333333333333\n",
      "Epoch: 20, Loss: 0.7457833886146545, Validation Accuracy: 0.7635833333333333\n",
      "Epoch: 21, Loss: 0.7023226618766785, Validation Accuracy: 0.7709166666666667\n",
      "Epoch: 22, Loss: 0.6866558194160461, Validation Accuracy: 0.7764166666666666\n",
      "Epoch: 23, Loss: 0.6597698330879211, Validation Accuracy: 0.7791666666666667\n",
      "Epoch: 24, Loss: 0.6443440914154053, Validation Accuracy: 0.7868333333333334\n",
      "Epoch: 25, Loss: 0.6247782111167908, Validation Accuracy: 0.7824166666666666\n",
      "Epoch: 26, Loss: 0.6243823766708374, Validation Accuracy: 0.7926666666666666\n",
      "Epoch: 27, Loss: 0.6050957441329956, Validation Accuracy: 0.7823333333333333\n",
      "Epoch: 28, Loss: 0.6207645535469055, Validation Accuracy: 0.79825\n",
      "Epoch: 29, Loss: 0.6002258062362671, Validation Accuracy: 0.7959166666666667\n",
      "Epoch: 30, Loss: 0.5898845791816711, Validation Accuracy: 0.8165833333333333\n",
      "Epoch: 31, Loss: 0.5653252005577087, Validation Accuracy: 0.8224166666666667\n",
      "Epoch: 32, Loss: 0.5342568159103394, Validation Accuracy: 0.837\n",
      "Epoch: 33, Loss: 0.5153768062591553, Validation Accuracy: 0.8378333333333333\n",
      "Epoch: 34, Loss: 0.49544084072113037, Validation Accuracy: 0.8455\n",
      "Epoch: 35, Loss: 0.4841562509536743, Validation Accuracy: 0.8445833333333334\n",
      "Epoch: 36, Loss: 0.4742857813835144, Validation Accuracy: 0.851\n",
      "Epoch: 37, Loss: 0.46797850728034973, Validation Accuracy: 0.8460833333333333\n",
      "Epoch: 38, Loss: 0.46403512358665466, Validation Accuracy: 0.8515\n",
      "Epoch: 39, Loss: 0.46086886525154114, Validation Accuracy: 0.8465\n",
      "Epoch: 40, Loss: 0.460894376039505, Validation Accuracy: 0.8511666666666666\n",
      "Epoch: 41, Loss: 0.45825207233428955, Validation Accuracy: 0.8464166666666667\n",
      "Epoch: 42, Loss: 0.459343820810318, Validation Accuracy: 0.851\n",
      "Epoch: 43, Loss: 0.4540347754955292, Validation Accuracy: 0.8495833333333334\n",
      "Epoch: 44, Loss: 0.4519708752632141, Validation Accuracy: 0.8551666666666666\n",
      "Epoch: 45, Loss: 0.44225892424583435, Validation Accuracy: 0.8545\n",
      "Epoch: 46, Loss: 0.4353139102458954, Validation Accuracy: 0.8625\n",
      "Epoch: 47, Loss: 0.42316898703575134, Validation Accuracy: 0.8638333333333333\n",
      "Epoch: 48, Loss: 0.413962721824646, Validation Accuracy: 0.8700833333333333\n",
      "Epoch: 49, Loss: 0.40343770384788513, Validation Accuracy: 0.871\n",
      "Epoch: 50, Loss: 0.3952071964740753, Validation Accuracy: 0.8750833333333333\n",
      "Epoch: 51, Loss: 0.3876660466194153, Validation Accuracy: 0.87625\n",
      "Epoch: 52, Loss: 0.381264328956604, Validation Accuracy: 0.8793333333333333\n",
      "Epoch: 53, Loss: 0.3758871257305145, Validation Accuracy: 0.87975\n",
      "Epoch: 54, Loss: 0.3709464371204376, Validation Accuracy: 0.88275\n",
      "Epoch: 55, Loss: 0.36704859137535095, Validation Accuracy: 0.8821666666666667\n",
      "Epoch: 56, Loss: 0.3632490336894989, Validation Accuracy: 0.8850833333333333\n",
      "Epoch: 57, Loss: 0.36030134558677673, Validation Accuracy: 0.88375\n",
      "Epoch: 58, Loss: 0.3574255108833313, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 59, Loss: 0.355099081993103, Validation Accuracy: 0.885\n",
      "Epoch: 60, Loss: 0.35307425260543823, Validation Accuracy: 0.88675\n",
      "Epoch: 61, Loss: 0.3512102961540222, Validation Accuracy: 0.8860833333333333\n",
      "Epoch: 62, Loss: 0.349935382604599, Validation Accuracy: 0.8863333333333333\n",
      "Epoch: 63, Loss: 0.34845319390296936, Validation Accuracy: 0.8869166666666667\n",
      "Epoch: 64, Loss: 0.3477623164653778, Validation Accuracy: 0.886\n",
      "Epoch: 65, Loss: 0.34627869725227356, Validation Accuracy: 0.8873333333333333\n",
      "Epoch: 66, Loss: 0.34574854373931885, Validation Accuracy: 0.8855\n",
      "Epoch: 67, Loss: 0.3437190353870392, Validation Accuracy: 0.8883333333333333\n",
      "Epoch: 68, Loss: 0.3427214026451111, Validation Accuracy: 0.8861666666666667\n",
      "Epoch: 69, Loss: 0.33961769938468933, Validation Accuracy: 0.8901666666666667\n",
      "Epoch: 70, Loss: 0.3377283215522766, Validation Accuracy: 0.889\n",
      "Epoch: 71, Loss: 0.3336896300315857, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 72, Loss: 0.330853134393692, Validation Accuracy: 0.8915\n",
      "Epoch: 73, Loss: 0.32641521096229553, Validation Accuracy: 0.8969166666666667\n",
      "Epoch: 74, Loss: 0.3231470286846161, Validation Accuracy: 0.895\n",
      "Epoch: 75, Loss: 0.318989634513855, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 76, Loss: 0.315651535987854, Validation Accuracy: 0.89725\n",
      "Epoch: 77, Loss: 0.31218719482421875, Validation Accuracy: 0.90175\n",
      "Epoch: 78, Loss: 0.30914416909217834, Validation Accuracy: 0.8995833333333333\n",
      "Epoch: 79, Loss: 0.3064076602458954, Validation Accuracy: 0.90275\n",
      "Epoch: 80, Loss: 0.3037034571170807, Validation Accuracy: 0.901\n",
      "Epoch: 81, Loss: 0.30149760842323303, Validation Accuracy: 0.904\n",
      "Epoch: 82, Loss: 0.2990230619907379, Validation Accuracy: 0.9024166666666666\n",
      "Epoch: 83, Loss: 0.2972366511821747, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 84, Loss: 0.29503583908081055, Validation Accuracy: 0.9035\n",
      "Epoch: 85, Loss: 0.2936069369316101, Validation Accuracy: 0.90625\n",
      "Epoch: 86, Loss: 0.2916419804096222, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 87, Loss: 0.2905810475349426, Validation Accuracy: 0.90725\n",
      "Epoch: 88, Loss: 0.2888501286506653, Validation Accuracy: 0.9038333333333334\n",
      "Epoch: 89, Loss: 0.28820767998695374, Validation Accuracy: 0.9075\n",
      "Epoch: 90, Loss: 0.28671494126319885, Validation Accuracy: 0.9043333333333333\n",
      "Epoch: 91, Loss: 0.2865687310695648, Validation Accuracy: 0.9075\n",
      "Epoch: 92, Loss: 0.2853080630302429, Validation Accuracy: 0.9046666666666666\n",
      "Epoch: 93, Loss: 0.2857859432697296, Validation Accuracy: 0.9076666666666666\n",
      "Epoch: 94, Loss: 0.28483349084854126, Validation Accuracy: 0.9048333333333334\n",
      "Epoch: 95, Loss: 0.28612253069877625, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 96, Loss: 0.28561219573020935, Validation Accuracy: 0.9045\n",
      "Epoch: 97, Loss: 0.28780001401901245, Validation Accuracy: 0.9058333333333334\n",
      "Epoch: 98, Loss: 0.2877753973007202, Validation Accuracy: 0.903\n",
      "Epoch: 99, Loss: 0.29082241654396057, Validation Accuracy: 0.9046666666666666\n",
      "Dataset 0\n",
      "Epoch: 0, Loss: 2.8970224857330322, Validation Accuracy: 0.16041666666666668\n",
      "Epoch: 1, Loss: 2.2965266704559326, Validation Accuracy: 0.24858333333333332\n",
      "Epoch: 2, Loss: 2.1270744800567627, Validation Accuracy: 0.3299166666666667\n",
      "Epoch: 3, Loss: 1.9921727180480957, Validation Accuracy: 0.39416666666666667\n",
      "Epoch: 4, Loss: 1.8616795539855957, Validation Accuracy: 0.463\n",
      "Epoch: 5, Loss: 1.7284903526306152, Validation Accuracy: 0.5270833333333333\n",
      "Epoch: 6, Loss: 1.5893393754959106, Validation Accuracy: 0.5835833333333333\n",
      "Epoch: 7, Loss: 1.4493581056594849, Validation Accuracy: 0.62475\n",
      "Epoch: 8, Loss: 1.3184363842010498, Validation Accuracy: 0.6615\n",
      "Epoch: 9, Loss: 1.2025024890899658, Validation Accuracy: 0.6930833333333334\n",
      "Epoch: 10, Loss: 1.1031924486160278, Validation Accuracy: 0.7173333333333334\n",
      "Epoch: 11, Loss: 1.020519495010376, Validation Accuracy: 0.7301666666666666\n",
      "Epoch: 12, Loss: 0.9614089131355286, Validation Accuracy: 0.6938333333333333\n",
      "Epoch: 13, Loss: 1.0036771297454834, Validation Accuracy: 0.5566666666666666\n",
      "Epoch: 14, Loss: 1.6750903129577637, Validation Accuracy: 0.38958333333333334\n",
      "Epoch: 15, Loss: 2.185211181640625, Validation Accuracy: 0.45575\n",
      "Epoch: 16, Loss: 1.8917094469070435, Validation Accuracy: 0.583\n",
      "Epoch: 17, Loss: 1.2827327251434326, Validation Accuracy: 0.6895\n",
      "Epoch: 18, Loss: 1.0379691123962402, Validation Accuracy: 0.7494166666666666\n",
      "Epoch: 19, Loss: 0.8992545008659363, Validation Accuracy: 0.783\n",
      "Epoch: 20, Loss: 0.8099618554115295, Validation Accuracy: 0.7943333333333333\n",
      "Epoch: 21, Loss: 0.7514026761054993, Validation Accuracy: 0.8054166666666667\n",
      "Epoch: 22, Loss: 0.7081794142723083, Validation Accuracy: 0.8106666666666666\n",
      "Epoch: 23, Loss: 0.6740126609802246, Validation Accuracy: 0.8176666666666667\n",
      "Epoch: 24, Loss: 0.6463297605514526, Validation Accuracy: 0.8190833333333334\n",
      "Epoch: 25, Loss: 0.6245467662811279, Validation Accuracy: 0.8234166666666667\n",
      "Epoch: 26, Loss: 0.6100792288780212, Validation Accuracy: 0.8119166666666666\n",
      "Epoch: 27, Loss: 0.6137142777442932, Validation Accuracy: 0.79125\n",
      "Epoch: 28, Loss: 0.656134307384491, Validation Accuracy: 0.7499166666666667\n",
      "Epoch: 29, Loss: 0.8326200246810913, Validation Accuracy: 0.7043333333333334\n",
      "Epoch: 30, Loss: 0.9301736950874329, Validation Accuracy: 0.7044166666666667\n",
      "Epoch: 31, Loss: 0.8494418263435364, Validation Accuracy: 0.6860833333333334\n",
      "Epoch: 32, Loss: 0.9340512156486511, Validation Accuracy: 0.7630833333333333\n",
      "Epoch: 33, Loss: 0.7454725503921509, Validation Accuracy: 0.7433333333333333\n",
      "Epoch: 34, Loss: 0.7408104538917542, Validation Accuracy: 0.7915833333333333\n",
      "Epoch: 35, Loss: 0.6598660349845886, Validation Accuracy: 0.7886666666666666\n",
      "Epoch: 36, Loss: 0.6427215337753296, Validation Accuracy: 0.8274166666666667\n",
      "Epoch: 37, Loss: 0.5701082944869995, Validation Accuracy: 0.8275\n",
      "Epoch: 38, Loss: 0.548927903175354, Validation Accuracy: 0.84775\n",
      "Epoch: 39, Loss: 0.520871102809906, Validation Accuracy: 0.84275\n",
      "Epoch: 40, Loss: 0.5121567249298096, Validation Accuracy: 0.8523333333333334\n",
      "Epoch: 41, Loss: 0.497022420167923, Validation Accuracy: 0.8476666666666667\n",
      "Epoch: 42, Loss: 0.4941354990005493, Validation Accuracy: 0.8546666666666667\n",
      "Epoch: 43, Loss: 0.48517683148384094, Validation Accuracy: 0.84725\n",
      "Epoch: 44, Loss: 0.4873432219028473, Validation Accuracy: 0.8545833333333334\n",
      "Epoch: 45, Loss: 0.48201867938041687, Validation Accuracy: 0.8440833333333333\n",
      "Epoch: 46, Loss: 0.48906001448631287, Validation Accuracy: 0.85225\n",
      "Epoch: 47, Loss: 0.4843997061252594, Validation Accuracy: 0.8395\n",
      "Epoch: 48, Loss: 0.4937416911125183, Validation Accuracy: 0.8496666666666667\n",
      "Epoch: 49, Loss: 0.4856104254722595, Validation Accuracy: 0.83975\n",
      "Epoch: 50, Loss: 0.4925802946090698, Validation Accuracy: 0.8526666666666667\n",
      "Epoch: 51, Loss: 0.47892290353775024, Validation Accuracy: 0.8444166666666667\n",
      "Epoch: 52, Loss: 0.4807088077068329, Validation Accuracy: 0.8570833333333333\n",
      "Epoch: 53, Loss: 0.46460476517677307, Validation Accuracy: 0.8535\n",
      "Epoch: 54, Loss: 0.46262186765670776, Validation Accuracy: 0.8623333333333333\n",
      "Epoch: 55, Loss: 0.44698870182037354, Validation Accuracy: 0.8600833333333333\n",
      "Epoch: 56, Loss: 0.44265469908714294, Validation Accuracy: 0.8675\n",
      "Epoch: 57, Loss: 0.4287593960762024, Validation Accuracy: 0.8676666666666667\n",
      "Epoch: 58, Loss: 0.423251211643219, Validation Accuracy: 0.8735\n",
      "Epoch: 59, Loss: 0.4118017852306366, Validation Accuracy: 0.8728333333333333\n",
      "Epoch: 60, Loss: 0.40626269578933716, Validation Accuracy: 0.87725\n",
      "Epoch: 61, Loss: 0.3974132537841797, Validation Accuracy: 0.8785\n",
      "Epoch: 62, Loss: 0.3924548625946045, Validation Accuracy: 0.88225\n",
      "Epoch: 63, Loss: 0.3857717216014862, Validation Accuracy: 0.883\n",
      "Epoch: 64, Loss: 0.38168203830718994, Validation Accuracy: 0.88525\n",
      "Epoch: 65, Loss: 0.3766564130783081, Validation Accuracy: 0.885\n",
      "Epoch: 66, Loss: 0.3733982443809509, Validation Accuracy: 0.888\n",
      "Epoch: 67, Loss: 0.3694493770599365, Validation Accuracy: 0.8874166666666666\n",
      "Epoch: 68, Loss: 0.3668317198753357, Validation Accuracy: 0.8893333333333333\n",
      "Epoch: 69, Loss: 0.36372360587120056, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 70, Loss: 0.3616524934768677, Validation Accuracy: 0.8905833333333333\n",
      "Epoch: 71, Loss: 0.3592047393321991, Validation Accuracy: 0.8891666666666667\n",
      "Epoch: 72, Loss: 0.3577192425727844, Validation Accuracy: 0.89175\n",
      "Epoch: 73, Loss: 0.35579898953437805, Validation Accuracy: 0.88975\n",
      "Epoch: 74, Loss: 0.3548041880130768, Validation Accuracy: 0.8930833333333333\n",
      "Epoch: 75, Loss: 0.3533843457698822, Validation Accuracy: 0.8903333333333333\n",
      "Epoch: 76, Loss: 0.3529885709285736, Validation Accuracy: 0.8929166666666667\n",
      "Epoch: 77, Loss: 0.3518954813480377, Validation Accuracy: 0.89025\n",
      "Epoch: 78, Loss: 0.35199376940727234, Validation Accuracy: 0.8924166666666666\n",
      "Epoch: 79, Loss: 0.3510207533836365, Validation Accuracy: 0.8904166666666666\n",
      "Epoch: 80, Loss: 0.35147249698638916, Validation Accuracy: 0.8928333333333334\n",
      "Epoch: 81, Loss: 0.35033273696899414, Validation Accuracy: 0.8904166666666666\n",
      "Epoch: 82, Loss: 0.35056889057159424, Validation Accuracy: 0.8931666666666667\n",
      "Epoch: 83, Loss: 0.3487783968448639, Validation Accuracy: 0.8915833333333333\n",
      "Epoch: 84, Loss: 0.3484728932380676, Validation Accuracy: 0.8938333333333334\n",
      "Epoch: 85, Loss: 0.3458492159843445, Validation Accuracy: 0.8925833333333333\n",
      "Epoch: 86, Loss: 0.3445807695388794, Validation Accuracy: 0.896\n",
      "Epoch: 87, Loss: 0.34107497334480286, Validation Accuracy: 0.8955\n",
      "Epoch: 88, Loss: 0.338827908039093, Validation Accuracy: 0.8983333333333333\n",
      "Epoch: 89, Loss: 0.3347774147987366, Validation Accuracy: 0.89725\n",
      "Epoch: 90, Loss: 0.33187100291252136, Validation Accuracy: 0.90075\n",
      "Epoch: 91, Loss: 0.32780012488365173, Validation Accuracy: 0.9\n",
      "Epoch: 92, Loss: 0.3246920108795166, Validation Accuracy: 0.9025\n",
      "Epoch: 93, Loss: 0.3209061324596405, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 94, Loss: 0.31796228885650635, Validation Accuracy: 0.9040833333333333\n",
      "Epoch: 95, Loss: 0.31470787525177, Validation Accuracy: 0.9035\n",
      "Epoch: 96, Loss: 0.3120466470718384, Validation Accuracy: 0.9065833333333333\n",
      "Epoch: 97, Loss: 0.30928948521614075, Validation Accuracy: 0.9051666666666667\n",
      "Epoch: 98, Loss: 0.30697283148765564, Validation Accuracy: 0.9085\n",
      "Epoch: 99, Loss: 0.30460843443870544, Validation Accuracy: 0.9069166666666667\n",
      "Dataset 1\n",
      "Epoch: 0, Loss: 2.5817911624908447, Validation Accuracy: 0.3060833333333333\n",
      "Epoch: 1, Loss: 2.098649501800537, Validation Accuracy: 0.3279166666666667\n",
      "Epoch: 2, Loss: 2.1598927974700928, Validation Accuracy: 0.34441666666666665\n",
      "Epoch: 3, Loss: 1.846933126449585, Validation Accuracy: 0.3388333333333333\n",
      "Epoch: 4, Loss: 1.8769785165786743, Validation Accuracy: 0.558\n",
      "Epoch: 5, Loss: 1.3835570812225342, Validation Accuracy: 0.67575\n",
      "Epoch: 6, Loss: 1.1096079349517822, Validation Accuracy: 0.7060833333333333\n",
      "Epoch: 7, Loss: 0.9733582139015198, Validation Accuracy: 0.7275833333333334\n",
      "Epoch: 8, Loss: 0.8863598108291626, Validation Accuracy: 0.7385833333333334\n",
      "Epoch: 9, Loss: 0.8282842040061951, Validation Accuracy: 0.733\n",
      "Epoch: 10, Loss: 0.8077030181884766, Validation Accuracy: 0.7166666666666667\n",
      "Epoch: 11, Loss: 0.8474810123443604, Validation Accuracy: 0.638\n",
      "Epoch: 12, Loss: 1.025368094444275, Validation Accuracy: 0.6051666666666666\n",
      "Epoch: 13, Loss: 1.1884697675704956, Validation Accuracy: 0.6173333333333333\n",
      "Epoch: 14, Loss: 1.0913746356964111, Validation Accuracy: 0.7566666666666667\n",
      "Epoch: 15, Loss: 0.7478687167167664, Validation Accuracy: 0.792\n",
      "Epoch: 16, Loss: 0.6558006405830383, Validation Accuracy: 0.8105\n",
      "Epoch: 17, Loss: 0.6127912402153015, Validation Accuracy: 0.8140833333333334\n",
      "Epoch: 18, Loss: 0.5857347846031189, Validation Accuracy: 0.8236666666666667\n",
      "Epoch: 19, Loss: 0.5658915042877197, Validation Accuracy: 0.8214166666666667\n",
      "Epoch: 20, Loss: 0.5533013343811035, Validation Accuracy: 0.8280833333333333\n",
      "Epoch: 21, Loss: 0.5453956127166748, Validation Accuracy: 0.8160833333333334\n",
      "Epoch: 22, Loss: 0.5500360131263733, Validation Accuracy: 0.81725\n",
      "Epoch: 23, Loss: 0.5582728385925293, Validation Accuracy: 0.7928333333333333\n",
      "Epoch: 24, Loss: 0.5984233021736145, Validation Accuracy: 0.7879166666666667\n",
      "Epoch: 25, Loss: 0.6132045984268188, Validation Accuracy: 0.7639166666666667\n",
      "Epoch: 26, Loss: 0.6685243248939514, Validation Accuracy: 0.7849166666666667\n",
      "Epoch: 27, Loss: 0.6167140603065491, Validation Accuracy: 0.79025\n",
      "Epoch: 28, Loss: 0.5971653461456299, Validation Accuracy: 0.8270833333333333\n",
      "Epoch: 29, Loss: 0.525876522064209, Validation Accuracy: 0.8329166666666666\n",
      "Epoch: 30, Loss: 0.4976353049278259, Validation Accuracy: 0.85225\n",
      "Epoch: 31, Loss: 0.47019699215888977, Validation Accuracy: 0.85125\n",
      "Epoch: 32, Loss: 0.45557844638824463, Validation Accuracy: 0.8625833333333334\n",
      "Epoch: 33, Loss: 0.44420185685157776, Validation Accuracy: 0.858\n",
      "Epoch: 34, Loss: 0.43601691722869873, Validation Accuracy: 0.86625\n",
      "Epoch: 35, Loss: 0.42958611249923706, Validation Accuracy: 0.8628333333333333\n",
      "Epoch: 36, Loss: 0.42568302154541016, Validation Accuracy: 0.8678333333333333\n",
      "Epoch: 37, Loss: 0.4219605326652527, Validation Accuracy: 0.8653333333333333\n",
      "Epoch: 38, Loss: 0.422875314950943, Validation Accuracy: 0.8665\n",
      "Epoch: 39, Loss: 0.421109139919281, Validation Accuracy: 0.8615833333333334\n",
      "Epoch: 40, Loss: 0.4287213087081909, Validation Accuracy: 0.8636666666666667\n",
      "Epoch: 41, Loss: 0.4263662099838257, Validation Accuracy: 0.8575833333333334\n",
      "Epoch: 42, Loss: 0.4405560791492462, Validation Accuracy: 0.8605833333333334\n",
      "Epoch: 43, Loss: 0.4311542510986328, Validation Accuracy: 0.8559166666666667\n",
      "Epoch: 44, Loss: 0.44514086842536926, Validation Accuracy: 0.8635\n",
      "Epoch: 45, Loss: 0.4229866564273834, Validation Accuracy: 0.8625833333333334\n",
      "Epoch: 46, Loss: 0.4263635277748108, Validation Accuracy: 0.8725\n",
      "Epoch: 47, Loss: 0.40060436725616455, Validation Accuracy: 0.87325\n",
      "Epoch: 48, Loss: 0.39483964443206787, Validation Accuracy: 0.8815\n",
      "Epoch: 49, Loss: 0.3763134777545929, Validation Accuracy: 0.8828333333333334\n",
      "Epoch: 50, Loss: 0.369258314371109, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 51, Loss: 0.3588610887527466, Validation Accuracy: 0.8888333333333334\n",
      "Epoch: 52, Loss: 0.35359811782836914, Validation Accuracy: 0.893\n",
      "Epoch: 53, Loss: 0.34766125679016113, Validation Accuracy: 0.8925833333333333\n",
      "Epoch: 54, Loss: 0.3437623381614685, Validation Accuracy: 0.8949166666666667\n",
      "Epoch: 55, Loss: 0.339781790971756, Validation Accuracy: 0.8946666666666667\n",
      "Epoch: 56, Loss: 0.3366526961326599, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 57, Loss: 0.3335719704627991, Validation Accuracy: 0.8965833333333333\n",
      "Epoch: 58, Loss: 0.3308950662612915, Validation Accuracy: 0.8980833333333333\n",
      "Epoch: 59, Loss: 0.3282610774040222, Validation Accuracy: 0.8979166666666667\n",
      "Epoch: 60, Loss: 0.325850248336792, Validation Accuracy: 0.89925\n",
      "Epoch: 61, Loss: 0.3234959840774536, Validation Accuracy: 0.8994166666666666\n",
      "Epoch: 62, Loss: 0.3212762176990509, Validation Accuracy: 0.9011666666666667\n",
      "Epoch: 63, Loss: 0.3191124498844147, Validation Accuracy: 0.9004166666666666\n",
      "Epoch: 64, Loss: 0.3170422315597534, Validation Accuracy: 0.90225\n",
      "Epoch: 65, Loss: 0.3150079846382141, Validation Accuracy: 0.9018333333333334\n",
      "Epoch: 66, Loss: 0.3130559027194977, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 67, Loss: 0.31113705039024353, Validation Accuracy: 0.9029166666666667\n",
      "Epoch: 68, Loss: 0.3092880845069885, Validation Accuracy: 0.9041666666666667\n",
      "Epoch: 69, Loss: 0.30748143792152405, Validation Accuracy: 0.9036666666666666\n",
      "Epoch: 70, Loss: 0.30572396516799927, Validation Accuracy: 0.9048333333333334\n",
      "Epoch: 71, Loss: 0.3040049970149994, Validation Accuracy: 0.905\n",
      "Epoch: 72, Loss: 0.30233603715896606, Validation Accuracy: 0.9055\n",
      "Epoch: 73, Loss: 0.3007167875766754, Validation Accuracy: 0.9063333333333333\n",
      "Epoch: 74, Loss: 0.29912930727005005, Validation Accuracy: 0.9066666666666666\n",
      "Epoch: 75, Loss: 0.29756635427474976, Validation Accuracy: 0.9074166666666666\n",
      "Epoch: 76, Loss: 0.29604560136795044, Validation Accuracy: 0.9078333333333334\n",
      "Epoch: 77, Loss: 0.29455992579460144, Validation Accuracy: 0.9076666666666666\n",
      "Epoch: 78, Loss: 0.2931029200553894, Validation Accuracy: 0.9085\n",
      "Epoch: 79, Loss: 0.29170262813568115, Validation Accuracy: 0.90875\n",
      "Epoch: 80, Loss: 0.2903271019458771, Validation Accuracy: 0.9089166666666667\n",
      "Epoch: 81, Loss: 0.28898975253105164, Validation Accuracy: 0.909\n",
      "Epoch: 82, Loss: 0.2877041697502136, Validation Accuracy: 0.9099166666666667\n",
      "Epoch: 83, Loss: 0.28644973039627075, Validation Accuracy: 0.9088333333333334\n",
      "Epoch: 84, Loss: 0.2852301001548767, Validation Accuracy: 0.9105\n",
      "Epoch: 85, Loss: 0.28406578302383423, Validation Accuracy: 0.9091666666666667\n",
      "Epoch: 86, Loss: 0.282929390668869, Validation Accuracy: 0.9114166666666667\n",
      "Epoch: 87, Loss: 0.28190097212791443, Validation Accuracy: 0.9093333333333333\n",
      "Epoch: 88, Loss: 0.2808660566806793, Validation Accuracy: 0.9119166666666667\n",
      "Epoch: 89, Loss: 0.27994900941848755, Validation Accuracy: 0.9098333333333334\n",
      "Epoch: 90, Loss: 0.27903926372528076, Validation Accuracy: 0.9124166666666667\n",
      "Epoch: 91, Loss: 0.2782435417175293, Validation Accuracy: 0.90975\n",
      "Epoch: 92, Loss: 0.27743491530418396, Validation Accuracy: 0.9128333333333334\n",
      "Epoch: 93, Loss: 0.27678173780441284, Validation Accuracy: 0.9101666666666667\n",
      "Epoch: 94, Loss: 0.27612200379371643, Validation Accuracy: 0.9131666666666667\n",
      "Epoch: 95, Loss: 0.2755511403083801, Validation Accuracy: 0.9098333333333334\n",
      "Epoch: 96, Loss: 0.2749948799610138, Validation Accuracy: 0.9140833333333334\n",
      "Epoch: 97, Loss: 0.2745518386363983, Validation Accuracy: 0.9096666666666666\n",
      "Epoch: 98, Loss: 0.2741241753101349, Validation Accuracy: 0.9146666666666666\n",
      "Epoch: 99, Loss: 0.27380886673927307, Validation Accuracy: 0.909\n"
     ]
    }
   ],
   "source": [
    "runs = 3 \n",
    "# array =  np.empty(len(permuted_datasets))\n",
    "list = []\n",
    "for i in range(runs):\n",
    "  net = FFNet()\n",
    "  optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "  train_data = train_3(model=net, optimizer=optimizer, datasets=permuted_datasets, loss_fn=cross_entropy, epochs=100)\n",
    "  list.append(train_data)\n",
    "  \n",
    "npa = np.asarray(list, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90508336, 0.91758335],\n",
       "       [0.90833336, 0.90466666],\n",
       "       [0.9069167 , 0.909     ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npa = np.array(npa)\n",
    "accuracies = npa[:, :, -1]\n",
    "accuracies = np.array(accuracies)\n",
    "# rows iterations, columns tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
